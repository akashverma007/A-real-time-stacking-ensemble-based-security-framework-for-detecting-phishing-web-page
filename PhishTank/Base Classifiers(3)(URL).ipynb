{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"PH13wfswmyDv"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30041,"status":"ok","timestamp":1656477844449,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"Aiz0olfdKb4b","outputId":"6be0ef5f-6fb5-4395-bf9c-11e667c2e569"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":557},"executionInfo":{"elapsed":3660,"status":"ok","timestamp":1656477848102,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"Dw-EEymHAGNs","outputId":"243f1bc0-6e90-46ca-ce91-c5f02775043f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Unnamed: 0                                       Domain  Have IP  \\\n","0               0                             graphicriver.net        0   \n","1               1                                    ecnavi.jp        0   \n","2               2                                 hubpages.com        0   \n","3               3                              extratorrent.cc        0   \n","4               4                                icicibank.com        0   \n","...           ...                                          ...      ...   \n","10332       11932                             sites.google.com        0   \n","10333       11933                             sites.google.com        0   \n","10334       11934             habbocreditosparati.blogspot.com        0   \n","10335       11935  creditiperhabbogratissicuro100.blogspot.com        0   \n","10336       11936                           aijcs.blogspot.com        0   \n","\n","       Have @  URL Length  URL Depth  Redirection  https Domain  TinyURL  \\\n","0           0           1          1            0             0        0   \n","1           0           1          1            1             0        0   \n","2           0           1          1            0             1        0   \n","3           0           1          3            0             0        0   \n","4           0           1          3            0             0        0   \n","...       ...         ...        ...          ...           ...      ...   \n","10332       0           0          2            0             1        0   \n","10333       0           0          2            0             0        0   \n","10334       0           0          0            0             0        1   \n","10335       0           1          3            0             0        1   \n","10336       0           1          3            0             0        1   \n","\n","       Prefix/Suffix  ...  Num Embeds  Num Images  Num Links  Num Titles  \\\n","0                  0  ...           0          49        691          42   \n","1                  0  ...           0           4         66           3   \n","2                  0  ...           0           1        100          27   \n","3                  0  ...           0           0          0           1   \n","4                  0  ...           0         117        219          23   \n","...              ...  ...         ...         ...        ...         ...   \n","10332              0  ...           0           0         17           4   \n","10333              0  ...           0           6         24           7   \n","10334              0  ...           0           4         17           4   \n","10335              0  ...           0           1         23           8   \n","10336              0  ...           0          19         42           7   \n","\n","       Num Script  Special Characters  Script To Special Chars Ratio  \\\n","0           13135                6400                       2.052344   \n","1            2034                 818                       2.486553   \n","2           32987               10451                       3.156349   \n","3               0                  52                       0.000000   \n","4            7944                3468                       2.290657   \n","...           ...                 ...                            ...   \n","10332        8146                2203                       3.697685   \n","10333        8353                2250                       3.712444   \n","10334        6403                4560                       1.404167   \n","10335        9817                7292                       1.346270   \n","10336        2550                3225                       0.790698   \n","\n","       Script To body Ratio  Body To Special Char Ratio  Label  \n","0                  0.528869                    0.257690      0  \n","1                  0.676197                    0.271941      0  \n","2                  0.836681                    0.265079      0  \n","3                  0.000000                    0.227074      0  \n","4                  0.524460                    0.228956      0  \n","...                     ...                         ...    ...  \n","10332              0.943698                    0.255213      1  \n","10333              0.937276                    0.252469      1  \n","10334              0.397677                    0.283212      1  \n","10335              0.385873                    0.286624      1  \n","10336              0.247669                    0.313228      1  \n","\n","[10337 rows x 47 columns]"],"text/html":["\n","  <div id=\"df-900fa8e6-1f9a-46de-905a-427346a324b6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Domain</th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>graphicriver.net</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>691</td>\n","      <td>42</td>\n","      <td>13135</td>\n","      <td>6400</td>\n","      <td>2.052344</td>\n","      <td>0.528869</td>\n","      <td>0.257690</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>ecnavi.jp</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>66</td>\n","      <td>3</td>\n","      <td>2034</td>\n","      <td>818</td>\n","      <td>2.486553</td>\n","      <td>0.676197</td>\n","      <td>0.271941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>hubpages.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>27</td>\n","      <td>32987</td>\n","      <td>10451</td>\n","      <td>3.156349</td>\n","      <td>0.836681</td>\n","      <td>0.265079</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>extratorrent.cc</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.227074</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>icicibank.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>117</td>\n","      <td>219</td>\n","      <td>23</td>\n","      <td>7944</td>\n","      <td>3468</td>\n","      <td>2.290657</td>\n","      <td>0.524460</td>\n","      <td>0.228956</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10332</th>\n","      <td>11932</td>\n","      <td>sites.google.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>17</td>\n","      <td>4</td>\n","      <td>8146</td>\n","      <td>2203</td>\n","      <td>3.697685</td>\n","      <td>0.943698</td>\n","      <td>0.255213</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10333</th>\n","      <td>11933</td>\n","      <td>sites.google.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>24</td>\n","      <td>7</td>\n","      <td>8353</td>\n","      <td>2250</td>\n","      <td>3.712444</td>\n","      <td>0.937276</td>\n","      <td>0.252469</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10334</th>\n","      <td>11934</td>\n","      <td>habbocreditosparati.blogspot.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>17</td>\n","      <td>4</td>\n","      <td>6403</td>\n","      <td>4560</td>\n","      <td>1.404167</td>\n","      <td>0.397677</td>\n","      <td>0.283212</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10335</th>\n","      <td>11935</td>\n","      <td>creditiperhabbogratissicuro100.blogspot.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>23</td>\n","      <td>8</td>\n","      <td>9817</td>\n","      <td>7292</td>\n","      <td>1.346270</td>\n","      <td>0.385873</td>\n","      <td>0.286624</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10336</th>\n","      <td>11936</td>\n","      <td>aijcs.blogspot.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>19</td>\n","      <td>42</td>\n","      <td>7</td>\n","      <td>2550</td>\n","      <td>3225</td>\n","      <td>0.790698</td>\n","      <td>0.247669</td>\n","      <td>0.313228</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10337 rows × 47 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-900fa8e6-1f9a-46de-905a-427346a324b6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-900fa8e6-1f9a-46de-905a-427346a324b6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-900fa8e6-1f9a-46de-905a-427346a324b6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["urldata = pd.read_csv(\"/content/drive/MyDrive/Phishing/PhishTank/URL-HTML/preprocessed_url_features.csv\")\n","urldata\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":993,"status":"ok","timestamp":1656477862330,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"JQ4_qEulWybT","outputId":"e13d5a0d-5602-4d70-ff8d-64ab7a205393"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Unnamed: 0', 'Domain', 'Have IP', 'Have @', 'URL Length', 'URL Depth',\n","       'Redirection', 'https Domain', 'TinyURL', 'Prefix/Suffix',\n","       'Have client', 'Have admin', 'Have login', 'Have server', '.php',\n","       '.html', '.info', '.txt', '.js', '.exe', 'Num of periods', 'Is encoded',\n","       'Num of encoded char', 'Num of parameters', 'Num of digits',\n","       'Num of spec char', 'iFrame', 'Mouse Over', 'Right Click',\n","       'Web Forwards', 'Number of page tokens', 'number of sentences',\n","       'number of html tags', 'number of whitespace', 'url Is Live',\n","       'HTML Length', 'Num Objects', 'Num Embeds', 'Num Images', 'Num Links',\n","       'Num Titles', 'Num Script', 'Special Characters',\n","       'Script To Special Chars Ratio', 'Script To body Ratio',\n","       'Body To Special Char Ratio', 'Label'],\n","      dtype='object')"]},"metadata":{},"execution_count":4}],"source":["urldata.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"elapsed":560,"status":"ok","timestamp":1656477880906,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"qwye89TwRTOH","outputId":"4588a7eb-5b35-45fd-b10d-2447a1c95d7f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Have IP  Have @  URL Length  URL Depth  Redirection  https Domain  TinyURL  \\\n","0        0       0           1          1            0             0        0   \n","1        0       0           1          1            1             0        0   \n","2        0       0           1          1            0             1        0   \n","3        0       0           1          3            0             0        0   \n","4        0       0           1          3            0             0        0   \n","\n","   Prefix/Suffix  Have client  Have admin  ...  .txt  .js  .exe  \\\n","0              0            0           0  ...     0    0     0   \n","1              0            0           0  ...     0    0     0   \n","2              0            0           0  ...     0    0     0   \n","3              0            0           0  ...     0    0     0   \n","4              0            0           0  ...     0    0     0   \n","\n","   Num of periods  Is encoded  Num of encoded char  Num of parameters  \\\n","0               1           0                    0                 10   \n","1               4           1                    2                  3   \n","2               1           1                    2                  2   \n","3               4           1                    5                  0   \n","4               2           0                    0                  1   \n","\n","   Num of digits  Num of spec char  Label  \n","0              0                25      0  \n","1             22                13      0  \n","2              2                 9      0  \n","3             19                18      0  \n","4             17                 7      0  \n","\n","[5 rows x 25 columns]"],"text/html":["\n","  <div id=\"df-03f761f0-d408-4f31-ac85-e6fd161a6dac\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>Have admin</th>\n","      <th>...</th>\n","      <th>.txt</th>\n","      <th>.js</th>\n","      <th>.exe</th>\n","      <th>Num of periods</th>\n","      <th>Is encoded</th>\n","      <th>Num of encoded char</th>\n","      <th>Num of parameters</th>\n","      <th>Num of digits</th>\n","      <th>Num of spec char</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>25</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>22</td>\n","      <td>13</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>19</td>\n","      <td>18</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>17</td>\n","      <td>7</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 25 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03f761f0-d408-4f31-ac85-e6fd161a6dac')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-03f761f0-d408-4f31-ac85-e6fd161a6dac button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-03f761f0-d408-4f31-ac85-e6fd161a6dac');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["urldata = urldata.drop(['Unnamed: 0', 'Domain', 'iFrame', 'Mouse Over', 'Right Click',\n","       'Web Forwards', 'Number of page tokens', 'number of sentences',\n","       'number of html tags', 'number of whitespace', 'url Is Live',\n","       'HTML Length', 'Num Objects', 'Num Embeds', 'Num Images', 'Num Links',\n","       'Num Titles', 'Num Script', 'Special Characters',\n","       'Script To Special Chars Ratio', 'Script To body Ratio',\n","       'Body To Special Char Ratio'], axis = 1).copy()\n","\n","urldata.shape\n","urldata.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":656,"status":"ok","timestamp":1656477909151,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"kKvKkmUNP5Cx","outputId":"44f686fe-4fcc-4df9-b41e-e4670cc80be1"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10337 entries, 0 to 10336\n","Data columns (total 25 columns):\n"," #   Column               Non-Null Count  Dtype\n","---  ------               --------------  -----\n"," 0   Have IP              10337 non-null  int64\n"," 1   Have @               10337 non-null  int64\n"," 2   URL Length           10337 non-null  int64\n"," 3   URL Depth            10337 non-null  int64\n"," 4   Redirection          10337 non-null  int64\n"," 5   https Domain         10337 non-null  int64\n"," 6   TinyURL              10337 non-null  int64\n"," 7   Prefix/Suffix        10337 non-null  int64\n"," 8   Have client          10337 non-null  int64\n"," 9   Have admin           10337 non-null  int64\n"," 10  Have login           10337 non-null  int64\n"," 11  Have server          10337 non-null  int64\n"," 12  .php                 10337 non-null  int64\n"," 13  .html                10337 non-null  int64\n"," 14  .info                10337 non-null  int64\n"," 15  .txt                 10337 non-null  int64\n"," 16  .js                  10337 non-null  int64\n"," 17  .exe                 10337 non-null  int64\n"," 18  Num of periods       10337 non-null  int64\n"," 19  Is encoded           10337 non-null  int64\n"," 20  Num of encoded char  10337 non-null  int64\n"," 21  Num of parameters    10337 non-null  int64\n"," 22  Num of digits        10337 non-null  int64\n"," 23  Num of spec char     10337 non-null  int64\n"," 24  Label                10337 non-null  int64\n","dtypes: int64(25)\n","memory usage: 2.0 MB\n"]}],"source":["urldata.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1656477915360,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"rvS3OQHTSHDt","outputId":"2fecb090-318a-40be-9203-02c14646ab4d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Label\n","0    5828\n","1    4509\n","dtype: int64"]},"metadata":{},"execution_count":7}],"source":["# Class Distribution of Labels\n","urldata.groupby('Label').size()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1656477916083,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"kHCjZCSBSKi3","outputId":"e1faae92-690e-4384-a942-6fc9750ca3e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total of Samples: 10337\n","Non-Phishing: 5828 (56.38% of total)\n","Phishing: 4509 (43.62% of total)\n"]}],"source":["# Analysis of Postives and Negatives in the Dataset\n","pos,neg = urldata['Label'].value_counts()\n","total = neg + pos\n","print ('Total of Samples: %s'% total)\n","print('Non-Phishing: {} ({:.2f}% of total)'.format(pos, 100 * pos / total))\n","print('Phishing: {} ({:.2f}% of total)'.format(neg, 100 * neg / total))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1656477961464,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"S3PEbrTLcfXg","outputId":"74d84570-2acc-4ab8-edb1-2f4744969345"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Have IP                0\n","Have @                 0\n","URL Length             0\n","URL Depth              0\n","Redirection            0\n","https Domain           0\n","TinyURL                0\n","Prefix/Suffix          0\n","Have client            0\n","Have admin             0\n","Have login             0\n","Have server            0\n",".php                   0\n",".html                  0\n",".info                  0\n",".txt                   0\n",".js                    0\n",".exe                   0\n","Num of periods         0\n","Is encoded             0\n","Num of encoded char    0\n","Num of parameters      0\n","Num of digits          0\n","Num of spec char       0\n","Label                  0\n","dtype: int64"]},"metadata":{},"execution_count":15}],"source":["#checking the data for null or missing values\n","urldata.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1656477962834,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"n6YfGa82P5JZ","outputId":"0c76f8fb-4caa-4c87-8256-c2c609862cef"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Have IP  Have @  URL Length  URL Depth  Redirection  https Domain  TinyURL  \\\n","0        0       0           1          2            0             0        0   \n","1        0       0           0          1            0             1        0   \n","2        0       0           0          0            0             1        0   \n","3        0       0           1         10            0             0        0   \n","4        0       0           0          3            0             1        0   \n","\n","   Prefix/Suffix  Have client  Have admin  ...  .txt  .js  .exe  \\\n","0              0            0           0  ...     0    0     0   \n","1              0            0           0  ...     0    0     0   \n","2              0            0           0  ...     0    0     0   \n","3              0            0           0  ...     0    0     0   \n","4              0            0           0  ...     0    0     0   \n","\n","   Num of periods  Is encoded  Num of encoded char  Num of parameters  \\\n","0               2           0                    0                  5   \n","1               1           0                    0                  0   \n","2               2           0                    0                  0   \n","3               1           0                    0                  0   \n","4               2           0                    0                  0   \n","\n","   Num of digits  Num of spec char  Label  \n","0             27                11      0  \n","1              0                 0      1  \n","2              3                 0      1  \n","3             22                 0      0  \n","4              0                 0      1  \n","\n","[5 rows x 25 columns]"],"text/html":["\n","  <div id=\"df-626263d7-a204-4a88-85cc-5f3d1dc82752\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>Have admin</th>\n","      <th>...</th>\n","      <th>.txt</th>\n","      <th>.js</th>\n","      <th>.exe</th>\n","      <th>Num of periods</th>\n","      <th>Is encoded</th>\n","      <th>Num of encoded char</th>\n","      <th>Num of parameters</th>\n","      <th>Num of digits</th>\n","      <th>Num of spec char</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>27</td>\n","      <td>11</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 25 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-626263d7-a204-4a88-85cc-5f3d1dc82752')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-626263d7-a204-4a88-85cc-5f3d1dc82752 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-626263d7-a204-4a88-85cc-5f3d1dc82752');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}],"source":["# shuffling the rows in the dataset so that when splitting the train and test set are equally distributed\n","urldata = urldata.sample(frac=1).reset_index(drop=True)\n","urldata.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lasv_YzlP5L6"},"outputs":[],"source":["import numpy as np\n","# Sepratating & assigning features and target columns to X & y\n","y = urldata['Label'].values\n","x = np.array(urldata.drop('Label',axis=1))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1656477963380,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"in9C2ArWP5O0","outputId":"a98cde6d-6f9e-4b74-c782-133ee220905e"},"outputs":[{"output_type":"stream","name":"stdout","text":["(5685, 24) (4652, 24)\n","(5685,) (4652,)\n"]}],"source":["# Splitting the dataset into train and test sets: 80-20 split\n","from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, \n","                                                    test_size = 0.45, random_state = 12)\n","print(x_train.shape, x_test.shape)\n","print(y_train.shape, y_test.shape)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jv6Y5m8ddMHC"},"outputs":[],"source":["output = {}\n","output['labels'] = y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N8k6QYBg7wu7"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"SOV9VybfNIgE"},"source":["**MLP**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mr-AOgJ1JtXY"},"outputs":[],"source":["import keras\n","\n","from sklearn.neural_network import MLPClassifier\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","import pickle\n","\n","def model_mlp(x_train, x_val, y_train, y_val, opt, n):\n","  mlpclassifier = MLPClassifier(alpha=0.0001, hidden_layer_sizes=([100,100,100]))\n","  #compile model using mse as a measure of model performance\n","  mlpclassifier.fit(x_train, y_train)\n","\n","  y_pred = mlpclassifier.predict(x_val)\n","\n","  conf_matrix = confusion_matrix(y_val, y_pred)\n","  print(conf_matrix)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred))\n","\n","  \n","  print(\"Validation Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed URL/MLP/model_'+str(n)+'.h5'\n","  pickle.dump(mlpclassifier, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","  return metrics.accuracy_score(y_val, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUCxdcapJtXZ","executionInfo":{"status":"ok","timestamp":1656478126625,"user_tz":-330,"elapsed":70892,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"e02aa788-6713-40b7-8a1c-26ac78678855"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[312   1]\n"," [  4 252]]\n","Precision: 0.9960\n","Recall: 0.9844\n","F1 Score: 0.9902\n","Validation Accuracy: 0.9912126537785588\n","model 0 saved\n","[[324   6]\n"," [  3 236]]\n","Precision: 0.9752\n","Recall: 0.9874\n","F1 Score: 0.9813\n","Validation Accuracy: 0.984182776801406\n","model 1 saved\n","[[318   5]\n"," [  3 243]]\n","Precision: 0.9798\n","Recall: 0.9878\n","F1 Score: 0.9838\n","Validation Accuracy: 0.9859402460456942\n","model 2 saved\n","[[323  12]\n"," [  7 227]]\n","Precision: 0.9498\n","Recall: 0.9701\n","F1 Score: 0.9598\n","Validation Accuracy: 0.9666080843585237\n","model 3 saved\n","[[321   4]\n"," [  3 241]]\n","Precision: 0.9837\n","Recall: 0.9877\n","F1 Score: 0.9857\n","Validation Accuracy: 0.9876977152899824\n","model 4 saved\n","[[296   5]\n"," [  3 264]]\n","Precision: 0.9814\n","Recall: 0.9888\n","F1 Score: 0.9851\n","Validation Accuracy: 0.9859154929577465\n","model 5 saved\n","[[334   0]\n"," [ 10 224]]\n","Precision: 1.0000\n","Recall: 0.9573\n","F1 Score: 0.9782\n","Validation Accuracy: 0.9823943661971831\n","model 6 saved\n","[[316   2]\n"," [  9 241]]\n","Precision: 0.9918\n","Recall: 0.9640\n","F1 Score: 0.9777\n","Validation Accuracy: 0.9806338028169014\n","model 7 saved\n","[[306   2]\n"," [  5 255]]\n","Precision: 0.9922\n","Recall: 0.9808\n","F1 Score: 0.9865\n","Validation Accuracy: 0.9876760563380281\n","model 8 saved\n","[[328   1]\n"," [  8 231]]\n","Precision: 0.9957\n","Recall: 0.9665\n","F1 Score: 0.9809\n","Validation Accuracy: 0.9841549295774648\n","model 9 saved\n","Average Validation Accuracy: 0.9836416124161488\n"]}],"source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_mlp(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1656478623079,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"6DA16IlPJtXZ","outputId":"2b5b0c5b-479e-42bc-df33-472e2841e765"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[9.93201827e-01 6.79817348e-03]\n"," [9.99954244e-01 4.57560327e-05]\n"," [9.97641069e-01 2.35893122e-03]\n"," ...\n"," [9.99999997e-01 3.34157655e-09]\n"," [9.98309614e-01 1.69038601e-03]\n"," [2.22044605e-16 1.00000000e+00]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish\n","0          0        9.932018e-01          6.798173e-03\n","1          0        9.999542e-01          4.575603e-05\n","2          0        9.976411e-01          2.358931e-03\n","3          0        9.875554e-01          1.244462e-02\n","4          0        9.999881e-01          1.189933e-05\n","...      ...                 ...                   ...\n","4647       1        2.401408e-10          1.000000e+00\n","4648       0        9.999578e-01          4.222117e-05\n","4649       0        1.000000e+00          3.341577e-09\n","4650       0        9.983096e-01          1.690386e-03\n","4651       1        2.220446e-16          1.000000e+00\n","\n","[4652 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-e0303e9a-bf0a-45b8-9f35-0f2f03eb81b6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>9.932018e-01</td>\n","      <td>6.798173e-03</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>9.999542e-01</td>\n","      <td>4.575603e-05</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>9.976411e-01</td>\n","      <td>2.358931e-03</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>9.875554e-01</td>\n","      <td>1.244462e-02</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>9.999881e-01</td>\n","      <td>1.189933e-05</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4647</th>\n","      <td>1</td>\n","      <td>2.401408e-10</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>4648</th>\n","      <td>0</td>\n","      <td>9.999578e-01</td>\n","      <td>4.222117e-05</td>\n","    </tr>\n","    <tr>\n","      <th>4649</th>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>3.341577e-09</td>\n","    </tr>\n","    <tr>\n","      <th>4650</th>\n","      <td>0</td>\n","      <td>9.983096e-01</td>\n","      <td>1.690386e-03</td>\n","    </tr>\n","    <tr>\n","      <th>4651</th>\n","      <td>1</td>\n","      <td>2.220446e-16</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4652 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0303e9a-bf0a-45b8-9f35-0f2f03eb81b6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e0303e9a-bf0a-45b8-9f35-0f2f03eb81b6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e0303e9a-bf0a-45b8-9f35-0f2f03eb81b6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":22}],"source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed URL/MLP/model_0.h5'\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['mlp_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['mlp_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output\n"]},{"cell_type":"code","source":[""],"metadata":{"id":"rbpIy5wtL3VQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Neural Network**"],"metadata":{"id":"iLF4sz5NsSZ6"}},{"cell_type":"code","source":["\n","import keras\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","def model_aa(x_train, x_val, y_train, y_val, opt, n, early_stopping_monitor):\n","\n","  n_cols = x_train.shape[1]\n","  # print(\"check point\")\n","  #create model\n","  model = Sequential()\n","  model.add(Dense(30, activation='relu', input_shape=(n_cols,)))\n","  model.add(Dense(10, activation='relu'))\n","\n","  model.add(Dense(1, activation = 'sigmoid'))\n","  # softmax\n","  #compile model using mse as a measure of model performance\n","  model.compile(optimizer = opt, loss= 'binary_crossentropy', metrics=[\"accuracy\"])\n","\n","  history = model.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping_monitor])\n","\n","\n","  # plt.plot(history.history['loss'])\n","  # plt.plot(history.history['val_loss'])\n","  # plt.title('model loss')\n","  # plt.ylabel('Loss')\n","  # plt.xlabel('Epoch')\n","  # plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n","  # plt.show()\n","\n","\n","  print('Validation Accuracy: ')\n","  # Predicting the Test set results\n","  y_pred = model.predict(x_val)\n","  y_pred = (y_pred > 0.5)\n","\n","\n","  print(classification_report(y_val, y_pred))\n","\n","  # Model Accuracy, how often is the classifier correct?\n","  print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","\n","  # Creating the Confusion Matrix\n","  cm = confusion_matrix(y_val, y_pred)\n","  print(cm)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred))\n","\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed URL/NN/model_'+str(n)+'.h5'\n","  pickle.dump(model, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","\n","  return metrics.accuracy_score(y_val, y_pred)\n","\n"],"metadata":{"id":"UfilmHKnL3LC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_aa(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n, early_stopping_monitor)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_OHdM1HNDio","executionInfo":{"status":"ok","timestamp":1656479162932,"user_tz":-330,"elapsed":525709,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"34fea0af-5493-4988-e0c7-a73a6527d282"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","160/160 [==============================] - 5s 6ms/step - loss: 1.2054 - accuracy: 0.5420 - val_loss: 0.4943 - val_accuracy: 0.8946\n","Epoch 2/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.3750 - accuracy: 0.9081 - val_loss: 0.2795 - val_accuracy: 0.9174\n","Epoch 3/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2278 - accuracy: 0.9345 - val_loss: 0.1745 - val_accuracy: 0.9596\n","Epoch 4/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1630 - accuracy: 0.9517 - val_loss: 0.1322 - val_accuracy: 0.9649\n","Epoch 5/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1343 - accuracy: 0.9617 - val_loss: 0.1098 - val_accuracy: 0.9719\n","Epoch 6/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1188 - accuracy: 0.9650 - val_loss: 0.0963 - val_accuracy: 0.9736\n","Epoch 7/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1100 - accuracy: 0.9660 - val_loss: 0.0867 - val_accuracy: 0.9754\n","Epoch 8/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9677 - val_loss: 0.0813 - val_accuracy: 0.9754\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0973 - accuracy: 0.9670 - val_loss: 0.0748 - val_accuracy: 0.9754\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0915 - accuracy: 0.9685 - val_loss: 0.0709 - val_accuracy: 0.9772\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0878 - accuracy: 0.9687 - val_loss: 0.0774 - val_accuracy: 0.9754\n","Epoch 12/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0842 - accuracy: 0.9715 - val_loss: 0.0624 - val_accuracy: 0.9807\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0817 - accuracy: 0.9722 - val_loss: 0.0609 - val_accuracy: 0.9824\n","Epoch 14/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.9734 - val_loss: 0.0608 - val_accuracy: 0.9789\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0778 - accuracy: 0.9728 - val_loss: 0.0590 - val_accuracy: 0.9824\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9740 - val_loss: 0.0597 - val_accuracy: 0.9807\n","Epoch 17/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9726 - val_loss: 0.0626 - val_accuracy: 0.9807\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0726 - accuracy: 0.9744 - val_loss: 0.0557 - val_accuracy: 0.9789\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9740 - val_loss: 0.0534 - val_accuracy: 0.9807\n","Epoch 20/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9762 - val_loss: 0.0545 - val_accuracy: 0.9789\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.9758 - val_loss: 0.0542 - val_accuracy: 0.9789\n","Epoch 22/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.9769 - val_loss: 0.0532 - val_accuracy: 0.9807\n","Epoch 23/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9771 - val_loss: 0.0526 - val_accuracy: 0.9824\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0639 - accuracy: 0.9765 - val_loss: 0.0477 - val_accuracy: 0.9807\n","Epoch 25/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9789 - val_loss: 0.0467 - val_accuracy: 0.9807\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0610 - accuracy: 0.9773 - val_loss: 0.0457 - val_accuracy: 0.9789\n","Epoch 27/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9779 - val_loss: 0.0432 - val_accuracy: 0.9842\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0588 - accuracy: 0.9775 - val_loss: 0.0441 - val_accuracy: 0.9807\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0564 - accuracy: 0.9789 - val_loss: 0.0430 - val_accuracy: 0.9824\n","Epoch 30/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9789 - val_loss: 0.0417 - val_accuracy: 0.9807\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0542 - accuracy: 0.9791 - val_loss: 0.0414 - val_accuracy: 0.9824\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0544 - accuracy: 0.9787 - val_loss: 0.0405 - val_accuracy: 0.9859\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0522 - accuracy: 0.9814 - val_loss: 0.0402 - val_accuracy: 0.9895\n","Epoch 34/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9787 - val_loss: 0.0381 - val_accuracy: 0.9842\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0505 - accuracy: 0.9810 - val_loss: 0.0455 - val_accuracy: 0.9895\n","Epoch 36/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9812 - val_loss: 0.0387 - val_accuracy: 0.9877\n","Epoch 37/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9806 - val_loss: 0.0711 - val_accuracy: 0.9666\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0548 - accuracy: 0.9777 - val_loss: 0.0417 - val_accuracy: 0.9895\n","Epoch 39/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9826 - val_loss: 0.0397 - val_accuracy: 0.9877\n","Epoch 40/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9818 - val_loss: 0.0352 - val_accuracy: 0.9912\n","Epoch 41/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9826 - val_loss: 0.0416 - val_accuracy: 0.9877\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0452 - accuracy: 0.9828 - val_loss: 0.0466 - val_accuracy: 0.9842\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0450 - accuracy: 0.9842 - val_loss: 0.0340 - val_accuracy: 0.9895\n","Epoch 44/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9836 - val_loss: 0.0308 - val_accuracy: 0.9895\n","Epoch 45/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0435 - accuracy: 0.9844 - val_loss: 0.0318 - val_accuracy: 0.9895\n","Epoch 46/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0414 - accuracy: 0.9838 - val_loss: 0.0303 - val_accuracy: 0.9895\n","Epoch 47/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9851 - val_loss: 0.0413 - val_accuracy: 0.9859\n","Epoch 48/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0417 - accuracy: 0.9834 - val_loss: 0.0427 - val_accuracy: 0.9859\n","Epoch 49/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0413 - accuracy: 0.9842 - val_loss: 0.0310 - val_accuracy: 0.9895\n","Epoch 50/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9861 - val_loss: 0.0295 - val_accuracy: 0.9912\n","Epoch 51/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0383 - accuracy: 0.9859 - val_loss: 0.0415 - val_accuracy: 0.9859\n","Epoch 52/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0433 - accuracy: 0.9846 - val_loss: 0.0335 - val_accuracy: 0.9895\n","Epoch 53/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9861 - val_loss: 0.0300 - val_accuracy: 0.9912\n","Epoch 54/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9865 - val_loss: 0.0353 - val_accuracy: 0.9877\n","Epoch 55/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9873 - val_loss: 0.0321 - val_accuracy: 0.9895\n","Epoch 56/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.9863 - val_loss: 0.0333 - val_accuracy: 0.9895\n","Epoch 57/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0353 - accuracy: 0.9873 - val_loss: 0.0343 - val_accuracy: 0.9877\n","Epoch 58/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0361 - accuracy: 0.9863 - val_loss: 0.0281 - val_accuracy: 0.9895\n","Epoch 59/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9883 - val_loss: 0.0335 - val_accuracy: 0.9877\n","Epoch 60/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0345 - accuracy: 0.9892 - val_loss: 0.0309 - val_accuracy: 0.9877\n","Epoch 61/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9885 - val_loss: 0.0323 - val_accuracy: 0.9877\n","Epoch 62/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9875 - val_loss: 0.0344 - val_accuracy: 0.9877\n","Epoch 63/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 0.0274 - val_accuracy: 0.9895\n","Epoch 64/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.9885 - val_loss: 0.0310 - val_accuracy: 0.9877\n","Epoch 65/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0325 - accuracy: 0.9883 - val_loss: 0.0353 - val_accuracy: 0.9877\n","Epoch 66/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9881 - val_loss: 0.0306 - val_accuracy: 0.9877\n","Epoch 67/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9883 - val_loss: 0.0295 - val_accuracy: 0.9859\n","Epoch 68/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9892 - val_loss: 0.0326 - val_accuracy: 0.9859\n","Epoch 69/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0315 - accuracy: 0.9889 - val_loss: 0.0305 - val_accuracy: 0.9895\n","Epoch 70/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.9885 - val_loss: 0.0279 - val_accuracy: 0.9877\n","Epoch 71/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9885 - val_loss: 0.0280 - val_accuracy: 0.9895\n","Epoch 72/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 0.0353 - val_accuracy: 0.9824\n","Epoch 73/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0392 - accuracy: 0.9879 - val_loss: 0.0765 - val_accuracy: 0.9719\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.96      0.97       313\n","           1       0.95      0.99      0.97       256\n","\n","    accuracy                           0.97       569\n","   macro avg       0.97      0.97      0.97       569\n","weighted avg       0.97      0.97      0.97       569\n","\n","Accuracy: 0.9718804920913884\n","[[300  13]\n"," [  3 253]]\n","Precision: 0.9511\n","Recall: 0.9883\n","F1 Score: 0.9693\n","INFO:tensorflow:Assets written to: ram://712ba873-4f92-4b4e-9d9f-f2acdc9d0b19/assets\n","model 0 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.4680 - accuracy: 0.8237 - val_loss: 0.3294 - val_accuracy: 0.9385\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2694 - accuracy: 0.9373 - val_loss: 0.2324 - val_accuracy: 0.9315\n","Epoch 3/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1769 - accuracy: 0.9466 - val_loss: 0.1677 - val_accuracy: 0.9402\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1261 - accuracy: 0.9633 - val_loss: 0.1358 - val_accuracy: 0.9613\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1058 - accuracy: 0.9693 - val_loss: 0.1187 - val_accuracy: 0.9701\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0943 - accuracy: 0.9709 - val_loss: 0.1114 - val_accuracy: 0.9701\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0883 - accuracy: 0.9711 - val_loss: 0.1047 - val_accuracy: 0.9701\n","Epoch 8/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 0.9715 - val_loss: 0.1009 - val_accuracy: 0.9736\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9736 - val_loss: 0.0983 - val_accuracy: 0.9719\n","Epoch 10/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9730 - val_loss: 0.0958 - val_accuracy: 0.9736\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9722 - val_loss: 0.1416 - val_accuracy: 0.9578\n","Epoch 12/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0820 - accuracy: 0.9717 - val_loss: 0.0947 - val_accuracy: 0.9719\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0746 - accuracy: 0.9742 - val_loss: 0.0918 - val_accuracy: 0.9754\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0711 - accuracy: 0.9746 - val_loss: 0.0876 - val_accuracy: 0.9736\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9762 - val_loss: 0.0852 - val_accuracy: 0.9754\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9767 - val_loss: 0.0848 - val_accuracy: 0.9754\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0663 - accuracy: 0.9767 - val_loss: 0.0844 - val_accuracy: 0.9754\n","Epoch 18/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9783 - val_loss: 0.0841 - val_accuracy: 0.9701\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9775 - val_loss: 0.0799 - val_accuracy: 0.9754\n","Epoch 20/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9785 - val_loss: 0.0787 - val_accuracy: 0.9772\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0619 - accuracy: 0.9781 - val_loss: 0.0771 - val_accuracy: 0.9754\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0607 - accuracy: 0.9779 - val_loss: 0.0792 - val_accuracy: 0.9754\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0600 - accuracy: 0.9777 - val_loss: 0.0765 - val_accuracy: 0.9772\n","Epoch 24/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9805 - val_loss: 0.0743 - val_accuracy: 0.9772\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0660 - accuracy: 0.9763 - val_loss: 0.0714 - val_accuracy: 0.9736\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0589 - accuracy: 0.9789 - val_loss: 0.0736 - val_accuracy: 0.9789\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0567 - accuracy: 0.9793 - val_loss: 0.0736 - val_accuracy: 0.9772\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0553 - accuracy: 0.9793 - val_loss: 0.0730 - val_accuracy: 0.9772\n","Epoch 29/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9797 - val_loss: 0.0707 - val_accuracy: 0.9754\n","Epoch 30/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9822 - val_loss: 0.0715 - val_accuracy: 0.9772\n","Epoch 31/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9763 - val_loss: 0.0705 - val_accuracy: 0.9736\n","Epoch 32/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9820 - val_loss: 0.0695 - val_accuracy: 0.9754\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0522 - accuracy: 0.9830 - val_loss: 0.0669 - val_accuracy: 0.9754\n","Epoch 34/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9834 - val_loss: 0.0678 - val_accuracy: 0.9754\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.9840 - val_loss: 0.0691 - val_accuracy: 0.9736\n","Epoch 36/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9848 - val_loss: 0.0657 - val_accuracy: 0.9754\n","Epoch 37/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 0.0638 - val_accuracy: 0.9736\n","Epoch 38/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9836 - val_loss: 0.0647 - val_accuracy: 0.9754\n","Epoch 39/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9838 - val_loss: 0.0654 - val_accuracy: 0.9754\n","Epoch 40/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9828 - val_loss: 0.0642 - val_accuracy: 0.9736\n","Epoch 41/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9849 - val_loss: 0.0646 - val_accuracy: 0.9736\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 0.0644 - val_accuracy: 0.9754\n","Epoch 43/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9849 - val_loss: 0.0642 - val_accuracy: 0.9736\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0434 - accuracy: 0.9859 - val_loss: 0.0628 - val_accuracy: 0.9719\n","Epoch 45/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9846 - val_loss: 0.0640 - val_accuracy: 0.9736\n","Epoch 46/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0435 - accuracy: 0.9853 - val_loss: 0.0599 - val_accuracy: 0.9754\n","Epoch 47/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9849 - val_loss: 0.0672 - val_accuracy: 0.9736\n","Epoch 48/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9824 - val_loss: 0.0645 - val_accuracy: 0.9701\n","Epoch 49/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0447 - accuracy: 0.9840 - val_loss: 0.0624 - val_accuracy: 0.9719\n","Epoch 50/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0416 - accuracy: 0.9855 - val_loss: 0.0600 - val_accuracy: 0.9754\n","Epoch 51/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9851 - val_loss: 0.0609 - val_accuracy: 0.9754\n","Epoch 52/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0400 - accuracy: 0.9857 - val_loss: 0.0607 - val_accuracy: 0.9754\n","Epoch 53/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9863 - val_loss: 0.0619 - val_accuracy: 0.9736\n","Epoch 54/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9865 - val_loss: 0.0638 - val_accuracy: 0.9736\n","Epoch 55/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.9863 - val_loss: 0.0615 - val_accuracy: 0.9754\n","Epoch 56/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9867 - val_loss: 0.0616 - val_accuracy: 0.9736\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.97      0.98       330\n","           1       0.96      0.97      0.97       239\n","\n","    accuracy                           0.97       569\n","   macro avg       0.97      0.97      0.97       569\n","weighted avg       0.97      0.97      0.97       569\n","\n","Accuracy: 0.9736379613356766\n","[[321   9]\n"," [  6 233]]\n","Precision: 0.9628\n","Recall: 0.9749\n","F1 Score: 0.9688\n","INFO:tensorflow:Assets written to: ram://aea064f3-81a4-48ab-95e4-4130d2770b6a/assets\n","model 1 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3015 - accuracy: 0.9062 - val_loss: 0.1885 - val_accuracy: 0.9262\n","Epoch 2/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1433 - accuracy: 0.9511 - val_loss: 0.1451 - val_accuracy: 0.9420\n","Epoch 3/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1196 - accuracy: 0.9568 - val_loss: 0.1289 - val_accuracy: 0.9543\n","Epoch 4/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1032 - accuracy: 0.9633 - val_loss: 0.1124 - val_accuracy: 0.9508\n","Epoch 5/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0933 - accuracy: 0.9662 - val_loss: 0.1038 - val_accuracy: 0.9649\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0867 - accuracy: 0.9697 - val_loss: 0.1014 - val_accuracy: 0.9631\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0833 - accuracy: 0.9707 - val_loss: 0.0960 - val_accuracy: 0.9596\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0803 - accuracy: 0.9701 - val_loss: 0.0954 - val_accuracy: 0.9666\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9719 - val_loss: 0.0924 - val_accuracy: 0.9649\n","Epoch 10/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9722 - val_loss: 0.0910 - val_accuracy: 0.9666\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0748 - accuracy: 0.9728 - val_loss: 0.0866 - val_accuracy: 0.9701\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0725 - accuracy: 0.9728 - val_loss: 0.0833 - val_accuracy: 0.9719\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0706 - accuracy: 0.9736 - val_loss: 0.0826 - val_accuracy: 0.9736\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0691 - accuracy: 0.9736 - val_loss: 0.0804 - val_accuracy: 0.9736\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9742 - val_loss: 0.0798 - val_accuracy: 0.9701\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0660 - accuracy: 0.9736 - val_loss: 0.0766 - val_accuracy: 0.9736\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0645 - accuracy: 0.9744 - val_loss: 0.0767 - val_accuracy: 0.9736\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0632 - accuracy: 0.9760 - val_loss: 0.0755 - val_accuracy: 0.9719\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9752 - val_loss: 0.0819 - val_accuracy: 0.9736\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0598 - accuracy: 0.9775 - val_loss: 0.0732 - val_accuracy: 0.9719\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0597 - accuracy: 0.9769 - val_loss: 0.0753 - val_accuracy: 0.9772\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9797 - val_loss: 0.0712 - val_accuracy: 0.9736\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0557 - accuracy: 0.9789 - val_loss: 0.0768 - val_accuracy: 0.9754\n","Epoch 24/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9803 - val_loss: 0.0730 - val_accuracy: 0.9772\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0535 - accuracy: 0.9795 - val_loss: 0.0745 - val_accuracy: 0.9754\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0741 - val_accuracy: 0.9754\n","Epoch 27/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9791 - val_loss: 0.0728 - val_accuracy: 0.9754\n","Epoch 28/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9806 - val_loss: 0.0718 - val_accuracy: 0.9772\n","Epoch 29/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9816 - val_loss: 0.0709 - val_accuracy: 0.9772\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0496 - accuracy: 0.9801 - val_loss: 0.0709 - val_accuracy: 0.9736\n","Epoch 31/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9818 - val_loss: 0.0726 - val_accuracy: 0.9754\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0484 - accuracy: 0.9816 - val_loss: 0.0681 - val_accuracy: 0.9754\n","Epoch 33/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9830 - val_loss: 0.0720 - val_accuracy: 0.9736\n","Epoch 34/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9826 - val_loss: 0.0740 - val_accuracy: 0.9736\n","Epoch 35/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9820 - val_loss: 0.0699 - val_accuracy: 0.9789\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0462 - accuracy: 0.9842 - val_loss: 0.0685 - val_accuracy: 0.9807\n","Epoch 37/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9832 - val_loss: 0.0718 - val_accuracy: 0.9754\n","Epoch 38/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9824 - val_loss: 0.0654 - val_accuracy: 0.9772\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0435 - accuracy: 0.9834 - val_loss: 0.0706 - val_accuracy: 0.9754\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0441 - accuracy: 0.9844 - val_loss: 0.0754 - val_accuracy: 0.9719\n","Epoch 41/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9838 - val_loss: 0.0678 - val_accuracy: 0.9789\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0428 - accuracy: 0.9842 - val_loss: 0.0711 - val_accuracy: 0.9754\n","Epoch 43/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9842 - val_loss: 0.0702 - val_accuracy: 0.9807\n","Epoch 44/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9851 - val_loss: 0.0811 - val_accuracy: 0.9754\n","Epoch 45/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.9846 - val_loss: 0.0715 - val_accuracy: 0.9807\n","Epoch 46/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9836 - val_loss: 0.0728 - val_accuracy: 0.9789\n","Epoch 47/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0403 - accuracy: 0.9842 - val_loss: 0.0701 - val_accuracy: 0.9789\n","Epoch 48/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0397 - accuracy: 0.9842 - val_loss: 0.0702 - val_accuracy: 0.9789\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.98      0.98       323\n","           1       0.97      0.98      0.98       246\n","\n","    accuracy                           0.98       569\n","   macro avg       0.98      0.98      0.98       569\n","weighted avg       0.98      0.98      0.98       569\n","\n","Accuracy: 0.9789103690685413\n","[[315   8]\n"," [  4 242]]\n","Precision: 0.9680\n","Recall: 0.9837\n","F1 Score: 0.9758\n","INFO:tensorflow:Assets written to: ram://2b7cb64e-e8af-42f7-b848-35c4bd229bda/assets\n","model 2 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3523 - accuracy: 0.8769 - val_loss: 0.2278 - val_accuracy: 0.9227\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1573 - accuracy: 0.9486 - val_loss: 0.1259 - val_accuracy: 0.9631\n","Epoch 3/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1196 - accuracy: 0.9631 - val_loss: 0.1150 - val_accuracy: 0.9719\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1058 - accuracy: 0.9660 - val_loss: 0.1029 - val_accuracy: 0.9719\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0966 - accuracy: 0.9681 - val_loss: 0.0957 - val_accuracy: 0.9736\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0898 - accuracy: 0.9717 - val_loss: 0.0890 - val_accuracy: 0.9701\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0845 - accuracy: 0.9705 - val_loss: 0.0872 - val_accuracy: 0.9701\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0814 - accuracy: 0.9730 - val_loss: 0.0835 - val_accuracy: 0.9684\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0784 - accuracy: 0.9711 - val_loss: 0.0816 - val_accuracy: 0.9719\n","Epoch 10/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0783 - accuracy: 0.9744 - val_loss: 0.0843 - val_accuracy: 0.9719\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0798 - accuracy: 0.9711 - val_loss: 0.0815 - val_accuracy: 0.9701\n","Epoch 12/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9742 - val_loss: 0.0779 - val_accuracy: 0.9684\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9742 - val_loss: 0.0764 - val_accuracy: 0.9684\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0685 - accuracy: 0.9754 - val_loss: 0.0764 - val_accuracy: 0.9701\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0666 - accuracy: 0.9758 - val_loss: 0.0751 - val_accuracy: 0.9684\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0646 - accuracy: 0.9765 - val_loss: 0.0741 - val_accuracy: 0.9684\n","Epoch 17/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9752 - val_loss: 0.0740 - val_accuracy: 0.9754\n","Epoch 18/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9769 - val_loss: 0.0744 - val_accuracy: 0.9772\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0677 - accuracy: 0.9740 - val_loss: 0.0720 - val_accuracy: 0.9754\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0606 - accuracy: 0.9763 - val_loss: 0.0713 - val_accuracy: 0.9701\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0585 - accuracy: 0.9775 - val_loss: 0.0708 - val_accuracy: 0.9684\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0570 - accuracy: 0.9781 - val_loss: 0.0725 - val_accuracy: 0.9719\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0566 - accuracy: 0.9781 - val_loss: 0.0707 - val_accuracy: 0.9754\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0550 - accuracy: 0.9803 - val_loss: 0.0713 - val_accuracy: 0.9736\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0538 - accuracy: 0.9791 - val_loss: 0.0688 - val_accuracy: 0.9666\n","Epoch 26/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9803 - val_loss: 0.0716 - val_accuracy: 0.9754\n","Epoch 27/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9803 - val_loss: 0.0712 - val_accuracy: 0.9719\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0511 - accuracy: 0.9806 - val_loss: 0.0685 - val_accuracy: 0.9772\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.9830 - val_loss: 0.0760 - val_accuracy: 0.9684\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0500 - accuracy: 0.9812 - val_loss: 0.0701 - val_accuracy: 0.9719\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0483 - accuracy: 0.9824 - val_loss: 0.0755 - val_accuracy: 0.9684\n","Epoch 32/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9781 - val_loss: 0.0661 - val_accuracy: 0.9789\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9814 - val_loss: 0.0657 - val_accuracy: 0.9772\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0467 - accuracy: 0.9824 - val_loss: 0.0676 - val_accuracy: 0.9772\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0453 - accuracy: 0.9822 - val_loss: 0.0661 - val_accuracy: 0.9772\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0447 - accuracy: 0.9844 - val_loss: 0.0650 - val_accuracy: 0.9772\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0433 - accuracy: 0.9838 - val_loss: 0.0647 - val_accuracy: 0.9772\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0427 - accuracy: 0.9842 - val_loss: 0.0645 - val_accuracy: 0.9772\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0422 - accuracy: 0.9828 - val_loss: 0.0651 - val_accuracy: 0.9772\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0417 - accuracy: 0.9822 - val_loss: 0.0670 - val_accuracy: 0.9772\n","Epoch 41/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0406 - accuracy: 0.9846 - val_loss: 0.0655 - val_accuracy: 0.9789\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0403 - accuracy: 0.9838 - val_loss: 0.0650 - val_accuracy: 0.9789\n","Epoch 43/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9849 - val_loss: 0.0681 - val_accuracy: 0.9772\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0389 - accuracy: 0.9834 - val_loss: 0.0650 - val_accuracy: 0.9754\n","Epoch 45/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0386 - accuracy: 0.9855 - val_loss: 0.0629 - val_accuracy: 0.9789\n","Epoch 46/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0378 - accuracy: 0.9842 - val_loss: 0.0645 - val_accuracy: 0.9772\n","Epoch 47/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0371 - accuracy: 0.9849 - val_loss: 0.0665 - val_accuracy: 0.9789\n","Epoch 48/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0365 - accuracy: 0.9857 - val_loss: 0.0598 - val_accuracy: 0.9772\n","Epoch 49/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9867 - val_loss: 0.0628 - val_accuracy: 0.9754\n","Epoch 50/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0350 - accuracy: 0.9867 - val_loss: 0.0584 - val_accuracy: 0.9789\n","Epoch 51/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0347 - accuracy: 0.9871 - val_loss: 0.0626 - val_accuracy: 0.9772\n","Epoch 52/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0345 - accuracy: 0.9867 - val_loss: 0.0618 - val_accuracy: 0.9772\n","Epoch 53/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.9877 - val_loss: 0.0600 - val_accuracy: 0.9772\n","Epoch 54/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9877 - val_loss: 0.0579 - val_accuracy: 0.9772\n","Epoch 55/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0333 - accuracy: 0.9873 - val_loss: 0.0633 - val_accuracy: 0.9789\n","Epoch 56/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0392 - accuracy: 0.9838 - val_loss: 0.0666 - val_accuracy: 0.9772\n","Epoch 57/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0344 - accuracy: 0.9865 - val_loss: 0.0563 - val_accuracy: 0.9789\n","Epoch 58/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0329 - accuracy: 0.9869 - val_loss: 0.0596 - val_accuracy: 0.9789\n","Epoch 59/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0320 - accuracy: 0.9859 - val_loss: 0.0594 - val_accuracy: 0.9789\n","Epoch 60/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9875 - val_loss: 0.0552 - val_accuracy: 0.9789\n","Epoch 61/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 0.0566 - val_accuracy: 0.9789\n","Epoch 62/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0298 - accuracy: 0.9891 - val_loss: 0.0557 - val_accuracy: 0.9789\n","Epoch 63/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0303 - accuracy: 0.9892 - val_loss: 0.0572 - val_accuracy: 0.9772\n","Epoch 64/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.9887 - val_loss: 0.0562 - val_accuracy: 0.9807\n","Epoch 65/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0295 - accuracy: 0.9885 - val_loss: 0.0569 - val_accuracy: 0.9789\n","Epoch 66/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0282 - accuracy: 0.9883 - val_loss: 0.0558 - val_accuracy: 0.9789\n","Epoch 67/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9892 - val_loss: 0.0549 - val_accuracy: 0.9772\n","Epoch 68/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0286 - accuracy: 0.9892 - val_loss: 0.0514 - val_accuracy: 0.9824\n","Epoch 69/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0274 - accuracy: 0.9891 - val_loss: 0.0531 - val_accuracy: 0.9807\n","Epoch 70/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9900 - val_loss: 0.0553 - val_accuracy: 0.9772\n","Epoch 71/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0275 - accuracy: 0.9889 - val_loss: 0.0529 - val_accuracy: 0.9807\n","Epoch 72/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0274 - accuracy: 0.9900 - val_loss: 0.0533 - val_accuracy: 0.9807\n","Epoch 73/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0268 - accuracy: 0.9892 - val_loss: 0.0553 - val_accuracy: 0.9807\n","Epoch 74/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0268 - accuracy: 0.9904 - val_loss: 0.0538 - val_accuracy: 0.9807\n","Epoch 75/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0256 - accuracy: 0.9906 - val_loss: 0.0526 - val_accuracy: 0.9789\n","Epoch 76/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0264 - accuracy: 0.9894 - val_loss: 0.0521 - val_accuracy: 0.9789\n","Epoch 77/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0255 - accuracy: 0.9908 - val_loss: 0.0518 - val_accuracy: 0.9789\n","Epoch 78/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0253 - accuracy: 0.9900 - val_loss: 0.0517 - val_accuracy: 0.9789\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.98      0.98       335\n","           1       0.97      0.97      0.97       234\n","\n","    accuracy                           0.98       569\n","   macro avg       0.98      0.98      0.98       569\n","weighted avg       0.98      0.98      0.98       569\n","\n","Accuracy: 0.9789103690685413\n","[[329   6]\n"," [  6 228]]\n","Precision: 0.9744\n","Recall: 0.9744\n","F1 Score: 0.9744\n","INFO:tensorflow:Assets written to: ram://2712d608-ccb7-4b46-affb-45280c691ffe/assets\n","model 3 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2816 - accuracy: 0.8958 - val_loss: 0.1756 - val_accuracy: 0.9350\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1314 - accuracy: 0.9558 - val_loss: 0.1334 - val_accuracy: 0.9596\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1048 - accuracy: 0.9652 - val_loss: 0.1171 - val_accuracy: 0.9666\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9683 - val_loss: 0.1188 - val_accuracy: 0.9613\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0864 - accuracy: 0.9715 - val_loss: 0.1039 - val_accuracy: 0.9649\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0806 - accuracy: 0.9726 - val_loss: 0.0989 - val_accuracy: 0.9666\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0784 - accuracy: 0.9720 - val_loss: 0.0953 - val_accuracy: 0.9684\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0740 - accuracy: 0.9742 - val_loss: 0.0930 - val_accuracy: 0.9684\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0718 - accuracy: 0.9752 - val_loss: 0.1724 - val_accuracy: 0.9649\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0689 - accuracy: 0.9760 - val_loss: 0.1788 - val_accuracy: 0.9596\n","Epoch 11/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0658 - accuracy: 0.9754 - val_loss: 0.1048 - val_accuracy: 0.9684\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0638 - accuracy: 0.9771 - val_loss: 0.1604 - val_accuracy: 0.9666\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0623 - accuracy: 0.9769 - val_loss: 0.1115 - val_accuracy: 0.9666\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0616 - accuracy: 0.9777 - val_loss: 0.0991 - val_accuracy: 0.9666\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9785 - val_loss: 0.1441 - val_accuracy: 0.9684\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9791 - val_loss: 0.0776 - val_accuracy: 0.9701\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0552 - accuracy: 0.9801 - val_loss: 0.2383 - val_accuracy: 0.9578\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0555 - accuracy: 0.9785 - val_loss: 0.0932 - val_accuracy: 0.9736\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9789 - val_loss: 0.1144 - val_accuracy: 0.9736\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0526 - accuracy: 0.9805 - val_loss: 0.0807 - val_accuracy: 0.9754\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0515 - accuracy: 0.9810 - val_loss: 0.1342 - val_accuracy: 0.9719\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0514 - accuracy: 0.9806 - val_loss: 0.1189 - val_accuracy: 0.9736\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0490 - accuracy: 0.9820 - val_loss: 0.2411 - val_accuracy: 0.9649\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0482 - accuracy: 0.9822 - val_loss: 0.1161 - val_accuracy: 0.9754\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0472 - accuracy: 0.9828 - val_loss: 0.1594 - val_accuracy: 0.9736\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0469 - accuracy: 0.9806 - val_loss: 0.1845 - val_accuracy: 0.9701\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.98      0.97       325\n","           1       0.98      0.95      0.96       244\n","\n","    accuracy                           0.97       569\n","   macro avg       0.97      0.97      0.97       569\n","weighted avg       0.97      0.97      0.97       569\n","\n","Accuracy: 0.9701230228471002\n","[[320   5]\n"," [ 12 232]]\n","Precision: 0.9789\n","Recall: 0.9508\n","F1 Score: 0.9647\n","INFO:tensorflow:Assets written to: ram://9f897dfe-8364-482b-bec2-c62e6a189d4a/assets\n","model 4 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.4690 - accuracy: 0.8478 - val_loss: 0.1496 - val_accuracy: 0.9419\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1419 - accuracy: 0.9466 - val_loss: 0.0929 - val_accuracy: 0.9665\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1037 - accuracy: 0.9681 - val_loss: 0.0748 - val_accuracy: 0.9718\n","Epoch 4/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0910 - accuracy: 0.9705 - val_loss: 0.0667 - val_accuracy: 0.9789\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0856 - accuracy: 0.9707 - val_loss: 0.0677 - val_accuracy: 0.9754\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0812 - accuracy: 0.9734 - val_loss: 0.0609 - val_accuracy: 0.9806\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0772 - accuracy: 0.9732 - val_loss: 0.0602 - val_accuracy: 0.9824\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0737 - accuracy: 0.9762 - val_loss: 0.0600 - val_accuracy: 0.9806\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0723 - accuracy: 0.9758 - val_loss: 0.0580 - val_accuracy: 0.9806\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0788 - accuracy: 0.9732 - val_loss: 0.0671 - val_accuracy: 0.9736\n","Epoch 11/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0705 - accuracy: 0.9760 - val_loss: 0.0563 - val_accuracy: 0.9806\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0672 - accuracy: 0.9771 - val_loss: 0.0543 - val_accuracy: 0.9771\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0655 - accuracy: 0.9777 - val_loss: 0.0534 - val_accuracy: 0.9771\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0642 - accuracy: 0.9767 - val_loss: 0.0532 - val_accuracy: 0.9824\n","Epoch 15/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0631 - accuracy: 0.9793 - val_loss: 0.0517 - val_accuracy: 0.9806\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0609 - accuracy: 0.9797 - val_loss: 0.0515 - val_accuracy: 0.9789\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0614 - accuracy: 0.9787 - val_loss: 0.0510 - val_accuracy: 0.9789\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0591 - accuracy: 0.9801 - val_loss: 0.0494 - val_accuracy: 0.9806\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0589 - accuracy: 0.9783 - val_loss: 0.0491 - val_accuracy: 0.9789\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.9799 - val_loss: 0.0480 - val_accuracy: 0.9771\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0561 - accuracy: 0.9807 - val_loss: 0.0470 - val_accuracy: 0.9789\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0564 - accuracy: 0.9814 - val_loss: 0.0493 - val_accuracy: 0.9806\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0549 - accuracy: 0.9793 - val_loss: 0.0526 - val_accuracy: 0.9842\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0555 - accuracy: 0.9803 - val_loss: 0.0452 - val_accuracy: 0.9789\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0526 - accuracy: 0.9820 - val_loss: 0.0455 - val_accuracy: 0.9789\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0528 - accuracy: 0.9814 - val_loss: 0.0456 - val_accuracy: 0.9789\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0628 - accuracy: 0.9781 - val_loss: 0.0501 - val_accuracy: 0.9824\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0519 - accuracy: 0.9828 - val_loss: 0.0442 - val_accuracy: 0.9824\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0504 - accuracy: 0.9836 - val_loss: 0.0446 - val_accuracy: 0.9806\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.9836 - val_loss: 0.0442 - val_accuracy: 0.9824\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0483 - accuracy: 0.9844 - val_loss: 0.0444 - val_accuracy: 0.9806\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9826 - val_loss: 0.0437 - val_accuracy: 0.9806\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0478 - accuracy: 0.9834 - val_loss: 0.0428 - val_accuracy: 0.9806\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0461 - accuracy: 0.9842 - val_loss: 0.0442 - val_accuracy: 0.9806\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0461 - accuracy: 0.9857 - val_loss: 0.0453 - val_accuracy: 0.9806\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0447 - accuracy: 0.9846 - val_loss: 0.0434 - val_accuracy: 0.9789\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0450 - accuracy: 0.9846 - val_loss: 0.0432 - val_accuracy: 0.9806\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0437 - accuracy: 0.9857 - val_loss: 0.0410 - val_accuracy: 0.9806\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0445 - accuracy: 0.9838 - val_loss: 0.0414 - val_accuracy: 0.9806\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0429 - accuracy: 0.9855 - val_loss: 0.0411 - val_accuracy: 0.9806\n","Epoch 41/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0421 - accuracy: 0.9865 - val_loss: 0.0413 - val_accuracy: 0.9824\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0419 - accuracy: 0.9850 - val_loss: 0.0408 - val_accuracy: 0.9806\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0414 - accuracy: 0.9859 - val_loss: 0.0402 - val_accuracy: 0.9824\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0408 - accuracy: 0.9861 - val_loss: 0.0418 - val_accuracy: 0.9824\n","Epoch 45/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0406 - accuracy: 0.9867 - val_loss: 0.0390 - val_accuracy: 0.9859\n","Epoch 46/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0409 - accuracy: 0.9865 - val_loss: 0.0423 - val_accuracy: 0.9824\n","Epoch 47/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0392 - accuracy: 0.9875 - val_loss: 0.0397 - val_accuracy: 0.9859\n","Epoch 48/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0391 - accuracy: 0.9873 - val_loss: 0.0394 - val_accuracy: 0.9806\n","Epoch 49/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0385 - accuracy: 0.9877 - val_loss: 0.0402 - val_accuracy: 0.9806\n","Epoch 50/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0387 - accuracy: 0.9859 - val_loss: 0.0380 - val_accuracy: 0.9842\n","Epoch 51/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.9873 - val_loss: 0.0369 - val_accuracy: 0.9859\n","Epoch 52/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9869 - val_loss: 0.0399 - val_accuracy: 0.9824\n","Epoch 53/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0383 - accuracy: 0.9861 - val_loss: 0.0374 - val_accuracy: 0.9842\n","Epoch 54/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0365 - accuracy: 0.9875 - val_loss: 0.0380 - val_accuracy: 0.9842\n","Epoch 55/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0360 - accuracy: 0.9877 - val_loss: 0.0386 - val_accuracy: 0.9806\n","Epoch 56/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0396 - accuracy: 0.9855 - val_loss: 0.0368 - val_accuracy: 0.9842\n","Epoch 57/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0370 - accuracy: 0.9863 - val_loss: 0.0369 - val_accuracy: 0.9806\n","Epoch 58/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0350 - accuracy: 0.9879 - val_loss: 0.0380 - val_accuracy: 0.9806\n","Epoch 59/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0354 - accuracy: 0.9875 - val_loss: 0.0387 - val_accuracy: 0.9842\n","Epoch 60/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0346 - accuracy: 0.9881 - val_loss: 0.0368 - val_accuracy: 0.9842\n","Epoch 61/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0341 - accuracy: 0.9881 - val_loss: 0.0363 - val_accuracy: 0.9859\n","Epoch 62/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0508 - accuracy: 0.9828 - val_loss: 0.0792 - val_accuracy: 0.9736\n","Epoch 63/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0383 - accuracy: 0.9869 - val_loss: 0.0398 - val_accuracy: 0.9859\n","Epoch 64/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0353 - accuracy: 0.9871 - val_loss: 0.0393 - val_accuracy: 0.9859\n","Epoch 65/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0341 - accuracy: 0.9869 - val_loss: 0.0379 - val_accuracy: 0.9824\n","Epoch 66/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9885 - val_loss: 0.0381 - val_accuracy: 0.9824\n","Epoch 67/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0326 - accuracy: 0.9879 - val_loss: 0.0395 - val_accuracy: 0.9842\n","Epoch 68/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0329 - accuracy: 0.9885 - val_loss: 0.0375 - val_accuracy: 0.9877\n","Epoch 69/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0320 - accuracy: 0.9883 - val_loss: 0.0361 - val_accuracy: 0.9859\n","Epoch 70/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9883 - val_loss: 0.0356 - val_accuracy: 0.9859\n","Epoch 71/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9898 - val_loss: 0.0347 - val_accuracy: 0.9842\n","Epoch 72/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0314 - accuracy: 0.9893 - val_loss: 0.0350 - val_accuracy: 0.9859\n","Epoch 73/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.0372 - val_accuracy: 0.9859\n","Epoch 74/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9881 - val_loss: 0.0344 - val_accuracy: 0.9842\n","Epoch 75/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0301 - accuracy: 0.9894 - val_loss: 0.0342 - val_accuracy: 0.9877\n","Epoch 76/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0314 - accuracy: 0.9894 - val_loss: 0.0322 - val_accuracy: 0.9859\n","Epoch 77/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0301 - accuracy: 0.9883 - val_loss: 0.0335 - val_accuracy: 0.9842\n","Epoch 78/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0303 - accuracy: 0.9883 - val_loss: 0.0375 - val_accuracy: 0.9842\n","Epoch 79/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0300 - accuracy: 0.9887 - val_loss: 0.0343 - val_accuracy: 0.9859\n","Epoch 80/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9877 - val_loss: 0.0340 - val_accuracy: 0.9842\n","Epoch 81/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0303 - accuracy: 0.9881 - val_loss: 0.0323 - val_accuracy: 0.9842\n","Epoch 82/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9898 - val_loss: 0.0313 - val_accuracy: 0.9859\n","Epoch 83/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0281 - accuracy: 0.9891 - val_loss: 0.0310 - val_accuracy: 0.9859\n","Epoch 84/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0293 - accuracy: 0.9893 - val_loss: 0.0327 - val_accuracy: 0.9877\n","Epoch 85/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0272 - accuracy: 0.9891 - val_loss: 0.0320 - val_accuracy: 0.9842\n","Epoch 86/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9893 - val_loss: 0.0313 - val_accuracy: 0.9859\n","Epoch 87/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0276 - accuracy: 0.9893 - val_loss: 0.0324 - val_accuracy: 0.9877\n","Epoch 88/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0279 - accuracy: 0.9893 - val_loss: 0.0320 - val_accuracy: 0.9894\n","Epoch 89/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0276 - accuracy: 0.9898 - val_loss: 0.0297 - val_accuracy: 0.9842\n","Epoch 90/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0270 - accuracy: 0.9910 - val_loss: 0.0308 - val_accuracy: 0.9877\n","Epoch 91/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9891 - val_loss: 0.0358 - val_accuracy: 0.9859\n","Epoch 92/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0279 - accuracy: 0.9898 - val_loss: 0.0311 - val_accuracy: 0.9859\n","Epoch 93/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0263 - accuracy: 0.9906 - val_loss: 0.0312 - val_accuracy: 0.9859\n","Epoch 94/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0257 - accuracy: 0.9891 - val_loss: 0.0332 - val_accuracy: 0.9877\n","Epoch 95/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0263 - accuracy: 0.9902 - val_loss: 0.0303 - val_accuracy: 0.9877\n","Epoch 96/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0254 - accuracy: 0.9900 - val_loss: 0.0309 - val_accuracy: 0.9859\n","Epoch 97/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0277 - accuracy: 0.9908 - val_loss: 0.0611 - val_accuracy: 0.9806\n","Epoch 98/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0264 - accuracy: 0.9902 - val_loss: 0.0299 - val_accuracy: 0.9859\n","Epoch 99/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9906 - val_loss: 0.0282 - val_accuracy: 0.9877\n","Epoch 100/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0245 - accuracy: 0.9908 - val_loss: 0.0296 - val_accuracy: 0.9877\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.99      0.99       301\n","           1       0.99      0.99      0.99       267\n","\n","    accuracy                           0.99       568\n","   macro avg       0.99      0.99      0.99       568\n","weighted avg       0.99      0.99      0.99       568\n","\n","Accuracy: 0.9876760563380281\n","[[297   4]\n"," [  3 264]]\n","Precision: 0.9851\n","Recall: 0.9888\n","F1 Score: 0.9869\n","INFO:tensorflow:Assets written to: ram://9d09d5a6-0907-4c40-850b-e3df313e956d/assets\n","model 5 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3655 - accuracy: 0.8898 - val_loss: 0.1921 - val_accuracy: 0.9507\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1658 - accuracy: 0.9416 - val_loss: 0.1300 - val_accuracy: 0.9595\n","Epoch 3/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1192 - accuracy: 0.9644 - val_loss: 0.1076 - val_accuracy: 0.9665\n","Epoch 4/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1050 - accuracy: 0.9668 - val_loss: 0.0988 - val_accuracy: 0.9701\n","Epoch 5/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0964 - accuracy: 0.9697 - val_loss: 0.0905 - val_accuracy: 0.9683\n","Epoch 6/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0904 - accuracy: 0.9701 - val_loss: 0.0864 - val_accuracy: 0.9701\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0864 - accuracy: 0.9722 - val_loss: 0.0838 - val_accuracy: 0.9718\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0893 - accuracy: 0.9683 - val_loss: 0.0934 - val_accuracy: 0.9613\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0837 - accuracy: 0.9717 - val_loss: 0.0817 - val_accuracy: 0.9754\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0783 - accuracy: 0.9722 - val_loss: 0.0783 - val_accuracy: 0.9718\n","Epoch 11/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0756 - accuracy: 0.9734 - val_loss: 0.0773 - val_accuracy: 0.9736\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0743 - accuracy: 0.9728 - val_loss: 0.0758 - val_accuracy: 0.9718\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0734 - accuracy: 0.9752 - val_loss: 0.0745 - val_accuracy: 0.9736\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0711 - accuracy: 0.9754 - val_loss: 0.0750 - val_accuracy: 0.9754\n","Epoch 15/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0696 - accuracy: 0.9740 - val_loss: 0.0732 - val_accuracy: 0.9736\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0689 - accuracy: 0.9748 - val_loss: 0.0717 - val_accuracy: 0.9754\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0677 - accuracy: 0.9738 - val_loss: 0.0717 - val_accuracy: 0.9736\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0666 - accuracy: 0.9744 - val_loss: 0.0725 - val_accuracy: 0.9754\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0647 - accuracy: 0.9758 - val_loss: 0.0704 - val_accuracy: 0.9754\n","Epoch 20/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0639 - accuracy: 0.9758 - val_loss: 0.0706 - val_accuracy: 0.9754\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0629 - accuracy: 0.9765 - val_loss: 0.0686 - val_accuracy: 0.9754\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0667 - accuracy: 0.9730 - val_loss: 0.0760 - val_accuracy: 0.9736\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0628 - accuracy: 0.9750 - val_loss: 0.0685 - val_accuracy: 0.9771\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0606 - accuracy: 0.9775 - val_loss: 0.0664 - val_accuracy: 0.9754\n","Epoch 25/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0603 - accuracy: 0.9767 - val_loss: 0.0663 - val_accuracy: 0.9754\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0582 - accuracy: 0.9785 - val_loss: 0.0661 - val_accuracy: 0.9736\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0567 - accuracy: 0.9762 - val_loss: 0.0657 - val_accuracy: 0.9789\n","Epoch 28/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0566 - accuracy: 0.9779 - val_loss: 0.0657 - val_accuracy: 0.9754\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0550 - accuracy: 0.9773 - val_loss: 0.0657 - val_accuracy: 0.9789\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0546 - accuracy: 0.9793 - val_loss: 0.0651 - val_accuracy: 0.9771\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9791 - val_loss: 0.0660 - val_accuracy: 0.9754\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0538 - accuracy: 0.9785 - val_loss: 0.0641 - val_accuracy: 0.9771\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0532 - accuracy: 0.9779 - val_loss: 0.0643 - val_accuracy: 0.9771\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0525 - accuracy: 0.9797 - val_loss: 0.0623 - val_accuracy: 0.9771\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0518 - accuracy: 0.9801 - val_loss: 0.0604 - val_accuracy: 0.9789\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0509 - accuracy: 0.9805 - val_loss: 0.0625 - val_accuracy: 0.9789\n","Epoch 37/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0505 - accuracy: 0.9799 - val_loss: 0.0612 - val_accuracy: 0.9771\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0499 - accuracy: 0.9814 - val_loss: 0.0585 - val_accuracy: 0.9754\n","Epoch 39/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0502 - accuracy: 0.9805 - val_loss: 0.0598 - val_accuracy: 0.9789\n","Epoch 40/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9820 - val_loss: 0.0598 - val_accuracy: 0.9789\n","Epoch 41/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0483 - accuracy: 0.9820 - val_loss: 0.0589 - val_accuracy: 0.9789\n","Epoch 42/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0470 - accuracy: 0.9832 - val_loss: 0.0620 - val_accuracy: 0.9771\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0474 - accuracy: 0.9814 - val_loss: 0.0561 - val_accuracy: 0.9771\n","Epoch 44/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0467 - accuracy: 0.9818 - val_loss: 0.0560 - val_accuracy: 0.9789\n","Epoch 45/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0465 - accuracy: 0.9834 - val_loss: 0.0559 - val_accuracy: 0.9789\n","Epoch 46/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0457 - accuracy: 0.9830 - val_loss: 0.0551 - val_accuracy: 0.9806\n","Epoch 47/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0445 - accuracy: 0.9838 - val_loss: 0.0541 - val_accuracy: 0.9789\n","Epoch 48/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0449 - accuracy: 0.9818 - val_loss: 0.0542 - val_accuracy: 0.9806\n","Epoch 49/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.9844 - val_loss: 0.0549 - val_accuracy: 0.9806\n","Epoch 50/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0425 - accuracy: 0.9838 - val_loss: 0.0535 - val_accuracy: 0.9789\n","Epoch 51/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0424 - accuracy: 0.9842 - val_loss: 0.0515 - val_accuracy: 0.9806\n","Epoch 52/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0421 - accuracy: 0.9848 - val_loss: 0.0531 - val_accuracy: 0.9806\n","Epoch 53/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0425 - accuracy: 0.9848 - val_loss: 0.0514 - val_accuracy: 0.9806\n","Epoch 54/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0427 - accuracy: 0.9840 - val_loss: 0.0526 - val_accuracy: 0.9806\n","Epoch 55/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0410 - accuracy: 0.9857 - val_loss: 0.0511 - val_accuracy: 0.9806\n","Epoch 56/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.9857 - val_loss: 0.0507 - val_accuracy: 0.9806\n","Epoch 57/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0407 - accuracy: 0.9846 - val_loss: 0.0513 - val_accuracy: 0.9806\n","Epoch 58/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0402 - accuracy: 0.9851 - val_loss: 0.0504 - val_accuracy: 0.9806\n","Epoch 59/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0408 - accuracy: 0.9851 - val_loss: 0.0532 - val_accuracy: 0.9771\n","Epoch 60/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0396 - accuracy: 0.9855 - val_loss: 0.0511 - val_accuracy: 0.9806\n","Epoch 61/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0387 - accuracy: 0.9865 - val_loss: 0.0482 - val_accuracy: 0.9824\n","Epoch 62/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0448 - accuracy: 0.9830 - val_loss: 0.0541 - val_accuracy: 0.9789\n","Epoch 63/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0386 - accuracy: 0.9861 - val_loss: 0.0501 - val_accuracy: 0.9824\n","Epoch 64/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0373 - accuracy: 0.9861 - val_loss: 0.0480 - val_accuracy: 0.9824\n","Epoch 65/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0376 - accuracy: 0.9861 - val_loss: 0.0486 - val_accuracy: 0.9842\n","Epoch 66/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.9848 - val_loss: 0.0479 - val_accuracy: 0.9824\n","Epoch 67/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0367 - accuracy: 0.9859 - val_loss: 0.0476 - val_accuracy: 0.9806\n","Epoch 68/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0360 - accuracy: 0.9873 - val_loss: 0.0472 - val_accuracy: 0.9824\n","Epoch 69/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0361 - accuracy: 0.9869 - val_loss: 0.0479 - val_accuracy: 0.9842\n","Epoch 70/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0354 - accuracy: 0.9865 - val_loss: 0.0470 - val_accuracy: 0.9824\n","Epoch 71/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0356 - accuracy: 0.9867 - val_loss: 0.0462 - val_accuracy: 0.9842\n","Epoch 72/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0345 - accuracy: 0.9877 - val_loss: 0.0463 - val_accuracy: 0.9806\n","Epoch 73/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9873 - val_loss: 0.0466 - val_accuracy: 0.9824\n","Epoch 74/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0349 - accuracy: 0.9867 - val_loss: 0.0462 - val_accuracy: 0.9806\n","Epoch 75/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0342 - accuracy: 0.9879 - val_loss: 0.0473 - val_accuracy: 0.9842\n","Epoch 76/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9861 - val_loss: 0.0506 - val_accuracy: 0.9789\n","Epoch 77/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0353 - accuracy: 0.9873 - val_loss: 0.0456 - val_accuracy: 0.9824\n","Epoch 78/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0331 - accuracy: 0.9879 - val_loss: 0.0463 - val_accuracy: 0.9824\n","Epoch 79/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0337 - accuracy: 0.9867 - val_loss: 0.0468 - val_accuracy: 0.9824\n","Epoch 80/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0325 - accuracy: 0.9879 - val_loss: 0.0511 - val_accuracy: 0.9789\n","Epoch 81/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0329 - accuracy: 0.9877 - val_loss: 0.0473 - val_accuracy: 0.9806\n","Epoch 82/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0319 - accuracy: 0.9873 - val_loss: 0.0457 - val_accuracy: 0.9824\n","Epoch 83/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9881 - val_loss: 0.0470 - val_accuracy: 0.9806\n","Epoch 84/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9881 - val_loss: 0.0435 - val_accuracy: 0.9842\n","Epoch 85/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.9881 - val_loss: 0.0465 - val_accuracy: 0.9824\n","Epoch 86/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0313 - accuracy: 0.9879 - val_loss: 0.0449 - val_accuracy: 0.9824\n","Epoch 87/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0311 - accuracy: 0.9885 - val_loss: 0.0471 - val_accuracy: 0.9824\n","Epoch 88/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0304 - accuracy: 0.9889 - val_loss: 0.0486 - val_accuracy: 0.9806\n","Epoch 89/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9879 - val_loss: 0.0454 - val_accuracy: 0.9806\n","Epoch 90/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9871 - val_loss: 0.0457 - val_accuracy: 0.9824\n","Epoch 91/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9894 - val_loss: 0.0445 - val_accuracy: 0.9824\n","Epoch 92/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0300 - accuracy: 0.9893 - val_loss: 0.0452 - val_accuracy: 0.9806\n","Epoch 93/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9867 - val_loss: 0.0458 - val_accuracy: 0.9824\n","Epoch 94/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.9881 - val_loss: 0.0452 - val_accuracy: 0.9789\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.98      0.98       334\n","           1       0.97      0.97      0.97       234\n","\n","    accuracy                           0.98       568\n","   macro avg       0.98      0.98      0.98       568\n","weighted avg       0.98      0.98      0.98       568\n","\n","Accuracy: 0.9788732394366197\n","[[328   6]\n"," [  6 228]]\n","Precision: 0.9744\n","Recall: 0.9744\n","F1 Score: 0.9744\n","INFO:tensorflow:Assets written to: ram://2be7910b-bc64-48e4-a31c-dff34b991f45/assets\n","model 6 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3176 - accuracy: 0.9009 - val_loss: 0.1562 - val_accuracy: 0.9401\n","Epoch 2/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1313 - accuracy: 0.9564 - val_loss: 0.1269 - val_accuracy: 0.9472\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1103 - accuracy: 0.9635 - val_loss: 0.1149 - val_accuracy: 0.9595\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1011 - accuracy: 0.9668 - val_loss: 0.1200 - val_accuracy: 0.9525\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9679 - val_loss: 0.1061 - val_accuracy: 0.9630\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0877 - accuracy: 0.9689 - val_loss: 0.1057 - val_accuracy: 0.9630\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0845 - accuracy: 0.9711 - val_loss: 0.1017 - val_accuracy: 0.9665\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0820 - accuracy: 0.9707 - val_loss: 0.0987 - val_accuracy: 0.9665\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0781 - accuracy: 0.9724 - val_loss: 0.1059 - val_accuracy: 0.9577\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0854 - accuracy: 0.9687 - val_loss: 0.1191 - val_accuracy: 0.9560\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0778 - accuracy: 0.9726 - val_loss: 0.1021 - val_accuracy: 0.9613\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0726 - accuracy: 0.9732 - val_loss: 0.0990 - val_accuracy: 0.9648\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0700 - accuracy: 0.9756 - val_loss: 0.0972 - val_accuracy: 0.9630\n","Epoch 14/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0678 - accuracy: 0.9756 - val_loss: 0.0999 - val_accuracy: 0.9613\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0665 - accuracy: 0.9764 - val_loss: 0.0950 - val_accuracy: 0.9613\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0653 - accuracy: 0.9764 - val_loss: 0.0923 - val_accuracy: 0.9683\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0636 - accuracy: 0.9777 - val_loss: 0.0908 - val_accuracy: 0.9665\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0611 - accuracy: 0.9787 - val_loss: 0.0909 - val_accuracy: 0.9648\n","Epoch 19/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0610 - accuracy: 0.9787 - val_loss: 0.1032 - val_accuracy: 0.9595\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0682 - accuracy: 0.9730 - val_loss: 0.1098 - val_accuracy: 0.9577\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0636 - accuracy: 0.9756 - val_loss: 0.0941 - val_accuracy: 0.9577\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0578 - accuracy: 0.9785 - val_loss: 0.0916 - val_accuracy: 0.9630\n","Epoch 23/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0555 - accuracy: 0.9795 - val_loss: 0.0876 - val_accuracy: 0.9613\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0543 - accuracy: 0.9797 - val_loss: 0.0889 - val_accuracy: 0.9630\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0531 - accuracy: 0.9808 - val_loss: 0.0875 - val_accuracy: 0.9630\n","Epoch 26/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0679 - accuracy: 0.9762 - val_loss: 0.1144 - val_accuracy: 0.9542\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0574 - accuracy: 0.9789 - val_loss: 0.0875 - val_accuracy: 0.9613\n","Epoch 28/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0517 - accuracy: 0.9810 - val_loss: 0.0839 - val_accuracy: 0.9648\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0504 - accuracy: 0.9818 - val_loss: 0.0802 - val_accuracy: 0.9683\n","Epoch 30/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0488 - accuracy: 0.9807 - val_loss: 0.0804 - val_accuracy: 0.9683\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0480 - accuracy: 0.9814 - val_loss: 0.0887 - val_accuracy: 0.9595\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0492 - accuracy: 0.9818 - val_loss: 0.1078 - val_accuracy: 0.9595\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0624 - accuracy: 0.9764 - val_loss: 0.0862 - val_accuracy: 0.9630\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0478 - accuracy: 0.9822 - val_loss: 0.0809 - val_accuracy: 0.9648\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0466 - accuracy: 0.9818 - val_loss: 0.0789 - val_accuracy: 0.9683\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0450 - accuracy: 0.9830 - val_loss: 0.0766 - val_accuracy: 0.9683\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.9832 - val_loss: 0.0803 - val_accuracy: 0.9630\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0434 - accuracy: 0.9838 - val_loss: 0.0750 - val_accuracy: 0.9736\n","Epoch 39/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0437 - accuracy: 0.9836 - val_loss: 0.0746 - val_accuracy: 0.9701\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0423 - accuracy: 0.9842 - val_loss: 0.0804 - val_accuracy: 0.9630\n","Epoch 41/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0412 - accuracy: 0.9842 - val_loss: 0.0855 - val_accuracy: 0.9630\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0434 - accuracy: 0.9844 - val_loss: 0.1027 - val_accuracy: 0.9665\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0565 - accuracy: 0.9777 - val_loss: 0.0744 - val_accuracy: 0.9683\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0418 - accuracy: 0.9836 - val_loss: 0.0774 - val_accuracy: 0.9648\n","Epoch 45/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0407 - accuracy: 0.9842 - val_loss: 0.0733 - val_accuracy: 0.9683\n","Epoch 46/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0391 - accuracy: 0.9850 - val_loss: 0.0760 - val_accuracy: 0.9683\n","Epoch 47/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0386 - accuracy: 0.9851 - val_loss: 0.0760 - val_accuracy: 0.9701\n","Epoch 48/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0383 - accuracy: 0.9859 - val_loss: 0.0750 - val_accuracy: 0.9701\n","Epoch 49/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0369 - accuracy: 0.9857 - val_loss: 0.0856 - val_accuracy: 0.9630\n","Epoch 50/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.9859 - val_loss: 0.0693 - val_accuracy: 0.9718\n","Epoch 51/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0364 - accuracy: 0.9871 - val_loss: 0.0702 - val_accuracy: 0.9718\n","Epoch 52/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0360 - accuracy: 0.9863 - val_loss: 0.0712 - val_accuracy: 0.9683\n","Epoch 53/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0355 - accuracy: 0.9859 - val_loss: 0.0755 - val_accuracy: 0.9683\n","Epoch 54/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0507 - accuracy: 0.9803 - val_loss: 0.0786 - val_accuracy: 0.9665\n","Epoch 55/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0384 - accuracy: 0.9855 - val_loss: 0.0747 - val_accuracy: 0.9665\n","Epoch 56/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0359 - accuracy: 0.9873 - val_loss: 0.0748 - val_accuracy: 0.9683\n","Epoch 57/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0350 - accuracy: 0.9863 - val_loss: 0.0714 - val_accuracy: 0.9683\n","Epoch 58/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.9875 - val_loss: 0.0697 - val_accuracy: 0.9701\n","Epoch 59/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.9881 - val_loss: 0.0748 - val_accuracy: 0.9701\n","Epoch 60/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0326 - accuracy: 0.9883 - val_loss: 0.0667 - val_accuracy: 0.9771\n","Epoch 61/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0326 - accuracy: 0.9873 - val_loss: 0.0655 - val_accuracy: 0.9718\n","Epoch 62/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 0.0657 - val_accuracy: 0.9736\n","Epoch 63/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9875 - val_loss: 0.0733 - val_accuracy: 0.9736\n","Epoch 64/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9877 - val_loss: 0.0811 - val_accuracy: 0.9683\n","Epoch 65/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9889 - val_loss: 0.0716 - val_accuracy: 0.9701\n","Epoch 66/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9885 - val_loss: 0.0693 - val_accuracy: 0.9701\n","Epoch 67/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0298 - accuracy: 0.9900 - val_loss: 0.0823 - val_accuracy: 0.9718\n","Epoch 68/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0299 - accuracy: 0.9883 - val_loss: 0.0655 - val_accuracy: 0.9754\n","Epoch 69/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9891 - val_loss: 0.0792 - val_accuracy: 0.9701\n","Epoch 70/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0332 - accuracy: 0.9877 - val_loss: 0.0678 - val_accuracy: 0.9718\n","Epoch 71/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9896 - val_loss: 0.0668 - val_accuracy: 0.9718\n","Epoch 72/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 0.0676 - val_accuracy: 0.9736\n","Epoch 73/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9887 - val_loss: 0.0651 - val_accuracy: 0.9789\n","Epoch 74/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9896 - val_loss: 0.0699 - val_accuracy: 0.9701\n","Epoch 75/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9900 - val_loss: 0.0711 - val_accuracy: 0.9736\n","Epoch 76/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0275 - accuracy: 0.9887 - val_loss: 0.0641 - val_accuracy: 0.9718\n","Epoch 77/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.0687 - val_accuracy: 0.9771\n","Epoch 78/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0457 - accuracy: 0.9830 - val_loss: 0.0684 - val_accuracy: 0.9736\n","Epoch 79/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 0.0567 - val_accuracy: 0.9824\n","Epoch 80/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0268 - accuracy: 0.9908 - val_loss: 0.0625 - val_accuracy: 0.9736\n","Epoch 81/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0253 - accuracy: 0.9914 - val_loss: 0.0710 - val_accuracy: 0.9718\n","Epoch 82/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.0691 - val_accuracy: 0.9718\n","Epoch 83/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0247 - accuracy: 0.9910 - val_loss: 0.0703 - val_accuracy: 0.9736\n","Epoch 84/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0246 - accuracy: 0.9908 - val_loss: 0.0705 - val_accuracy: 0.9701\n","Epoch 85/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0244 - accuracy: 0.9910 - val_loss: 0.0637 - val_accuracy: 0.9771\n","Epoch 86/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0243 - accuracy: 0.9916 - val_loss: 0.0722 - val_accuracy: 0.9718\n","Epoch 87/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0235 - accuracy: 0.9912 - val_loss: 0.0715 - val_accuracy: 0.9736\n","Epoch 88/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0235 - accuracy: 0.9916 - val_loss: 0.0610 - val_accuracy: 0.9806\n","Epoch 89/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0234 - accuracy: 0.9910 - val_loss: 0.0648 - val_accuracy: 0.9754\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.99      0.98       318\n","           1       0.99      0.96      0.97       250\n","\n","    accuracy                           0.98       568\n","   macro avg       0.98      0.97      0.97       568\n","weighted avg       0.98      0.98      0.98       568\n","\n","Accuracy: 0.9753521126760564\n","[[315   3]\n"," [ 11 239]]\n","Precision: 0.9876\n","Recall: 0.9560\n","F1 Score: 0.9715\n","INFO:tensorflow:Assets written to: ram://d8674a9a-f645-4f46-a712-c9664d222ccb/assets\n","model 7 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2801 - accuracy: 0.9021 - val_loss: 0.1493 - val_accuracy: 0.9577\n","Epoch 2/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1399 - accuracy: 0.9513 - val_loss: 0.1167 - val_accuracy: 0.9613\n","Epoch 3/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1127 - accuracy: 0.9623 - val_loss: 0.1071 - val_accuracy: 0.9595\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1012 - accuracy: 0.9674 - val_loss: 0.0979 - val_accuracy: 0.9648\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0911 - accuracy: 0.9717 - val_loss: 0.0899 - val_accuracy: 0.9648\n","Epoch 6/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0864 - accuracy: 0.9715 - val_loss: 0.1004 - val_accuracy: 0.9613\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0837 - accuracy: 0.9721 - val_loss: 0.0877 - val_accuracy: 0.9701\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0817 - accuracy: 0.9734 - val_loss: 0.0851 - val_accuracy: 0.9683\n","Epoch 9/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0778 - accuracy: 0.9738 - val_loss: 0.0814 - val_accuracy: 0.9736\n","Epoch 10/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0758 - accuracy: 0.9748 - val_loss: 0.0814 - val_accuracy: 0.9701\n","Epoch 11/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0739 - accuracy: 0.9740 - val_loss: 0.0843 - val_accuracy: 0.9701\n","Epoch 12/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0733 - accuracy: 0.9740 - val_loss: 0.0804 - val_accuracy: 0.9701\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0732 - accuracy: 0.9744 - val_loss: 0.0756 - val_accuracy: 0.9736\n","Epoch 14/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0710 - accuracy: 0.9754 - val_loss: 0.0770 - val_accuracy: 0.9754\n","Epoch 15/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0701 - accuracy: 0.9744 - val_loss: 0.0770 - val_accuracy: 0.9771\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0690 - accuracy: 0.9752 - val_loss: 0.0761 - val_accuracy: 0.9736\n","Epoch 17/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0723 - accuracy: 0.9746 - val_loss: 0.0903 - val_accuracy: 0.9683\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0702 - accuracy: 0.9748 - val_loss: 0.0734 - val_accuracy: 0.9754\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0664 - accuracy: 0.9754 - val_loss: 0.0719 - val_accuracy: 0.9771\n","Epoch 20/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0634 - accuracy: 0.9762 - val_loss: 0.0725 - val_accuracy: 0.9789\n","Epoch 21/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0632 - accuracy: 0.9785 - val_loss: 0.0733 - val_accuracy: 0.9718\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0623 - accuracy: 0.9775 - val_loss: 0.0691 - val_accuracy: 0.9754\n","Epoch 23/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0609 - accuracy: 0.9767 - val_loss: 0.0694 - val_accuracy: 0.9771\n","Epoch 24/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0603 - accuracy: 0.9777 - val_loss: 0.0689 - val_accuracy: 0.9806\n","Epoch 25/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0595 - accuracy: 0.9781 - val_loss: 0.0700 - val_accuracy: 0.9806\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0592 - accuracy: 0.9767 - val_loss: 0.0678 - val_accuracy: 0.9718\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0576 - accuracy: 0.9783 - val_loss: 0.0653 - val_accuracy: 0.9771\n","Epoch 28/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0575 - accuracy: 0.9789 - val_loss: 0.0674 - val_accuracy: 0.9736\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0644 - accuracy: 0.9769 - val_loss: 0.0793 - val_accuracy: 0.9736\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0582 - accuracy: 0.9773 - val_loss: 0.0680 - val_accuracy: 0.9771\n","Epoch 31/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0557 - accuracy: 0.9785 - val_loss: 0.0647 - val_accuracy: 0.9789\n","Epoch 32/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0541 - accuracy: 0.9791 - val_loss: 0.0644 - val_accuracy: 0.9806\n","Epoch 33/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0537 - accuracy: 0.9801 - val_loss: 0.0618 - val_accuracy: 0.9824\n","Epoch 34/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0534 - accuracy: 0.9797 - val_loss: 0.0629 - val_accuracy: 0.9789\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9795 - val_loss: 0.0635 - val_accuracy: 0.9754\n","Epoch 36/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0513 - accuracy: 0.9793 - val_loss: 0.0638 - val_accuracy: 0.9789\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9793 - val_loss: 0.0589 - val_accuracy: 0.9789\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0500 - accuracy: 0.9810 - val_loss: 0.0597 - val_accuracy: 0.9789\n","Epoch 39/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0491 - accuracy: 0.9822 - val_loss: 0.0589 - val_accuracy: 0.9789\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0486 - accuracy: 0.9822 - val_loss: 0.0580 - val_accuracy: 0.9806\n","Epoch 41/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0476 - accuracy: 0.9820 - val_loss: 0.0599 - val_accuracy: 0.9806\n","Epoch 42/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0465 - accuracy: 0.9832 - val_loss: 0.0600 - val_accuracy: 0.9789\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0472 - accuracy: 0.9826 - val_loss: 0.0585 - val_accuracy: 0.9806\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0448 - accuracy: 0.9838 - val_loss: 0.0567 - val_accuracy: 0.9806\n","Epoch 45/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0457 - accuracy: 0.9812 - val_loss: 0.0569 - val_accuracy: 0.9806\n","Epoch 46/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0449 - accuracy: 0.9820 - val_loss: 0.0597 - val_accuracy: 0.9806\n","Epoch 47/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0443 - accuracy: 0.9818 - val_loss: 0.0588 - val_accuracy: 0.9806\n","Epoch 48/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0435 - accuracy: 0.9836 - val_loss: 0.0576 - val_accuracy: 0.9806\n","Epoch 49/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0427 - accuracy: 0.9842 - val_loss: 0.0575 - val_accuracy: 0.9789\n","Epoch 50/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0426 - accuracy: 0.9834 - val_loss: 0.0570 - val_accuracy: 0.9806\n","Epoch 51/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0420 - accuracy: 0.9838 - val_loss: 0.0572 - val_accuracy: 0.9824\n","Epoch 52/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0421 - accuracy: 0.9836 - val_loss: 0.0557 - val_accuracy: 0.9806\n","Epoch 53/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0454 - accuracy: 0.9842 - val_loss: 0.0587 - val_accuracy: 0.9806\n","Epoch 54/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0410 - accuracy: 0.9840 - val_loss: 0.0547 - val_accuracy: 0.9824\n","Epoch 55/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0400 - accuracy: 0.9842 - val_loss: 0.0551 - val_accuracy: 0.9824\n","Epoch 56/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0399 - accuracy: 0.9838 - val_loss: 0.0542 - val_accuracy: 0.9806\n","Epoch 57/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0397 - accuracy: 0.9848 - val_loss: 0.0547 - val_accuracy: 0.9824\n","Epoch 58/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0381 - accuracy: 0.9848 - val_loss: 0.0560 - val_accuracy: 0.9806\n","Epoch 59/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0388 - accuracy: 0.9842 - val_loss: 0.0545 - val_accuracy: 0.9824\n","Epoch 60/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0375 - accuracy: 0.9857 - val_loss: 0.0573 - val_accuracy: 0.9806\n","Epoch 61/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0373 - accuracy: 0.9859 - val_loss: 0.0559 - val_accuracy: 0.9824\n","Epoch 62/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0483 - accuracy: 0.9832 - val_loss: 0.0820 - val_accuracy: 0.9718\n","Epoch 63/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0424 - accuracy: 0.9844 - val_loss: 0.0579 - val_accuracy: 0.9806\n","Epoch 64/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0361 - accuracy: 0.9859 - val_loss: 0.0566 - val_accuracy: 0.9806\n","Epoch 65/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0359 - accuracy: 0.9855 - val_loss: 0.0578 - val_accuracy: 0.9842\n","Epoch 66/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0353 - accuracy: 0.9861 - val_loss: 0.0584 - val_accuracy: 0.9824\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.98      0.98       308\n","           1       0.97      0.99      0.98       260\n","\n","    accuracy                           0.98       568\n","   macro avg       0.98      0.98      0.98       568\n","weighted avg       0.98      0.98      0.98       568\n","\n","Accuracy: 0.9823943661971831\n","[[301   7]\n"," [  3 257]]\n","Precision: 0.9735\n","Recall: 0.9885\n","F1 Score: 0.9809\n","INFO:tensorflow:Assets written to: ram://ddb3c91f-808a-4cd7-9cd6-83b5bda46292/assets\n","model 8 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.3833 - accuracy: 0.8687 - val_loss: 0.1814 - val_accuracy: 0.9366\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1509 - accuracy: 0.9461 - val_loss: 0.1255 - val_accuracy: 0.9648\n","Epoch 3/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1182 - accuracy: 0.9637 - val_loss: 0.1162 - val_accuracy: 0.9595\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1020 - accuracy: 0.9656 - val_loss: 0.1070 - val_accuracy: 0.9683\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0932 - accuracy: 0.9666 - val_loss: 0.1069 - val_accuracy: 0.9648\n","Epoch 6/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0924 - accuracy: 0.9658 - val_loss: 0.1024 - val_accuracy: 0.9665\n","Epoch 7/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0839 - accuracy: 0.9703 - val_loss: 0.1016 - val_accuracy: 0.9701\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0812 - accuracy: 0.9717 - val_loss: 0.0982 - val_accuracy: 0.9736\n","Epoch 9/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0790 - accuracy: 0.9728 - val_loss: 0.1023 - val_accuracy: 0.9701\n","Epoch 10/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0768 - accuracy: 0.9726 - val_loss: 0.0981 - val_accuracy: 0.9718\n","Epoch 11/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0755 - accuracy: 0.9730 - val_loss: 0.1035 - val_accuracy: 0.9701\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0740 - accuracy: 0.9740 - val_loss: 0.0957 - val_accuracy: 0.9736\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0743 - accuracy: 0.9744 - val_loss: 0.0957 - val_accuracy: 0.9736\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0714 - accuracy: 0.9744 - val_loss: 0.0939 - val_accuracy: 0.9754\n","Epoch 15/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0707 - accuracy: 0.9746 - val_loss: 0.0938 - val_accuracy: 0.9754\n","Epoch 16/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0784 - accuracy: 0.9715 - val_loss: 0.0941 - val_accuracy: 0.9665\n","Epoch 17/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0702 - accuracy: 0.9754 - val_loss: 0.0944 - val_accuracy: 0.9718\n","Epoch 18/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0679 - accuracy: 0.9771 - val_loss: 0.0898 - val_accuracy: 0.9754\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0669 - accuracy: 0.9754 - val_loss: 0.0918 - val_accuracy: 0.9754\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0652 - accuracy: 0.9762 - val_loss: 0.0976 - val_accuracy: 0.9736\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0656 - accuracy: 0.9767 - val_loss: 0.0943 - val_accuracy: 0.9736\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0646 - accuracy: 0.9767 - val_loss: 0.0913 - val_accuracy: 0.9754\n","Epoch 23/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0630 - accuracy: 0.9771 - val_loss: 0.0889 - val_accuracy: 0.9754\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0629 - accuracy: 0.9769 - val_loss: 0.0891 - val_accuracy: 0.9736\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0618 - accuracy: 0.9765 - val_loss: 0.0853 - val_accuracy: 0.9771\n","Epoch 26/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0608 - accuracy: 0.9765 - val_loss: 0.0847 - val_accuracy: 0.9771\n","Epoch 27/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0602 - accuracy: 0.9779 - val_loss: 0.0898 - val_accuracy: 0.9736\n","Epoch 28/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0595 - accuracy: 0.9781 - val_loss: 0.0894 - val_accuracy: 0.9736\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0588 - accuracy: 0.9775 - val_loss: 0.0882 - val_accuracy: 0.9754\n","Epoch 30/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0570 - accuracy: 0.9787 - val_loss: 0.0847 - val_accuracy: 0.9736\n","Epoch 31/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0571 - accuracy: 0.9783 - val_loss: 0.0841 - val_accuracy: 0.9736\n","Epoch 32/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0558 - accuracy: 0.9785 - val_loss: 0.0843 - val_accuracy: 0.9771\n","Epoch 33/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9789 - val_loss: 0.0823 - val_accuracy: 0.9718\n","Epoch 34/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0557 - accuracy: 0.9787 - val_loss: 0.0813 - val_accuracy: 0.9754\n","Epoch 35/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0534 - accuracy: 0.9797 - val_loss: 0.0806 - val_accuracy: 0.9771\n","Epoch 36/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0526 - accuracy: 0.9801 - val_loss: 0.0807 - val_accuracy: 0.9771\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0517 - accuracy: 0.9808 - val_loss: 0.0791 - val_accuracy: 0.9736\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0518 - accuracy: 0.9810 - val_loss: 0.0826 - val_accuracy: 0.9789\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0502 - accuracy: 0.9814 - val_loss: 0.0807 - val_accuracy: 0.9771\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0498 - accuracy: 0.9810 - val_loss: 0.0802 - val_accuracy: 0.9736\n","Epoch 41/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0495 - accuracy: 0.9807 - val_loss: 0.0827 - val_accuracy: 0.9736\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0484 - accuracy: 0.9807 - val_loss: 0.0764 - val_accuracy: 0.9754\n","Epoch 43/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0481 - accuracy: 0.9830 - val_loss: 0.0770 - val_accuracy: 0.9771\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0474 - accuracy: 0.9824 - val_loss: 0.0789 - val_accuracy: 0.9789\n","Epoch 45/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0463 - accuracy: 0.9828 - val_loss: 0.0747 - val_accuracy: 0.9754\n","Epoch 46/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0458 - accuracy: 0.9828 - val_loss: 0.0750 - val_accuracy: 0.9754\n","Epoch 47/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0447 - accuracy: 0.9838 - val_loss: 0.0766 - val_accuracy: 0.9754\n","Epoch 48/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0452 - accuracy: 0.9830 - val_loss: 0.0763 - val_accuracy: 0.9771\n","Epoch 49/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0436 - accuracy: 0.9832 - val_loss: 0.0772 - val_accuracy: 0.9789\n","Epoch 50/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0438 - accuracy: 0.9848 - val_loss: 0.0743 - val_accuracy: 0.9754\n","Epoch 51/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0427 - accuracy: 0.9842 - val_loss: 0.0723 - val_accuracy: 0.9789\n","Epoch 52/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0427 - accuracy: 0.9834 - val_loss: 0.0734 - val_accuracy: 0.9771\n","Epoch 53/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0417 - accuracy: 0.9828 - val_loss: 0.0717 - val_accuracy: 0.9789\n","Epoch 54/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0415 - accuracy: 0.9840 - val_loss: 0.0732 - val_accuracy: 0.9771\n","Epoch 55/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0414 - accuracy: 0.9848 - val_loss: 0.0753 - val_accuracy: 0.9771\n","Epoch 56/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0394 - accuracy: 0.9850 - val_loss: 0.0741 - val_accuracy: 0.9789\n","Epoch 57/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0402 - accuracy: 0.9853 - val_loss: 0.0684 - val_accuracy: 0.9824\n","Epoch 58/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0383 - accuracy: 0.9855 - val_loss: 0.0725 - val_accuracy: 0.9789\n","Epoch 59/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0372 - accuracy: 0.9873 - val_loss: 0.0681 - val_accuracy: 0.9806\n","Epoch 60/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0370 - accuracy: 0.9853 - val_loss: 0.0697 - val_accuracy: 0.9824\n","Epoch 61/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0360 - accuracy: 0.9875 - val_loss: 0.0669 - val_accuracy: 0.9859\n","Epoch 62/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0358 - accuracy: 0.9877 - val_loss: 0.0647 - val_accuracy: 0.9859\n","Epoch 63/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0343 - accuracy: 0.9883 - val_loss: 0.0705 - val_accuracy: 0.9789\n","Epoch 64/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0403 - accuracy: 0.9859 - val_loss: 0.0646 - val_accuracy: 0.9859\n","Epoch 65/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0334 - accuracy: 0.9887 - val_loss: 0.0687 - val_accuracy: 0.9824\n","Epoch 66/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9891 - val_loss: 0.0658 - val_accuracy: 0.9859\n","Epoch 67/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.9885 - val_loss: 0.0658 - val_accuracy: 0.9842\n","Epoch 68/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9881 - val_loss: 0.0662 - val_accuracy: 0.9877\n","Epoch 69/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9889 - val_loss: 0.0648 - val_accuracy: 0.9877\n","Epoch 70/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0308 - accuracy: 0.9887 - val_loss: 0.0643 - val_accuracy: 0.9859\n","Epoch 71/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0295 - accuracy: 0.9904 - val_loss: 0.0644 - val_accuracy: 0.9859\n","Epoch 72/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.9894 - val_loss: 0.0643 - val_accuracy: 0.9894\n","Epoch 73/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0309 - accuracy: 0.9889 - val_loss: 0.0647 - val_accuracy: 0.9877\n","Epoch 74/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.9902 - val_loss: 0.0668 - val_accuracy: 0.9894\n","Epoch 75/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.9904 - val_loss: 0.0644 - val_accuracy: 0.9894\n","Epoch 76/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9900 - val_loss: 0.0647 - val_accuracy: 0.9859\n","Epoch 77/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0277 - accuracy: 0.9906 - val_loss: 0.0664 - val_accuracy: 0.9894\n","Epoch 78/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9910 - val_loss: 0.0666 - val_accuracy: 0.9877\n","Epoch 79/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0273 - accuracy: 0.9900 - val_loss: 0.0686 - val_accuracy: 0.9894\n","Epoch 80/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0268 - accuracy: 0.9902 - val_loss: 0.0679 - val_accuracy: 0.9894\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99       329\n","           1       0.98      1.00      0.99       239\n","\n","    accuracy                           0.99       568\n","   macro avg       0.99      0.99      0.99       568\n","weighted avg       0.99      0.99      0.99       568\n","\n","Accuracy: 0.9894366197183099\n","[[324   5]\n"," [  1 238]]\n","Precision: 0.9794\n","Recall: 0.9958\n","F1 Score: 0.9876\n","INFO:tensorflow:Assets written to: ram://dbe9a60e-0c2a-405f-9682-f48baca4a4a3/assets\n","model 9 saved\n","Average Validation Accuracy: 0.9787194608777445\n"]}]},{"cell_type":"code","source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed URL/NN/model_9.h5'\n","\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","def predict_prob(number):\n","  return [number[0],1-number[0]]\n","\n","y_prob = np.array(list(map(predict_prob, loaded_model.predict(x_test))))\n","y_prob \n","\n","# y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['nn_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['nn_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545},"id":"dolEygpVsl_4","executionInfo":{"status":"ok","timestamp":1656479337374,"user_tz":-330,"elapsed":2597,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"6909061b-4182-4422-cbdf-7263540980bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[9.93201827e-01 6.79817348e-03]\n"," [9.99954244e-01 4.57560327e-05]\n"," [9.97641069e-01 2.35893122e-03]\n"," ...\n"," [9.99999997e-01 3.34157655e-09]\n"," [9.98309614e-01 1.69038601e-03]\n"," [2.22044605e-16 1.00000000e+00]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  nn_prediction_non  \\\n","0          0        9.932018e-01          6.798173e-03       9.932018e-01   \n","1          0        9.999542e-01          4.575603e-05       9.999542e-01   \n","2          0        9.976411e-01          2.358931e-03       9.976411e-01   \n","3          0        9.875554e-01          1.244462e-02       9.875554e-01   \n","4          0        9.999881e-01          1.189933e-05       9.999881e-01   \n","...      ...                 ...                   ...                ...   \n","4647       1        2.401408e-10          1.000000e+00       2.401408e-10   \n","4648       0        9.999578e-01          4.222117e-05       9.999578e-01   \n","4649       0        1.000000e+00          3.341577e-09       1.000000e+00   \n","4650       0        9.983096e-01          1.690386e-03       9.983096e-01   \n","4651       1        2.220446e-16          1.000000e+00       2.220446e-16   \n","\n","      nn_prediction_phish  \n","0            6.798173e-03  \n","1            4.575603e-05  \n","2            2.358931e-03  \n","3            1.244462e-02  \n","4            1.189933e-05  \n","...                   ...  \n","4647         1.000000e+00  \n","4648         4.222117e-05  \n","4649         3.341577e-09  \n","4650         1.690386e-03  \n","4651         1.000000e+00  \n","\n","[4652 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-c3695c78-93a5-4d6c-9bf4-4d3af8eec78d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>9.932018e-01</td>\n","      <td>6.798173e-03</td>\n","      <td>9.932018e-01</td>\n","      <td>6.798173e-03</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>9.999542e-01</td>\n","      <td>4.575603e-05</td>\n","      <td>9.999542e-01</td>\n","      <td>4.575603e-05</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>9.976411e-01</td>\n","      <td>2.358931e-03</td>\n","      <td>9.976411e-01</td>\n","      <td>2.358931e-03</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>9.875554e-01</td>\n","      <td>1.244462e-02</td>\n","      <td>9.875554e-01</td>\n","      <td>1.244462e-02</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>9.999881e-01</td>\n","      <td>1.189933e-05</td>\n","      <td>9.999881e-01</td>\n","      <td>1.189933e-05</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4647</th>\n","      <td>1</td>\n","      <td>2.401408e-10</td>\n","      <td>1.000000e+00</td>\n","      <td>2.401408e-10</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>4648</th>\n","      <td>0</td>\n","      <td>9.999578e-01</td>\n","      <td>4.222117e-05</td>\n","      <td>9.999578e-01</td>\n","      <td>4.222117e-05</td>\n","    </tr>\n","    <tr>\n","      <th>4649</th>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>3.341577e-09</td>\n","      <td>1.000000e+00</td>\n","      <td>3.341577e-09</td>\n","    </tr>\n","    <tr>\n","      <th>4650</th>\n","      <td>0</td>\n","      <td>9.983096e-01</td>\n","      <td>1.690386e-03</td>\n","      <td>9.983096e-01</td>\n","      <td>1.690386e-03</td>\n","    </tr>\n","    <tr>\n","      <th>4651</th>\n","      <td>1</td>\n","      <td>2.220446e-16</td>\n","      <td>1.000000e+00</td>\n","      <td>2.220446e-16</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4652 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3695c78-93a5-4d6c-9bf4-4d3af8eec78d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c3695c78-93a5-4d6c-9bf4-4d3af8eec78d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c3695c78-93a5-4d6c-9bf4-4d3af8eec78d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":[""],"metadata":{"id":"d6frnOv-L24r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Neural Network 2**"],"metadata":{"id":"fMdqVtYLwwy4"}},{"cell_type":"code","source":["\n","import keras\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","def model_a(x_train, x_val, y_train, y_val, opt, n, early_stopping_monitor):\n","\n","  n_cols = x_train.shape[1]\n","\n","  #create model\n","  model_2 = Sequential()\n","  model_2.add(Dense(30, activation='sigmoid', input_shape=(n_cols,)))\n","  model_2.add(Dense(25, activation='sigmoid'))\n","  model_2.add(Dense(20, activation='sigmoid'))\n","  model_2.add(Dense(15, activation='sigmoid'))\n","  model_2.add(Dense(10, activation='sigmoid'))\n","  model_2.add(Dense(1, activation = 'sigmoid'))\n","\n","  #compile model using mse as a measure of model performance\n","  model_2.compile(optimizer='adam', loss='mean_squared_error')\n","\n","\n","\n","  history = model_2.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping_monitor])\n","\n","\n","  # plt.plot(history.history['loss'])\n","  # plt.plot(history.history['val_loss'])\n","  # plt.title('model loss')\n","  # plt.ylabel('Loss')\n","  # plt.xlabel('Epoch')\n","  # plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n","  # plt.show()\n","\n","\n","  print('Validation Accuracy: ')\n","  # Predicting the Test set results\n","  y_pred = model_2.predict(x_val)\n","  y_pred = (y_pred > 0.5)\n","\n","\n","  print(classification_report(y_val, y_pred))\n","\n","  # Model Accuracy, how often is the classifier correct?\n","  print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","\n","  # Creating the Confusion Matrix\n","  cm = confusion_matrix(y_val, y_pred)\n","  print(cm)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred))\n","\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed URL/NN_2/model_'+str(n)+'.h5'\n","  pickle.dump(model_2, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","\n","  return metrics.accuracy_score(y_val, y_pred)\n","\n"],"metadata":{"id":"L8ZhB8W9tVQS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_a(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n, early_stopping_monitor)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osCV0Uo5wqac","executionInfo":{"status":"ok","timestamp":1656479698226,"user_tz":-330,"elapsed":345317,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"692157a7-34c9-4609-e075-8d1dd0b11eb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2617 - val_loss: 0.2414\n","Epoch 2/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1866 - val_loss: 0.1074\n","Epoch 3/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.0526\n","Epoch 4/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0548 - val_loss: 0.0436\n","Epoch 5/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0394\n","Epoch 6/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0469 - val_loss: 0.0388\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0453 - val_loss: 0.0353\n","Epoch 8/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0440 - val_loss: 0.0341\n","Epoch 9/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0426 - val_loss: 0.0339\n","Epoch 10/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.0404 - val_loss: 0.0313\n","Epoch 11/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.0391 - val_loss: 0.0309\n","Epoch 12/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.0385 - val_loss: 0.0301\n","Epoch 13/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.0380 - val_loss: 0.0289\n","Epoch 14/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0374 - val_loss: 0.0287\n","Epoch 15/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0363 - val_loss: 0.0293\n","Epoch 16/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.0362 - val_loss: 0.0286\n","Epoch 17/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.0363 - val_loss: 0.0281\n","Epoch 18/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0275\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0349 - val_loss: 0.0287\n","Epoch 20/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0356 - val_loss: 0.0274\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0185\n","Epoch 22/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0121\n","Epoch 23/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0114\n","Epoch 24/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0122\n","Epoch 25/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0123\n","Epoch 26/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0099\n","Epoch 27/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0141\n","Epoch 28/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0106\n","Epoch 29/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0096\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0166 - val_loss: 0.0110\n","Epoch 31/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0096\n","Epoch 32/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0102\n","Epoch 33/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0111\n","Epoch 34/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0093\n","Epoch 35/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0102\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0150 - val_loss: 0.0094\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0152 - val_loss: 0.0104\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0146 - val_loss: 0.0089\n","Epoch 39/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0092\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0136 - val_loss: 0.0088\n","Epoch 41/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0135 - val_loss: 0.0094\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0138 - val_loss: 0.0089\n","Epoch 43/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0091\n","Epoch 44/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0090\n","Epoch 45/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0098\n","Epoch 46/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0091\n","Epoch 47/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0082\n","Epoch 48/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0088\n","Epoch 49/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0087\n","Epoch 50/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0084\n","Epoch 51/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0104\n","Epoch 52/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0090\n","Epoch 53/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0089\n","Epoch 54/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0096\n","Epoch 55/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0091\n","Epoch 56/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0094\n","Epoch 57/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0106\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99       313\n","           1       0.97      1.00      0.98       256\n","\n","    accuracy                           0.99       569\n","   macro avg       0.99      0.99      0.99       569\n","weighted avg       0.99      0.99      0.99       569\n","\n","Accuracy: 0.9859402460456942\n","[[306   7]\n"," [  1 255]]\n","Precision: 0.9733\n","Recall: 0.9961\n","F1 Score: 0.9846\n","INFO:tensorflow:Assets written to: ram://86c6ce63-8e2b-4b9f-9d7d-369ba7ec3ca7/assets\n","model 0 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2342 - val_loss: 0.1857\n","Epoch 2/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1017 - val_loss: 0.0703\n","Epoch 3/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.0585\n","Epoch 4/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0518\n","Epoch 5/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0358 - val_loss: 0.0393\n","Epoch 6/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0292\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0334\n","Epoch 8/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0255\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0224\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0200 - val_loss: 0.0216\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0200 - val_loss: 0.0221\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0183 - val_loss: 0.0207\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0203\n","Epoch 14/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0210\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0207\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0201\n","Epoch 17/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0213\n","Epoch 18/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0198\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0201\n","Epoch 20/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0202\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0200\n","Epoch 22/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0203\n","Epoch 23/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0210\n","Epoch 24/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0194\n","Epoch 25/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0195\n","Epoch 26/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0237\n","Epoch 27/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0224\n","Epoch 28/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0213\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0150 - val_loss: 0.0186\n","Epoch 30/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0188\n","Epoch 31/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0182\n","Epoch 32/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0202\n","Epoch 33/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0189\n","Epoch 34/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0193\n","Epoch 35/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0183\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0127 - val_loss: 0.0216\n","Epoch 37/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0211\n","Epoch 38/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0170\n","Epoch 39/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0184\n","Epoch 40/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0168\n","Epoch 41/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0181\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0119 - val_loss: 0.0180\n","Epoch 43/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0190\n","Epoch 44/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0212\n","Epoch 45/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0194\n","Epoch 46/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0179\n","Epoch 47/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0228\n","Epoch 48/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0182\n","Epoch 49/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0169\n","Epoch 50/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0185\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.98      0.98       330\n","           1       0.97      0.98      0.98       239\n","\n","    accuracy                           0.98       569\n","   macro avg       0.98      0.98      0.98       569\n","weighted avg       0.98      0.98      0.98       569\n","\n","Accuracy: 0.9789103690685413\n","[[322   8]\n"," [  4 235]]\n","Precision: 0.9671\n","Recall: 0.9833\n","F1 Score: 0.9751\n","INFO:tensorflow:Assets written to: ram://bdefa1df-4f8e-4943-a27c-5a54c43a3463/assets\n","model 1 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2434 - val_loss: 0.2311\n","Epoch 2/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1502 - val_loss: 0.0897\n","Epoch 3/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0672\n","Epoch 4/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0667\n","Epoch 5/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0637\n","Epoch 6/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.0629\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.0627\n","Epoch 8/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.0616\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.0616\n","Epoch 10/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.0603\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0392 - val_loss: 0.0597\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0389 - val_loss: 0.0593\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.0593\n","Epoch 14/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0379 - val_loss: 0.0582\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.0575\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0353 - val_loss: 0.0555\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0346 - val_loss: 0.0525\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0338 - val_loss: 0.0528\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0331 - val_loss: 0.0521\n","Epoch 20/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0513\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.0517\n","Epoch 22/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0326 - val_loss: 0.0505\n","Epoch 23/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0326 - val_loss: 0.0506\n","Epoch 24/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0514\n","Epoch 25/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0479\n","Epoch 26/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0263\n","Epoch 27/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0241\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0174 - val_loss: 0.0219\n","Epoch 29/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0223\n","Epoch 30/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0206\n","Epoch 31/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0198\n","Epoch 32/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0204\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0148 - val_loss: 0.0195\n","Epoch 34/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0187\n","Epoch 35/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0196\n","Epoch 36/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0189\n","Epoch 37/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0184\n","Epoch 38/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0185\n","Epoch 39/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0187\n","Epoch 40/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0192\n","Epoch 41/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0174\n","Epoch 42/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0173\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0125 - val_loss: 0.0178\n","Epoch 44/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0168\n","Epoch 45/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0129 - val_loss: 0.0205\n","Epoch 46/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0168\n","Epoch 47/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0161\n","Epoch 48/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0122 - val_loss: 0.0172\n","Epoch 49/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0156\n","Epoch 50/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0165\n","Epoch 51/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0148\n","Epoch 52/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0156\n","Epoch 53/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0179\n","Epoch 54/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0190\n","Epoch 55/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0118 - val_loss: 0.0145\n","Epoch 56/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.0113 - val_loss: 0.0154\n","Epoch 57/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0147\n","Epoch 58/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0158\n","Epoch 59/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0162\n","Epoch 60/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0143\n","Epoch 61/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0143\n","Epoch 62/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0167\n","Epoch 63/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0141\n","Epoch 64/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0161\n","Epoch 65/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0147\n","Epoch 66/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0148\n","Epoch 67/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0136\n","Epoch 68/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0167\n","Epoch 69/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0174\n","Epoch 70/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0136\n","Epoch 71/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.0141\n","Epoch 72/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0162\n","Epoch 73/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0105 - val_loss: 0.0141\n","Epoch 74/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0148\n","Epoch 75/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0140\n","Epoch 76/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0155\n","Epoch 77/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0152\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.98      0.98       323\n","           1       0.97      0.99      0.98       246\n","\n","    accuracy                           0.98       569\n","   macro avg       0.98      0.98      0.98       569\n","weighted avg       0.98      0.98      0.98       569\n","\n","Accuracy: 0.9806678383128296\n","[[315   8]\n"," [  3 243]]\n","Precision: 0.9681\n","Recall: 0.9878\n","F1 Score: 0.9779\n","INFO:tensorflow:Assets written to: ram://d1e7bafa-fb3a-4aae-8eb1-bb573c735743/assets\n","model 2 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2448 - val_loss: 0.2301\n","Epoch 2/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1563 - val_loss: 0.0835\n","Epoch 3/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.0551\n","Epoch 4/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0504\n","Epoch 5/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0473\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0448 - val_loss: 0.0462\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0468\n","Epoch 8/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0422 - val_loss: 0.0454\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0414 - val_loss: 0.0452\n","Epoch 10/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0409 - val_loss: 0.0467\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0401 - val_loss: 0.0454\n","Epoch 12/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0374 - val_loss: 0.0467\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.0466\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0360 - val_loss: 0.0465\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0354 - val_loss: 0.0462\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0352 - val_loss: 0.0461\n","Epoch 17/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0351 - val_loss: 0.0462\n","Epoch 18/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0345 - val_loss: 0.0459\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0345 - val_loss: 0.0463\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.94      0.96       335\n","           1       0.91      0.97      0.94       234\n","\n","    accuracy                           0.95       569\n","   macro avg       0.95      0.95      0.95       569\n","weighted avg       0.95      0.95      0.95       569\n","\n","Accuracy: 0.9490333919156415\n","[[314  21]\n"," [  8 226]]\n","Precision: 0.9150\n","Recall: 0.9658\n","F1 Score: 0.9397\n","INFO:tensorflow:Assets written to: ram://8d54f748-a6b3-45a2-a03c-083a5345d7ac/assets\n","model 3 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2421 - val_loss: 0.2226\n","Epoch 2/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1312 - val_loss: 0.0693\n","Epoch 3/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0508\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0487 - val_loss: 0.0484\n","Epoch 5/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0459 - val_loss: 0.0481\n","Epoch 6/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0429\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0421\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0419 - val_loss: 0.0413\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0412 - val_loss: 0.0437\n","Epoch 10/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.0402\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0385 - val_loss: 0.0362\n","Epoch 12/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0362 - val_loss: 0.0351\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0356 - val_loss: 0.0359\n","Epoch 14/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0273\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0260\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0235\n","Epoch 17/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0225\n","Epoch 18/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0235\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0232\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0168 - val_loss: 0.0260\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0230\n","Epoch 22/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0252\n","Epoch 23/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0222\n","Epoch 24/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0210\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0146 - val_loss: 0.0222\n","Epoch 26/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0219\n","Epoch 27/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0193\n","Epoch 28/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0266\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0139 - val_loss: 0.0197\n","Epoch 30/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0256\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0133 - val_loss: 0.0189\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0125 - val_loss: 0.0221\n","Epoch 33/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0215\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0133 - val_loss: 0.0193\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0129 - val_loss: 0.0178\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0207\n","Epoch 37/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0227\n","Epoch 38/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0246\n","Epoch 39/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0191\n","Epoch 40/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0178\n","Epoch 41/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0193\n","Epoch 42/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0214\n","Epoch 43/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0184\n","Epoch 44/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0164\n","Epoch 45/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0218\n","Epoch 46/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0220\n","Epoch 47/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0186\n","Epoch 48/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0209\n","Epoch 49/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0196\n","Epoch 50/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0196\n","Epoch 51/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0179\n","Epoch 52/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0155\n","Epoch 53/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0210\n","Epoch 54/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0181\n","Epoch 55/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0199\n","Epoch 56/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0117 - val_loss: 0.0152\n","Epoch 57/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0192\n","Epoch 58/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0182\n","Epoch 59/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0180\n","Epoch 60/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0109 - val_loss: 0.0202\n","Epoch 61/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0177\n","Epoch 62/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0184\n","Epoch 63/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0203\n","Epoch 64/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0206\n","Epoch 65/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0185\n","Epoch 66/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0105 - val_loss: 0.0173\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.99      0.98       325\n","           1       0.98      0.97      0.98       244\n","\n","    accuracy                           0.98       569\n","   macro avg       0.98      0.98      0.98       569\n","weighted avg       0.98      0.98      0.98       569\n","\n","Accuracy: 0.9806678383128296\n","[[321   4]\n"," [  7 237]]\n","Precision: 0.9834\n","Recall: 0.9713\n","F1 Score: 0.9773\n","INFO:tensorflow:Assets written to: ram://a5cf2b3a-5b5d-47e5-8ba7-6d82fb76f944/assets\n","model 4 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2414 - val_loss: 0.2230\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1332 - val_loss: 0.0714\n","Epoch 3/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0585 - val_loss: 0.0520\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0487 - val_loss: 0.0456\n","Epoch 5/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0455 - val_loss: 0.0442\n","Epoch 6/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0447 - val_loss: 0.0408\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0399\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0434 - val_loss: 0.0428\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0432 - val_loss: 0.0388\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0422 - val_loss: 0.0405\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0416\n","Epoch 12/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0422 - val_loss: 0.0394\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0376\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0416 - val_loss: 0.0372\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0412 - val_loss: 0.0360\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0374\n","Epoch 17/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.0359\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0415 - val_loss: 0.0358\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.0365\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0403 - val_loss: 0.0349\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0384 - val_loss: 0.0347\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0367 - val_loss: 0.0345\n","Epoch 23/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0363 - val_loss: 0.0318\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0355 - val_loss: 0.0320\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0354 - val_loss: 0.0324\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0351 - val_loss: 0.0323\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0353 - val_loss: 0.0311\n","Epoch 28/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0314\n","Epoch 29/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0342 - val_loss: 0.0309\n","Epoch 30/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0333 - val_loss: 0.0275\n","Epoch 31/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0189\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0197 - val_loss: 0.0182\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0185 - val_loss: 0.0182\n","Epoch 34/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0212\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0176 - val_loss: 0.0161\n","Epoch 36/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0151\n","Epoch 37/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0161\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0158 - val_loss: 0.0157\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0152 - val_loss: 0.0154\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0152 - val_loss: 0.0152\n","Epoch 41/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0147\n","Epoch 42/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0143\n","Epoch 43/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0154\n","Epoch 44/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0134\n","Epoch 45/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0144 - val_loss: 0.0138\n","Epoch 46/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0143 - val_loss: 0.0148\n","Epoch 47/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0143\n","Epoch 48/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0127\n","Epoch 49/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0131\n","Epoch 50/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0153\n","Epoch 51/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0132\n","Epoch 52/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0148\n","Epoch 53/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0147\n","Epoch 54/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0139 - val_loss: 0.0141\n","Epoch 55/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0128 - val_loss: 0.0131\n","Epoch 56/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0107\n","Epoch 57/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0130 - val_loss: 0.0127\n","Epoch 58/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0119\n","Epoch 59/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0119\n","Epoch 60/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0106\n","Epoch 61/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0152\n","Epoch 62/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0105\n","Epoch 63/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0100\n","Epoch 64/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0121 - val_loss: 0.0173\n","Epoch 65/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0119 - val_loss: 0.0143\n","Epoch 66/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0156\n","Epoch 67/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0119\n","Epoch 68/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0120\n","Epoch 69/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0105\n","Epoch 70/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0115\n","Epoch 71/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0111\n","Epoch 72/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0119\n","Epoch 73/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0119\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.98      0.99       301\n","           1       0.98      0.99      0.99       267\n","\n","    accuracy                           0.99       568\n","   macro avg       0.99      0.99      0.99       568\n","weighted avg       0.99      0.99      0.99       568\n","\n","Accuracy: 0.9859154929577465\n","[[295   6]\n"," [  2 265]]\n","Precision: 0.9779\n","Recall: 0.9925\n","F1 Score: 0.9851\n","INFO:tensorflow:Assets written to: ram://aeb21308-5162-4628-87f2-0eb2f1de637f/assets\n","model 5 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2455 - val_loss: 0.2313\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1626 - val_loss: 0.0869\n","Epoch 3/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0685 - val_loss: 0.0508\n","Epoch 4/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0431\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0483 - val_loss: 0.0405\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0457 - val_loss: 0.0396\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0437 - val_loss: 0.0374\n","Epoch 8/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0398\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0427 - val_loss: 0.0390\n","Epoch 10/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0353\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0398 - val_loss: 0.0357\n","Epoch 12/100\n","160/160 [==============================] - 1s 6ms/step - loss: 0.0377 - val_loss: 0.0345\n","Epoch 13/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0372 - val_loss: 0.0337\n","Epoch 14/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.0340\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0358 - val_loss: 0.0346\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0357 - val_loss: 0.0381\n","Epoch 17/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0350\n","Epoch 18/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0350\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0343 - val_loss: 0.0348\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0332 - val_loss: 0.0323\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0238 - val_loss: 0.0224\n","Epoch 22/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0215\n","Epoch 23/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0204\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0166 - val_loss: 0.0211\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0166 - val_loss: 0.0200\n","Epoch 26/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0209\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0155 - val_loss: 0.0201\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0149 - val_loss: 0.0203\n","Epoch 29/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0196\n","Epoch 30/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0199\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0138 - val_loss: 0.0227\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0140 - val_loss: 0.0200\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0141 - val_loss: 0.0192\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0135 - val_loss: 0.0201\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0132 - val_loss: 0.0200\n","Epoch 36/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0198\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0135 - val_loss: 0.0216\n","Epoch 38/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0213\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0128 - val_loss: 0.0205\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0127 - val_loss: 0.0202\n","Epoch 41/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0198\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0125 - val_loss: 0.0198\n","Epoch 43/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0196\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.98      0.98       334\n","           1       0.97      0.97      0.97       234\n","\n","    accuracy                           0.98       568\n","   macro avg       0.98      0.98      0.98       568\n","weighted avg       0.98      0.98      0.98       568\n","\n","Accuracy: 0.977112676056338\n","[[328   6]\n"," [  7 227]]\n","Precision: 0.9742\n","Recall: 0.9701\n","F1 Score: 0.9722\n","INFO:tensorflow:Assets written to: ram://fe38a5f4-9f78-425c-80e4-6e27394b69e4/assets\n","model 6 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2411 - val_loss: 0.2200\n","Epoch 2/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1289 - val_loss: 0.0668\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0585 - val_loss: 0.0464\n","Epoch 4/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0400\n","Epoch 5/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.0378\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0445 - val_loss: 0.0355\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0434 - val_loss: 0.0351\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0412 - val_loss: 0.0357\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0394 - val_loss: 0.0354\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0379 - val_loss: 0.0350\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0374 - val_loss: 0.0382\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0368 - val_loss: 0.0335\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0336 - val_loss: 0.0307\n","Epoch 14/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.0245 - val_loss: 0.0250\n","Epoch 15/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0213 - val_loss: 0.0221\n","Epoch 16/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0207 - val_loss: 0.0210\n","Epoch 17/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.0191 - val_loss: 0.0208\n","Epoch 18/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0184 - val_loss: 0.0200\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0181 - val_loss: 0.0196\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0177 - val_loss: 0.0204\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0232\n","Epoch 22/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0203\n","Epoch 23/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0186\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0164 - val_loss: 0.0177\n","Epoch 25/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0180\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0161 - val_loss: 0.0188\n","Epoch 27/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0182\n","Epoch 28/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0186\n","Epoch 29/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0208\n","Epoch 30/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0171\n","Epoch 31/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0177\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0153 - val_loss: 0.0174\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0145 - val_loss: 0.0184\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0144 - val_loss: 0.0185\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0151 - val_loss: 0.0174\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0145 - val_loss: 0.0190\n","Epoch 37/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0167\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0138 - val_loss: 0.0169\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0139 - val_loss: 0.0170\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0131 - val_loss: 0.0157\n","Epoch 41/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0158\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0137 - val_loss: 0.0153\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0129 - val_loss: 0.0145\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0128 - val_loss: 0.0151\n","Epoch 45/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0195\n","Epoch 46/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0142\n","Epoch 47/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0164\n","Epoch 48/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0119 - val_loss: 0.0138\n","Epoch 49/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0132\n","Epoch 50/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0119 - val_loss: 0.0128\n","Epoch 51/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0127 - val_loss: 0.0149\n","Epoch 52/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0122 - val_loss: 0.0131\n","Epoch 53/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0153\n","Epoch 54/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0196\n","Epoch 55/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0117 - val_loss: 0.0140\n","Epoch 56/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0140\n","Epoch 57/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0112 - val_loss: 0.0136\n","Epoch 58/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0121 - val_loss: 0.0173\n","Epoch 59/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0148\n","Epoch 60/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0138\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.99      0.99       318\n","           1       0.99      0.97      0.98       250\n","\n","    accuracy                           0.98       568\n","   macro avg       0.99      0.98      0.98       568\n","weighted avg       0.98      0.98      0.98       568\n","\n","Accuracy: 0.9841549295774648\n","[[316   2]\n"," [  7 243]]\n","Precision: 0.9918\n","Recall: 0.9720\n","F1 Score: 0.9818\n","INFO:tensorflow:Assets written to: ram://4697dd07-ef12-4cb2-add9-3d509e8e5d7c/assets\n","model 7 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2367 - val_loss: 0.2010\n","Epoch 2/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1063 - val_loss: 0.0542\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0540 - val_loss: 0.0411\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0476 - val_loss: 0.0387\n","Epoch 5/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0363\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0440 - val_loss: 0.0354\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0427 - val_loss: 0.0357\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0421 - val_loss: 0.0341\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.0327\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0386 - val_loss: 0.0312\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0375 - val_loss: 0.0313\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0370 - val_loss: 0.0304\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0348 - val_loss: 0.0231\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0229 - val_loss: 0.0213\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0203\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0200 - val_loss: 0.0201\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0197 - val_loss: 0.0195\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0183 - val_loss: 0.0198\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0188\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0168 - val_loss: 0.0197\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0190\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0170 - val_loss: 0.0178\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0160 - val_loss: 0.0255\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0158 - val_loss: 0.0182\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0154 - val_loss: 0.0167\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0156 - val_loss: 0.0168\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0144 - val_loss: 0.0158\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0143 - val_loss: 0.0162\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0140 - val_loss: 0.0142\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0140 - val_loss: 0.0144\n","Epoch 31/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0139\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0139 - val_loss: 0.0138\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0133 - val_loss: 0.0138\n","Epoch 34/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0138\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0133 - val_loss: 0.0138\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0129 - val_loss: 0.0144\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0121 - val_loss: 0.0139\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0122 - val_loss: 0.0148\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0126 - val_loss: 0.0153\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0140\n","Epoch 41/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0116\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0137\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0117 - val_loss: 0.0123\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0115 - val_loss: 0.0125\n","Epoch 45/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0117\n","Epoch 46/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0111 - val_loss: 0.0142\n","Epoch 47/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0120 - val_loss: 0.0119\n","Epoch 48/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0126 - val_loss: 0.0125\n","Epoch 49/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0125\n","Epoch 50/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0106 - val_loss: 0.0116\n","Epoch 51/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0108 - val_loss: 0.0126\n","Epoch 52/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0118\n","Epoch 53/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0121\n","Epoch 54/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0108 - val_loss: 0.0138\n","Epoch 55/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0118 - val_loss: 0.0106\n","Epoch 56/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0108 - val_loss: 0.0136\n","Epoch 57/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0112\n","Epoch 58/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.0112 - val_loss: 0.0128\n","Epoch 59/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.0105 - val_loss: 0.0127\n","Epoch 60/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0105 - val_loss: 0.0136\n","Epoch 61/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0106 - val_loss: 0.0132\n","Epoch 62/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0106 - val_loss: 0.0129\n","Epoch 63/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0104 - val_loss: 0.0128\n","Epoch 64/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0118 - val_loss: 0.0121\n","Epoch 65/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0126\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.99      0.99       308\n","           1       0.98      0.99      0.99       260\n","\n","    accuracy                           0.99       568\n","   macro avg       0.99      0.99      0.99       568\n","weighted avg       0.99      0.99      0.99       568\n","\n","Accuracy: 0.9876760563380281\n","[[304   4]\n"," [  3 257]]\n","Precision: 0.9847\n","Recall: 0.9885\n","F1 Score: 0.9866\n","INFO:tensorflow:Assets written to: ram://bfabeb0f-eb4c-49c2-89e2-5f29712b4ee2/assets\n","model 8 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2438 - val_loss: 0.2214\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1281 - val_loss: 0.0624\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0550 - val_loss: 0.0447\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0421 - val_loss: 0.0334\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0314 - val_loss: 0.0282\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0263 - val_loss: 0.0280\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0233 - val_loss: 0.0260\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0209 - val_loss: 0.0252\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0195 - val_loss: 0.0210\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0191 - val_loss: 0.0211\n","Epoch 11/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.0189 - val_loss: 0.0207\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0181 - val_loss: 0.0211\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0177 - val_loss: 0.0196\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0189\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0175 - val_loss: 0.0213\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0171 - val_loss: 0.0183\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0164 - val_loss: 0.0176\n","Epoch 18/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0188\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0159 - val_loss: 0.0192\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0152 - val_loss: 0.0196\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0148 - val_loss: 0.0195\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0146 - val_loss: 0.0206\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0148 - val_loss: 0.0177\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0143 - val_loss: 0.0191\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0154 - val_loss: 0.0194\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0139 - val_loss: 0.0172\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0132 - val_loss: 0.0192\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0137 - val_loss: 0.0150\n","Epoch 29/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0170\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0133 - val_loss: 0.0168\n","Epoch 31/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0180\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0128 - val_loss: 0.0199\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0129 - val_loss: 0.0183\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0125 - val_loss: 0.0149\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0130 - val_loss: 0.0214\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0120 - val_loss: 0.0173\n","Epoch 37/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0223\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0127 - val_loss: 0.0172\n","Epoch 39/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0156\n","Epoch 40/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0155\n","Epoch 41/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0178\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0119 - val_loss: 0.0150\n","Epoch 43/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0195\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.0112 - val_loss: 0.0149\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.98      0.98       329\n","           1       0.97      0.99      0.98       239\n","\n","    accuracy                           0.98       568\n","   macro avg       0.98      0.98      0.98       568\n","weighted avg       0.98      0.98      0.98       568\n","\n","Accuracy: 0.9806338028169014\n","[[321   8]\n"," [  3 236]]\n","Precision: 0.9672\n","Recall: 0.9874\n","F1 Score: 0.9772\n","INFO:tensorflow:Assets written to: ram://e97b6014-1081-48fd-8168-b1da6620853b/assets\n","model 9 saved\n","Average Validation Accuracy: 0.9790712641402017\n"]}]},{"cell_type":"code","source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed URL/NN_2/model_8.h5'\n","\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","def predict_prob(number):\n","  return [number[0],1-number[0]]\n","\n","y_prob = np.array(list(map(predict_prob, loaded_model.predict(x_test))))\n","y_prob \n","\n","# y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['nn2_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['nn2_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":609},"id":"JPT9oIQ0wuZf","executionInfo":{"status":"ok","timestamp":1656479828801,"user_tz":-330,"elapsed":3899,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"0de8a41b-7142-416a-8fe2-a3b5c72ba177"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[9.93201827e-01 6.79817348e-03]\n"," [9.99954244e-01 4.57560327e-05]\n"," [9.97641069e-01 2.35893122e-03]\n"," ...\n"," [9.99999997e-01 3.34157655e-09]\n"," [9.98309614e-01 1.69038601e-03]\n"," [2.22044605e-16 1.00000000e+00]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  nn_prediction_non  \\\n","0          0        9.932018e-01          6.798173e-03       9.932018e-01   \n","1          0        9.999542e-01          4.575603e-05       9.999542e-01   \n","2          0        9.976411e-01          2.358931e-03       9.976411e-01   \n","3          0        9.875554e-01          1.244462e-02       9.875554e-01   \n","4          0        9.999881e-01          1.189933e-05       9.999881e-01   \n","...      ...                 ...                   ...                ...   \n","4647       1        2.401408e-10          1.000000e+00       2.401408e-10   \n","4648       0        9.999578e-01          4.222117e-05       9.999578e-01   \n","4649       0        1.000000e+00          3.341577e-09       1.000000e+00   \n","4650       0        9.983096e-01          1.690386e-03       9.983096e-01   \n","4651       1        2.220446e-16          1.000000e+00       2.220446e-16   \n","\n","      nn_prediction_phish  nn2_prediction_non  nn2_prediction_phish  \n","0            6.798173e-03        9.932018e-01          6.798173e-03  \n","1            4.575603e-05        9.999542e-01          4.575603e-05  \n","2            2.358931e-03        9.976411e-01          2.358931e-03  \n","3            1.244462e-02        9.875554e-01          1.244462e-02  \n","4            1.189933e-05        9.999881e-01          1.189933e-05  \n","...                   ...                 ...                   ...  \n","4647         1.000000e+00        2.401408e-10          1.000000e+00  \n","4648         4.222117e-05        9.999578e-01          4.222117e-05  \n","4649         3.341577e-09        1.000000e+00          3.341577e-09  \n","4650         1.690386e-03        9.983096e-01          1.690386e-03  \n","4651         1.000000e+00        2.220446e-16          1.000000e+00  \n","\n","[4652 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-1af2b3d0-5a07-4865-a120-7c1d3f4aeccd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","      <th>nn2_prediction_non</th>\n","      <th>nn2_prediction_phish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>9.932018e-01</td>\n","      <td>6.798173e-03</td>\n","      <td>9.932018e-01</td>\n","      <td>6.798173e-03</td>\n","      <td>9.932018e-01</td>\n","      <td>6.798173e-03</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>9.999542e-01</td>\n","      <td>4.575603e-05</td>\n","      <td>9.999542e-01</td>\n","      <td>4.575603e-05</td>\n","      <td>9.999542e-01</td>\n","      <td>4.575603e-05</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>9.976411e-01</td>\n","      <td>2.358931e-03</td>\n","      <td>9.976411e-01</td>\n","      <td>2.358931e-03</td>\n","      <td>9.976411e-01</td>\n","      <td>2.358931e-03</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>9.875554e-01</td>\n","      <td>1.244462e-02</td>\n","      <td>9.875554e-01</td>\n","      <td>1.244462e-02</td>\n","      <td>9.875554e-01</td>\n","      <td>1.244462e-02</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>9.999881e-01</td>\n","      <td>1.189933e-05</td>\n","      <td>9.999881e-01</td>\n","      <td>1.189933e-05</td>\n","      <td>9.999881e-01</td>\n","      <td>1.189933e-05</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4647</th>\n","      <td>1</td>\n","      <td>2.401408e-10</td>\n","      <td>1.000000e+00</td>\n","      <td>2.401408e-10</td>\n","      <td>1.000000e+00</td>\n","      <td>2.401408e-10</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>4648</th>\n","      <td>0</td>\n","      <td>9.999578e-01</td>\n","      <td>4.222117e-05</td>\n","      <td>9.999578e-01</td>\n","      <td>4.222117e-05</td>\n","      <td>9.999578e-01</td>\n","      <td>4.222117e-05</td>\n","    </tr>\n","    <tr>\n","      <th>4649</th>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>3.341577e-09</td>\n","      <td>1.000000e+00</td>\n","      <td>3.341577e-09</td>\n","      <td>1.000000e+00</td>\n","      <td>3.341577e-09</td>\n","    </tr>\n","    <tr>\n","      <th>4650</th>\n","      <td>0</td>\n","      <td>9.983096e-01</td>\n","      <td>1.690386e-03</td>\n","      <td>9.983096e-01</td>\n","      <td>1.690386e-03</td>\n","      <td>9.983096e-01</td>\n","      <td>1.690386e-03</td>\n","    </tr>\n","    <tr>\n","      <th>4651</th>\n","      <td>1</td>\n","      <td>2.220446e-16</td>\n","      <td>1.000000e+00</td>\n","      <td>2.220446e-16</td>\n","      <td>1.000000e+00</td>\n","      <td>2.220446e-16</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4652 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1af2b3d0-5a07-4865-a120-7c1d3f4aeccd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1af2b3d0-5a07-4865-a120-7c1d3f4aeccd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1af2b3d0-5a07-4865-a120-7c1d3f4aeccd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":[""],"metadata":{"id":"NEihgjKWtVK_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output.shape"],"metadata":{"id":"KDYz8o5ytVIu"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsQkUbz6AiTx"},"outputs":[],"source":["# Storing the data in CSV file\n","output.to_csv('/content/drive/MyDrive/Phishing/PhishTank/Base_classifier_result(pre URL cross)(3).csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RN_-swX0JdhP"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W9DI0WYaJde9"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49lwyWNz0mSo"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_9Vdw_Wx2NEo"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Base Classifiers(3)(URL).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}