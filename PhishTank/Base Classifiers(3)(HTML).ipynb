{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"PH13wfswmyDv"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25324,"status":"ok","timestamp":1656479960038,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"Aiz0olfdKb4b","outputId":"014a466d-6677-4c07-c498-f55e882182fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":557},"executionInfo":{"elapsed":1436,"status":"ok","timestamp":1656480050963,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"Dw-EEymHAGNs","outputId":"9d527824-9742-4c6a-ab12-4c53d64dbc30"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Unnamed: 0                                       Domain  Have IP  \\\n","0               0                             graphicriver.net        0   \n","1               1                                    ecnavi.jp        0   \n","2               2                                 hubpages.com        0   \n","3               3                              extratorrent.cc        0   \n","4               4                                icicibank.com        0   \n","...           ...                                          ...      ...   \n","10332       11932                             sites.google.com        0   \n","10333       11933                             sites.google.com        0   \n","10334       11934             habbocreditosparati.blogspot.com        0   \n","10335       11935  creditiperhabbogratissicuro100.blogspot.com        0   \n","10336       11936                           aijcs.blogspot.com        0   \n","\n","       Have @  URL Length  URL Depth  Redirection  https Domain  TinyURL  \\\n","0           0           1          1            0             0        0   \n","1           0           1          1            1             0        0   \n","2           0           1          1            0             1        0   \n","3           0           1          3            0             0        0   \n","4           0           1          3            0             0        0   \n","...       ...         ...        ...          ...           ...      ...   \n","10332       0           0          2            0             1        0   \n","10333       0           0          2            0             0        0   \n","10334       0           0          0            0             0        1   \n","10335       0           1          3            0             0        1   \n","10336       0           1          3            0             0        1   \n","\n","       Prefix/Suffix  ...  Num Embeds  Num Images  Num Links  Num Titles  \\\n","0                  0  ...           0          49        691          42   \n","1                  0  ...           0           4         66           3   \n","2                  0  ...           0           1        100          27   \n","3                  0  ...           0           0          0           1   \n","4                  0  ...           0         117        219          23   \n","...              ...  ...         ...         ...        ...         ...   \n","10332              0  ...           0           0         17           4   \n","10333              0  ...           0           6         24           7   \n","10334              0  ...           0           4         17           4   \n","10335              0  ...           0           1         23           8   \n","10336              0  ...           0          19         42           7   \n","\n","       Num Script  Special Characters  Script To Special Chars Ratio  \\\n","0           13135                6400                       2.052344   \n","1            2034                 818                       2.486553   \n","2           32987               10451                       3.156349   \n","3               0                  52                       0.000000   \n","4            7944                3468                       2.290657   \n","...           ...                 ...                            ...   \n","10332        8146                2203                       3.697685   \n","10333        8353                2250                       3.712444   \n","10334        6403                4560                       1.404167   \n","10335        9817                7292                       1.346270   \n","10336        2550                3225                       0.790698   \n","\n","       Script To body Ratio  Body To Special Char Ratio  Label  \n","0                  0.528869                    0.257690      0  \n","1                  0.676197                    0.271941      0  \n","2                  0.836681                    0.265079      0  \n","3                  0.000000                    0.227074      0  \n","4                  0.524460                    0.228956      0  \n","...                     ...                         ...    ...  \n","10332              0.943698                    0.255213      1  \n","10333              0.937276                    0.252469      1  \n","10334              0.397677                    0.283212      1  \n","10335              0.385873                    0.286624      1  \n","10336              0.247669                    0.313228      1  \n","\n","[10337 rows x 47 columns]"],"text/html":["\n","  <div id=\"df-621c0aad-1444-4747-b4ce-7428424c3f72\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Domain</th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>graphicriver.net</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>691</td>\n","      <td>42</td>\n","      <td>13135</td>\n","      <td>6400</td>\n","      <td>2.052344</td>\n","      <td>0.528869</td>\n","      <td>0.257690</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>ecnavi.jp</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>66</td>\n","      <td>3</td>\n","      <td>2034</td>\n","      <td>818</td>\n","      <td>2.486553</td>\n","      <td>0.676197</td>\n","      <td>0.271941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>hubpages.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>27</td>\n","      <td>32987</td>\n","      <td>10451</td>\n","      <td>3.156349</td>\n","      <td>0.836681</td>\n","      <td>0.265079</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>extratorrent.cc</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.227074</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>icicibank.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>117</td>\n","      <td>219</td>\n","      <td>23</td>\n","      <td>7944</td>\n","      <td>3468</td>\n","      <td>2.290657</td>\n","      <td>0.524460</td>\n","      <td>0.228956</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10332</th>\n","      <td>11932</td>\n","      <td>sites.google.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>17</td>\n","      <td>4</td>\n","      <td>8146</td>\n","      <td>2203</td>\n","      <td>3.697685</td>\n","      <td>0.943698</td>\n","      <td>0.255213</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10333</th>\n","      <td>11933</td>\n","      <td>sites.google.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>24</td>\n","      <td>7</td>\n","      <td>8353</td>\n","      <td>2250</td>\n","      <td>3.712444</td>\n","      <td>0.937276</td>\n","      <td>0.252469</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10334</th>\n","      <td>11934</td>\n","      <td>habbocreditosparati.blogspot.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>17</td>\n","      <td>4</td>\n","      <td>6403</td>\n","      <td>4560</td>\n","      <td>1.404167</td>\n","      <td>0.397677</td>\n","      <td>0.283212</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10335</th>\n","      <td>11935</td>\n","      <td>creditiperhabbogratissicuro100.blogspot.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>23</td>\n","      <td>8</td>\n","      <td>9817</td>\n","      <td>7292</td>\n","      <td>1.346270</td>\n","      <td>0.385873</td>\n","      <td>0.286624</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10336</th>\n","      <td>11936</td>\n","      <td>aijcs.blogspot.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>19</td>\n","      <td>42</td>\n","      <td>7</td>\n","      <td>2550</td>\n","      <td>3225</td>\n","      <td>0.790698</td>\n","      <td>0.247669</td>\n","      <td>0.313228</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10337 rows × 47 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-621c0aad-1444-4747-b4ce-7428424c3f72')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-621c0aad-1444-4747-b4ce-7428424c3f72 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-621c0aad-1444-4747-b4ce-7428424c3f72');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["urldata = pd.read_csv(\"/content/drive/MyDrive/Phishing/PhishTank/URL-HTML/preprocessed_url_features.csv\")\n","urldata\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":506,"status":"ok","timestamp":1656480055744,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"JQ4_qEulWybT","outputId":"7c7daf46-7a22-4d08-83f4-8760788b8d58"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Unnamed: 0', 'Domain', 'Have IP', 'Have @', 'URL Length', 'URL Depth',\n","       'Redirection', 'https Domain', 'TinyURL', 'Prefix/Suffix',\n","       'Have client', 'Have admin', 'Have login', 'Have server', '.php',\n","       '.html', '.info', '.txt', '.js', '.exe', 'Num of periods', 'Is encoded',\n","       'Num of encoded char', 'Num of parameters', 'Num of digits',\n","       'Num of spec char', 'iFrame', 'Mouse Over', 'Right Click',\n","       'Web Forwards', 'Number of page tokens', 'number of sentences',\n","       'number of html tags', 'number of whitespace', 'url Is Live',\n","       'HTML Length', 'Num Objects', 'Num Embeds', 'Num Images', 'Num Links',\n","       'Num Titles', 'Num Script', 'Special Characters',\n","       'Script To Special Chars Ratio', 'Script To body Ratio',\n","       'Body To Special Char Ratio', 'Label'],\n","      dtype='object')"]},"metadata":{},"execution_count":4}],"source":["urldata.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"elapsed":394,"status":"ok","timestamp":1656480077480,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"qwye89TwRTOH","outputId":"276beb12-33db-4f1e-e624-cc58e59b0148"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   iFrame  Mouse Over  Right Click  Web Forwards  Number of page tokens  \\\n","0       1           0            0             1                  21444   \n","1       1           0            0             1                   1075   \n","2       1           0            0             1                   4531   \n","3       1           0            0             1                     32   \n","4       1           0            0             1                   4880   \n","\n","   number of sentences  number of html tags  number of whitespace  \\\n","0                 1853                 3247                     0   \n","1                  136                  236                     0   \n","2                 2634                  486                     0   \n","3                    9                    8                     0   \n","4                  981                 1412                     0   \n","\n","   url Is Live  HTML Length  ...  Num Embeds  Num Images  Num Links  \\\n","0            1        24836  ...           0          49        691   \n","1            1         3008  ...           0           4         66   \n","2            1        39426  ...           0           1        100   \n","3            0          229  ...           0           0          0   \n","4            1        15147  ...           0         117        219   \n","\n","   Num Titles  Num Script  Special Characters  Script To Special Chars Ratio  \\\n","0          42       13135                6400                       2.052344   \n","1           3        2034                 818                       2.486553   \n","2          27       32987               10451                       3.156349   \n","3           1           0                  52                       0.000000   \n","4          23        7944                3468                       2.290657   \n","\n","   Script To body Ratio  Body To Special Char Ratio  Label  \n","0              0.528869                    0.257690      0  \n","1              0.676197                    0.271941      0  \n","2              0.836681                    0.265079      0  \n","3              0.000000                    0.227074      0  \n","4              0.524460                    0.228956      0  \n","\n","[5 rows x 21 columns]"],"text/html":["\n","  <div id=\"df-a113aaf5-f52f-4fe4-a304-3cfd55e831e1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>iFrame</th>\n","      <th>Mouse Over</th>\n","      <th>Right Click</th>\n","      <th>Web Forwards</th>\n","      <th>Number of page tokens</th>\n","      <th>number of sentences</th>\n","      <th>number of html tags</th>\n","      <th>number of whitespace</th>\n","      <th>url Is Live</th>\n","      <th>HTML Length</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>21444</td>\n","      <td>1853</td>\n","      <td>3247</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>24836</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>691</td>\n","      <td>42</td>\n","      <td>13135</td>\n","      <td>6400</td>\n","      <td>2.052344</td>\n","      <td>0.528869</td>\n","      <td>0.257690</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1075</td>\n","      <td>136</td>\n","      <td>236</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3008</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>66</td>\n","      <td>3</td>\n","      <td>2034</td>\n","      <td>818</td>\n","      <td>2.486553</td>\n","      <td>0.676197</td>\n","      <td>0.271941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4531</td>\n","      <td>2634</td>\n","      <td>486</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>39426</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>27</td>\n","      <td>32987</td>\n","      <td>10451</td>\n","      <td>3.156349</td>\n","      <td>0.836681</td>\n","      <td>0.265079</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>32</td>\n","      <td>9</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>229</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.227074</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4880</td>\n","      <td>981</td>\n","      <td>1412</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>15147</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>117</td>\n","      <td>219</td>\n","      <td>23</td>\n","      <td>7944</td>\n","      <td>3468</td>\n","      <td>2.290657</td>\n","      <td>0.524460</td>\n","      <td>0.228956</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a113aaf5-f52f-4fe4-a304-3cfd55e831e1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a113aaf5-f52f-4fe4-a304-3cfd55e831e1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a113aaf5-f52f-4fe4-a304-3cfd55e831e1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["urldata = urldata.drop(['Unnamed: 0', 'Domain', 'Have IP', 'Have @', 'URL Length', 'URL Depth',\n","       'Redirection', 'https Domain', 'TinyURL', 'Prefix/Suffix',\n","       'Have client', 'Have admin', 'Have login', 'Have server', '.php',\n","       '.html', '.info', '.txt', '.js', '.exe', 'Num of periods', 'Is encoded',\n","       'Num of encoded char', 'Num of parameters', 'Num of digits',\n","       'Num of spec char'], axis = 1).copy()\n","\n","urldata.shape\n","urldata.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":367,"status":"ok","timestamp":1656480081717,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"kKvKkmUNP5Cx","outputId":"8a5007e3-cbba-4849-b091-a87d9a48ca15"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10337 entries, 0 to 10336\n","Data columns (total 21 columns):\n"," #   Column                         Non-Null Count  Dtype  \n","---  ------                         --------------  -----  \n"," 0   iFrame                         10337 non-null  int64  \n"," 1   Mouse Over                     10337 non-null  int64  \n"," 2   Right Click                    10337 non-null  int64  \n"," 3   Web Forwards                   10337 non-null  int64  \n"," 4   Number of page tokens          10337 non-null  int64  \n"," 5   number of sentences            10337 non-null  int64  \n"," 6   number of html tags            10337 non-null  int64  \n"," 7   number of whitespace           10337 non-null  int64  \n"," 8   url Is Live                    10337 non-null  int64  \n"," 9   HTML Length                    10337 non-null  int64  \n"," 10  Num Objects                    10337 non-null  int64  \n"," 11  Num Embeds                     10337 non-null  int64  \n"," 12  Num Images                     10337 non-null  int64  \n"," 13  Num Links                      10337 non-null  int64  \n"," 14  Num Titles                     10337 non-null  int64  \n"," 15  Num Script                     10337 non-null  int64  \n"," 16  Special Characters             10337 non-null  int64  \n"," 17  Script To Special Chars Ratio  10337 non-null  float64\n"," 18  Script To body Ratio           10337 non-null  float64\n"," 19  Body To Special Char Ratio     10337 non-null  float64\n"," 20  Label                          10337 non-null  int64  \n","dtypes: float64(3), int64(18)\n","memory usage: 1.7 MB\n"]}],"source":["urldata.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1656480082874,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"rvS3OQHTSHDt","outputId":"b06d58a5-0ec7-483e-dc81-2884e15d8819"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Label\n","0    5828\n","1    4509\n","dtype: int64"]},"metadata":{},"execution_count":7}],"source":["# Class Distribution of Labels\n","urldata.groupby('Label').size()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1656480084264,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"kHCjZCSBSKi3","outputId":"58d7c219-5e50-4a8a-a8c2-534e95f0f04d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total of Samples: 10337\n","Non-Phishing: 5828 (56.38% of total)\n","Phishing: 4509 (43.62% of total)\n"]}],"source":["# Analysis of Postives and Negatives in the Dataset\n","pos,neg = urldata['Label'].value_counts()\n","total = neg + pos\n","print ('Total of Samples: %s'% total)\n","print('Non-Phishing: {} ({:.2f}% of total)'.format(pos, 100 * pos / total))\n","print('Phishing: {} ({:.2f}% of total)'.format(neg, 100 * neg / total))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bUPfWi4TcfIA"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1656480117396,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"S3PEbrTLcfXg","outputId":"0b22a55e-6c30-419a-b773-1e345fcad06e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["iFrame                           0\n","Mouse Over                       0\n","Right Click                      0\n","Web Forwards                     0\n","Number of page tokens            0\n","number of sentences              0\n","number of html tags              0\n","number of whitespace             0\n","url Is Live                      0\n","HTML Length                      0\n","Num Objects                      0\n","Num Embeds                       0\n","Num Images                       0\n","Num Links                        0\n","Num Titles                       0\n","Num Script                       0\n","Special Characters               0\n","Script To Special Chars Ratio    0\n","Script To body Ratio             0\n","Body To Special Char Ratio       0\n","Label                            0\n","dtype: int64"]},"metadata":{},"execution_count":14}],"source":["#checking the data for null or missing values\n","urldata.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1656480118065,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"n6YfGa82P5JZ","outputId":"de109c65-bba5-4a03-b2f4-cbb736a4fd2a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   iFrame  Mouse Over  Right Click  Web Forwards  Number of page tokens  \\\n","0       1           0            0             1                     22   \n","1       1           0            0             1                     37   \n","2       1           0            0             1                     16   \n","3       1           0            0             1                  33577   \n","4       1           0            0             1                     87   \n","\n","   number of sentences  number of html tags  number of whitespace  \\\n","0                    3                    6                     0   \n","1                    4                    7                     0   \n","2                   12                    9                     0   \n","3                 4430                 1320                     0   \n","4                  113                   18                     0   \n","\n","   url Is Live  HTML Length  ...  Num Embeds  Num Images  Num Links  \\\n","0            0          164  ...           0           0          0   \n","1            0          186  ...           0           0          0   \n","2            1           83  ...           0           0          0   \n","3            1       402091  ...           0           8        188   \n","4            1         2403  ...           0           0          0   \n","\n","   Num Titles  Num Script  Special Characters  Script To Special Chars Ratio  \\\n","0           1           0                  28                       0.000000   \n","1           1           0                  31                       0.000000   \n","2           0          83                  14                       5.928571   \n","3           8      263443              103749                       2.539234   \n","4           0        2343                 828                       2.829710   \n","\n","   Script To body Ratio  Body To Special Char Ratio  Label  \n","0              0.000000                    0.170732      1  \n","1              0.000000                    0.166667      1  \n","2              1.000000                    0.168675      1  \n","3              0.655183                    0.258024      0  \n","4              0.975031                    0.344569      1  \n","\n","[5 rows x 21 columns]"],"text/html":["\n","  <div id=\"df-d154c12a-4e18-4c4f-82d1-493eb8d9a229\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>iFrame</th>\n","      <th>Mouse Over</th>\n","      <th>Right Click</th>\n","      <th>Web Forwards</th>\n","      <th>Number of page tokens</th>\n","      <th>number of sentences</th>\n","      <th>number of html tags</th>\n","      <th>number of whitespace</th>\n","      <th>url Is Live</th>\n","      <th>HTML Length</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>22</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>164</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>28</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.170732</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>37</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>186</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>31</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.166667</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>16</td>\n","      <td>12</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>83</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>83</td>\n","      <td>14</td>\n","      <td>5.928571</td>\n","      <td>1.000000</td>\n","      <td>0.168675</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>33577</td>\n","      <td>4430</td>\n","      <td>1320</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>402091</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>188</td>\n","      <td>8</td>\n","      <td>263443</td>\n","      <td>103749</td>\n","      <td>2.539234</td>\n","      <td>0.655183</td>\n","      <td>0.258024</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>87</td>\n","      <td>113</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2403</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2343</td>\n","      <td>828</td>\n","      <td>2.829710</td>\n","      <td>0.975031</td>\n","      <td>0.344569</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d154c12a-4e18-4c4f-82d1-493eb8d9a229')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d154c12a-4e18-4c4f-82d1-493eb8d9a229 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d154c12a-4e18-4c4f-82d1-493eb8d9a229');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}],"source":["import numpy as np\n","# shuffling the rows in the dataset so that when splitting the train and test set are equally distributed\n","urldata = urldata.sample(frac=1).reset_index(drop=True)\n","urldata.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lasv_YzlP5L6"},"outputs":[],"source":["# Sepratating & assigning features and target columns to X & y\n","y = urldata['Label'].values\n","x = np.array(urldata.drop('Label',axis=1))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":367,"status":"ok","timestamp":1656480122513,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"in9C2ArWP5O0","outputId":"c2099401-f0c6-4efb-9217-01121c06643c"},"outputs":[{"output_type":"stream","name":"stdout","text":["(5685, 20) (4652, 20)\n","(5685,) (4652,)\n"]}],"source":["# Splitting the dataset into train and test sets: 80-20 split\n","from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, \n","                                                    test_size = 0.45, random_state = 12)\n","print(x_train.shape, x_test.shape)\n","print(y_train.shape, y_test.shape)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jv6Y5m8ddMHC"},"outputs":[],"source":["output = {}\n","output['labels'] = y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N8k6QYBg7wu7"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"SOV9VybfNIgE"},"source":["**MLP**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mr-AOgJ1JtXY"},"outputs":[],"source":["import keras\n","\n","from sklearn.neural_network import MLPClassifier\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","import pickle\n","\n","def model_mlp(x_train, x_val, y_train, y_val, opt, n):\n","  mlpclassifier = MLPClassifier(alpha=0.0001, hidden_layer_sizes=([100,100,100]))\n","  #compile model using mse as a measure of model performance\n","  mlpclassifier.fit(x_train, y_train)\n","\n","  y_pred = mlpclassifier.predict(x_val)\n","\n","  conf_matrix = confusion_matrix(y_val, y_pred)\n","  print(conf_matrix)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred))\n","\n","  \n","  print(\"Validation Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed HTML/MLP/model_'+str(n)+'.h5'\n","  pickle.dump(mlpclassifier, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","  return metrics.accuracy_score(y_val, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUCxdcapJtXZ","executionInfo":{"status":"ok","timestamp":1656480207984,"user_tz":-330,"elapsed":64717,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"c9eab992-5893-462d-c283-4f3fcd5dd3e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[219 103]\n"," [ 34 213]]\n","Precision: 0.6741\n","Recall: 0.8623\n","F1 Score: 0.7567\n","Validation Accuracy: 0.7592267135325131\n","model 0 saved\n","[[295  25]\n"," [ 86 163]]\n","Precision: 0.8670\n","Recall: 0.6546\n","F1 Score: 0.7460\n","Validation Accuracy: 0.804920913884007\n","model 1 saved\n","[[ 98 226]\n"," [ 23 222]]\n","Precision: 0.4955\n","Recall: 0.9061\n","F1 Score: 0.6407\n","Validation Accuracy: 0.562390158172232\n","model 2 saved\n","[[259  75]\n"," [ 63 172]]\n","Precision: 0.6964\n","Recall: 0.7319\n","F1 Score: 0.7137\n","Validation Accuracy: 0.7574692442882249\n","model 3 saved\n","[[272  52]\n"," [ 90 155]]\n","Precision: 0.7488\n","Recall: 0.6327\n","F1 Score: 0.6858\n","Validation Accuracy: 0.7504393673110721\n","model 4 saved\n","[[282  55]\n"," [ 73 158]]\n","Precision: 0.7418\n","Recall: 0.6840\n","F1 Score: 0.7117\n","Validation Accuracy: 0.7746478873239436\n","model 5 saved\n","[[271  31]\n"," [ 77 189]]\n","Precision: 0.8591\n","Recall: 0.7105\n","F1 Score: 0.7778\n","Validation Accuracy: 0.8098591549295775\n","model 6 saved\n","[[179 138]\n"," [ 19 232]]\n","Precision: 0.6270\n","Recall: 0.9243\n","F1 Score: 0.7472\n","Validation Accuracy: 0.7235915492957746\n","model 7 saved\n","[[273  49]\n"," [ 92 154]]\n","Precision: 0.7586\n","Recall: 0.6260\n","F1 Score: 0.6860\n","Validation Accuracy: 0.7517605633802817\n","model 8 saved\n","[[236  60]\n"," [ 53 219]]\n","Precision: 0.7849\n","Recall: 0.8051\n","F1 Score: 0.7949\n","Validation Accuracy: 0.801056338028169\n","model 9 saved\n","Average Validation Accuracy: 0.7495361890145796\n"]}],"source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_mlp(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545},"executionInfo":{"elapsed":368,"status":"ok","timestamp":1656480279815,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"6DA16IlPJtXZ","outputId":"b757ae4c-e083-4988-94fe-4e910dddd8bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[9.99999374e-01 6.25759875e-07]\n"," [6.02153377e-01 3.97846623e-01]\n"," [9.66002549e-01 3.39974510e-02]\n"," ...\n"," [1.00000000e+00 9.16716182e-28]\n"," [9.99999997e-01 2.65941634e-09]\n"," [9.99999486e-01 5.14457726e-07]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish\n","0          0            0.999999          6.257599e-07\n","1          0            0.602153          3.978466e-01\n","2          1            0.966003          3.399745e-02\n","3          1            0.580367          4.196330e-01\n","4          1            0.113440          8.865602e-01\n","...      ...                 ...                   ...\n","4647       1            0.075658          9.243419e-01\n","4648       0            1.000000          9.731610e-27\n","4649       0            1.000000          9.167162e-28\n","4650       0            1.000000          2.659416e-09\n","4651       0            0.999999          5.144577e-07\n","\n","[4652 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-727069cd-1114-4b01-91e6-ad9720d5c3f7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.999999</td>\n","      <td>6.257599e-07</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0.602153</td>\n","      <td>3.978466e-01</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0.966003</td>\n","      <td>3.399745e-02</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0.580367</td>\n","      <td>4.196330e-01</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.113440</td>\n","      <td>8.865602e-01</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4647</th>\n","      <td>1</td>\n","      <td>0.075658</td>\n","      <td>9.243419e-01</td>\n","    </tr>\n","    <tr>\n","      <th>4648</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>9.731610e-27</td>\n","    </tr>\n","    <tr>\n","      <th>4649</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>9.167162e-28</td>\n","    </tr>\n","    <tr>\n","      <th>4650</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>2.659416e-09</td>\n","    </tr>\n","    <tr>\n","      <th>4651</th>\n","      <td>0</td>\n","      <td>0.999999</td>\n","      <td>5.144577e-07</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4652 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-727069cd-1114-4b01-91e6-ad9720d5c3f7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-727069cd-1114-4b01-91e6-ad9720d5c3f7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-727069cd-1114-4b01-91e6-ad9720d5c3f7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}],"source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed HTML/MLP/model_6.h5'\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['mlp_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['mlp_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output\n"]},{"cell_type":"code","source":[""],"metadata":{"id":"rbpIy5wtL3VQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Neural Network**"],"metadata":{"id":"iLF4sz5NsSZ6"}},{"cell_type":"code","source":["\n","import keras\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","def model_aa(x_train, x_val, y_train, y_val, opt, n, early_stopping_monitor):\n","\n","  n_cols = x_train.shape[1]\n","  # print(\"check point\")\n","  #create model\n","  model = Sequential()\n","  model.add(Dense(30, activation='relu', input_shape=(n_cols,)))\n","  model.add(Dense(10, activation='relu'))\n","\n","  model.add(Dense(1, activation = 'sigmoid'))\n","  # softmax\n","  #compile model using mse as a measure of model performance\n","  model.compile(optimizer = opt, loss= 'binary_crossentropy', metrics=[\"accuracy\"])\n","\n","  history = model.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping_monitor])\n","\n","\n","  # plt.plot(history.history['loss'])\n","  # plt.plot(history.history['val_loss'])\n","  # plt.title('model loss')\n","  # plt.ylabel('Loss')\n","  # plt.xlabel('Epoch')\n","  # plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n","  # plt.show()\n","\n","\n","  print('Validation Accuracy: ')\n","  # Predicting the Test set results\n","  y_pred = model.predict(x_val)\n","  y_pred = (y_pred > 0.5)\n","\n","\n","  print(classification_report(y_val, y_pred))\n","\n","  # Model Accuracy, how often is the classifier correct?\n","  print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","\n","  # Creating the Confusion Matrix\n","  cm = confusion_matrix(y_val, y_pred)\n","  print(cm)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred))\n","\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed HTML/NN/model_'+str(n)+'.h5'\n","  pickle.dump(model, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","\n","  return metrics.accuracy_score(y_val, y_pred)\n","\n"],"metadata":{"id":"UfilmHKnL3LC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_aa(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n, early_stopping_monitor)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_OHdM1HNDio","executionInfo":{"status":"ok","timestamp":1656480578034,"user_tz":-330,"elapsed":285275,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"33bcacf4-9615-4a96-ced4-24e39f670d09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","160/160 [==============================] - 4s 4ms/step - loss: 2053.9919 - accuracy: 0.5784 - val_loss: 279.5327 - val_accuracy: 0.5975\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 161.9198 - accuracy: 0.6335 - val_loss: 75.5217 - val_accuracy: 0.6397\n","Epoch 3/100\n","160/160 [==============================] - 1s 4ms/step - loss: 68.9886 - accuracy: 0.6724 - val_loss: 34.7369 - val_accuracy: 0.7083\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 47.5932 - accuracy: 0.6951 - val_loss: 34.1017 - val_accuracy: 0.7153\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 44.6418 - accuracy: 0.7136 - val_loss: 132.0211 - val_accuracy: 0.6028\n","Epoch 6/100\n","160/160 [==============================] - 1s 4ms/step - loss: 46.8089 - accuracy: 0.7080 - val_loss: 29.2888 - val_accuracy: 0.7417\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 50.2680 - accuracy: 0.6968 - val_loss: 30.8347 - val_accuracy: 0.7276\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 34.9879 - accuracy: 0.7236 - val_loss: 39.6010 - val_accuracy: 0.7522\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 36.2311 - accuracy: 0.7293 - val_loss: 27.1519 - val_accuracy: 0.7487\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 37.7891 - accuracy: 0.7250 - val_loss: 23.1083 - val_accuracy: 0.7258\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 30.8122 - accuracy: 0.7328 - val_loss: 30.7890 - val_accuracy: 0.7592\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 32.1033 - accuracy: 0.7379 - val_loss: 42.9925 - val_accuracy: 0.7206\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 51.4483 - accuracy: 0.7109 - val_loss: 52.4956 - val_accuracy: 0.7258\n","Epoch 14/100\n","160/160 [==============================] - 0s 3ms/step - loss: 31.6284 - accuracy: 0.7351 - val_loss: 24.5557 - val_accuracy: 0.7100\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 28.3227 - accuracy: 0.7275 - val_loss: 29.9647 - val_accuracy: 0.7557\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 21.3464 - accuracy: 0.7336 - val_loss: 17.4872 - val_accuracy: 0.6960\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 19.5493 - accuracy: 0.7412 - val_loss: 29.2939 - val_accuracy: 0.7206\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 17.7366 - accuracy: 0.7406 - val_loss: 13.6314 - val_accuracy: 0.7417\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 20.7949 - accuracy: 0.7383 - val_loss: 95.0030 - val_accuracy: 0.7153\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 22.4891 - accuracy: 0.7422 - val_loss: 13.6487 - val_accuracy: 0.7540\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 19.0954 - accuracy: 0.7428 - val_loss: 13.6671 - val_accuracy: 0.7434\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 31.3317 - accuracy: 0.7346 - val_loss: 29.4667 - val_accuracy: 0.6344\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 12.7031 - accuracy: 0.7600 - val_loss: 11.5925 - val_accuracy: 0.7768\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 28.7805 - accuracy: 0.7334 - val_loss: 52.4286 - val_accuracy: 0.7118\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 28.5195 - accuracy: 0.7414 - val_loss: 13.0939 - val_accuracy: 0.7698\n","Epoch 26/100\n","160/160 [==============================] - 0s 3ms/step - loss: 23.9698 - accuracy: 0.7408 - val_loss: 22.7010 - val_accuracy: 0.6942\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 20.6467 - accuracy: 0.7480 - val_loss: 11.3201 - val_accuracy: 0.7223\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 34.2668 - accuracy: 0.7265 - val_loss: 16.5738 - val_accuracy: 0.7663\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 25.5724 - accuracy: 0.7416 - val_loss: 14.0834 - val_accuracy: 0.7381\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 17.7985 - accuracy: 0.7435 - val_loss: 9.1963 - val_accuracy: 0.7627\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 18.8244 - accuracy: 0.7500 - val_loss: 17.5936 - val_accuracy: 0.7575\n","Epoch 32/100\n","160/160 [==============================] - 0s 3ms/step - loss: 21.6404 - accuracy: 0.7418 - val_loss: 16.3970 - val_accuracy: 0.7557\n","Epoch 33/100\n","160/160 [==============================] - 0s 3ms/step - loss: 21.8959 - accuracy: 0.7453 - val_loss: 45.2558 - val_accuracy: 0.7469\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 31.8973 - accuracy: 0.7443 - val_loss: 68.0525 - val_accuracy: 0.7223\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 15.5802 - accuracy: 0.7506 - val_loss: 9.5604 - val_accuracy: 0.7733\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 14.5644 - accuracy: 0.7531 - val_loss: 27.5510 - val_accuracy: 0.7434\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 18.2250 - accuracy: 0.7608 - val_loss: 20.2927 - val_accuracy: 0.7786\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 51.1314 - accuracy: 0.7125 - val_loss: 20.0177 - val_accuracy: 0.7575\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 25.5294 - accuracy: 0.7463 - val_loss: 22.5319 - val_accuracy: 0.7575\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 11.5372 - accuracy: 0.7750 - val_loss: 29.6192 - val_accuracy: 0.7575\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.84      0.80       322\n","           1       0.76      0.64      0.70       247\n","\n","    accuracy                           0.76       569\n","   macro avg       0.76      0.74      0.75       569\n","weighted avg       0.76      0.76      0.75       569\n","\n","Accuracy: 0.7574692442882249\n","[[272  50]\n"," [ 88 159]]\n","Precision: 0.7608\n","Recall: 0.6437\n","F1 Score: 0.6974\n","INFO:tensorflow:Assets written to: ram://2194aa88-fedf-4939-bcca-be49be9b1556/assets\n","model 0 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 146.6189 - accuracy: 0.5614 - val_loss: 45.7065 - val_accuracy: 0.6186\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 25.6675 - accuracy: 0.6169 - val_loss: 24.8165 - val_accuracy: 0.6169\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 18.0295 - accuracy: 0.6810 - val_loss: 27.6560 - val_accuracy: 0.7135\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 14.2332 - accuracy: 0.7185 - val_loss: 14.2397 - val_accuracy: 0.7223\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 16.7163 - accuracy: 0.7113 - val_loss: 13.7787 - val_accuracy: 0.7504\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 16.8216 - accuracy: 0.7236 - val_loss: 13.7316 - val_accuracy: 0.7610\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 14.5060 - accuracy: 0.7164 - val_loss: 16.6058 - val_accuracy: 0.7346\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 10.2329 - accuracy: 0.7396 - val_loss: 16.7599 - val_accuracy: 0.7364\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 12.9294 - accuracy: 0.7248 - val_loss: 14.3597 - val_accuracy: 0.7522\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 16.4729 - accuracy: 0.7226 - val_loss: 12.4753 - val_accuracy: 0.7768\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 10.5182 - accuracy: 0.7439 - val_loss: 13.6789 - val_accuracy: 0.7540\n","Epoch 12/100\n","160/160 [==============================] - 0s 3ms/step - loss: 8.2321 - accuracy: 0.7344 - val_loss: 11.7622 - val_accuracy: 0.7346\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 8.2831 - accuracy: 0.7420 - val_loss: 9.5290 - val_accuracy: 0.7733\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 6.1666 - accuracy: 0.7477 - val_loss: 24.4558 - val_accuracy: 0.7276\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 6.8777 - accuracy: 0.7400 - val_loss: 13.3954 - val_accuracy: 0.7083\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 8.0714 - accuracy: 0.7355 - val_loss: 14.6372 - val_accuracy: 0.7592\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 10.4020 - accuracy: 0.7416 - val_loss: 13.5686 - val_accuracy: 0.7522\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 8.8280 - accuracy: 0.7357 - val_loss: 14.2018 - val_accuracy: 0.7645\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 8.5286 - accuracy: 0.7461 - val_loss: 9.4710 - val_accuracy: 0.7575\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 11.3918 - accuracy: 0.7328 - val_loss: 8.8599 - val_accuracy: 0.7786\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 6.2302 - accuracy: 0.7502 - val_loss: 13.0334 - val_accuracy: 0.7944\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 7.9800 - accuracy: 0.7557 - val_loss: 12.2340 - val_accuracy: 0.7680\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 7.5376 - accuracy: 0.7400 - val_loss: 11.4742 - val_accuracy: 0.7540\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 6.0379 - accuracy: 0.7529 - val_loss: 10.2781 - val_accuracy: 0.7838\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 6.7291 - accuracy: 0.7451 - val_loss: 12.8664 - val_accuracy: 0.7557\n","Epoch 26/100\n","160/160 [==============================] - 1s 4ms/step - loss: 6.7318 - accuracy: 0.7527 - val_loss: 12.0317 - val_accuracy: 0.7750\n","Epoch 27/100\n","160/160 [==============================] - 1s 4ms/step - loss: 7.6725 - accuracy: 0.7435 - val_loss: 13.4068 - val_accuracy: 0.7733\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 6.7650 - accuracy: 0.7539 - val_loss: 6.1974 - val_accuracy: 0.7821\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 8.7733 - accuracy: 0.7586 - val_loss: 8.3706 - val_accuracy: 0.7680\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 6.9083 - accuracy: 0.7432 - val_loss: 16.5215 - val_accuracy: 0.7592\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 4.9237 - accuracy: 0.7619 - val_loss: 6.3297 - val_accuracy: 0.7733\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 5.8239 - accuracy: 0.7553 - val_loss: 9.7885 - val_accuracy: 0.8032\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 5.5113 - accuracy: 0.7496 - val_loss: 9.5201 - val_accuracy: 0.7645\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 5.6663 - accuracy: 0.7525 - val_loss: 9.6303 - val_accuracy: 0.7645\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 5.5018 - accuracy: 0.7547 - val_loss: 7.9566 - val_accuracy: 0.7118\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 5.6662 - accuracy: 0.7512 - val_loss: 10.5267 - val_accuracy: 0.7750\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 5.3118 - accuracy: 0.7686 - val_loss: 5.4495 - val_accuracy: 0.7522\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 5.1023 - accuracy: 0.7641 - val_loss: 9.7113 - val_accuracy: 0.7293\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 6.4770 - accuracy: 0.7435 - val_loss: 6.1937 - val_accuracy: 0.7873\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 6.2955 - accuracy: 0.7563 - val_loss: 11.5648 - val_accuracy: 0.7592\n","Epoch 41/100\n","160/160 [==============================] - 0s 3ms/step - loss: 6.1618 - accuracy: 0.7629 - val_loss: 11.8885 - val_accuracy: 0.7522\n","Epoch 42/100\n","160/160 [==============================] - 1s 4ms/step - loss: 6.5003 - accuracy: 0.7435 - val_loss: 11.0561 - val_accuracy: 0.7522\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 5.0347 - accuracy: 0.7471 - val_loss: 8.3640 - val_accuracy: 0.7926\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 6.4446 - accuracy: 0.7477 - val_loss: 5.1016 - val_accuracy: 0.7873\n","Epoch 45/100\n","160/160 [==============================] - 1s 3ms/step - loss: 5.9802 - accuracy: 0.7559 - val_loss: 6.4590 - val_accuracy: 0.7944\n","Epoch 46/100\n","160/160 [==============================] - 1s 3ms/step - loss: 5.1807 - accuracy: 0.7547 - val_loss: 8.5311 - val_accuracy: 0.7680\n","Epoch 47/100\n","160/160 [==============================] - 1s 3ms/step - loss: 8.6705 - accuracy: 0.7349 - val_loss: 10.6726 - val_accuracy: 0.7961\n","Epoch 48/100\n","160/160 [==============================] - 1s 3ms/step - loss: 4.7046 - accuracy: 0.7652 - val_loss: 4.7469 - val_accuracy: 0.7698\n","Epoch 49/100\n","160/160 [==============================] - 1s 3ms/step - loss: 4.3553 - accuracy: 0.7668 - val_loss: 9.5868 - val_accuracy: 0.7715\n","Epoch 50/100\n","160/160 [==============================] - 1s 3ms/step - loss: 4.2825 - accuracy: 0.7674 - val_loss: 6.0508 - val_accuracy: 0.7750\n","Epoch 51/100\n","160/160 [==============================] - 0s 3ms/step - loss: 5.2512 - accuracy: 0.7582 - val_loss: 7.1058 - val_accuracy: 0.7873\n","Epoch 52/100\n","160/160 [==============================] - 1s 3ms/step - loss: 4.4918 - accuracy: 0.7641 - val_loss: 6.5158 - val_accuracy: 0.8014\n","Epoch 53/100\n","160/160 [==============================] - 1s 3ms/step - loss: 6.5968 - accuracy: 0.7400 - val_loss: 15.7524 - val_accuracy: 0.6292\n","Epoch 54/100\n","160/160 [==============================] - 0s 3ms/step - loss: 8.4231 - accuracy: 0.7420 - val_loss: 7.3261 - val_accuracy: 0.7786\n","Epoch 55/100\n","160/160 [==============================] - 1s 3ms/step - loss: 5.5177 - accuracy: 0.7555 - val_loss: 6.9021 - val_accuracy: 0.8084\n","Epoch 56/100\n","160/160 [==============================] - 1s 3ms/step - loss: 6.1120 - accuracy: 0.7633 - val_loss: 14.7477 - val_accuracy: 0.7645\n","Epoch 57/100\n","160/160 [==============================] - 1s 3ms/step - loss: 4.7802 - accuracy: 0.7602 - val_loss: 9.1547 - val_accuracy: 0.7698\n","Epoch 58/100\n","160/160 [==============================] - 0s 3ms/step - loss: 5.8454 - accuracy: 0.7477 - val_loss: 8.6759 - val_accuracy: 0.7979\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.78      0.81       320\n","           1       0.74      0.82      0.78       249\n","\n","    accuracy                           0.80       569\n","   macro avg       0.80      0.80      0.80       569\n","weighted avg       0.80      0.80      0.80       569\n","\n","Accuracy: 0.7978910369068541\n","[[250  70]\n"," [ 45 204]]\n","Precision: 0.7445\n","Recall: 0.8193\n","F1 Score: 0.7801\n","INFO:tensorflow:Assets written to: ram://565a8a90-a42b-4387-9ee1-278ba601b222/assets\n","model 1 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 396.9541 - accuracy: 0.4554 - val_loss: 0.6967 - val_accuracy: 0.4306\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 4.5113 - accuracy: 0.4748 - val_loss: 0.6920 - val_accuracy: 0.5694\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 3.5492 - accuracy: 0.5618 - val_loss: 0.6891 - val_accuracy: 0.5694\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 2.7325 - accuracy: 0.5618 - val_loss: 0.6873 - val_accuracy: 0.5694\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 2.2458 - accuracy: 0.5618 - val_loss: 0.6862 - val_accuracy: 0.5694\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 1.7806 - accuracy: 0.5618 - val_loss: 0.6853 - val_accuracy: 0.5694\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 1.2296 - accuracy: 0.5616 - val_loss: 0.6848 - val_accuracy: 0.5694\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.8001 - accuracy: 0.5618 - val_loss: 0.6845 - val_accuracy: 0.5694\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6860 - accuracy: 0.5618 - val_loss: 0.6842 - val_accuracy: 0.5694\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6859 - accuracy: 0.5618 - val_loss: 0.6840 - val_accuracy: 0.5694\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6858 - accuracy: 0.5618 - val_loss: 0.6840 - val_accuracy: 0.5694\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6857 - accuracy: 0.5618 - val_loss: 0.6839 - val_accuracy: 0.5694\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6857 - accuracy: 0.5618 - val_loss: 0.6838 - val_accuracy: 0.5694\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6856 - accuracy: 0.5618 - val_loss: 0.6837 - val_accuracy: 0.5694\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.5618 - val_loss: 0.6837 - val_accuracy: 0.5694\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6856 - accuracy: 0.5618 - val_loss: 0.6837 - val_accuracy: 0.5694\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6837 - val_accuracy: 0.5694\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6837 - val_accuracy: 0.5694\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 22/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 23/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 24/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 26/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 27/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 28/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 30/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 31/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 34/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 36/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 37/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 38/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 39/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 40/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Epoch 41/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6836 - val_accuracy: 0.5694\n","Validation Accuracy: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.57      1.00      0.73       324\n","           1       0.00      0.00      0.00       245\n","\n","    accuracy                           0.57       569\n","   macro avg       0.28      0.50      0.36       569\n","weighted avg       0.32      0.57      0.41       569\n","\n","Accuracy: 0.5694200351493849\n","[[324   0]\n"," [245   0]]\n","Precision: 0.0000\n","Recall: 0.0000\n","F1 Score: 0.0000\n","INFO:tensorflow:Assets written to: ram://2909b241-ca88-4243-9ee6-1b7e1c917c2b/assets\n","model 2 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 5ms/step - loss: 179.2388 - accuracy: 0.5444 - val_loss: 89.2186 - val_accuracy: 0.6134\n","Epoch 2/100\n","160/160 [==============================] - 1s 4ms/step - loss: 52.9039 - accuracy: 0.5884 - val_loss: 23.6565 - val_accuracy: 0.6397\n","Epoch 3/100\n","160/160 [==============================] - 1s 4ms/step - loss: 52.1703 - accuracy: 0.6419 - val_loss: 30.7135 - val_accuracy: 0.5501\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 26.3006 - accuracy: 0.6873 - val_loss: 22.3573 - val_accuracy: 0.7346\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 26.3694 - accuracy: 0.7080 - val_loss: 31.7387 - val_accuracy: 0.6977\n","Epoch 6/100\n","160/160 [==============================] - 1s 4ms/step - loss: 34.1094 - accuracy: 0.6947 - val_loss: 36.6361 - val_accuracy: 0.5923\n","Epoch 7/100\n","160/160 [==============================] - 1s 4ms/step - loss: 27.7674 - accuracy: 0.6921 - val_loss: 102.4704 - val_accuracy: 0.7206\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 23.1374 - accuracy: 0.7127 - val_loss: 26.7580 - val_accuracy: 0.6696\n","Epoch 9/100\n","160/160 [==============================] - 1s 4ms/step - loss: 40.0030 - accuracy: 0.7048 - val_loss: 33.8420 - val_accuracy: 0.7047\n","Epoch 10/100\n","160/160 [==============================] - 1s 4ms/step - loss: 15.7056 - accuracy: 0.7312 - val_loss: 15.2817 - val_accuracy: 0.7188\n","Epoch 11/100\n","160/160 [==============================] - 1s 4ms/step - loss: 12.9270 - accuracy: 0.7359 - val_loss: 7.9737 - val_accuracy: 0.7452\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 13.3513 - accuracy: 0.7330 - val_loss: 11.4736 - val_accuracy: 0.7293\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 12.2178 - accuracy: 0.7326 - val_loss: 13.3237 - val_accuracy: 0.7083\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 24.4900 - accuracy: 0.7131 - val_loss: 11.1711 - val_accuracy: 0.7381\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 45.1208 - accuracy: 0.6955 - val_loss: 14.8230 - val_accuracy: 0.7135\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 20.7729 - accuracy: 0.7291 - val_loss: 13.2254 - val_accuracy: 0.7153\n","Epoch 17/100\n","160/160 [==============================] - 0s 3ms/step - loss: 16.5414 - accuracy: 0.7219 - val_loss: 13.5644 - val_accuracy: 0.7346\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 19.0929 - accuracy: 0.7301 - val_loss: 9.5142 - val_accuracy: 0.7522\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 12.7063 - accuracy: 0.7430 - val_loss: 13.5348 - val_accuracy: 0.7065\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 22.5719 - accuracy: 0.7052 - val_loss: 15.6782 - val_accuracy: 0.6801\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 33.2984 - accuracy: 0.7148 - val_loss: 18.6743 - val_accuracy: 0.6942\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.57      0.68       334\n","           1       0.59      0.88      0.70       235\n","\n","    accuracy                           0.69       569\n","   macro avg       0.73      0.72      0.69       569\n","weighted avg       0.75      0.69      0.69       569\n","\n","Accuracy: 0.6942003514938488\n","[[189 145]\n"," [ 29 206]]\n","Precision: 0.5869\n","Recall: 0.8766\n","F1 Score: 0.7031\n","INFO:tensorflow:Assets written to: ram://4faac1f2-24e8-4256-95e7-aea5e79a961a/assets\n","model 3 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 238.2863 - accuracy: 0.6689 - val_loss: 60.4356 - val_accuracy: 0.6977\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 74.1042 - accuracy: 0.6970 - val_loss: 58.7164 - val_accuracy: 0.7012\n","Epoch 3/100\n","160/160 [==============================] - 1s 4ms/step - loss: 65.1580 - accuracy: 0.6699 - val_loss: 30.0361 - val_accuracy: 0.7188\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 49.2714 - accuracy: 0.7019 - val_loss: 35.4413 - val_accuracy: 0.6907\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 35.1763 - accuracy: 0.7117 - val_loss: 21.8574 - val_accuracy: 0.7083\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 23.8103 - accuracy: 0.7179 - val_loss: 12.1154 - val_accuracy: 0.7276\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 34.9531 - accuracy: 0.7029 - val_loss: 52.2081 - val_accuracy: 0.6591\n","Epoch 8/100\n","160/160 [==============================] - 1s 4ms/step - loss: 22.0884 - accuracy: 0.7052 - val_loss: 11.3485 - val_accuracy: 0.7170\n","Epoch 9/100\n","160/160 [==============================] - 1s 5ms/step - loss: 20.7402 - accuracy: 0.7097 - val_loss: 18.0328 - val_accuracy: 0.7065\n","Epoch 10/100\n","160/160 [==============================] - 1s 5ms/step - loss: 28.1746 - accuracy: 0.7144 - val_loss: 53.2846 - val_accuracy: 0.6608\n","Epoch 11/100\n","160/160 [==============================] - 1s 4ms/step - loss: 22.8556 - accuracy: 0.7115 - val_loss: 8.6043 - val_accuracy: 0.7417\n","Epoch 12/100\n","160/160 [==============================] - 1s 5ms/step - loss: 15.5018 - accuracy: 0.7324 - val_loss: 20.0051 - val_accuracy: 0.6942\n","Epoch 13/100\n","160/160 [==============================] - 1s 4ms/step - loss: 12.2223 - accuracy: 0.7306 - val_loss: 53.0156 - val_accuracy: 0.6784\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 15.9759 - accuracy: 0.6992 - val_loss: 11.1260 - val_accuracy: 0.7100\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 18.0401 - accuracy: 0.7072 - val_loss: 8.3926 - val_accuracy: 0.7417\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 11.1998 - accuracy: 0.7338 - val_loss: 10.2528 - val_accuracy: 0.7364\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 18.2006 - accuracy: 0.7211 - val_loss: 35.6279 - val_accuracy: 0.6503\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 12.6111 - accuracy: 0.7181 - val_loss: 8.2677 - val_accuracy: 0.7170\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 16.0415 - accuracy: 0.7197 - val_loss: 51.4516 - val_accuracy: 0.5149\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 16.9721 - accuracy: 0.7080 - val_loss: 64.7133 - val_accuracy: 0.6555\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 16.9148 - accuracy: 0.7205 - val_loss: 11.6549 - val_accuracy: 0.6749\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 14.9087 - accuracy: 0.7144 - val_loss: 10.4326 - val_accuracy: 0.6942\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 21.2150 - accuracy: 0.7000 - val_loss: 8.4788 - val_accuracy: 0.7188\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 16.2587 - accuracy: 0.6925 - val_loss: 14.6211 - val_accuracy: 0.6784\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 14.9014 - accuracy: 0.7115 - val_loss: 27.9895 - val_accuracy: 0.6116\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 10.3469 - accuracy: 0.7031 - val_loss: 8.9990 - val_accuracy: 0.6872\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 12.7271 - accuracy: 0.6851 - val_loss: 9.7441 - val_accuracy: 0.6889\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 11.4594 - accuracy: 0.7048 - val_loss: 29.0642 - val_accuracy: 0.4991\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.21      0.32       324\n","           1       0.46      0.88      0.60       245\n","\n","    accuracy                           0.50       569\n","   macro avg       0.58      0.55      0.46       569\n","weighted avg       0.60      0.50      0.44       569\n","\n","Accuracy: 0.4991212653778559\n","[[ 68 256]\n"," [ 29 216]]\n","Precision: 0.4576\n","Recall: 0.8816\n","F1 Score: 0.6025\n","INFO:tensorflow:Assets written to: ram://988da781-5401-42b9-ae78-846519a4a82a/assets\n","model 4 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 276.9175 - accuracy: 0.6039 - val_loss: 48.8721 - val_accuracy: 0.7007\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 51.8468 - accuracy: 0.7067 - val_loss: 38.0104 - val_accuracy: 0.5898\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 35.6703 - accuracy: 0.7194 - val_loss: 26.4285 - val_accuracy: 0.7254\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 51.7998 - accuracy: 0.6947 - val_loss: 11.1184 - val_accuracy: 0.7130\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 25.8125 - accuracy: 0.7244 - val_loss: 13.9061 - val_accuracy: 0.7165\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 21.2340 - accuracy: 0.7350 - val_loss: 8.3455 - val_accuracy: 0.7342\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 23.9109 - accuracy: 0.7200 - val_loss: 6.9656 - val_accuracy: 0.7236\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 25.4086 - accuracy: 0.7092 - val_loss: 12.0800 - val_accuracy: 0.7077\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 28.6100 - accuracy: 0.7073 - val_loss: 11.8342 - val_accuracy: 0.7025\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 24.7300 - accuracy: 0.7297 - val_loss: 7.4332 - val_accuracy: 0.7518\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 19.6249 - accuracy: 0.7332 - val_loss: 7.7669 - val_accuracy: 0.7447\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 11.2203 - accuracy: 0.7463 - val_loss: 5.7388 - val_accuracy: 0.7500\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 19.7189 - accuracy: 0.7225 - val_loss: 13.0188 - val_accuracy: 0.7218\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 28.7007 - accuracy: 0.7096 - val_loss: 14.6946 - val_accuracy: 0.6831\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 20.0086 - accuracy: 0.7262 - val_loss: 8.9346 - val_accuracy: 0.7254\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 15.3144 - accuracy: 0.7262 - val_loss: 15.1858 - val_accuracy: 0.6937\n","Epoch 17/100\n","160/160 [==============================] - 1s 4ms/step - loss: 13.7150 - accuracy: 0.7356 - val_loss: 10.3234 - val_accuracy: 0.7394\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 21.2476 - accuracy: 0.7254 - val_loss: 4.3972 - val_accuracy: 0.7500\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 10.6830 - accuracy: 0.7407 - val_loss: 8.5045 - val_accuracy: 0.7271\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 11.4217 - accuracy: 0.7428 - val_loss: 3.7535 - val_accuracy: 0.7641\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 13.1992 - accuracy: 0.7368 - val_loss: 21.4013 - val_accuracy: 0.7342\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 12.3262 - accuracy: 0.7284 - val_loss: 4.9575 - val_accuracy: 0.6655\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 17.3023 - accuracy: 0.7370 - val_loss: 4.8411 - val_accuracy: 0.7570\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 17.3232 - accuracy: 0.7243 - val_loss: 14.1120 - val_accuracy: 0.7218\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 9.4196 - accuracy: 0.7557 - val_loss: 3.9136 - val_accuracy: 0.7694\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 16.4467 - accuracy: 0.7448 - val_loss: 9.1155 - val_accuracy: 0.7817\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 10.0669 - accuracy: 0.7608 - val_loss: 8.2842 - val_accuracy: 0.7870\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 15.5924 - accuracy: 0.7448 - val_loss: 39.7906 - val_accuracy: 0.7465\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 16.2380 - accuracy: 0.7442 - val_loss: 4.9101 - val_accuracy: 0.7518\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 10.3100 - accuracy: 0.7579 - val_loss: 11.5320 - val_accuracy: 0.7183\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.72      0.75       337\n","           1       0.64      0.72      0.67       231\n","\n","    accuracy                           0.72       568\n","   macro avg       0.71      0.72      0.71       568\n","weighted avg       0.73      0.72      0.72       568\n","\n","Accuracy: 0.7183098591549296\n","[[242  95]\n"," [ 65 166]]\n","Precision: 0.6360\n","Recall: 0.7186\n","F1 Score: 0.6748\n","INFO:tensorflow:Assets written to: ram://e42d8f49-b129-4a0c-8ada-6081a5f0fa3e/assets\n","model 5 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 547.9888 - accuracy: 0.5634 - val_loss: 63.4320 - val_accuracy: 0.5722\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 42.0470 - accuracy: 0.6951 - val_loss: 16.4789 - val_accuracy: 0.7482\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 26.6893 - accuracy: 0.7010 - val_loss: 45.7532 - val_accuracy: 0.6884\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 27.6445 - accuracy: 0.7061 - val_loss: 19.7979 - val_accuracy: 0.7606\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 39.6575 - accuracy: 0.6760 - val_loss: 12.2978 - val_accuracy: 0.7676\n","Epoch 6/100\n","160/160 [==============================] - 0s 3ms/step - loss: 19.0064 - accuracy: 0.7327 - val_loss: 23.0840 - val_accuracy: 0.6813\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 22.4391 - accuracy: 0.7246 - val_loss: 12.5698 - val_accuracy: 0.8187\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 19.4753 - accuracy: 0.7233 - val_loss: 161.4696 - val_accuracy: 0.5722\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 37.9367 - accuracy: 0.7035 - val_loss: 17.1146 - val_accuracy: 0.6514\n","Epoch 10/100\n","160/160 [==============================] - 1s 4ms/step - loss: 16.6381 - accuracy: 0.7381 - val_loss: 11.7672 - val_accuracy: 0.7482\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 32.0096 - accuracy: 0.7149 - val_loss: 56.4357 - val_accuracy: 0.6972\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 13.0690 - accuracy: 0.7500 - val_loss: 16.2770 - val_accuracy: 0.7500\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 12.2877 - accuracy: 0.7514 - val_loss: 10.0967 - val_accuracy: 0.7870\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 22.2385 - accuracy: 0.7342 - val_loss: 25.9004 - val_accuracy: 0.7588\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 25.4194 - accuracy: 0.7162 - val_loss: 10.5326 - val_accuracy: 0.7993\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 21.4899 - accuracy: 0.7360 - val_loss: 6.7298 - val_accuracy: 0.7975\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 11.9499 - accuracy: 0.7502 - val_loss: 13.6600 - val_accuracy: 0.7711\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 12.2484 - accuracy: 0.7510 - val_loss: 21.0613 - val_accuracy: 0.7570\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 10.4888 - accuracy: 0.7500 - val_loss: 13.8611 - val_accuracy: 0.7570\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 13.0746 - accuracy: 0.7457 - val_loss: 24.5601 - val_accuracy: 0.6426\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 20.7501 - accuracy: 0.7287 - val_loss: 32.3561 - val_accuracy: 0.7183\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 12.9410 - accuracy: 0.7481 - val_loss: 10.8201 - val_accuracy: 0.7623\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 8.4164 - accuracy: 0.7585 - val_loss: 31.1596 - val_accuracy: 0.7324\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 10.4125 - accuracy: 0.7532 - val_loss: 4.3070 - val_accuracy: 0.7940\n","Epoch 25/100\n","160/160 [==============================] - 1s 4ms/step - loss: 13.9159 - accuracy: 0.7381 - val_loss: 63.0252 - val_accuracy: 0.7025\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 16.8162 - accuracy: 0.7203 - val_loss: 8.6117 - val_accuracy: 0.7606\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 23.0503 - accuracy: 0.7241 - val_loss: 30.0124 - val_accuracy: 0.6673\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 11.9322 - accuracy: 0.7479 - val_loss: 6.7053 - val_accuracy: 0.8257\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 17.9930 - accuracy: 0.7311 - val_loss: 14.4612 - val_accuracy: 0.7359\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 12.4489 - accuracy: 0.7563 - val_loss: 36.6942 - val_accuracy: 0.7254\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 17.4673 - accuracy: 0.7536 - val_loss: 40.7123 - val_accuracy: 0.7130\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 14.1513 - accuracy: 0.7518 - val_loss: 6.8177 - val_accuracy: 0.7958\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 17.0763 - accuracy: 0.7495 - val_loss: 7.1058 - val_accuracy: 0.7887\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 16.2465 - accuracy: 0.7465 - val_loss: 18.8029 - val_accuracy: 0.7553\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.82      0.78       302\n","           1       0.77      0.68      0.72       266\n","\n","    accuracy                           0.76       568\n","   macro avg       0.76      0.75      0.75       568\n","weighted avg       0.76      0.76      0.75       568\n","\n","Accuracy: 0.7552816901408451\n","[[249  53]\n"," [ 86 180]]\n","Precision: 0.7725\n","Recall: 0.6767\n","F1 Score: 0.7214\n","INFO:tensorflow:Assets written to: ram://bac4513c-4d41-446b-bd4f-bf0b62dac76d/assets\n","model 6 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 94.3857 - accuracy: 0.5495 - val_loss: 20.7958 - val_accuracy: 0.5123\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 16.3571 - accuracy: 0.4997 - val_loss: 37.5287 - val_accuracy: 0.5123\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 14.7125 - accuracy: 0.5237 - val_loss: 15.9018 - val_accuracy: 0.5194\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 10.0098 - accuracy: 0.5431 - val_loss: 6.1029 - val_accuracy: 0.5018\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 4.7012 - accuracy: 0.5273 - val_loss: 3.8908 - val_accuracy: 0.6602\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 2.1402 - accuracy: 0.6992 - val_loss: 3.7202 - val_accuracy: 0.6461\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 2.7078 - accuracy: 0.7086 - val_loss: 1.4757 - val_accuracy: 0.6778\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 2.0721 - accuracy: 0.7112 - val_loss: 1.1922 - val_accuracy: 0.6831\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 1.0387 - accuracy: 0.6994 - val_loss: 1.6481 - val_accuracy: 0.6796\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 1.1755 - accuracy: 0.7043 - val_loss: 1.0385 - val_accuracy: 0.6849\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 1.0903 - accuracy: 0.7018 - val_loss: 0.8172 - val_accuracy: 0.6866\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.8745 - accuracy: 0.7086 - val_loss: 0.8778 - val_accuracy: 0.6866\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.8796 - accuracy: 0.7123 - val_loss: 1.0874 - val_accuracy: 0.6796\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6570 - accuracy: 0.7043 - val_loss: 0.7911 - val_accuracy: 0.6813\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6808 - accuracy: 0.7047 - val_loss: 0.6635 - val_accuracy: 0.6778\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6148 - accuracy: 0.7041 - val_loss: 0.6990 - val_accuracy: 0.6849\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6079 - accuracy: 0.7127 - val_loss: 0.6857 - val_accuracy: 0.6813\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6026 - accuracy: 0.7157 - val_loss: 0.6649 - val_accuracy: 0.6849\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5984 - accuracy: 0.7160 - val_loss: 0.6711 - val_accuracy: 0.6761\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5993 - accuracy: 0.7114 - val_loss: 0.6549 - val_accuracy: 0.6778\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5946 - accuracy: 0.7090 - val_loss: 0.6586 - val_accuracy: 0.6761\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5905 - accuracy: 0.7108 - val_loss: 0.6583 - val_accuracy: 0.6849\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5911 - accuracy: 0.7198 - val_loss: 0.7047 - val_accuracy: 0.6901\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5903 - accuracy: 0.7166 - val_loss: 0.6480 - val_accuracy: 0.6884\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5834 - accuracy: 0.7176 - val_loss: 0.6380 - val_accuracy: 0.6901\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5802 - accuracy: 0.7168 - val_loss: 0.6313 - val_accuracy: 0.6884\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5826 - accuracy: 0.7211 - val_loss: 0.6064 - val_accuracy: 0.6937\n","Epoch 28/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.5846 - accuracy: 0.7174 - val_loss: 0.6045 - val_accuracy: 0.6849\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5883 - accuracy: 0.7098 - val_loss: 0.6280 - val_accuracy: 0.6937\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6765 - accuracy: 0.7151 - val_loss: 0.6082 - val_accuracy: 0.6849\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5799 - accuracy: 0.7125 - val_loss: 0.6151 - val_accuracy: 0.6796\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5801 - accuracy: 0.7160 - val_loss: 0.6017 - val_accuracy: 0.6884\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5715 - accuracy: 0.7215 - val_loss: 0.6058 - val_accuracy: 0.6849\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5720 - accuracy: 0.7213 - val_loss: 0.6128 - val_accuracy: 0.6972\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5676 - accuracy: 0.7188 - val_loss: 0.6123 - val_accuracy: 0.6972\n","Epoch 36/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.5685 - accuracy: 0.7209 - val_loss: 0.6028 - val_accuracy: 0.6937\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5728 - accuracy: 0.7203 - val_loss: 0.6001 - val_accuracy: 0.6866\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5664 - accuracy: 0.7139 - val_loss: 0.6086 - val_accuracy: 0.6954\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5608 - accuracy: 0.7336 - val_loss: 0.6088 - val_accuracy: 0.6989\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5583 - accuracy: 0.7299 - val_loss: 0.5925 - val_accuracy: 0.6989\n","Epoch 41/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5587 - accuracy: 0.7295 - val_loss: 0.6058 - val_accuracy: 0.6937\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5532 - accuracy: 0.7346 - val_loss: 0.5975 - val_accuracy: 0.6919\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5512 - accuracy: 0.7358 - val_loss: 0.6057 - val_accuracy: 0.6937\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.7348 - val_loss: 0.5954 - val_accuracy: 0.6901\n","Epoch 45/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5540 - accuracy: 0.7325 - val_loss: 0.6068 - val_accuracy: 0.6954\n","Epoch 46/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5536 - accuracy: 0.7366 - val_loss: 0.6131 - val_accuracy: 0.7025\n","Epoch 47/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.5481 - accuracy: 0.7411 - val_loss: 0.6286 - val_accuracy: 0.7025\n","Epoch 48/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5589 - accuracy: 0.7409 - val_loss: 0.6010 - val_accuracy: 0.7130\n","Epoch 49/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.5463 - accuracy: 0.7463 - val_loss: 0.5980 - val_accuracy: 0.7025\n","Epoch 50/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.5534 - accuracy: 0.7440 - val_loss: 0.6900 - val_accuracy: 0.7042\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.67      0.93      0.78       317\n","           1       0.83      0.42      0.56       251\n","\n","    accuracy                           0.70       568\n","   macro avg       0.75      0.67      0.67       568\n","weighted avg       0.74      0.70      0.68       568\n","\n","Accuracy: 0.704225352112676\n","[[295  22]\n"," [146 105]]\n","Precision: 0.8268\n","Recall: 0.4183\n","F1 Score: 0.5556\n","INFO:tensorflow:Assets written to: ram://5243f1fb-1542-45fd-a076-f56195ddb96f/assets\n","model 7 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 5ms/step - loss: 126.6981 - accuracy: 0.6021 - val_loss: 43.5785 - val_accuracy: 0.5845\n","Epoch 2/100\n","160/160 [==============================] - 1s 4ms/step - loss: 36.6558 - accuracy: 0.6987 - val_loss: 19.0101 - val_accuracy: 0.7289\n","Epoch 3/100\n","160/160 [==============================] - 1s 4ms/step - loss: 35.9496 - accuracy: 0.6959 - val_loss: 19.0945 - val_accuracy: 0.7254\n","Epoch 4/100\n","160/160 [==============================] - 1s 4ms/step - loss: 15.0044 - accuracy: 0.7235 - val_loss: 10.2216 - val_accuracy: 0.7553\n","Epoch 5/100\n","160/160 [==============================] - 1s 4ms/step - loss: 16.6348 - accuracy: 0.7219 - val_loss: 14.9093 - val_accuracy: 0.7289\n","Epoch 6/100\n","160/160 [==============================] - 1s 4ms/step - loss: 14.9815 - accuracy: 0.7327 - val_loss: 13.3867 - val_accuracy: 0.7518\n","Epoch 7/100\n","160/160 [==============================] - 1s 4ms/step - loss: 13.5670 - accuracy: 0.7442 - val_loss: 9.2489 - val_accuracy: 0.7359\n","Epoch 8/100\n","160/160 [==============================] - 1s 4ms/step - loss: 9.7249 - accuracy: 0.7403 - val_loss: 9.2282 - val_accuracy: 0.7553\n","Epoch 9/100\n","160/160 [==============================] - 1s 4ms/step - loss: 10.4206 - accuracy: 0.7405 - val_loss: 12.2192 - val_accuracy: 0.7306\n","Epoch 10/100\n","160/160 [==============================] - 1s 4ms/step - loss: 9.1320 - accuracy: 0.7387 - val_loss: 6.6681 - val_accuracy: 0.7606\n","Epoch 11/100\n","160/160 [==============================] - 1s 4ms/step - loss: 17.7802 - accuracy: 0.7174 - val_loss: 8.5438 - val_accuracy: 0.7482\n","Epoch 12/100\n","160/160 [==============================] - 1s 4ms/step - loss: 7.9195 - accuracy: 0.7520 - val_loss: 6.6996 - val_accuracy: 0.7658\n","Epoch 13/100\n","160/160 [==============================] - 1s 4ms/step - loss: 5.5968 - accuracy: 0.7575 - val_loss: 8.6227 - val_accuracy: 0.7465\n","Epoch 14/100\n","160/160 [==============================] - 1s 4ms/step - loss: 12.3440 - accuracy: 0.7287 - val_loss: 7.0876 - val_accuracy: 0.7570\n","Epoch 15/100\n","160/160 [==============================] - 1s 4ms/step - loss: 13.1653 - accuracy: 0.7454 - val_loss: 5.6928 - val_accuracy: 0.7729\n","Epoch 16/100\n","160/160 [==============================] - 1s 4ms/step - loss: 5.7580 - accuracy: 0.7624 - val_loss: 7.3438 - val_accuracy: 0.7394\n","Epoch 17/100\n","160/160 [==============================] - 1s 4ms/step - loss: 9.6400 - accuracy: 0.7428 - val_loss: 4.5706 - val_accuracy: 0.7641\n","Epoch 18/100\n","160/160 [==============================] - 1s 4ms/step - loss: 10.1926 - accuracy: 0.7442 - val_loss: 10.2601 - val_accuracy: 0.7711\n","Epoch 19/100\n","160/160 [==============================] - 1s 4ms/step - loss: 15.0743 - accuracy: 0.7387 - val_loss: 7.0648 - val_accuracy: 0.7570\n","Epoch 20/100\n","160/160 [==============================] - 1s 4ms/step - loss: 10.4720 - accuracy: 0.7413 - val_loss: 5.3541 - val_accuracy: 0.7570\n","Epoch 21/100\n","160/160 [==============================] - 1s 4ms/step - loss: 7.3861 - accuracy: 0.7571 - val_loss: 6.7467 - val_accuracy: 0.7676\n","Epoch 22/100\n","160/160 [==============================] - 1s 4ms/step - loss: 5.4422 - accuracy: 0.7635 - val_loss: 7.1941 - val_accuracy: 0.7535\n","Epoch 23/100\n","160/160 [==============================] - 1s 4ms/step - loss: 13.8070 - accuracy: 0.7399 - val_loss: 3.9617 - val_accuracy: 0.7729\n","Epoch 24/100\n","160/160 [==============================] - 1s 4ms/step - loss: 7.8886 - accuracy: 0.7524 - val_loss: 7.2981 - val_accuracy: 0.7694\n","Epoch 25/100\n","160/160 [==============================] - 1s 4ms/step - loss: 5.8939 - accuracy: 0.7622 - val_loss: 3.9002 - val_accuracy: 0.7852\n","Epoch 26/100\n","160/160 [==============================] - 1s 4ms/step - loss: 4.5223 - accuracy: 0.7708 - val_loss: 3.2484 - val_accuracy: 0.7817\n","Epoch 27/100\n","160/160 [==============================] - 1s 4ms/step - loss: 6.2731 - accuracy: 0.7536 - val_loss: 5.3940 - val_accuracy: 0.7764\n","Epoch 28/100\n","160/160 [==============================] - 1s 4ms/step - loss: 5.8804 - accuracy: 0.7674 - val_loss: 8.5722 - val_accuracy: 0.7482\n","Epoch 29/100\n","160/160 [==============================] - 1s 4ms/step - loss: 11.5520 - accuracy: 0.7536 - val_loss: 5.8121 - val_accuracy: 0.7588\n","Epoch 30/100\n","160/160 [==============================] - 1s 4ms/step - loss: 5.9244 - accuracy: 0.7672 - val_loss: 8.9853 - val_accuracy: 0.7430\n","Epoch 31/100\n","160/160 [==============================] - 1s 4ms/step - loss: 4.6455 - accuracy: 0.7747 - val_loss: 4.9582 - val_accuracy: 0.7430\n","Epoch 32/100\n","160/160 [==============================] - 1s 4ms/step - loss: 9.2900 - accuracy: 0.7538 - val_loss: 4.3037 - val_accuracy: 0.7835\n","Epoch 33/100\n","160/160 [==============================] - 1s 4ms/step - loss: 13.2431 - accuracy: 0.7284 - val_loss: 4.1422 - val_accuracy: 0.7746\n","Epoch 34/100\n","160/160 [==============================] - 1s 4ms/step - loss: 11.3339 - accuracy: 0.7387 - val_loss: 8.7646 - val_accuracy: 0.7394\n","Epoch 35/100\n","160/160 [==============================] - 1s 4ms/step - loss: 6.2355 - accuracy: 0.7672 - val_loss: 6.4257 - val_accuracy: 0.7694\n","Epoch 36/100\n","160/160 [==============================] - 1s 4ms/step - loss: 6.3112 - accuracy: 0.7680 - val_loss: 4.4273 - val_accuracy: 0.7641\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.68      0.77       322\n","           1       0.68      0.87      0.76       246\n","\n","    accuracy                           0.76       568\n","   macro avg       0.78      0.78      0.76       568\n","weighted avg       0.79      0.76      0.76       568\n","\n","Accuracy: 0.7640845070422535\n","[[220 102]\n"," [ 32 214]]\n","Precision: 0.6772\n","Recall: 0.8699\n","F1 Score: 0.7616\n","INFO:tensorflow:Assets written to: ram://93025bdf-a2a2-45e7-9034-60089d85d932/assets\n","model 8 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 5ms/step - loss: 70.1022 - accuracy: 0.5826 - val_loss: 24.9697 - val_accuracy: 0.5757\n","Epoch 2/100\n","160/160 [==============================] - 1s 4ms/step - loss: 25.3670 - accuracy: 0.5783 - val_loss: 24.3116 - val_accuracy: 0.6919\n","Epoch 3/100\n","160/160 [==============================] - 1s 4ms/step - loss: 20.6350 - accuracy: 0.6158 - val_loss: 18.1909 - val_accuracy: 0.6602\n","Epoch 4/100\n","160/160 [==============================] - 1s 4ms/step - loss: 16.1400 - accuracy: 0.6428 - val_loss: 15.5638 - val_accuracy: 0.6725\n","Epoch 5/100\n","160/160 [==============================] - 1s 4ms/step - loss: 16.1492 - accuracy: 0.6461 - val_loss: 16.2878 - val_accuracy: 0.5563\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 10.7106 - accuracy: 0.6549 - val_loss: 4.6974 - val_accuracy: 0.6937\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 6.3724 - accuracy: 0.6758 - val_loss: 4.5331 - val_accuracy: 0.7025\n","Epoch 8/100\n","160/160 [==============================] - 1s 4ms/step - loss: 5.3051 - accuracy: 0.7073 - val_loss: 1.9335 - val_accuracy: 0.7289\n","Epoch 9/100\n","160/160 [==============================] - 1s 4ms/step - loss: 4.3263 - accuracy: 0.7217 - val_loss: 1.5027 - val_accuracy: 0.7465\n","Epoch 10/100\n","160/160 [==============================] - 1s 4ms/step - loss: 4.0798 - accuracy: 0.7180 - val_loss: 3.2213 - val_accuracy: 0.7324\n","Epoch 11/100\n","160/160 [==============================] - 1s 4ms/step - loss: 3.4298 - accuracy: 0.7260 - val_loss: 1.6643 - val_accuracy: 0.7482\n","Epoch 12/100\n","160/160 [==============================] - 1s 4ms/step - loss: 4.0978 - accuracy: 0.7235 - val_loss: 2.8913 - val_accuracy: 0.7095\n","Epoch 13/100\n","160/160 [==============================] - 1s 4ms/step - loss: 3.6856 - accuracy: 0.7182 - val_loss: 1.3533 - val_accuracy: 0.7359\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 3.2092 - accuracy: 0.7051 - val_loss: 2.4572 - val_accuracy: 0.7077\n","Epoch 15/100\n","160/160 [==============================] - 1s 4ms/step - loss: 3.4135 - accuracy: 0.7157 - val_loss: 3.0906 - val_accuracy: 0.6937\n","Epoch 16/100\n","160/160 [==============================] - 1s 4ms/step - loss: 2.6908 - accuracy: 0.7188 - val_loss: 1.0358 - val_accuracy: 0.7676\n","Epoch 17/100\n","160/160 [==============================] - 1s 4ms/step - loss: 1.8172 - accuracy: 0.7397 - val_loss: 0.9491 - val_accuracy: 0.7870\n","Epoch 18/100\n","160/160 [==============================] - 1s 4ms/step - loss: 2.6723 - accuracy: 0.7284 - val_loss: 1.8859 - val_accuracy: 0.7482\n","Epoch 19/100\n","160/160 [==============================] - 1s 4ms/step - loss: 1.5530 - accuracy: 0.7434 - val_loss: 1.5705 - val_accuracy: 0.7676\n","Epoch 20/100\n","160/160 [==============================] - 1s 4ms/step - loss: 2.1527 - accuracy: 0.7307 - val_loss: 2.7490 - val_accuracy: 0.7412\n","Epoch 21/100\n","160/160 [==============================] - 1s 4ms/step - loss: 1.4378 - accuracy: 0.7432 - val_loss: 1.3931 - val_accuracy: 0.7588\n","Epoch 22/100\n","160/160 [==============================] - 1s 4ms/step - loss: 2.2725 - accuracy: 0.7319 - val_loss: 1.3755 - val_accuracy: 0.7729\n","Epoch 23/100\n","160/160 [==============================] - 1s 4ms/step - loss: 1.7260 - accuracy: 0.7364 - val_loss: 2.6933 - val_accuracy: 0.6285\n","Epoch 24/100\n","160/160 [==============================] - 1s 4ms/step - loss: 2.0526 - accuracy: 0.7352 - val_loss: 3.9468 - val_accuracy: 0.7254\n","Epoch 25/100\n","160/160 [==============================] - 1s 4ms/step - loss: 1.9101 - accuracy: 0.7387 - val_loss: 0.9302 - val_accuracy: 0.7799\n","Epoch 26/100\n","160/160 [==============================] - 1s 4ms/step - loss: 2.4022 - accuracy: 0.7362 - val_loss: 0.6837 - val_accuracy: 0.7923\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 1.9915 - accuracy: 0.7413 - val_loss: 0.8678 - val_accuracy: 0.7835\n","Epoch 28/100\n","160/160 [==============================] - 1s 4ms/step - loss: 1.9542 - accuracy: 0.7479 - val_loss: 2.4555 - val_accuracy: 0.7535\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 3.6395 - accuracy: 0.7149 - val_loss: 1.6090 - val_accuracy: 0.7588\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 1.7984 - accuracy: 0.7502 - val_loss: 0.9700 - val_accuracy: 0.7729\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 1.2612 - accuracy: 0.7534 - val_loss: 2.0550 - val_accuracy: 0.7254\n","Epoch 32/100\n","160/160 [==============================] - 1s 4ms/step - loss: 1.2362 - accuracy: 0.7596 - val_loss: 1.4645 - val_accuracy: 0.7606\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 2.4974 - accuracy: 0.7416 - val_loss: 3.4693 - val_accuracy: 0.7165\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 1.6450 - accuracy: 0.7495 - val_loss: 0.9374 - val_accuracy: 0.7711\n","Epoch 35/100\n","160/160 [==============================] - 1s 4ms/step - loss: 1.4254 - accuracy: 0.7553 - val_loss: 2.4748 - val_accuracy: 0.7218\n","Epoch 36/100\n","160/160 [==============================] - 1s 4ms/step - loss: 1.1945 - accuracy: 0.7610 - val_loss: 0.7649 - val_accuracy: 0.7817\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.81      0.80       296\n","           1       0.79      0.75      0.77       272\n","\n","    accuracy                           0.78       568\n","   macro avg       0.78      0.78      0.78       568\n","weighted avg       0.78      0.78      0.78       568\n","\n","Accuracy: 0.7816901408450704\n","[[241  55]\n"," [ 69 203]]\n","Precision: 0.7868\n","Recall: 0.7463\n","F1 Score: 0.7660\n","INFO:tensorflow:Assets written to: ram://887ecfdf-4acb-45df-8f76-9f4967ebd0ee/assets\n","model 9 saved\n","Average Validation Accuracy: 0.7041693482511941\n"]}]},{"cell_type":"code","source":[" # load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed HTML/NN/model_1.h5'\n","\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","def predict_prob(number):\n","  return [number[0],1-number[0]]\n","\n","y_prob = np.array(list(map(predict_prob, loaded_model.predict(x_test))))\n","y_prob \n","\n","# y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['nn_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['nn_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545},"id":"dolEygpVsl_4","executionInfo":{"status":"ok","timestamp":1656481108677,"user_tz":-330,"elapsed":1573,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"86349a51-63ef-48f6-9c86-2b7e785c1fb9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[9.99999374e-01 6.25759875e-07]\n"," [6.02153377e-01 3.97846623e-01]\n"," [9.66002549e-01 3.39974510e-02]\n"," ...\n"," [1.00000000e+00 9.16716182e-28]\n"," [9.99999997e-01 2.65941634e-09]\n"," [9.99999486e-01 5.14457726e-07]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  nn_prediction_non  \\\n","0          0            0.999999          6.257599e-07           0.999999   \n","1          0            0.602153          3.978466e-01           0.602153   \n","2          1            0.966003          3.399745e-02           0.966003   \n","3          1            0.580367          4.196330e-01           0.580367   \n","4          1            0.113440          8.865602e-01           0.113440   \n","...      ...                 ...                   ...                ...   \n","4647       1            0.075658          9.243419e-01           0.075658   \n","4648       0            1.000000          9.731610e-27           1.000000   \n","4649       0            1.000000          9.167162e-28           1.000000   \n","4650       0            1.000000          2.659416e-09           1.000000   \n","4651       0            0.999999          5.144577e-07           0.999999   \n","\n","      nn_prediction_phish  \n","0            6.257599e-07  \n","1            3.978466e-01  \n","2            3.399745e-02  \n","3            4.196330e-01  \n","4            8.865602e-01  \n","...                   ...  \n","4647         9.243419e-01  \n","4648         9.731610e-27  \n","4649         9.167162e-28  \n","4650         2.659416e-09  \n","4651         5.144577e-07  \n","\n","[4652 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-aad9872e-5eab-4abc-af0e-ebf63d524d5e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.999999</td>\n","      <td>6.257599e-07</td>\n","      <td>0.999999</td>\n","      <td>6.257599e-07</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0.602153</td>\n","      <td>3.978466e-01</td>\n","      <td>0.602153</td>\n","      <td>3.978466e-01</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0.966003</td>\n","      <td>3.399745e-02</td>\n","      <td>0.966003</td>\n","      <td>3.399745e-02</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0.580367</td>\n","      <td>4.196330e-01</td>\n","      <td>0.580367</td>\n","      <td>4.196330e-01</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.113440</td>\n","      <td>8.865602e-01</td>\n","      <td>0.113440</td>\n","      <td>8.865602e-01</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4647</th>\n","      <td>1</td>\n","      <td>0.075658</td>\n","      <td>9.243419e-01</td>\n","      <td>0.075658</td>\n","      <td>9.243419e-01</td>\n","    </tr>\n","    <tr>\n","      <th>4648</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>9.731610e-27</td>\n","      <td>1.000000</td>\n","      <td>9.731610e-27</td>\n","    </tr>\n","    <tr>\n","      <th>4649</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>9.167162e-28</td>\n","      <td>1.000000</td>\n","      <td>9.167162e-28</td>\n","    </tr>\n","    <tr>\n","      <th>4650</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>2.659416e-09</td>\n","      <td>1.000000</td>\n","      <td>2.659416e-09</td>\n","    </tr>\n","    <tr>\n","      <th>4651</th>\n","      <td>0</td>\n","      <td>0.999999</td>\n","      <td>5.144577e-07</td>\n","      <td>0.999999</td>\n","      <td>5.144577e-07</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4652 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aad9872e-5eab-4abc-af0e-ebf63d524d5e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-aad9872e-5eab-4abc-af0e-ebf63d524d5e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-aad9872e-5eab-4abc-af0e-ebf63d524d5e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":[""],"metadata":{"id":"d6frnOv-L24r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Neural Network 2**"],"metadata":{"id":"fMdqVtYLwwy4"}},{"cell_type":"code","source":["\n","import keras\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","def model_a(x_train, x_val, y_train, y_val, opt, n, early_stopping_monitor):\n","\n","  n_cols = x_train.shape[1]\n","\n","  #create model\n","  model_2 = Sequential()\n","  model_2.add(Dense(30, activation='sigmoid', input_shape=(n_cols,)))\n","  model_2.add(Dense(25, activation='sigmoid'))\n","  model_2.add(Dense(20, activation='sigmoid'))\n","  model_2.add(Dense(15, activation='sigmoid'))\n","  model_2.add(Dense(10, activation='sigmoid'))\n","  model_2.add(Dense(1, activation = 'sigmoid'))\n","\n","  #compile model using mse as a measure of model performance\n","  model_2.compile(optimizer='adam', loss='mean_squared_error')\n","\n","\n","\n","  history = model_2.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping_monitor])\n","\n","\n","  # plt.plot(history.history['loss'])\n","  # plt.plot(history.history['val_loss'])\n","  # plt.title('model loss')\n","  # plt.ylabel('Loss')\n","  # plt.xlabel('Epoch')\n","  # plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n","  # plt.show()\n","\n","\n","  print('Validation Accuracy: ')\n","  # Predicting the Test set results\n","  y_pred = model_2.predict(x_val)\n","  y_pred = (y_pred > 0.5)\n","\n","\n","  print(classification_report(y_val, y_pred))\n","\n","  # Model Accuracy, how often is the classifier correct?\n","  print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","\n","  # Creating the Confusion Matrix\n","  cm = confusion_matrix(y_val, y_pred)\n","  print(cm)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred))\n","\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed HTML/NN_2/model_'+str(n)+'.h5'\n","  pickle.dump(model_2, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","\n","  return metrics.accuracy_score(y_val, y_pred)\n","\n"],"metadata":{"id":"L8ZhB8W9tVQS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_a(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n, early_stopping_monitor)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osCV0Uo5wqac","executionInfo":{"status":"ok","timestamp":1656481353812,"user_tz":-330,"elapsed":237460,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"8fdd8804-8ca6-4c2a-f0c6-31e10aec747b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","160/160 [==============================] - 2s 6ms/step - loss: 0.2462 - val_loss: 0.2456\n","Epoch 2/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2453 - val_loss: 0.2430\n","Epoch 3/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2394 - val_loss: 0.2257\n","Epoch 4/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2198 - val_loss: 0.2058\n","Epoch 5/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2063 - val_loss: 0.1979\n","Epoch 6/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1983 - val_loss: 0.1853\n","Epoch 7/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1947 - val_loss: 0.1924\n","Epoch 8/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1932 - val_loss: 0.1861\n","Epoch 9/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1900 - val_loss: 0.1830\n","Epoch 10/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1874 - val_loss: 0.1826\n","Epoch 11/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1851 - val_loss: 0.1806\n","Epoch 12/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1825 - val_loss: 0.1753\n","Epoch 13/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1804 - val_loss: 0.1736\n","Epoch 14/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1844 - val_loss: 0.1573\n","Epoch 15/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1782 - val_loss: 0.1645\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1847 - val_loss: 0.1740\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1781 - val_loss: 0.1692\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1754 - val_loss: 0.1636\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1736 - val_loss: 0.1636\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1745 - val_loss: 0.1511\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1793 - val_loss: 0.1698\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1756 - val_loss: 0.1613\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1726 - val_loss: 0.1571\n","Epoch 24/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1733 - val_loss: 0.1603\n","Epoch 25/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1766 - val_loss: 0.1715\n","Epoch 26/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1798 - val_loss: 0.1675\n","Epoch 27/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1770 - val_loss: 0.1651\n","Epoch 28/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1716 - val_loss: 0.1455\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1650 - val_loss: 0.1474\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1629 - val_loss: 0.1480\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1625 - val_loss: 0.1490\n","Epoch 32/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1674 - val_loss: 0.1524\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1634 - val_loss: 0.1548\n","Epoch 34/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1644 - val_loss: 0.1435\n","Epoch 35/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1684 - val_loss: 0.1633\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1749 - val_loss: 0.1642\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1745 - val_loss: 0.1611\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1734 - val_loss: 0.1566\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1754 - val_loss: 0.1593\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1717 - val_loss: 0.1559\n","Epoch 41/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1692 - val_loss: 0.1585\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1680 - val_loss: 0.1617\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1751 - val_loss: 0.1723\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1722 - val_loss: 0.1625\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.96      0.83       322\n","           1       0.91      0.55      0.69       247\n","\n","    accuracy                           0.78       569\n","   macro avg       0.82      0.75      0.76       569\n","weighted avg       0.81      0.78      0.77       569\n","\n","Accuracy: 0.7803163444639719\n","[[308  14]\n"," [111 136]]\n","Precision: 0.9067\n","Recall: 0.5506\n","F1 Score: 0.6851\n","INFO:tensorflow:Assets written to: ram://5f468cc9-7e83-4eee-87a9-19c66770f5cc/assets\n","model 0 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2459 - val_loss: 0.2455\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2433 - val_loss: 0.2372\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2249 - val_loss: 0.2127\n","Epoch 4/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2068 - val_loss: 0.2009\n","Epoch 5/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1995 - val_loss: 0.1935\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1928 - val_loss: 0.1910\n","Epoch 7/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1895 - val_loss: 0.1885\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1865 - val_loss: 0.1853\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1865 - val_loss: 0.1863\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1862 - val_loss: 0.1853\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1868 - val_loss: 0.1872\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1849 - val_loss: 0.1849\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1853 - val_loss: 0.1852\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1848 - val_loss: 0.1871\n","Epoch 15/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1826 - val_loss: 0.1804\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1780 - val_loss: 0.1835\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1785 - val_loss: 0.1867\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1843 - val_loss: 0.1892\n","Epoch 19/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1934 - val_loss: 0.1900\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1844 - val_loss: 0.1854\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1808 - val_loss: 0.1778\n","Epoch 22/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1788 - val_loss: 0.1814\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1757 - val_loss: 0.1708\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1656 - val_loss: 0.1664\n","Epoch 25/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1623 - val_loss: 0.1628\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1625 - val_loss: 0.1685\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1601 - val_loss: 0.1671\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1642 - val_loss: 0.1598\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1623 - val_loss: 0.1646\n","Epoch 30/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1607 - val_loss: 0.1669\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1607 - val_loss: 0.1636\n","Epoch 32/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1630 - val_loss: 0.1800\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1713 - val_loss: 0.1942\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1827 - val_loss: 0.1913\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1697 - val_loss: 0.1665\n","Epoch 36/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1640 - val_loss: 0.1663\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1615 - val_loss: 0.1634\n","Epoch 38/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1573 - val_loss: 0.1675\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.91      0.82       320\n","           1       0.84      0.59      0.70       249\n","\n","    accuracy                           0.77       569\n","   macro avg       0.79      0.75      0.76       569\n","weighted avg       0.79      0.77      0.77       569\n","\n","Accuracy: 0.773286467486819\n","[[292  28]\n"," [101 148]]\n","Precision: 0.8409\n","Recall: 0.5944\n","F1 Score: 0.6965\n","INFO:tensorflow:Assets written to: ram://93c677b2-d250-4f42-9ddd-dd432c5ac1e0/assets\n","model 1 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2476 - val_loss: 0.2447\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2437 - val_loss: 0.2384\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2272 - val_loss: 0.2212\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2104 - val_loss: 0.2060\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1914 - val_loss: 0.1841\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1728 - val_loss: 0.2028\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1831 - val_loss: 0.1817\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1692 - val_loss: 0.1811\n","Epoch 9/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1713 - val_loss: 0.1737\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1689 - val_loss: 0.1688\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1672 - val_loss: 0.1758\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1713 - val_loss: 0.1881\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1739 - val_loss: 0.1897\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1732 - val_loss: 0.1830\n","Epoch 15/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1762 - val_loss: 0.1836\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1733 - val_loss: 0.1895\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1758 - val_loss: 0.1817\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1711 - val_loss: 0.1791\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1665 - val_loss: 0.1635\n","Epoch 20/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1781 - val_loss: 0.1940\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1742 - val_loss: 0.1744\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1731 - val_loss: 0.1711\n","Epoch 23/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1694 - val_loss: 0.1773\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1674 - val_loss: 0.1704\n","Epoch 25/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1701 - val_loss: 0.1742\n","Epoch 26/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1768 - val_loss: 0.1802\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1728 - val_loss: 0.1775\n","Epoch 28/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1717 - val_loss: 0.1779\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1795 - val_loss: 0.1882\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.86      0.78       324\n","           1       0.75      0.55      0.63       245\n","\n","    accuracy                           0.73       569\n","   macro avg       0.73      0.70      0.71       569\n","weighted avg       0.73      0.73      0.72       569\n","\n","Accuracy: 0.7258347978910369\n","[[279  45]\n"," [111 134]]\n","Precision: 0.7486\n","Recall: 0.5469\n","F1 Score: 0.6321\n","INFO:tensorflow:Assets written to: ram://270b6b45-67cc-4397-885d-28d8cb1458c5/assets\n","model 2 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2462 - val_loss: 0.2420\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2415 - val_loss: 0.2295\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2243 - val_loss: 0.2064\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2099 - val_loss: 0.1945\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2015 - val_loss: 0.1883\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2028 - val_loss: 0.1902\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2011 - val_loss: 0.1876\n","Epoch 8/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1968 - val_loss: 0.1865\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1888 - val_loss: 0.1749\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1891 - val_loss: 0.1763\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1854 - val_loss: 0.1902\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1856 - val_loss: 0.1775\n","Epoch 13/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1831 - val_loss: 0.1749\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1820 - val_loss: 0.1846\n","Epoch 15/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1905 - val_loss: 0.1975\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1825 - val_loss: 0.1759\n","Epoch 17/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1748 - val_loss: 0.1636\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1770 - val_loss: 0.1695\n","Epoch 19/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1758 - val_loss: 0.1700\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1789 - val_loss: 0.1679\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1754 - val_loss: 0.1609\n","Epoch 22/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1849 - val_loss: 0.1729\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1847 - val_loss: 0.1710\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1818 - val_loss: 0.1701\n","Epoch 25/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1832 - val_loss: 0.1684\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1805 - val_loss: 0.1676\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1786 - val_loss: 0.1680\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1777 - val_loss: 0.1689\n","Epoch 29/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1783 - val_loss: 0.1686\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1768 - val_loss: 0.1688\n","Epoch 31/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1731 - val_loss: 0.1670\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.90      0.82       334\n","           1       0.80      0.57      0.67       235\n","\n","    accuracy                           0.76       569\n","   macro avg       0.78      0.74      0.74       569\n","weighted avg       0.77      0.76      0.76       569\n","\n","Accuracy: 0.7644991212653779\n","[[301  33]\n"," [101 134]]\n","Precision: 0.8024\n","Recall: 0.5702\n","F1 Score: 0.6667\n","INFO:tensorflow:Assets written to: ram://f8159838-1b71-4582-8ee1-47169e90c16e/assets\n","model 3 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2473 - val_loss: 0.2441\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2417 - val_loss: 0.2366\n","Epoch 3/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2265 - val_loss: 0.2268\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2167 - val_loss: 0.2161\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2062 - val_loss: 0.2079\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2012 - val_loss: 0.2179\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2074 - val_loss: 0.2185\n","Epoch 8/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2015 - val_loss: 0.2266\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2012 - val_loss: 0.2142\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1983 - val_loss: 0.2112\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1957 - val_loss: 0.2088\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1875 - val_loss: 0.2051\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1884 - val_loss: 0.2197\n","Epoch 14/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1923 - val_loss: 0.1967\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1843 - val_loss: 0.2012\n","Epoch 16/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1813 - val_loss: 0.1924\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1796 - val_loss: 0.1909\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1832 - val_loss: 0.1962\n","Epoch 19/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1849 - val_loss: 0.1926\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1821 - val_loss: 0.1922\n","Epoch 21/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1811 - val_loss: 0.1925\n","Epoch 22/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1794 - val_loss: 0.1875\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1762 - val_loss: 0.1957\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1748 - val_loss: 0.1859\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1717 - val_loss: 0.1813\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1650 - val_loss: 0.1802\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1686 - val_loss: 0.1758\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1585 - val_loss: 0.1984\n","Epoch 29/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1774 - val_loss: 0.1824\n","Epoch 30/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1642 - val_loss: 0.1766\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1638 - val_loss: 0.1707\n","Epoch 32/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1637 - val_loss: 0.1667\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1634 - val_loss: 0.1725\n","Epoch 34/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1559 - val_loss: 0.1708\n","Epoch 35/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1579 - val_loss: 0.1491\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1650 - val_loss: 0.1860\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1613 - val_loss: 0.1660\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1618 - val_loss: 0.1781\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1746 - val_loss: 0.1714\n","Epoch 40/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1660 - val_loss: 0.1643\n","Epoch 41/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1665 - val_loss: 0.2093\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1864 - val_loss: 0.1943\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1941 - val_loss: 0.2121\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1859 - val_loss: 0.1796\n","Epoch 45/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1773 - val_loss: 0.1736\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.86      0.78       324\n","           1       0.74      0.53      0.62       245\n","\n","    accuracy                           0.72       569\n","   macro avg       0.72      0.70      0.70       569\n","weighted avg       0.72      0.72      0.71       569\n","\n","Accuracy: 0.718804920913884\n","[[278  46]\n"," [114 131]]\n","Precision: 0.7401\n","Recall: 0.5347\n","F1 Score: 0.6209\n","INFO:tensorflow:Assets written to: ram://82217a50-5ee8-43a3-b70b-dd64e5e371c4/assets\n","model 4 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2523 - val_loss: 0.2416\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2453 - val_loss: 0.2417\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2377 - val_loss: 0.2306\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2240 - val_loss: 0.2217\n","Epoch 5/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.2132 - val_loss: 0.2175\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2082 - val_loss: 0.2187\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2037 - val_loss: 0.2073\n","Epoch 8/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2045 - val_loss: 0.2061\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1982 - val_loss: 0.1978\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1936 - val_loss: 0.1968\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1903 - val_loss: 0.2002\n","Epoch 12/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1918 - val_loss: 0.2014\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1892 - val_loss: 0.2032\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1875 - val_loss: 0.1935\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1844 - val_loss: 0.1905\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1856 - val_loss: 0.1945\n","Epoch 17/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1868 - val_loss: 0.1962\n","Epoch 18/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.2011 - val_loss: 0.2017\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1951 - val_loss: 0.1994\n","Epoch 20/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1924 - val_loss: 0.2008\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2278 - val_loss: 0.2333\n","Epoch 22/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.2311 - val_loss: 0.2366\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2307 - val_loss: 0.2329\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2298 - val_loss: 0.2340\n","Epoch 25/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.2285 - val_loss: 0.2331\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.64      0.92      0.76       337\n","           1       0.69      0.26      0.37       231\n","\n","    accuracy                           0.65       568\n","   macro avg       0.66      0.59      0.56       568\n","weighted avg       0.66      0.65      0.60       568\n","\n","Accuracy: 0.6496478873239436\n","[[310  27]\n"," [172  59]]\n","Precision: 0.6860\n","Recall: 0.2554\n","F1 Score: 0.3722\n","INFO:tensorflow:Assets written to: ram://990e5e05-53e0-4950-a738-80386934608e/assets\n","model 5 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2483 - val_loss: 0.2508\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2427 - val_loss: 0.2428\n","Epoch 3/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.2287 - val_loss: 0.2221\n","Epoch 4/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.2114 - val_loss: 0.2120\n","Epoch 5/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.2018 - val_loss: 0.2049\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1953 - val_loss: 0.1990\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1909 - val_loss: 0.2012\n","Epoch 8/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1991 - val_loss: 0.2048\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1978 - val_loss: 0.2037\n","Epoch 10/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.2034 - val_loss: 0.2091\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.2003 - val_loss: 0.2061\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2039 - val_loss: 0.2048\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1983 - val_loss: 0.2014\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2094 - val_loss: 0.2097\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2025 - val_loss: 0.2059\n","Epoch 16/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1963 - val_loss: 0.1996\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.91      0.78       302\n","           1       0.83      0.51      0.63       266\n","\n","    accuracy                           0.72       568\n","   macro avg       0.75      0.71      0.70       568\n","weighted avg       0.75      0.72      0.71       568\n","\n","Accuracy: 0.7200704225352113\n","[[274  28]\n"," [131 135]]\n","Precision: 0.8282\n","Recall: 0.5075\n","F1 Score: 0.6294\n","INFO:tensorflow:Assets written to: ram://9d40d5bb-9442-4a96-aace-0f9666a50454/assets\n","model 6 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2457 - val_loss: 0.2449\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2400 - val_loss: 0.2331\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2200 - val_loss: 0.2168\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2079 - val_loss: 0.2113\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2011 - val_loss: 0.2082\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1937 - val_loss: 0.2050\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1884 - val_loss: 0.1980\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1896 - val_loss: 0.2076\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1910 - val_loss: 0.2068\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1911 - val_loss: 0.1949\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1821 - val_loss: 0.2024\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1807 - val_loss: 0.1825\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1899 - val_loss: 0.2036\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1882 - val_loss: 0.1985\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1932 - val_loss: 0.2086\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1893 - val_loss: 0.1966\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1843 - val_loss: 0.1987\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1830 - val_loss: 0.1959\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1825 - val_loss: 0.1965\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1834 - val_loss: 0.1971\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1827 - val_loss: 0.1981\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1821 - val_loss: 0.1978\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.91      0.78       317\n","           1       0.81      0.46      0.59       251\n","\n","    accuracy                           0.71       568\n","   macro avg       0.74      0.69      0.68       568\n","weighted avg       0.74      0.71      0.69       568\n","\n","Accuracy: 0.7130281690140845\n","[[289  28]\n"," [135 116]]\n","Precision: 0.8056\n","Recall: 0.4622\n","F1 Score: 0.5873\n","INFO:tensorflow:Assets written to: ram://59763a8f-ac0a-410f-9add-1ce35daeea59/assets\n","model 7 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2465 - val_loss: 0.2441\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2427 - val_loss: 0.2338\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2254 - val_loss: 0.2045\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2081 - val_loss: 0.1902\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1974 - val_loss: 0.1812\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1936 - val_loss: 0.1771\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1904 - val_loss: 0.1791\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1917 - val_loss: 0.1832\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1967 - val_loss: 0.1772\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1861 - val_loss: 0.1783\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1843 - val_loss: 0.1801\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1921 - val_loss: 0.1830\n","Epoch 13/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1918 - val_loss: 0.1787\n","Epoch 14/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1852 - val_loss: 0.1773\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1815 - val_loss: 0.1824\n","Epoch 16/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1830 - val_loss: 0.1727\n","Epoch 17/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1769 - val_loss: 0.1730\n","Epoch 18/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1858 - val_loss: 0.1754\n","Epoch 19/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1873 - val_loss: 0.1752\n","Epoch 20/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1826 - val_loss: 0.1726\n","Epoch 21/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.1818 - val_loss: 0.1737\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1851 - val_loss: 0.1705\n","Epoch 23/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1783 - val_loss: 0.1690\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1752 - val_loss: 0.1692\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1684 - val_loss: 0.1683\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1759 - val_loss: 0.1716\n","Epoch 27/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1753 - val_loss: 0.1780\n","Epoch 28/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1688 - val_loss: 0.1637\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1662 - val_loss: 0.1719\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1833 - val_loss: 0.1901\n","Epoch 31/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1811 - val_loss: 0.1785\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1712 - val_loss: 0.1802\n","Epoch 33/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1731 - val_loss: 0.1632\n","Epoch 34/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1638 - val_loss: 0.1583\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1684 - val_loss: 0.1645\n","Epoch 36/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1790 - val_loss: 0.1770\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1793 - val_loss: 0.1794\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1788 - val_loss: 0.1788\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1775 - val_loss: 0.1765\n","Epoch 40/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1788 - val_loss: 0.1768\n","Epoch 41/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1788 - val_loss: 0.1757\n","Epoch 42/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1801 - val_loss: 0.1819\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1919 - val_loss: 0.1876\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1887 - val_loss: 0.1754\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.93      0.81       322\n","           1       0.85      0.52      0.65       246\n","\n","    accuracy                           0.75       568\n","   macro avg       0.79      0.73      0.73       568\n","weighted avg       0.78      0.75      0.74       568\n","\n","Accuracy: 0.7535211267605634\n","[[300  22]\n"," [118 128]]\n","Precision: 0.8533\n","Recall: 0.5203\n","F1 Score: 0.6465\n","INFO:tensorflow:Assets written to: ram://c9798576-f004-4a93-8909-d7557334371e/assets\n","model 8 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2457 - val_loss: 0.2504\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2436 - val_loss: 0.2455\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2304 - val_loss: 0.2192\n","Epoch 4/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2060 - val_loss: 0.1995\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1993 - val_loss: 0.1957\n","Epoch 6/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1927 - val_loss: 0.1867\n","Epoch 7/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1888 - val_loss: 0.1947\n","Epoch 8/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1901 - val_loss: 0.1941\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1828 - val_loss: 0.1843\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1836 - val_loss: 0.1880\n","Epoch 11/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1872 - val_loss: 0.1846\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1849 - val_loss: 0.1838\n","Epoch 13/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1779 - val_loss: 0.1756\n","Epoch 14/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1946 - val_loss: 0.1845\n","Epoch 15/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1862 - val_loss: 0.1857\n","Epoch 16/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1919 - val_loss: 0.1983\n","Epoch 17/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1907 - val_loss: 0.1889\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1867 - val_loss: 0.1859\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1847 - val_loss: 0.1830\n","Epoch 20/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1817 - val_loss: 0.1816\n","Epoch 21/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1780 - val_loss: 0.1817\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1759 - val_loss: 0.1748\n","Epoch 23/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1712 - val_loss: 0.1728\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1743 - val_loss: 0.1923\n","Epoch 25/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1784 - val_loss: 0.1827\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1777 - val_loss: 0.1833\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1750 - val_loss: 0.1868\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1777 - val_loss: 0.1770\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1700 - val_loss: 0.1854\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1719 - val_loss: 0.1742\n","Epoch 31/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1768 - val_loss: 0.1854\n","Epoch 32/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1723 - val_loss: 0.1776\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1728 - val_loss: 0.1664\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1714 - val_loss: 0.1745\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1706 - val_loss: 0.1732\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1766 - val_loss: 0.1901\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1766 - val_loss: 0.1821\n","Epoch 38/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1771 - val_loss: 0.1892\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1743 - val_loss: 0.1848\n","Epoch 40/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1779 - val_loss: 0.1819\n","Epoch 41/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1845 - val_loss: 0.1762\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1757 - val_loss: 0.1762\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1737 - val_loss: 0.1739\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.69      0.94      0.80       296\n","           1       0.90      0.54      0.67       272\n","\n","    accuracy                           0.75       568\n","   macro avg       0.79      0.74      0.74       568\n","weighted avg       0.79      0.75      0.74       568\n","\n","Accuracy: 0.75\n","[[279  17]\n"," [125 147]]\n","Precision: 0.8963\n","Recall: 0.5404\n","F1 Score: 0.6743\n","INFO:tensorflow:Assets written to: ram://58e6db1f-db80-4e70-9b96-4174ef97a44e/assets\n","model 9 saved\n","Average Validation Accuracy: 0.7349009257654893\n"]}]},{"cell_type":"code","source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed HTML/NN_2/model_4.h5'\n","\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","def predict_prob(number):\n","  return [number[0],1-number[0]]\n","\n","y_prob = np.array(list(map(predict_prob, loaded_model.predict(x_test))))\n","y_prob \n","\n","# y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['nn2_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['nn2_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":609},"id":"JPT9oIQ0wuZf","executionInfo":{"status":"ok","timestamp":1656481640804,"user_tz":-330,"elapsed":1255,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"6adb3ddc-94e7-4ec7-ea9d-00e0d0bf9359"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[9.99999374e-01 6.25759875e-07]\n"," [6.02153377e-01 3.97846623e-01]\n"," [9.66002549e-01 3.39974510e-02]\n"," ...\n"," [1.00000000e+00 9.16716182e-28]\n"," [9.99999997e-01 2.65941634e-09]\n"," [9.99999486e-01 5.14457726e-07]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  nn_prediction_non  \\\n","0          0            0.999999          6.257599e-07           0.999999   \n","1          0            0.602153          3.978466e-01           0.602153   \n","2          1            0.966003          3.399745e-02           0.966003   \n","3          1            0.580367          4.196330e-01           0.580367   \n","4          1            0.113440          8.865602e-01           0.113440   \n","...      ...                 ...                   ...                ...   \n","4647       1            0.075658          9.243419e-01           0.075658   \n","4648       0            1.000000          9.731610e-27           1.000000   \n","4649       0            1.000000          9.167162e-28           1.000000   \n","4650       0            1.000000          2.659416e-09           1.000000   \n","4651       0            0.999999          5.144577e-07           0.999999   \n","\n","      nn_prediction_phish  nn2_prediction_non  nn2_prediction_phish  \n","0            6.257599e-07            0.999999          6.257599e-07  \n","1            3.978466e-01            0.602153          3.978466e-01  \n","2            3.399745e-02            0.966003          3.399745e-02  \n","3            4.196330e-01            0.580367          4.196330e-01  \n","4            8.865602e-01            0.113440          8.865602e-01  \n","...                   ...                 ...                   ...  \n","4647         9.243419e-01            0.075658          9.243419e-01  \n","4648         9.731610e-27            1.000000          9.731610e-27  \n","4649         9.167162e-28            1.000000          9.167162e-28  \n","4650         2.659416e-09            1.000000          2.659416e-09  \n","4651         5.144577e-07            0.999999          5.144577e-07  \n","\n","[4652 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-5893c2d8-41f7-4305-ab5e-c71700454a85\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","      <th>nn2_prediction_non</th>\n","      <th>nn2_prediction_phish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.999999</td>\n","      <td>6.257599e-07</td>\n","      <td>0.999999</td>\n","      <td>6.257599e-07</td>\n","      <td>0.999999</td>\n","      <td>6.257599e-07</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0.602153</td>\n","      <td>3.978466e-01</td>\n","      <td>0.602153</td>\n","      <td>3.978466e-01</td>\n","      <td>0.602153</td>\n","      <td>3.978466e-01</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0.966003</td>\n","      <td>3.399745e-02</td>\n","      <td>0.966003</td>\n","      <td>3.399745e-02</td>\n","      <td>0.966003</td>\n","      <td>3.399745e-02</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0.580367</td>\n","      <td>4.196330e-01</td>\n","      <td>0.580367</td>\n","      <td>4.196330e-01</td>\n","      <td>0.580367</td>\n","      <td>4.196330e-01</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.113440</td>\n","      <td>8.865602e-01</td>\n","      <td>0.113440</td>\n","      <td>8.865602e-01</td>\n","      <td>0.113440</td>\n","      <td>8.865602e-01</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4647</th>\n","      <td>1</td>\n","      <td>0.075658</td>\n","      <td>9.243419e-01</td>\n","      <td>0.075658</td>\n","      <td>9.243419e-01</td>\n","      <td>0.075658</td>\n","      <td>9.243419e-01</td>\n","    </tr>\n","    <tr>\n","      <th>4648</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>9.731610e-27</td>\n","      <td>1.000000</td>\n","      <td>9.731610e-27</td>\n","      <td>1.000000</td>\n","      <td>9.731610e-27</td>\n","    </tr>\n","    <tr>\n","      <th>4649</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>9.167162e-28</td>\n","      <td>1.000000</td>\n","      <td>9.167162e-28</td>\n","      <td>1.000000</td>\n","      <td>9.167162e-28</td>\n","    </tr>\n","    <tr>\n","      <th>4650</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>2.659416e-09</td>\n","      <td>1.000000</td>\n","      <td>2.659416e-09</td>\n","      <td>1.000000</td>\n","      <td>2.659416e-09</td>\n","    </tr>\n","    <tr>\n","      <th>4651</th>\n","      <td>0</td>\n","      <td>0.999999</td>\n","      <td>5.144577e-07</td>\n","      <td>0.999999</td>\n","      <td>5.144577e-07</td>\n","      <td>0.999999</td>\n","      <td>5.144577e-07</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4652 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5893c2d8-41f7-4305-ab5e-c71700454a85')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5893c2d8-41f7-4305-ab5e-c71700454a85 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5893c2d8-41f7-4305-ab5e-c71700454a85');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":[""],"metadata":{"id":"NEihgjKWtVK_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KDYz8o5ytVIu","executionInfo":{"status":"ok","timestamp":1656481651406,"user_tz":-330,"elapsed":9,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"d33ad3f3-1853-4554-8b4c-b08d06c8a204"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4652, 7)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsQkUbz6AiTx"},"outputs":[],"source":["# Storing the data in CSV file\n","output.to_csv('/content/drive/MyDrive/Phishing/PhishTank/Base_classifier_result(pre HTML cross)(3).csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RN_-swX0JdhP"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W9DI0WYaJde9"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49lwyWNz0mSo"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_9Vdw_Wx2NEo"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Base Classifiers(3)(HTML).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}