{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"PH13wfswmyDv","executionInfo":{"status":"ok","timestamp":1657780962327,"user_tz":-330,"elapsed":936,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":99488,"status":"ok","timestamp":1657781061804,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"Aiz0olfdKb4b","outputId":"96fe13f6-547a-464b-ef6d-1f6186ef37c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":502},"executionInfo":{"elapsed":1962,"status":"ok","timestamp":1657781108612,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"Dw-EEymHAGNs","outputId":"6ad9a4c1-c977-4f82-c714-e9ca03806ff0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Unnamed: 0                                       Domain  Have IP  \\\n","0               0                             graphicriver.net        0   \n","1               1                                    ecnavi.jp        0   \n","2               2                                 hubpages.com        0   \n","3               3                              extratorrent.cc        0   \n","4               4                                icicibank.com        0   \n","...           ...                                          ...      ...   \n","10332       11932                             sites.google.com        0   \n","10333       11933                             sites.google.com        0   \n","10334       11934             habbocreditosparati.blogspot.com        0   \n","10335       11935  creditiperhabbogratissicuro100.blogspot.com        0   \n","10336       11936                           aijcs.blogspot.com        0   \n","\n","       Have @  URL Length  URL Depth  Redirection  https Domain  TinyURL  \\\n","0           0           1          1            0             0        0   \n","1           0           1          1            1             0        0   \n","2           0           1          1            0             1        0   \n","3           0           1          3            0             0        0   \n","4           0           1          3            0             0        0   \n","...       ...         ...        ...          ...           ...      ...   \n","10332       0           0          2            0             1        0   \n","10333       0           0          2            0             0        0   \n","10334       0           0          0            0             0        1   \n","10335       0           1          3            0             0        1   \n","10336       0           1          3            0             0        1   \n","\n","       Prefix/Suffix  ...  Num Embeds  Num Images  Num Links  Num Titles  \\\n","0                  0  ...           0          49        691          42   \n","1                  0  ...           0           4         66           3   \n","2                  0  ...           0           1        100          27   \n","3                  0  ...           0           0          0           1   \n","4                  0  ...           0         117        219          23   \n","...              ...  ...         ...         ...        ...         ...   \n","10332              0  ...           0           0         17           4   \n","10333              0  ...           0           6         24           7   \n","10334              0  ...           0           4         17           4   \n","10335              0  ...           0           1         23           8   \n","10336              0  ...           0          19         42           7   \n","\n","       Num Script  Special Characters  Script To Special Chars Ratio  \\\n","0           13135                6400                       2.052344   \n","1            2034                 818                       2.486553   \n","2           32987               10451                       3.156349   \n","3               0                  52                       0.000000   \n","4            7944                3468                       2.290657   \n","...           ...                 ...                            ...   \n","10332        8146                2203                       3.697685   \n","10333        8353                2250                       3.712444   \n","10334        6403                4560                       1.404167   \n","10335        9817                7292                       1.346270   \n","10336        2550                3225                       0.790698   \n","\n","       Script To body Ratio  Body To Special Char Ratio  Label  \n","0                  0.528869                    0.257690      0  \n","1                  0.676197                    0.271941      0  \n","2                  0.836681                    0.265079      0  \n","3                  0.000000                    0.227074      0  \n","4                  0.524460                    0.228956      0  \n","...                     ...                         ...    ...  \n","10332              0.943698                    0.255213      1  \n","10333              0.937276                    0.252469      1  \n","10334              0.397677                    0.283212      1  \n","10335              0.385873                    0.286624      1  \n","10336              0.247669                    0.313228      1  \n","\n","[10337 rows x 47 columns]"],"text/html":["\n","  <div id=\"df-62645a8e-a096-4162-9da7-1f375161d237\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Domain</th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>graphicriver.net</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>691</td>\n","      <td>42</td>\n","      <td>13135</td>\n","      <td>6400</td>\n","      <td>2.052344</td>\n","      <td>0.528869</td>\n","      <td>0.257690</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>ecnavi.jp</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>66</td>\n","      <td>3</td>\n","      <td>2034</td>\n","      <td>818</td>\n","      <td>2.486553</td>\n","      <td>0.676197</td>\n","      <td>0.271941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>hubpages.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>27</td>\n","      <td>32987</td>\n","      <td>10451</td>\n","      <td>3.156349</td>\n","      <td>0.836681</td>\n","      <td>0.265079</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>extratorrent.cc</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.227074</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>icicibank.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>117</td>\n","      <td>219</td>\n","      <td>23</td>\n","      <td>7944</td>\n","      <td>3468</td>\n","      <td>2.290657</td>\n","      <td>0.524460</td>\n","      <td>0.228956</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10332</th>\n","      <td>11932</td>\n","      <td>sites.google.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>17</td>\n","      <td>4</td>\n","      <td>8146</td>\n","      <td>2203</td>\n","      <td>3.697685</td>\n","      <td>0.943698</td>\n","      <td>0.255213</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10333</th>\n","      <td>11933</td>\n","      <td>sites.google.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>24</td>\n","      <td>7</td>\n","      <td>8353</td>\n","      <td>2250</td>\n","      <td>3.712444</td>\n","      <td>0.937276</td>\n","      <td>0.252469</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10334</th>\n","      <td>11934</td>\n","      <td>habbocreditosparati.blogspot.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>17</td>\n","      <td>4</td>\n","      <td>6403</td>\n","      <td>4560</td>\n","      <td>1.404167</td>\n","      <td>0.397677</td>\n","      <td>0.283212</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10335</th>\n","      <td>11935</td>\n","      <td>creditiperhabbogratissicuro100.blogspot.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>23</td>\n","      <td>8</td>\n","      <td>9817</td>\n","      <td>7292</td>\n","      <td>1.346270</td>\n","      <td>0.385873</td>\n","      <td>0.286624</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10336</th>\n","      <td>11936</td>\n","      <td>aijcs.blogspot.com</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>19</td>\n","      <td>42</td>\n","      <td>7</td>\n","      <td>2550</td>\n","      <td>3225</td>\n","      <td>0.790698</td>\n","      <td>0.247669</td>\n","      <td>0.313228</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10337 rows × 47 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62645a8e-a096-4162-9da7-1f375161d237')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-62645a8e-a096-4162-9da7-1f375161d237 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-62645a8e-a096-4162-9da7-1f375161d237');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["urldata = pd.read_csv(\"/content/drive/MyDrive/Phishing/PhishTank/URL-HTML/preprocessed_url_features.csv\")\n","urldata\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1657781108615,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"JQ4_qEulWybT","outputId":"d48013ea-4721-4348-a4c4-1596ea1ff96e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Unnamed: 0', 'Domain', 'Have IP', 'Have @', 'URL Length', 'URL Depth',\n","       'Redirection', 'https Domain', 'TinyURL', 'Prefix/Suffix',\n","       'Have client', 'Have admin', 'Have login', 'Have server', '.php',\n","       '.html', '.info', '.txt', '.js', '.exe', 'Num of periods', 'Is encoded',\n","       'Num of encoded char', 'Num of parameters', 'Num of digits',\n","       'Num of spec char', 'iFrame', 'Mouse Over', 'Right Click',\n","       'Web Forwards', 'Number of page tokens', 'number of sentences',\n","       'number of html tags', 'number of whitespace', 'url Is Live',\n","       'HTML Length', 'Num Objects', 'Num Embeds', 'Num Images', 'Num Links',\n","       'Num Titles', 'Num Script', 'Special Characters',\n","       'Script To Special Chars Ratio', 'Script To body Ratio',\n","       'Body To Special Char Ratio', 'Label'],\n","      dtype='object')"]},"metadata":{},"execution_count":4}],"source":["urldata.columns"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1657781108617,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"qwye89TwRTOH","outputId":"9f5df70c-49fd-42ff-c620-35753c603977"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Have IP  Have @  URL Length  URL Depth  Redirection  https Domain  TinyURL  \\\n","0        0       0           1          1            0             0        0   \n","1        0       0           1          1            1             0        0   \n","2        0       0           1          1            0             1        0   \n","3        0       0           1          3            0             0        0   \n","4        0       0           1          3            0             0        0   \n","\n","   Prefix/Suffix  Have client  Have admin  ...  Num Embeds  Num Images  \\\n","0              0            0           0  ...           0          49   \n","1              0            0           0  ...           0           4   \n","2              0            0           0  ...           0           1   \n","3              0            0           0  ...           0           0   \n","4              0            0           0  ...           0         117   \n","\n","   Num Links  Num Titles  Num Script  Special Characters  \\\n","0        691          42       13135                6400   \n","1         66           3        2034                 818   \n","2        100          27       32987               10451   \n","3          0           1           0                  52   \n","4        219          23        7944                3468   \n","\n","   Script To Special Chars Ratio  Script To body Ratio  \\\n","0                       2.052344              0.528869   \n","1                       2.486553              0.676197   \n","2                       3.156349              0.836681   \n","3                       0.000000              0.000000   \n","4                       2.290657              0.524460   \n","\n","   Body To Special Char Ratio  Label  \n","0                    0.257690      0  \n","1                    0.271941      0  \n","2                    0.265079      0  \n","3                    0.227074      0  \n","4                    0.228956      0  \n","\n","[5 rows x 45 columns]"],"text/html":["\n","  <div id=\"df-ec2d279c-c0f1-49d9-987d-b5ad28240a91\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>Have admin</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>691</td>\n","      <td>42</td>\n","      <td>13135</td>\n","      <td>6400</td>\n","      <td>2.052344</td>\n","      <td>0.528869</td>\n","      <td>0.257690</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>66</td>\n","      <td>3</td>\n","      <td>2034</td>\n","      <td>818</td>\n","      <td>2.486553</td>\n","      <td>0.676197</td>\n","      <td>0.271941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>27</td>\n","      <td>32987</td>\n","      <td>10451</td>\n","      <td>3.156349</td>\n","      <td>0.836681</td>\n","      <td>0.265079</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.227074</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>117</td>\n","      <td>219</td>\n","      <td>23</td>\n","      <td>7944</td>\n","      <td>3468</td>\n","      <td>2.290657</td>\n","      <td>0.524460</td>\n","      <td>0.228956</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 45 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec2d279c-c0f1-49d9-987d-b5ad28240a91')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ec2d279c-c0f1-49d9-987d-b5ad28240a91 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ec2d279c-c0f1-49d9-987d-b5ad28240a91');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["urldata = urldata.drop(['Unnamed: 0', 'Domain'], axis = 1).copy()\n","\n","urldata.shape\n","urldata.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":634,"status":"ok","timestamp":1657781115312,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"kKvKkmUNP5Cx","outputId":"ee010242-300c-402c-91dc-15e1db8dc4e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10337 entries, 0 to 10336\n","Data columns (total 45 columns):\n"," #   Column                         Non-Null Count  Dtype  \n","---  ------                         --------------  -----  \n"," 0   Have IP                        10337 non-null  int64  \n"," 1   Have @                         10337 non-null  int64  \n"," 2   URL Length                     10337 non-null  int64  \n"," 3   URL Depth                      10337 non-null  int64  \n"," 4   Redirection                    10337 non-null  int64  \n"," 5   https Domain                   10337 non-null  int64  \n"," 6   TinyURL                        10337 non-null  int64  \n"," 7   Prefix/Suffix                  10337 non-null  int64  \n"," 8   Have client                    10337 non-null  int64  \n"," 9   Have admin                     10337 non-null  int64  \n"," 10  Have login                     10337 non-null  int64  \n"," 11  Have server                    10337 non-null  int64  \n"," 12  .php                           10337 non-null  int64  \n"," 13  .html                          10337 non-null  int64  \n"," 14  .info                          10337 non-null  int64  \n"," 15  .txt                           10337 non-null  int64  \n"," 16  .js                            10337 non-null  int64  \n"," 17  .exe                           10337 non-null  int64  \n"," 18  Num of periods                 10337 non-null  int64  \n"," 19  Is encoded                     10337 non-null  int64  \n"," 20  Num of encoded char            10337 non-null  int64  \n"," 21  Num of parameters              10337 non-null  int64  \n"," 22  Num of digits                  10337 non-null  int64  \n"," 23  Num of spec char               10337 non-null  int64  \n"," 24  iFrame                         10337 non-null  int64  \n"," 25  Mouse Over                     10337 non-null  int64  \n"," 26  Right Click                    10337 non-null  int64  \n"," 27  Web Forwards                   10337 non-null  int64  \n"," 28  Number of page tokens          10337 non-null  int64  \n"," 29  number of sentences            10337 non-null  int64  \n"," 30  number of html tags            10337 non-null  int64  \n"," 31  number of whitespace           10337 non-null  int64  \n"," 32  url Is Live                    10337 non-null  int64  \n"," 33  HTML Length                    10337 non-null  int64  \n"," 34  Num Objects                    10337 non-null  int64  \n"," 35  Num Embeds                     10337 non-null  int64  \n"," 36  Num Images                     10337 non-null  int64  \n"," 37  Num Links                      10337 non-null  int64  \n"," 38  Num Titles                     10337 non-null  int64  \n"," 39  Num Script                     10337 non-null  int64  \n"," 40  Special Characters             10337 non-null  int64  \n"," 41  Script To Special Chars Ratio  10337 non-null  float64\n"," 42  Script To body Ratio           10337 non-null  float64\n"," 43  Body To Special Char Ratio     10337 non-null  float64\n"," 44  Label                          10337 non-null  int64  \n","dtypes: float64(3), int64(42)\n","memory usage: 3.5 MB\n"]}],"source":["urldata.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rvS3OQHTSHDt"},"outputs":[],"source":["# Class Distribution of Labels\n","urldata.groupby('Label').size()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kHCjZCSBSKi3"},"outputs":[],"source":["# Analysis of Postives and Negatives in the Dataset\n","pos,neg = urldata['Label'].value_counts()\n","total = neg + pos\n","print ('Total of Samples: %s'% total)\n","print('Non-Phishing: {} ({:.2f}% of total)'.format(pos, 100 * pos / total))\n","print('Phishing: {} ({:.2f}% of total)'.format(neg, 100 * neg / total))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WX-8Xbm3cfFf"},"outputs":[],"source":["urldata.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bUPfWi4TcfIA"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1656476260830,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"S3PEbrTLcfXg","outputId":"c72462bd-1604-468a-cfe2-06ee377cedde"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Have IP                          0\n","Have @                           0\n","URL Length                       0\n","URL Depth                        0\n","Redirection                      0\n","https Domain                     0\n","TinyURL                          0\n","Prefix/Suffix                    0\n","Have client                      0\n","Have admin                       0\n","Have login                       0\n","Have server                      0\n",".php                             0\n",".html                            0\n",".info                            0\n",".txt                             0\n",".js                              0\n",".exe                             0\n","Num of periods                   0\n","Is encoded                       0\n","Num of encoded char              0\n","Num of parameters                0\n","Num of digits                    0\n","Num of spec char                 0\n","iFrame                           0\n","Mouse Over                       0\n","Right Click                      0\n","Web Forwards                     0\n","Number of page tokens            0\n","number of sentences              0\n","number of html tags              0\n","number of whitespace             0\n","url Is Live                      0\n","HTML Length                      0\n","Num Objects                      0\n","Num Embeds                       0\n","Num Images                       0\n","Num Links                        0\n","Num Titles                       0\n","Num Script                       0\n","Special Characters               0\n","Script To Special Chars Ratio    0\n","Script To body Ratio             0\n","Body To Special Char Ratio       0\n","Label                            0\n","dtype: int64"]},"metadata":{},"execution_count":11}],"source":["#checking the data for null or missing values\n","urldata.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1656476260831,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"n6YfGa82P5JZ","outputId":"5cccc3a1-f56e-49e4-9260-d0cd7d626d92"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Have IP  Have @  URL Length  URL Depth  Redirection  https Domain  TinyURL  \\\n","0        0       0           1          4            0             0        0   \n","1        0       0           1          2            0             1        0   \n","2        0       0           1          3            0             0        0   \n","3        0       0           0          0            0             1        1   \n","4        0       0           1          3            0             0        1   \n","\n","   Prefix/Suffix  Have client  Have admin  ...  Num Embeds  Num Images  \\\n","0              0            0           0  ...           0           5   \n","1              1            0           0  ...           0           0   \n","2              0            0           0  ...           0           0   \n","3              0            0           0  ...           0           0   \n","4              0            0           0  ...           0          59   \n","\n","   Num Links  Num Titles  Num Script  Special Characters  \\\n","0         11           5      242609               76820   \n","1          0           0           0                   0   \n","2          0           1           0                  46   \n","3          0           1        4748                1488   \n","4        147           3        7912                3552   \n","\n","   Script To Special Chars Ratio  Script To body Ratio  \\\n","0                       3.158149              0.946209   \n","1                       0.000000              0.000000   \n","2                       0.000000              0.000000   \n","3                       3.190860              0.968782   \n","4                       2.227477              0.561892   \n","\n","   Body To Special Char Ratio  Label  \n","0                    0.299609      0  \n","1                    0.000000      1  \n","2                    0.216981      0  \n","3                    0.303612      1  \n","4                    0.252255      0  \n","\n","[5 rows x 45 columns]"],"text/html":["\n","  <div id=\"df-f311889c-e10d-4a04-8893-6315a90d1500\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>Have admin</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>242609</td>\n","      <td>76820</td>\n","      <td>3.158149</td>\n","      <td>0.946209</td>\n","      <td>0.299609</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>46</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.216981</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4748</td>\n","      <td>1488</td>\n","      <td>3.190860</td>\n","      <td>0.968782</td>\n","      <td>0.303612</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>59</td>\n","      <td>147</td>\n","      <td>3</td>\n","      <td>7912</td>\n","      <td>3552</td>\n","      <td>2.227477</td>\n","      <td>0.561892</td>\n","      <td>0.252255</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 45 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f311889c-e10d-4a04-8893-6315a90d1500')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f311889c-e10d-4a04-8893-6315a90d1500 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f311889c-e10d-4a04-8893-6315a90d1500');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}],"source":["# shuffling the rows in the dataset so that when splitting the train and test set are equally distributed\n","urldata = urldata.sample(frac=1).reset_index(drop=True)\n","urldata.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lasv_YzlP5L6"},"outputs":[],"source":["import numpy as np\n","# Sepratating & assigning features and target columns to X & y\n","y = urldata['Label'].values\n","x = np.array(urldata.drop('Label',axis=1))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":685,"status":"ok","timestamp":1656476262713,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"in9C2ArWP5O0","outputId":"46bbb7f8-bc45-4f4f-db37-6505c9a0ab75"},"outputs":[{"output_type":"stream","name":"stdout","text":["(5685, 44) (4652, 44)\n","(5685,) (4652,)\n"]}],"source":["# Splitting the dataset into train and test sets: 80-20 split\n","from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, \n","                                                    test_size = 0.45, random_state = 12)\n","print(x_train.shape, x_test.shape)\n","print(y_train.shape, y_test.shape)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jv6Y5m8ddMHC"},"outputs":[],"source":["output = {}\n","output['labels'] = y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N8k6QYBg7wu7"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"SOV9VybfNIgE"},"source":["**MLP**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mr-AOgJ1JtXY"},"outputs":[],"source":["import keras\n","\n","from sklearn.neural_network import MLPClassifier\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","import pickle\n","\n","def model_mlp(x_train, x_val, y_train, y_val, opt, n):\n","  mlpclassifier = MLPClassifier(alpha=0.0001, hidden_layer_sizes=([100,100,100]))\n","  #compile model using mse as a measure of model performance\n","  mlpclassifier.fit(x_train, y_train)\n","\n","  y_pred = mlpclassifier.predict(x_val)\n","\n","  conf_matrix = confusion_matrix(y_val, y_pred)\n","  print(conf_matrix)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred))\n","\n","  \n","  print(\"Validation Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed URL-HTML/MLP/model_'+str(n)+'.h5'\n","  pickle.dump(mlpclassifier, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","  return metrics.accuracy_score(y_val, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUCxdcapJtXZ","executionInfo":{"status":"ok","timestamp":1656400778347,"user_tz":-330,"elapsed":50871,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"9805622a-3834-4f65-edf0-48ded1beb185"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[318  10]\n"," [ 95 146]]\n","Precision: 0.9359\n","Recall: 0.6058\n","F1 Score: 0.7355\n","Validation Accuracy: 0.8154657293497364\n","model 0 saved\n","[[297   8]\n"," [ 57 207]]\n","Precision: 0.9628\n","Recall: 0.7841\n","F1 Score: 0.8643\n","Validation Accuracy: 0.8857644991212654\n","model 1 saved\n","[[181 145]\n"," [ 14 229]]\n","Precision: 0.6123\n","Recall: 0.9424\n","F1 Score: 0.7423\n","Validation Accuracy: 0.7205623901581723\n","model 2 saved\n","[[277  40]\n"," [ 51 201]]\n","Precision: 0.8340\n","Recall: 0.7976\n","F1 Score: 0.8154\n","Validation Accuracy: 0.8400702987697716\n","model 3 saved\n","[[311  10]\n"," [110 138]]\n","Precision: 0.9324\n","Recall: 0.5565\n","F1 Score: 0.6970\n","Validation Accuracy: 0.789103690685413\n","model 4 saved\n","[[310   9]\n"," [ 61 188]]\n","Precision: 0.9543\n","Recall: 0.7550\n","F1 Score: 0.8430\n","Validation Accuracy: 0.8767605633802817\n","model 5 saved\n","[[331  11]\n"," [ 56 170]]\n","Precision: 0.9392\n","Recall: 0.7522\n","F1 Score: 0.8354\n","Validation Accuracy: 0.8820422535211268\n","model 6 saved\n","[[291  37]\n"," [ 37 203]]\n","Precision: 0.8458\n","Recall: 0.8458\n","F1 Score: 0.8458\n","Validation Accuracy: 0.8697183098591549\n","model 7 saved\n","[[300   9]\n"," [105 154]]\n","Precision: 0.9448\n","Recall: 0.5946\n","F1 Score: 0.7299\n","Validation Accuracy: 0.7992957746478874\n","model 8 saved\n","[[217 101]\n"," [ 12 238]]\n","Precision: 0.7021\n","Recall: 0.9520\n","F1 Score: 0.8081\n","Validation Accuracy: 0.801056338028169\n","model 9 saved\n","Average Validation Accuracy: 0.8279839847520979\n"]}],"source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_mlp(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545},"executionInfo":{"elapsed":1093,"status":"ok","timestamp":1656476275377,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"6DA16IlPJtXZ","outputId":"0399d3c2-a1e7-4551-e9ff-44420b845659"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[9.99989064e-01 1.09358504e-05]\n"," [1.00000000e+00 5.71218323e-20]\n"," [1.00000000e+00 1.80439015e-83]\n"," ...\n"," [9.99999999e-01 1.36435856e-09]\n"," [1.00000000e+00 1.35258179e-12]\n"," [1.00000000e+00 7.21198602e-13]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish\n","0          0            0.999989          1.093585e-05\n","1          0            1.000000          5.712183e-20\n","2          0            1.000000          1.804390e-83\n","3          0            0.991853          8.147189e-03\n","4          0            0.998126          1.874161e-03\n","...      ...                 ...                   ...\n","4647       1            0.010479          9.895206e-01\n","4648       0            0.999998          1.553756e-06\n","4649       0            1.000000          1.364359e-09\n","4650       0            1.000000          1.352582e-12\n","4651       0            1.000000          7.211986e-13\n","\n","[4652 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-bb1dd3b8-5b54-447a-8711-5840527f1091\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.999989</td>\n","      <td>1.093585e-05</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>5.712183e-20</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>1.804390e-83</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.991853</td>\n","      <td>8.147189e-03</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0.998126</td>\n","      <td>1.874161e-03</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4647</th>\n","      <td>1</td>\n","      <td>0.010479</td>\n","      <td>9.895206e-01</td>\n","    </tr>\n","    <tr>\n","      <th>4648</th>\n","      <td>0</td>\n","      <td>0.999998</td>\n","      <td>1.553756e-06</td>\n","    </tr>\n","    <tr>\n","      <th>4649</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>1.364359e-09</td>\n","    </tr>\n","    <tr>\n","      <th>4650</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>1.352582e-12</td>\n","    </tr>\n","    <tr>\n","      <th>4651</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>7.211986e-13</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4652 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb1dd3b8-5b54-447a-8711-5840527f1091')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bb1dd3b8-5b54-447a-8711-5840527f1091 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bb1dd3b8-5b54-447a-8711-5840527f1091');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}],"source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed URL-HTML/MLP/model_1.h5'\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['mlp_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['mlp_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output\n"]},{"cell_type":"code","source":[""],"metadata":{"id":"rbpIy5wtL3VQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Neural Network**"],"metadata":{"id":"iLF4sz5NsSZ6"}},{"cell_type":"code","source":["\n","import keras\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","def model_aa(x_train, x_val, y_train, y_val, opt, n, early_stopping_monitor):\n","\n","  n_cols = x_train.shape[1]\n","  # print(\"check point\")\n","  #create model\n","  model = Sequential()\n","  model.add(Dense(30, activation='relu', input_shape=(n_cols,)))\n","  model.add(Dense(10, activation='relu'))\n","\n","  model.add(Dense(1, activation = 'sigmoid'))\n","  # softmax\n","  #compile model using mse as a measure of model performance\n","  model.compile(optimizer = opt, loss= 'binary_crossentropy', metrics=[\"accuracy\"])\n","\n","  history = model.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping_monitor])\n","\n","\n","  # plt.plot(history.history['loss'])\n","  # plt.plot(history.history['val_loss'])\n","  # plt.title('model loss')\n","  # plt.ylabel('Loss')\n","  # plt.xlabel('Epoch')\n","  # plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n","  # plt.show()\n","\n","\n","  print('Validation Accuracy: ')\n","  # Predicting the Test set results\n","  y_pred = model.predict(x_val)\n","  y_pred = (y_pred > 0.5)\n","\n","\n","  print(classification_report(y_val, y_pred))\n","\n","  # Model Accuracy, how often is the classifier correct?\n","  print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","\n","  # Creating the Confusion Matrix\n","  cm = confusion_matrix(y_val, y_pred)\n","  print(cm)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred))\n","\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed URL-HTML/NN/model_'+str(n)+'.h5'\n","  pickle.dump(model, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","\n","  return metrics.accuracy_score(y_val, y_pred)\n","\n"],"metadata":{"id":"UfilmHKnL3LC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_aa(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n, early_stopping_monitor)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_OHdM1HNDio","executionInfo":{"status":"ok","timestamp":1656409698067,"user_tz":-330,"elapsed":314806,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"89ae0a4f-82e4-4d7a-f9ba-37db763e7e7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","160/160 [==============================] - 4s 4ms/step - loss: 531.2415 - accuracy: 0.5940 - val_loss: 83.2652 - val_accuracy: 0.5694\n","Epoch 2/100\n","160/160 [==============================] - 0s 3ms/step - loss: 76.6814 - accuracy: 0.6501 - val_loss: 39.9997 - val_accuracy: 0.6608\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 58.1835 - accuracy: 0.7183 - val_loss: 21.4702 - val_accuracy: 0.7838\n","Epoch 4/100\n","160/160 [==============================] - 0s 3ms/step - loss: 31.0870 - accuracy: 0.7533 - val_loss: 65.0925 - val_accuracy: 0.6344\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 31.1484 - accuracy: 0.7748 - val_loss: 35.0175 - val_accuracy: 0.8084\n","Epoch 6/100\n","160/160 [==============================] - 0s 3ms/step - loss: 29.1642 - accuracy: 0.7852 - val_loss: 38.4875 - val_accuracy: 0.7944\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 75.3237 - accuracy: 0.7602 - val_loss: 65.0725 - val_accuracy: 0.8137\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 30.1059 - accuracy: 0.8012 - val_loss: 200.7376 - val_accuracy: 0.6397\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 22.9806 - accuracy: 0.8149 - val_loss: 26.9092 - val_accuracy: 0.8225\n","Epoch 10/100\n","160/160 [==============================] - 0s 3ms/step - loss: 24.3001 - accuracy: 0.8245 - val_loss: 24.7956 - val_accuracy: 0.8190\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 39.5031 - accuracy: 0.7830 - val_loss: 102.6179 - val_accuracy: 0.7487\n","Epoch 12/100\n","160/160 [==============================] - 0s 3ms/step - loss: 21.7363 - accuracy: 0.8258 - val_loss: 33.3570 - val_accuracy: 0.7979\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 12.6500 - accuracy: 0.8405 - val_loss: 28.7683 - val_accuracy: 0.8559\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.91      0.88       318\n","           1       0.88      0.78      0.83       251\n","\n","    accuracy                           0.86       569\n","   macro avg       0.86      0.85      0.85       569\n","weighted avg       0.86      0.86      0.85       569\n","\n","Accuracy: 0.8558875219683656\n","[[290  28]\n"," [ 54 197]]\n","Precision: 0.8756\n","Recall: 0.7849\n","F1 Score: 0.8277\n","INFO:tensorflow:Assets written to: ram://2d3aa46d-5b71-4987-83a3-a2648562ccc1/assets\n","model 0 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 5ms/step - loss: 377.8134 - accuracy: 0.6538 - val_loss: 108.7798 - val_accuracy: 0.7381\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 52.6435 - accuracy: 0.7455 - val_loss: 31.8130 - val_accuracy: 0.7979\n","Epoch 3/100\n","160/160 [==============================] - 0s 3ms/step - loss: 37.3941 - accuracy: 0.7807 - val_loss: 41.1736 - val_accuracy: 0.6995\n","Epoch 4/100\n","160/160 [==============================] - 0s 3ms/step - loss: 37.3029 - accuracy: 0.7881 - val_loss: 47.6055 - val_accuracy: 0.7803\n","Epoch 5/100\n","160/160 [==============================] - 0s 3ms/step - loss: 31.9769 - accuracy: 0.8020 - val_loss: 21.3028 - val_accuracy: 0.8243\n","Epoch 6/100\n","160/160 [==============================] - 0s 3ms/step - loss: 30.0973 - accuracy: 0.8176 - val_loss: 18.9946 - val_accuracy: 0.8278\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 13.2740 - accuracy: 0.8419 - val_loss: 13.6945 - val_accuracy: 0.8453\n","Epoch 8/100\n","160/160 [==============================] - 0s 3ms/step - loss: 16.1769 - accuracy: 0.8270 - val_loss: 17.2931 - val_accuracy: 0.7909\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 16.9910 - accuracy: 0.8321 - val_loss: 18.7693 - val_accuracy: 0.7153\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 20.3765 - accuracy: 0.8168 - val_loss: 16.0282 - val_accuracy: 0.8401\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 22.7918 - accuracy: 0.8333 - val_loss: 50.7518 - val_accuracy: 0.8155\n","Epoch 12/100\n","160/160 [==============================] - 0s 3ms/step - loss: 15.6248 - accuracy: 0.8440 - val_loss: 21.3418 - val_accuracy: 0.8278\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 21.5809 - accuracy: 0.8411 - val_loss: 14.0294 - val_accuracy: 0.8401\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 11.4254 - accuracy: 0.8557 - val_loss: 9.2386 - val_accuracy: 0.8647\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 9.8822 - accuracy: 0.8673 - val_loss: 9.2557 - val_accuracy: 0.8541\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 15.7257 - accuracy: 0.8423 - val_loss: 24.7923 - val_accuracy: 0.7680\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 19.7989 - accuracy: 0.8462 - val_loss: 41.2320 - val_accuracy: 0.8014\n","Epoch 18/100\n","160/160 [==============================] - 0s 3ms/step - loss: 17.1781 - accuracy: 0.8481 - val_loss: 42.6697 - val_accuracy: 0.8032\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 15.9409 - accuracy: 0.8647 - val_loss: 15.3150 - val_accuracy: 0.8506\n","Epoch 20/100\n","160/160 [==============================] - 0s 3ms/step - loss: 15.0775 - accuracy: 0.8628 - val_loss: 23.4962 - val_accuracy: 0.8207\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 21.4166 - accuracy: 0.8446 - val_loss: 15.0194 - val_accuracy: 0.8629\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 9.7112 - accuracy: 0.8700 - val_loss: 7.2909 - val_accuracy: 0.8647\n","Epoch 23/100\n","160/160 [==============================] - 1s 4ms/step - loss: 12.4558 - accuracy: 0.8585 - val_loss: 9.6457 - val_accuracy: 0.8330\n","Epoch 24/100\n","160/160 [==============================] - 1s 4ms/step - loss: 9.4535 - accuracy: 0.8706 - val_loss: 13.9677 - val_accuracy: 0.8612\n","Epoch 25/100\n","160/160 [==============================] - 1s 4ms/step - loss: 23.7188 - accuracy: 0.8503 - val_loss: 160.1909 - val_accuracy: 0.7698\n","Epoch 26/100\n","160/160 [==============================] - 1s 4ms/step - loss: 34.8632 - accuracy: 0.8479 - val_loss: 11.9634 - val_accuracy: 0.8647\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 31.0975 - accuracy: 0.8575 - val_loss: 152.4966 - val_accuracy: 0.7944\n","Epoch 28/100\n","160/160 [==============================] - 0s 3ms/step - loss: 22.9929 - accuracy: 0.8538 - val_loss: 10.5605 - val_accuracy: 0.8559\n","Epoch 29/100\n","160/160 [==============================] - 0s 3ms/step - loss: 12.4821 - accuracy: 0.8728 - val_loss: 14.1194 - val_accuracy: 0.8295\n","Epoch 30/100\n","160/160 [==============================] - 0s 3ms/step - loss: 14.2957 - accuracy: 0.8710 - val_loss: 11.6558 - val_accuracy: 0.8664\n","Epoch 31/100\n","160/160 [==============================] - 0s 3ms/step - loss: 11.5156 - accuracy: 0.8808 - val_loss: 23.2063 - val_accuracy: 0.8506\n","Epoch 32/100\n","160/160 [==============================] - 0s 3ms/step - loss: 10.9778 - accuracy: 0.8749 - val_loss: 17.0329 - val_accuracy: 0.8559\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.97      0.88       320\n","           1       0.95      0.71      0.81       249\n","\n","    accuracy                           0.86       569\n","   macro avg       0.88      0.84      0.85       569\n","weighted avg       0.87      0.86      0.85       569\n","\n","Accuracy: 0.8558875219683656\n","[[311   9]\n"," [ 73 176]]\n","Precision: 0.9514\n","Recall: 0.7068\n","F1 Score: 0.8111\n","INFO:tensorflow:Assets written to: ram://1829e9d8-de18-45c4-b167-f470c7158bb3/assets\n","model 1 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 53.2303 - accuracy: 0.7457 - val_loss: 29.2150 - val_accuracy: 0.8067\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 45.6838 - accuracy: 0.7838 - val_loss: 31.2124 - val_accuracy: 0.8137\n","Epoch 3/100\n","160/160 [==============================] - 0s 3ms/step - loss: 40.0411 - accuracy: 0.7924 - val_loss: 50.0404 - val_accuracy: 0.7715\n","Epoch 4/100\n","160/160 [==============================] - 0s 3ms/step - loss: 22.2478 - accuracy: 0.8170 - val_loss: 15.1112 - val_accuracy: 0.8453\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 12.1314 - accuracy: 0.8421 - val_loss: 22.5710 - val_accuracy: 0.8032\n","Epoch 6/100\n","160/160 [==============================] - 0s 3ms/step - loss: 15.2559 - accuracy: 0.8272 - val_loss: 33.9953 - val_accuracy: 0.8313\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 20.0216 - accuracy: 0.8358 - val_loss: 8.4753 - val_accuracy: 0.8910\n","Epoch 8/100\n","160/160 [==============================] - 0s 3ms/step - loss: 11.9054 - accuracy: 0.8509 - val_loss: 32.1930 - val_accuracy: 0.8155\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 10.9311 - accuracy: 0.8536 - val_loss: 12.3837 - val_accuracy: 0.8699\n","Epoch 10/100\n","160/160 [==============================] - 0s 3ms/step - loss: 8.0287 - accuracy: 0.8589 - val_loss: 8.3894 - val_accuracy: 0.8805\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 17.0627 - accuracy: 0.8344 - val_loss: 9.1332 - val_accuracy: 0.8664\n","Epoch 12/100\n","160/160 [==============================] - 0s 3ms/step - loss: 12.3659 - accuracy: 0.8477 - val_loss: 15.2538 - val_accuracy: 0.8594\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 15.3045 - accuracy: 0.8524 - val_loss: 10.7523 - val_accuracy: 0.8612\n","Epoch 14/100\n","160/160 [==============================] - 0s 3ms/step - loss: 7.0657 - accuracy: 0.8681 - val_loss: 9.1487 - val_accuracy: 0.8489\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 9.7892 - accuracy: 0.8552 - val_loss: 6.8550 - val_accuracy: 0.8822\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 9.8187 - accuracy: 0.8550 - val_loss: 7.7079 - val_accuracy: 0.8524\n","Epoch 17/100\n","160/160 [==============================] - 0s 3ms/step - loss: 6.8675 - accuracy: 0.8718 - val_loss: 7.2396 - val_accuracy: 0.8559\n","Epoch 18/100\n","160/160 [==============================] - 0s 3ms/step - loss: 9.2270 - accuracy: 0.8577 - val_loss: 48.2439 - val_accuracy: 0.7803\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 9.9998 - accuracy: 0.8712 - val_loss: 5.1026 - val_accuracy: 0.9069\n","Epoch 20/100\n","160/160 [==============================] - 0s 3ms/step - loss: 4.3927 - accuracy: 0.8853 - val_loss: 6.0757 - val_accuracy: 0.8840\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 10.4944 - accuracy: 0.8692 - val_loss: 5.2829 - val_accuracy: 0.8946\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 9.4746 - accuracy: 0.8622 - val_loss: 8.3772 - val_accuracy: 0.8699\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 7.5758 - accuracy: 0.8690 - val_loss: 7.5372 - val_accuracy: 0.8787\n","Epoch 24/100\n","160/160 [==============================] - 0s 3ms/step - loss: 11.7596 - accuracy: 0.8686 - val_loss: 17.7853 - val_accuracy: 0.8366\n","Epoch 25/100\n","160/160 [==============================] - 0s 3ms/step - loss: 7.6408 - accuracy: 0.8767 - val_loss: 6.1188 - val_accuracy: 0.8875\n","Epoch 26/100\n","160/160 [==============================] - 0s 3ms/step - loss: 4.7874 - accuracy: 0.8898 - val_loss: 9.7968 - val_accuracy: 0.8506\n","Epoch 27/100\n","160/160 [==============================] - 0s 3ms/step - loss: 11.0971 - accuracy: 0.8622 - val_loss: 10.1129 - val_accuracy: 0.8752\n","Epoch 28/100\n","160/160 [==============================] - 0s 3ms/step - loss: 6.1817 - accuracy: 0.8864 - val_loss: 6.5156 - val_accuracy: 0.8840\n","Epoch 29/100\n","160/160 [==============================] - 0s 3ms/step - loss: 6.5529 - accuracy: 0.8874 - val_loss: 5.1674 - val_accuracy: 0.8981\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.88      0.90       304\n","           1       0.87      0.92      0.89       265\n","\n","    accuracy                           0.90       569\n","   macro avg       0.90      0.90      0.90       569\n","weighted avg       0.90      0.90      0.90       569\n","\n","Accuracy: 0.8980667838312829\n","[[268  36]\n"," [ 22 243]]\n","Precision: 0.8710\n","Recall: 0.9170\n","F1 Score: 0.8934\n","INFO:tensorflow:Assets written to: ram://47449ba0-3040-4141-9b1c-8298a10caf3b/assets\n","model 2 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 207.7421 - accuracy: 0.6636 - val_loss: 24.9626 - val_accuracy: 0.8120\n","Epoch 2/100\n","160/160 [==============================] - 0s 3ms/step - loss: 42.9207 - accuracy: 0.7566 - val_loss: 156.3986 - val_accuracy: 0.5448\n","Epoch 3/100\n","160/160 [==============================] - 0s 3ms/step - loss: 55.3067 - accuracy: 0.7414 - val_loss: 25.3295 - val_accuracy: 0.7768\n","Epoch 4/100\n","160/160 [==============================] - 0s 3ms/step - loss: 29.4069 - accuracy: 0.7791 - val_loss: 33.3624 - val_accuracy: 0.7469\n","Epoch 5/100\n","160/160 [==============================] - 0s 3ms/step - loss: 19.5813 - accuracy: 0.7877 - val_loss: 8.3359 - val_accuracy: 0.8014\n","Epoch 6/100\n","160/160 [==============================] - 0s 3ms/step - loss: 17.6174 - accuracy: 0.8028 - val_loss: 5.4496 - val_accuracy: 0.8682\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 18.7015 - accuracy: 0.7928 - val_loss: 6.1571 - val_accuracy: 0.8418\n","Epoch 8/100\n","160/160 [==============================] - 0s 3ms/step - loss: 20.0819 - accuracy: 0.7940 - val_loss: 8.4713 - val_accuracy: 0.7961\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 29.0167 - accuracy: 0.7830 - val_loss: 49.2221 - val_accuracy: 0.7698\n","Epoch 10/100\n","160/160 [==============================] - 0s 3ms/step - loss: 21.8271 - accuracy: 0.7961 - val_loss: 8.4033 - val_accuracy: 0.8453\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 18.1983 - accuracy: 0.8133 - val_loss: 6.2045 - val_accuracy: 0.8313\n","Epoch 12/100\n","160/160 [==============================] - 0s 3ms/step - loss: 9.5217 - accuracy: 0.8436 - val_loss: 4.8192 - val_accuracy: 0.8612\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 13.3527 - accuracy: 0.8200 - val_loss: 21.5995 - val_accuracy: 0.7838\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 10.7581 - accuracy: 0.8227 - val_loss: 5.2664 - val_accuracy: 0.8682\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 14.0088 - accuracy: 0.8247 - val_loss: 42.6083 - val_accuracy: 0.7750\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 12.3593 - accuracy: 0.8366 - val_loss: 10.1390 - val_accuracy: 0.7926\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 12.3789 - accuracy: 0.8344 - val_loss: 3.4227 - val_accuracy: 0.8735\n","Epoch 18/100\n","160/160 [==============================] - 0s 3ms/step - loss: 16.9535 - accuracy: 0.8278 - val_loss: 4.7191 - val_accuracy: 0.8770\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 6.5994 - accuracy: 0.8604 - val_loss: 8.8473 - val_accuracy: 0.8137\n","Epoch 20/100\n","160/160 [==============================] - 0s 3ms/step - loss: 12.7142 - accuracy: 0.8370 - val_loss: 20.5284 - val_accuracy: 0.8172\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 9.5004 - accuracy: 0.8514 - val_loss: 3.3275 - val_accuracy: 0.8893\n","Epoch 22/100\n","160/160 [==============================] - 0s 3ms/step - loss: 7.5787 - accuracy: 0.8636 - val_loss: 20.0021 - val_accuracy: 0.8032\n","Epoch 23/100\n","160/160 [==============================] - 0s 3ms/step - loss: 13.1037 - accuracy: 0.8520 - val_loss: 11.3799 - val_accuracy: 0.8418\n","Epoch 24/100\n","160/160 [==============================] - 1s 4ms/step - loss: 11.0350 - accuracy: 0.8468 - val_loss: 8.9961 - val_accuracy: 0.8612\n","Epoch 25/100\n","160/160 [==============================] - 1s 5ms/step - loss: 12.7272 - accuracy: 0.8378 - val_loss: 2.9628 - val_accuracy: 0.9016\n","Epoch 26/100\n","160/160 [==============================] - 1s 4ms/step - loss: 11.2479 - accuracy: 0.8540 - val_loss: 3.8226 - val_accuracy: 0.8770\n","Epoch 27/100\n","160/160 [==============================] - 1s 5ms/step - loss: 6.6463 - accuracy: 0.8679 - val_loss: 6.6136 - val_accuracy: 0.8787\n","Epoch 28/100\n","160/160 [==============================] - 1s 5ms/step - loss: 7.3034 - accuracy: 0.8718 - val_loss: 19.6275 - val_accuracy: 0.8190\n","Epoch 29/100\n","160/160 [==============================] - 1s 5ms/step - loss: 13.8768 - accuracy: 0.8546 - val_loss: 3.1768 - val_accuracy: 0.9033\n","Epoch 30/100\n","160/160 [==============================] - 1s 5ms/step - loss: 15.0993 - accuracy: 0.8497 - val_loss: 7.4541 - val_accuracy: 0.8770\n","Epoch 31/100\n","160/160 [==============================] - 1s 5ms/step - loss: 10.2990 - accuracy: 0.8698 - val_loss: 2.9684 - val_accuracy: 0.9139\n","Epoch 32/100\n","160/160 [==============================] - 1s 5ms/step - loss: 13.9449 - accuracy: 0.8466 - val_loss: 4.0104 - val_accuracy: 0.8910\n","Epoch 33/100\n","160/160 [==============================] - 1s 5ms/step - loss: 8.1217 - accuracy: 0.8745 - val_loss: 2.3084 - val_accuracy: 0.9121\n","Epoch 34/100\n","160/160 [==============================] - 1s 5ms/step - loss: 5.0365 - accuracy: 0.8814 - val_loss: 3.7141 - val_accuracy: 0.8998\n","Epoch 35/100\n","160/160 [==============================] - 1s 4ms/step - loss: 5.9824 - accuracy: 0.8862 - val_loss: 2.2151 - val_accuracy: 0.9069\n","Epoch 36/100\n","160/160 [==============================] - 1s 6ms/step - loss: 5.7177 - accuracy: 0.8800 - val_loss: 4.6509 - val_accuracy: 0.8787\n","Epoch 37/100\n","160/160 [==============================] - 1s 4ms/step - loss: 7.5485 - accuracy: 0.8735 - val_loss: 91.0382 - val_accuracy: 0.6327\n","Epoch 38/100\n","160/160 [==============================] - 0s 3ms/step - loss: 16.6183 - accuracy: 0.8581 - val_loss: 47.7318 - val_accuracy: 0.7838\n","Epoch 39/100\n","160/160 [==============================] - 0s 3ms/step - loss: 9.8982 - accuracy: 0.8755 - val_loss: 33.3122 - val_accuracy: 0.6714\n","Epoch 40/100\n","160/160 [==============================] - 0s 3ms/step - loss: 9.7120 - accuracy: 0.8794 - val_loss: 14.8503 - val_accuracy: 0.8576\n","Epoch 41/100\n","160/160 [==============================] - 0s 3ms/step - loss: 7.8938 - accuracy: 0.8780 - val_loss: 3.5388 - val_accuracy: 0.8875\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 6.5104 - accuracy: 0.8905 - val_loss: 4.2866 - val_accuracy: 0.8963\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 17.3182 - accuracy: 0.8497 - val_loss: 10.4055 - val_accuracy: 0.8735\n","Epoch 44/100\n","160/160 [==============================] - 0s 3ms/step - loss: 5.7273 - accuracy: 0.8900 - val_loss: 5.1026 - val_accuracy: 0.8893\n","Epoch 45/100\n","160/160 [==============================] - 1s 3ms/step - loss: 16.5574 - accuracy: 0.8544 - val_loss: 5.8959 - val_accuracy: 0.8928\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.97      0.91       309\n","           1       0.96      0.80      0.87       260\n","\n","    accuracy                           0.89       569\n","   macro avg       0.91      0.89      0.89       569\n","weighted avg       0.90      0.89      0.89       569\n","\n","Accuracy: 0.8927943760984183\n","[[300   9]\n"," [ 52 208]]\n","Precision: 0.9585\n","Recall: 0.8000\n","F1 Score: 0.8721\n","INFO:tensorflow:Assets written to: ram://f4ebe36f-d1b9-4fe1-ab7a-2e254bf18166/assets\n","model 3 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 343.6498 - accuracy: 0.5534 - val_loss: 30.3231 - val_accuracy: 0.6450\n","Epoch 2/100\n","160/160 [==============================] - 1s 5ms/step - loss: 56.5574 - accuracy: 0.6908 - val_loss: 25.1067 - val_accuracy: 0.7557\n","Epoch 3/100\n","160/160 [==============================] - 1s 5ms/step - loss: 28.6990 - accuracy: 0.7215 - val_loss: 21.1298 - val_accuracy: 0.6837\n","Epoch 4/100\n","160/160 [==============================] - 1s 5ms/step - loss: 27.6430 - accuracy: 0.7285 - val_loss: 53.3943 - val_accuracy: 0.7381\n","Epoch 5/100\n","160/160 [==============================] - 1s 6ms/step - loss: 26.0672 - accuracy: 0.7496 - val_loss: 9.2540 - val_accuracy: 0.7346\n","Epoch 6/100\n","160/160 [==============================] - 1s 5ms/step - loss: 28.0185 - accuracy: 0.7545 - val_loss: 8.2729 - val_accuracy: 0.8102\n","Epoch 7/100\n","160/160 [==============================] - 1s 5ms/step - loss: 16.1973 - accuracy: 0.7498 - val_loss: 18.5656 - val_accuracy: 0.7803\n","Epoch 8/100\n","160/160 [==============================] - 1s 5ms/step - loss: 12.8373 - accuracy: 0.7490 - val_loss: 23.2288 - val_accuracy: 0.7768\n","Epoch 9/100\n","160/160 [==============================] - 1s 4ms/step - loss: 23.8662 - accuracy: 0.7502 - val_loss: 25.4464 - val_accuracy: 0.7786\n","Epoch 10/100\n","160/160 [==============================] - 1s 5ms/step - loss: 32.0943 - accuracy: 0.7510 - val_loss: 55.5559 - val_accuracy: 0.7838\n","Epoch 11/100\n","160/160 [==============================] - 1s 4ms/step - loss: 15.0557 - accuracy: 0.7920 - val_loss: 70.6626 - val_accuracy: 0.7944\n","Epoch 12/100\n","160/160 [==============================] - 1s 5ms/step - loss: 29.1044 - accuracy: 0.7660 - val_loss: 13.9523 - val_accuracy: 0.8137\n","Epoch 13/100\n","160/160 [==============================] - 1s 5ms/step - loss: 14.9132 - accuracy: 0.7733 - val_loss: 6.6257 - val_accuracy: 0.8014\n","Epoch 14/100\n","160/160 [==============================] - 1s 5ms/step - loss: 4.8747 - accuracy: 0.7703 - val_loss: 4.6329 - val_accuracy: 0.8084\n","Epoch 15/100\n","160/160 [==============================] - 1s 7ms/step - loss: 8.4302 - accuracy: 0.7580 - val_loss: 2.4903 - val_accuracy: 0.8084\n","Epoch 16/100\n","160/160 [==============================] - 1s 6ms/step - loss: 10.9508 - accuracy: 0.7647 - val_loss: 3.9218 - val_accuracy: 0.8155\n","Epoch 17/100\n","160/160 [==============================] - 1s 6ms/step - loss: 8.2726 - accuracy: 0.7242 - val_loss: 10.0173 - val_accuracy: 0.7909\n","Epoch 18/100\n","160/160 [==============================] - 1s 6ms/step - loss: 8.6927 - accuracy: 0.7117 - val_loss: 1.0485 - val_accuracy: 0.7909\n","Epoch 19/100\n","160/160 [==============================] - 1s 6ms/step - loss: 0.8924 - accuracy: 0.6624 - val_loss: 0.9708 - val_accuracy: 0.7627\n","Epoch 20/100\n","160/160 [==============================] - 1s 7ms/step - loss: 1.4844 - accuracy: 0.6908 - val_loss: 7.0759 - val_accuracy: 0.7856\n","Epoch 21/100\n","160/160 [==============================] - 1s 6ms/step - loss: 1.7815 - accuracy: 0.6579 - val_loss: 0.5612 - val_accuracy: 0.6538\n","Epoch 22/100\n","160/160 [==============================] - 1s 6ms/step - loss: 0.6034 - accuracy: 0.6486 - val_loss: 0.5419 - val_accuracy: 0.6397\n","Epoch 23/100\n","160/160 [==============================] - 1s 6ms/step - loss: 0.6148 - accuracy: 0.6935 - val_loss: 0.5496 - val_accuracy: 0.7698\n","Epoch 24/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.6041 - accuracy: 0.7219 - val_loss: 0.5553 - val_accuracy: 0.5343\n","Epoch 25/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.5798 - accuracy: 0.7174 - val_loss: 0.5217 - val_accuracy: 0.7768\n","Epoch 26/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.5906 - accuracy: 0.7250 - val_loss: 0.5353 - val_accuracy: 0.7873\n","Epoch 27/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.5544 - accuracy: 0.7457 - val_loss: 0.5403 - val_accuracy: 0.7768\n","Epoch 28/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.5327 - accuracy: 0.7486 - val_loss: 0.5028 - val_accuracy: 0.7663\n","Epoch 29/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.5238 - accuracy: 0.7502 - val_loss: 0.5026 - val_accuracy: 0.7645\n","Epoch 30/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.5118 - accuracy: 0.7498 - val_loss: 0.5274 - val_accuracy: 0.7698\n","Epoch 31/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.5082 - accuracy: 0.7504 - val_loss: 0.5126 - val_accuracy: 0.7680\n","Epoch 32/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.5026 - accuracy: 0.7512 - val_loss: 0.4985 - val_accuracy: 0.7698\n","Epoch 33/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.4961 - accuracy: 0.7531 - val_loss: 0.5171 - val_accuracy: 0.7698\n","Epoch 34/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.5141 - accuracy: 0.7529 - val_loss: 0.4738 - val_accuracy: 0.7698\n","Epoch 35/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.4913 - accuracy: 0.7525 - val_loss: 0.4540 - val_accuracy: 0.7873\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4924 - accuracy: 0.7559 - val_loss: 0.4739 - val_accuracy: 0.7698\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4794 - accuracy: 0.7533 - val_loss: 0.4711 - val_accuracy: 0.7715\n","Epoch 38/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7551 - val_loss: 0.4995 - val_accuracy: 0.7715\n","Epoch 39/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7598 - val_loss: 0.4472 - val_accuracy: 0.7891\n","Epoch 40/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7609 - val_loss: 0.4694 - val_accuracy: 0.7768\n","Epoch 41/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4803 - accuracy: 0.7527 - val_loss: 0.4741 - val_accuracy: 0.7768\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4748 - accuracy: 0.7494 - val_loss: 0.4686 - val_accuracy: 0.7750\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4714 - accuracy: 0.7547 - val_loss: 0.4552 - val_accuracy: 0.7733\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4697 - accuracy: 0.7531 - val_loss: 0.4428 - val_accuracy: 0.7750\n","Epoch 45/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7594 - val_loss: 0.4519 - val_accuracy: 0.7803\n","Epoch 46/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4502 - accuracy: 0.7629 - val_loss: 0.4318 - val_accuracy: 0.7821\n","Epoch 47/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4505 - accuracy: 0.7590 - val_loss: 0.4362 - val_accuracy: 0.7803\n","Epoch 48/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4430 - accuracy: 0.7604 - val_loss: 0.4602 - val_accuracy: 0.7821\n","Epoch 49/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7608 - val_loss: 0.4502 - val_accuracy: 0.7856\n","Epoch 50/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7598 - val_loss: 0.4122 - val_accuracy: 0.7873\n","Epoch 51/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7611 - val_loss: 0.4655 - val_accuracy: 0.7698\n","Epoch 52/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4370 - accuracy: 0.7559 - val_loss: 0.4116 - val_accuracy: 0.7803\n","Epoch 53/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7639 - val_loss: 0.4208 - val_accuracy: 0.7926\n","Epoch 54/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7637 - val_loss: 0.3968 - val_accuracy: 0.7873\n","Epoch 55/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.7086 - val_loss: 0.4926 - val_accuracy: 0.6028\n","Epoch 56/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6904 - accuracy: 0.7306 - val_loss: 0.5147 - val_accuracy: 0.7891\n","Epoch 57/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4935 - accuracy: 0.7875 - val_loss: 0.4727 - val_accuracy: 0.8313\n","Epoch 58/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4746 - accuracy: 0.7963 - val_loss: 0.5160 - val_accuracy: 0.8260\n","Epoch 59/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.4672 - accuracy: 0.7963 - val_loss: 0.4514 - val_accuracy: 0.8243\n","Epoch 60/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.4525 - accuracy: 0.8024 - val_loss: 0.4274 - val_accuracy: 0.8278\n","Epoch 61/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.4481 - accuracy: 0.8014 - val_loss: 0.4076 - val_accuracy: 0.8330\n","Epoch 62/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.4363 - accuracy: 0.8039 - val_loss: 0.4188 - val_accuracy: 0.8348\n","Epoch 63/100\n","160/160 [==============================] - 1s 7ms/step - loss: 0.4388 - accuracy: 0.8059 - val_loss: 0.4248 - val_accuracy: 0.8225\n","Epoch 64/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.4384 - accuracy: 0.8039 - val_loss: 0.4013 - val_accuracy: 0.8576\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.78      0.85       291\n","           1       0.80      0.94      0.87       278\n","\n","    accuracy                           0.86       569\n","   macro avg       0.87      0.86      0.86       569\n","weighted avg       0.87      0.86      0.86       569\n","\n","Accuracy: 0.8576449912126538\n","[[228  63]\n"," [ 18 260]]\n","Precision: 0.8050\n","Recall: 0.9353\n","F1 Score: 0.8652\n","INFO:tensorflow:Assets written to: ram://bc9c1b78-2245-4871-8959-5a1352ddbb5b/assets\n","model 4 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 169.0790 - accuracy: 0.6541 - val_loss: 6.8166 - val_accuracy: 0.7870\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 21.6054 - accuracy: 0.7528 - val_loss: 25.1833 - val_accuracy: 0.7711\n","Epoch 3/100\n","160/160 [==============================] - 0s 3ms/step - loss: 25.7508 - accuracy: 0.7751 - val_loss: 14.0238 - val_accuracy: 0.7975\n","Epoch 4/100\n","160/160 [==============================] - 0s 3ms/step - loss: 18.1549 - accuracy: 0.8011 - val_loss: 26.0737 - val_accuracy: 0.7658\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 15.5176 - accuracy: 0.8278 - val_loss: 52.5923 - val_accuracy: 0.5739\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 19.2336 - accuracy: 0.8044 - val_loss: 5.5101 - val_accuracy: 0.8433\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 14.1670 - accuracy: 0.8351 - val_loss: 20.7724 - val_accuracy: 0.7852\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 14.6564 - accuracy: 0.8315 - val_loss: 8.3698 - val_accuracy: 0.8504\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 7.6923 - accuracy: 0.8480 - val_loss: 3.4796 - val_accuracy: 0.8732\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 8.9284 - accuracy: 0.8448 - val_loss: 5.7882 - val_accuracy: 0.8521\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 15.6726 - accuracy: 0.8263 - val_loss: 8.6064 - val_accuracy: 0.8310\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 10.3534 - accuracy: 0.8470 - val_loss: 28.1234 - val_accuracy: 0.7940\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 12.2085 - accuracy: 0.8380 - val_loss: 5.3921 - val_accuracy: 0.8451\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 4.7245 - accuracy: 0.8738 - val_loss: 1.8166 - val_accuracy: 0.8979\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 7.9749 - accuracy: 0.8552 - val_loss: 4.6919 - val_accuracy: 0.8662\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 10.4880 - accuracy: 0.8392 - val_loss: 2.2599 - val_accuracy: 0.9085\n","Epoch 17/100\n","160/160 [==============================] - 0s 3ms/step - loss: 6.9194 - accuracy: 0.8652 - val_loss: 2.0305 - val_accuracy: 0.8961\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 5.2448 - accuracy: 0.8837 - val_loss: 32.0239 - val_accuracy: 0.6479\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 14.5944 - accuracy: 0.8292 - val_loss: 16.5288 - val_accuracy: 0.8345\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 17.6755 - accuracy: 0.8364 - val_loss: 5.4888 - val_accuracy: 0.8785\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 8.9648 - accuracy: 0.8562 - val_loss: 7.4034 - val_accuracy: 0.7500\n","Epoch 22/100\n","160/160 [==============================] - 0s 3ms/step - loss: 8.2903 - accuracy: 0.8546 - val_loss: 11.8909 - val_accuracy: 0.8574\n","Epoch 23/100\n","160/160 [==============================] - 0s 3ms/step - loss: 5.6000 - accuracy: 0.8796 - val_loss: 2.0012 - val_accuracy: 0.9102\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 5.7164 - accuracy: 0.8741 - val_loss: 1.8271 - val_accuracy: 0.8996\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.89      0.91       326\n","           1       0.86      0.92      0.89       242\n","\n","    accuracy                           0.90       568\n","   macro avg       0.90      0.90      0.90       568\n","weighted avg       0.90      0.90      0.90       568\n","\n","Accuracy: 0.8996478873239436\n","[[289  37]\n"," [ 20 222]]\n","Precision: 0.8571\n","Recall: 0.9174\n","F1 Score: 0.8862\n","INFO:tensorflow:Assets written to: ram://b037cfd1-1c63-45c3-884f-afcec587de74/assets\n","model 5 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 75.7014 - accuracy: 0.4202 - val_loss: 5.1600 - val_accuracy: 0.3116\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 2.0241 - accuracy: 0.3551 - val_loss: 1.1524 - val_accuracy: 0.3592\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.8761 - accuracy: 0.3791 - val_loss: 0.6840 - val_accuracy: 0.6373\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6679 - accuracy: 0.6111 - val_loss: 0.6283 - val_accuracy: 0.6373\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6520 - accuracy: 0.6105 - val_loss: 0.6144 - val_accuracy: 0.6391\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6428 - accuracy: 0.6097 - val_loss: 0.6125 - val_accuracy: 0.6373\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.6097 - val_loss: 0.6093 - val_accuracy: 0.6373\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6321 - accuracy: 0.6121 - val_loss: 0.6068 - val_accuracy: 0.6356\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.6117 - val_loss: 0.6034 - val_accuracy: 0.6408\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6263 - accuracy: 0.6093 - val_loss: 0.6026 - val_accuracy: 0.6356\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.6093 - val_loss: 0.6025 - val_accuracy: 0.6338\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6204 - accuracy: 0.6113 - val_loss: 0.6009 - val_accuracy: 0.6356\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.6138 - val_loss: 0.6005 - val_accuracy: 0.6426\n","Epoch 14/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.6164 - accuracy: 0.6152 - val_loss: 0.5995 - val_accuracy: 0.6426\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.6189 - val_loss: 0.5989 - val_accuracy: 0.6426\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6151 - accuracy: 0.6164 - val_loss: 0.5999 - val_accuracy: 0.6373\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6134 - accuracy: 0.6150 - val_loss: 0.5996 - val_accuracy: 0.6373\n","Epoch 18/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.6209 - val_loss: 0.5996 - val_accuracy: 0.6444\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.6185 - val_loss: 0.5979 - val_accuracy: 0.6444\n","Epoch 20/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6215 - val_loss: 0.5990 - val_accuracy: 0.6444\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6098 - accuracy: 0.6226 - val_loss: 0.5967 - val_accuracy: 0.6444\n","Epoch 22/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6240 - val_loss: 0.5962 - val_accuracy: 0.6461\n","Epoch 23/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.6252 - val_loss: 0.5938 - val_accuracy: 0.6532\n","Epoch 24/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.6271 - val_loss: 0.5972 - val_accuracy: 0.6391\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6075 - accuracy: 0.6232 - val_loss: 0.5909 - val_accuracy: 0.6532\n","Epoch 26/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.6281 - val_loss: 0.5939 - val_accuracy: 0.6496\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6030 - accuracy: 0.6297 - val_loss: 0.5868 - val_accuracy: 0.6602\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5978 - accuracy: 0.6353 - val_loss: 0.5843 - val_accuracy: 0.6585\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5975 - accuracy: 0.6363 - val_loss: 0.5845 - val_accuracy: 0.6602\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5945 - accuracy: 0.6396 - val_loss: 0.5796 - val_accuracy: 0.6655\n","Epoch 31/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.6418 - val_loss: 0.5794 - val_accuracy: 0.6637\n","Epoch 32/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.6420 - val_loss: 0.5775 - val_accuracy: 0.6655\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5904 - accuracy: 0.6387 - val_loss: 0.5770 - val_accuracy: 0.6602\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5892 - accuracy: 0.6369 - val_loss: 0.5739 - val_accuracy: 0.6637\n","Epoch 35/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.6355 - val_loss: 0.6103 - val_accuracy: 0.6338\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6095 - accuracy: 0.6213 - val_loss: 0.5920 - val_accuracy: 0.6567\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5970 - accuracy: 0.6349 - val_loss: 0.5883 - val_accuracy: 0.6585\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5930 - accuracy: 0.6369 - val_loss: 0.5845 - val_accuracy: 0.6655\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5909 - accuracy: 0.6398 - val_loss: 0.5823 - val_accuracy: 0.6637\n","Epoch 40/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.6402 - val_loss: 0.5802 - val_accuracy: 0.6673\n","Epoch 41/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5872 - accuracy: 0.6412 - val_loss: 0.5781 - val_accuracy: 0.6673\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5855 - accuracy: 0.6402 - val_loss: 0.5749 - val_accuracy: 0.6690\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5950 - accuracy: 0.6502 - val_loss: 0.5736 - val_accuracy: 0.6637\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.6138 - accuracy: 0.6346 - val_loss: 0.5942 - val_accuracy: 0.6549\n","Epoch 45/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.6334 - val_loss: 0.5917 - val_accuracy: 0.6585\n","Epoch 46/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5941 - accuracy: 0.6344 - val_loss: 0.5876 - val_accuracy: 0.6673\n","Epoch 47/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.6373 - val_loss: 0.5843 - val_accuracy: 0.6673\n","Epoch 48/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5913 - accuracy: 0.6390 - val_loss: 0.5845 - val_accuracy: 0.6690\n","Epoch 49/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5966 - accuracy: 0.6420 - val_loss: 0.5828 - val_accuracy: 0.6655\n","Epoch 50/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5872 - accuracy: 0.7200 - val_loss: 0.5595 - val_accuracy: 0.7518\n","Epoch 51/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.7573 - val_loss: 0.5341 - val_accuracy: 0.7606\n","Epoch 52/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5207 - accuracy: 0.7633 - val_loss: 0.5240 - val_accuracy: 0.7588\n","Epoch 53/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5013 - accuracy: 0.7628 - val_loss: 0.5229 - val_accuracy: 0.7553\n","Epoch 54/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.5179 - accuracy: 0.7567 - val_loss: 0.5100 - val_accuracy: 0.7606\n","Epoch 55/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4995 - accuracy: 0.7520 - val_loss: 0.5080 - val_accuracy: 0.7782\n","Epoch 56/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7598 - val_loss: 0.4993 - val_accuracy: 0.7570\n","Epoch 57/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4824 - accuracy: 0.7616 - val_loss: 0.4997 - val_accuracy: 0.7764\n","Epoch 58/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4752 - accuracy: 0.7651 - val_loss: 0.4959 - val_accuracy: 0.7746\n","Epoch 59/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4929 - accuracy: 0.7669 - val_loss: 0.4958 - val_accuracy: 0.7764\n","Epoch 60/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7661 - val_loss: 0.4963 - val_accuracy: 0.7764\n","Epoch 61/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4731 - accuracy: 0.7637 - val_loss: 0.4909 - val_accuracy: 0.7746\n","Epoch 62/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4703 - accuracy: 0.7649 - val_loss: 0.4932 - val_accuracy: 0.7729\n","Epoch 63/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4767 - accuracy: 0.7629 - val_loss: 0.4864 - val_accuracy: 0.7641\n","Epoch 64/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4756 - accuracy: 0.7610 - val_loss: 0.4936 - val_accuracy: 0.7870\n","Epoch 65/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4848 - accuracy: 0.7563 - val_loss: 0.4767 - val_accuracy: 0.7729\n","Epoch 66/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4694 - accuracy: 0.7639 - val_loss: 0.4860 - val_accuracy: 0.7799\n","Epoch 67/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4680 - accuracy: 0.7671 - val_loss: 0.4905 - val_accuracy: 0.7782\n","Epoch 68/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4642 - accuracy: 0.7676 - val_loss: 0.4788 - val_accuracy: 0.7746\n","Epoch 69/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4645 - accuracy: 0.7659 - val_loss: 0.4878 - val_accuracy: 0.7799\n","Epoch 70/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4630 - accuracy: 0.7698 - val_loss: 0.4957 - val_accuracy: 0.8028\n","Epoch 71/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4818 - accuracy: 0.7631 - val_loss: 0.4982 - val_accuracy: 0.7975\n","Epoch 72/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4825 - accuracy: 0.7583 - val_loss: 0.5122 - val_accuracy: 0.7993\n","Epoch 73/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4673 - accuracy: 0.7706 - val_loss: 0.4793 - val_accuracy: 0.7870\n","Epoch 74/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4605 - accuracy: 0.7731 - val_loss: 0.4682 - val_accuracy: 0.7799\n","Epoch 75/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4600 - accuracy: 0.7678 - val_loss: 0.4738 - val_accuracy: 0.7852\n","Epoch 76/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4552 - accuracy: 0.7723 - val_loss: 0.4795 - val_accuracy: 0.7905\n","Epoch 77/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4515 - accuracy: 0.7751 - val_loss: 0.4896 - val_accuracy: 0.7905\n","Epoch 78/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4622 - accuracy: 0.7698 - val_loss: 0.4742 - val_accuracy: 0.7606\n","Epoch 79/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4950 - accuracy: 0.7581 - val_loss: 0.4833 - val_accuracy: 0.7606\n","Epoch 80/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4807 - accuracy: 0.7520 - val_loss: 0.4845 - val_accuracy: 0.7535\n","Epoch 81/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4767 - accuracy: 0.7502 - val_loss: 0.4871 - val_accuracy: 0.7606\n","Epoch 82/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7536 - val_loss: 0.4721 - val_accuracy: 0.7623\n","Epoch 83/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4706 - accuracy: 0.7543 - val_loss: 0.4714 - val_accuracy: 0.7623\n","Epoch 84/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.4713 - accuracy: 0.7604 - val_loss: 0.4819 - val_accuracy: 0.7694\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.99      0.84       339\n","           1       0.96      0.45      0.61       229\n","\n","    accuracy                           0.77       568\n","   macro avg       0.84      0.72      0.72       568\n","weighted avg       0.82      0.77      0.74       568\n","\n","Accuracy: 0.7693661971830986\n","[[335   4]\n"," [127 102]]\n","Precision: 0.9623\n","Recall: 0.4454\n","F1 Score: 0.6090\n","INFO:tensorflow:Assets written to: ram://bdf966bf-627e-4677-bf24-76c86be2d65a/assets\n","model 6 saved\n","Epoch 1/100\n","160/160 [==============================] - 2s 8ms/step - loss: 114.1121 - accuracy: 0.6783 - val_loss: 26.8813 - val_accuracy: 0.7412\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 58.0147 - accuracy: 0.7444 - val_loss: 131.8155 - val_accuracy: 0.5511\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 36.1827 - accuracy: 0.7794 - val_loss: 15.2042 - val_accuracy: 0.8257\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 34.3203 - accuracy: 0.7989 - val_loss: 34.8496 - val_accuracy: 0.7870\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 28.7018 - accuracy: 0.7995 - val_loss: 58.5025 - val_accuracy: 0.7799\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 19.3414 - accuracy: 0.8079 - val_loss: 12.0887 - val_accuracy: 0.8169\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 14.4208 - accuracy: 0.8222 - val_loss: 10.8911 - val_accuracy: 0.8204\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 21.1627 - accuracy: 0.8163 - val_loss: 30.4730 - val_accuracy: 0.7905\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 19.9302 - accuracy: 0.8220 - val_loss: 19.0231 - val_accuracy: 0.8134\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 20.5880 - accuracy: 0.8288 - val_loss: 13.7608 - val_accuracy: 0.8504\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 9.4342 - accuracy: 0.8442 - val_loss: 5.5165 - val_accuracy: 0.8820\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 22.6908 - accuracy: 0.8147 - val_loss: 27.7935 - val_accuracy: 0.8011\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 16.7034 - accuracy: 0.8360 - val_loss: 30.8410 - val_accuracy: 0.6989\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 14.4443 - accuracy: 0.8327 - val_loss: 12.1089 - val_accuracy: 0.8521\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 24.6339 - accuracy: 0.8263 - val_loss: 12.4325 - val_accuracy: 0.8468\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 34.9560 - accuracy: 0.8098 - val_loss: 8.1539 - val_accuracy: 0.8961\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 13.1458 - accuracy: 0.8497 - val_loss: 8.6890 - val_accuracy: 0.8750\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 10.4973 - accuracy: 0.8585 - val_loss: 16.4914 - val_accuracy: 0.7518\n","Epoch 19/100\n","160/160 [==============================] - 1s 4ms/step - loss: 39.3352 - accuracy: 0.8040 - val_loss: 8.5211 - val_accuracy: 0.8926\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 14.0631 - accuracy: 0.8581 - val_loss: 18.2876 - val_accuracy: 0.7254\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 12.6208 - accuracy: 0.8435 - val_loss: 6.9403 - val_accuracy: 0.8979\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.91      0.92       345\n","           1       0.87      0.87      0.87       223\n","\n","    accuracy                           0.90       568\n","   macro avg       0.89      0.89      0.89       568\n","weighted avg       0.90      0.90      0.90       568\n","\n","Accuracy: 0.897887323943662\n","[[315  30]\n"," [ 28 195]]\n","Precision: 0.8667\n","Recall: 0.8744\n","F1 Score: 0.8705\n","INFO:tensorflow:Assets written to: ram://deba3f0c-1667-43fd-bf84-70f4f64ff593/assets\n","model 7 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 106.9611 - accuracy: 0.6267 - val_loss: 52.0618 - val_accuracy: 0.6725\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 24.7615 - accuracy: 0.7553 - val_loss: 9.4250 - val_accuracy: 0.8063\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 24.9893 - accuracy: 0.7680 - val_loss: 44.3869 - val_accuracy: 0.7447\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 22.9582 - accuracy: 0.7940 - val_loss: 12.9711 - val_accuracy: 0.8134\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 16.4160 - accuracy: 0.8026 - val_loss: 14.9820 - val_accuracy: 0.8134\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 14.1407 - accuracy: 0.8210 - val_loss: 13.4779 - val_accuracy: 0.7958\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 13.7865 - accuracy: 0.8280 - val_loss: 14.6692 - val_accuracy: 0.8204\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 18.0194 - accuracy: 0.8079 - val_loss: 14.1564 - val_accuracy: 0.8116\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 13.1237 - accuracy: 0.8397 - val_loss: 5.2061 - val_accuracy: 0.8662\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 15.9588 - accuracy: 0.8294 - val_loss: 12.1675 - val_accuracy: 0.8380\n","Epoch 11/100\n","160/160 [==============================] - 1s 4ms/step - loss: 10.1667 - accuracy: 0.8568 - val_loss: 4.5596 - val_accuracy: 0.8908\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 11.8890 - accuracy: 0.8446 - val_loss: 4.2535 - val_accuracy: 0.8697\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 7.9737 - accuracy: 0.8661 - val_loss: 3.1111 - val_accuracy: 0.8908\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 8.2368 - accuracy: 0.8663 - val_loss: 2.5565 - val_accuracy: 0.9085\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 6.9034 - accuracy: 0.8681 - val_loss: 4.9915 - val_accuracy: 0.8521\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 13.8274 - accuracy: 0.8417 - val_loss: 13.1520 - val_accuracy: 0.8187\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 14.0295 - accuracy: 0.8401 - val_loss: 12.5924 - val_accuracy: 0.8504\n","Epoch 18/100\n","160/160 [==============================] - 0s 3ms/step - loss: 7.0810 - accuracy: 0.8698 - val_loss: 3.3981 - val_accuracy: 0.8908\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 10.7686 - accuracy: 0.8642 - val_loss: 4.5484 - val_accuracy: 0.9173\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 8.3931 - accuracy: 0.8724 - val_loss: 5.0993 - val_accuracy: 0.8926\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 5.6562 - accuracy: 0.8718 - val_loss: 4.3171 - val_accuracy: 0.8768\n","Epoch 22/100\n","160/160 [==============================] - 1s 4ms/step - loss: 8.0139 - accuracy: 0.8718 - val_loss: 3.9996 - val_accuracy: 0.8768\n","Epoch 23/100\n","160/160 [==============================] - 1s 5ms/step - loss: 6.8200 - accuracy: 0.8759 - val_loss: 2.8278 - val_accuracy: 0.8908\n","Epoch 24/100\n","160/160 [==============================] - 1s 6ms/step - loss: 7.0435 - accuracy: 0.8765 - val_loss: 7.6772 - val_accuracy: 0.8662\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.98      0.89       316\n","           1       0.97      0.72      0.83       252\n","\n","    accuracy                           0.87       568\n","   macro avg       0.89      0.85      0.86       568\n","weighted avg       0.88      0.87      0.86       568\n","\n","Accuracy: 0.8661971830985915\n","[[310   6]\n"," [ 70 182]]\n","Precision: 0.9681\n","Recall: 0.7222\n","F1 Score: 0.8273\n","INFO:tensorflow:Assets written to: ram://6ea69daf-93f4-417a-a5f7-aa69e5aa2c8f/assets\n","model 8 saved\n","Epoch 1/100\n","160/160 [==============================] - 2s 6ms/step - loss: 254.3493 - accuracy: 0.7024 - val_loss: 68.5348 - val_accuracy: 0.7711\n","Epoch 2/100\n","160/160 [==============================] - 1s 5ms/step - loss: 136.0898 - accuracy: 0.7330 - val_loss: 260.6877 - val_accuracy: 0.7324\n","Epoch 3/100\n","160/160 [==============================] - 1s 4ms/step - loss: 88.6902 - accuracy: 0.7514 - val_loss: 82.4076 - val_accuracy: 0.6056\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 64.1710 - accuracy: 0.7819 - val_loss: 37.8231 - val_accuracy: 0.8521\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 44.1429 - accuracy: 0.7968 - val_loss: 120.3322 - val_accuracy: 0.7570\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 74.8653 - accuracy: 0.7848 - val_loss: 31.6813 - val_accuracy: 0.8697\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 32.7656 - accuracy: 0.8188 - val_loss: 33.1812 - val_accuracy: 0.8310\n","Epoch 8/100\n","160/160 [==============================] - 1s 5ms/step - loss: 34.7286 - accuracy: 0.8280 - val_loss: 33.8582 - val_accuracy: 0.8310\n","Epoch 9/100\n","160/160 [==============================] - 1s 5ms/step - loss: 31.9006 - accuracy: 0.8280 - val_loss: 39.0924 - val_accuracy: 0.8239\n","Epoch 10/100\n","160/160 [==============================] - 1s 5ms/step - loss: 63.1083 - accuracy: 0.8085 - val_loss: 62.9001 - val_accuracy: 0.6813\n","Epoch 11/100\n","160/160 [==============================] - 1s 5ms/step - loss: 46.6960 - accuracy: 0.8210 - val_loss: 35.8614 - val_accuracy: 0.8187\n","Epoch 12/100\n","160/160 [==============================] - 1s 5ms/step - loss: 40.8362 - accuracy: 0.8227 - val_loss: 25.4352 - val_accuracy: 0.8856\n","Epoch 13/100\n","160/160 [==============================] - 1s 5ms/step - loss: 38.1246 - accuracy: 0.8335 - val_loss: 31.5203 - val_accuracy: 0.8468\n","Epoch 14/100\n","160/160 [==============================] - 1s 5ms/step - loss: 56.3549 - accuracy: 0.8013 - val_loss: 29.9977 - val_accuracy: 0.8415\n","Epoch 15/100\n","160/160 [==============================] - 1s 5ms/step - loss: 32.1189 - accuracy: 0.8458 - val_loss: 20.4592 - val_accuracy: 0.9102\n","Epoch 16/100\n","160/160 [==============================] - 1s 5ms/step - loss: 31.2081 - accuracy: 0.8470 - val_loss: 56.4858 - val_accuracy: 0.8099\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 44.8418 - accuracy: 0.8300 - val_loss: 25.9272 - val_accuracy: 0.8592\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 19.8691 - accuracy: 0.8679 - val_loss: 16.2361 - val_accuracy: 0.9208\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 27.7907 - accuracy: 0.8597 - val_loss: 41.1560 - val_accuracy: 0.8222\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 60.5272 - accuracy: 0.8204 - val_loss: 27.0227 - val_accuracy: 0.8768\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 38.8826 - accuracy: 0.8372 - val_loss: 115.9446 - val_accuracy: 0.7746\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 42.0383 - accuracy: 0.8306 - val_loss: 15.8759 - val_accuracy: 0.9014\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 33.5297 - accuracy: 0.8396 - val_loss: 16.5236 - val_accuracy: 0.9014\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 33.4831 - accuracy: 0.8433 - val_loss: 62.7640 - val_accuracy: 0.8151\n","Epoch 25/100\n","160/160 [==============================] - 1s 4ms/step - loss: 32.6539 - accuracy: 0.8333 - val_loss: 9.6603 - val_accuracy: 0.8926\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 36.5074 - accuracy: 0.8360 - val_loss: 21.0124 - val_accuracy: 0.8732\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 23.7367 - accuracy: 0.8499 - val_loss: 19.8603 - val_accuracy: 0.8856\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 23.6105 - accuracy: 0.8599 - val_loss: 14.7216 - val_accuracy: 0.8715\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 14.6221 - accuracy: 0.8765 - val_loss: 13.7260 - val_accuracy: 0.8961\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 37.6043 - accuracy: 0.8482 - val_loss: 8.3636 - val_accuracy: 0.9120\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 60.1134 - accuracy: 0.8280 - val_loss: 118.0109 - val_accuracy: 0.7923\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 33.6252 - accuracy: 0.8540 - val_loss: 16.6600 - val_accuracy: 0.8556\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 12.7579 - accuracy: 0.8839 - val_loss: 9.0948 - val_accuracy: 0.9137\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 31.3843 - accuracy: 0.8493 - val_loss: 28.2190 - val_accuracy: 0.8451\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 19.8119 - accuracy: 0.8657 - val_loss: 31.6086 - val_accuracy: 0.7412\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 26.0570 - accuracy: 0.8562 - val_loss: 144.3108 - val_accuracy: 0.6461\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 59.4889 - accuracy: 0.8208 - val_loss: 26.6434 - val_accuracy: 0.8451\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 38.6809 - accuracy: 0.8573 - val_loss: 7.9046 - val_accuracy: 0.9173\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 52.3292 - accuracy: 0.8405 - val_loss: 8.9712 - val_accuracy: 0.9173\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 23.6307 - accuracy: 0.8712 - val_loss: 14.6352 - val_accuracy: 0.8873\n","Epoch 41/100\n","160/160 [==============================] - 1s 3ms/step - loss: 47.4079 - accuracy: 0.8587 - val_loss: 9.2782 - val_accuracy: 0.9137\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 31.8814 - accuracy: 0.8765 - val_loss: 8.0165 - val_accuracy: 0.9085\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 25.5255 - accuracy: 0.8747 - val_loss: 130.5665 - val_accuracy: 0.6585\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 20.9056 - accuracy: 0.8837 - val_loss: 15.3075 - val_accuracy: 0.8838\n","Epoch 45/100\n","160/160 [==============================] - 1s 3ms/step - loss: 29.9347 - accuracy: 0.8679 - val_loss: 9.8966 - val_accuracy: 0.9190\n","Epoch 46/100\n","160/160 [==============================] - 1s 3ms/step - loss: 39.7892 - accuracy: 0.8562 - val_loss: 36.9084 - val_accuracy: 0.8363\n","Epoch 47/100\n","160/160 [==============================] - 1s 3ms/step - loss: 15.8478 - accuracy: 0.8890 - val_loss: 11.7329 - val_accuracy: 0.8996\n","Epoch 48/100\n","160/160 [==============================] - 1s 3ms/step - loss: 25.5218 - accuracy: 0.8820 - val_loss: 8.1609 - val_accuracy: 0.9173\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.98      0.93       321\n","           1       0.97      0.84      0.90       247\n","\n","    accuracy                           0.92       568\n","   macro avg       0.93      0.91      0.91       568\n","weighted avg       0.92      0.92      0.92       568\n","\n","Accuracy: 0.9172535211267606\n","[[314   7]\n"," [ 40 207]]\n","Precision: 0.9673\n","Recall: 0.8381\n","F1 Score: 0.8980\n","INFO:tensorflow:Assets written to: ram://ac0dd8d8-a3ad-47d8-9dac-9a95ca698ed7/assets\n","model 9 saved\n","Average Validation Accuracy: 0.8710633307755142\n"]}]},{"cell_type":"code","source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed URL-HTML/NN/model_9.h5'\n","\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","def predict_prob(number):\n","  return [number[0],1-number[0]]\n","\n","y_prob = np.array(list(map(predict_prob, loaded_model.predict(x_test))))\n","y_prob \n","\n","# y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['nn_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['nn_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545},"id":"dolEygpVsl_4","executionInfo":{"status":"ok","timestamp":1656476421772,"user_tz":-330,"elapsed":7565,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"f4ec34ac-9ba7-424d-aa52-e220f3e99bde"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[9.99989064e-01 1.09358504e-05]\n"," [1.00000000e+00 5.71218323e-20]\n"," [1.00000000e+00 1.80439015e-83]\n"," ...\n"," [9.99999999e-01 1.36435856e-09]\n"," [1.00000000e+00 1.35258179e-12]\n"," [1.00000000e+00 7.21198602e-13]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  nn_prediction_non  \\\n","0          0            0.999989          1.093585e-05           0.999989   \n","1          0            1.000000          5.712183e-20           1.000000   \n","2          0            1.000000          1.804390e-83           1.000000   \n","3          0            0.991853          8.147189e-03           0.991853   \n","4          0            0.998126          1.874161e-03           0.998126   \n","...      ...                 ...                   ...                ...   \n","4647       1            0.010479          9.895206e-01           0.010479   \n","4648       0            0.999998          1.553756e-06           0.999998   \n","4649       0            1.000000          1.364359e-09           1.000000   \n","4650       0            1.000000          1.352582e-12           1.000000   \n","4651       0            1.000000          7.211986e-13           1.000000   \n","\n","      nn_prediction_phish  \n","0            1.093585e-05  \n","1            5.712183e-20  \n","2            1.804390e-83  \n","3            8.147189e-03  \n","4            1.874161e-03  \n","...                   ...  \n","4647         9.895206e-01  \n","4648         1.553756e-06  \n","4649         1.364359e-09  \n","4650         1.352582e-12  \n","4651         7.211986e-13  \n","\n","[4652 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-8a8f3484-b3a2-48b6-838b-246d3ecb4521\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.999989</td>\n","      <td>1.093585e-05</td>\n","      <td>0.999989</td>\n","      <td>1.093585e-05</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>5.712183e-20</td>\n","      <td>1.000000</td>\n","      <td>5.712183e-20</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>1.804390e-83</td>\n","      <td>1.000000</td>\n","      <td>1.804390e-83</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.991853</td>\n","      <td>8.147189e-03</td>\n","      <td>0.991853</td>\n","      <td>8.147189e-03</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0.998126</td>\n","      <td>1.874161e-03</td>\n","      <td>0.998126</td>\n","      <td>1.874161e-03</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4647</th>\n","      <td>1</td>\n","      <td>0.010479</td>\n","      <td>9.895206e-01</td>\n","      <td>0.010479</td>\n","      <td>9.895206e-01</td>\n","    </tr>\n","    <tr>\n","      <th>4648</th>\n","      <td>0</td>\n","      <td>0.999998</td>\n","      <td>1.553756e-06</td>\n","      <td>0.999998</td>\n","      <td>1.553756e-06</td>\n","    </tr>\n","    <tr>\n","      <th>4649</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>1.364359e-09</td>\n","      <td>1.000000</td>\n","      <td>1.364359e-09</td>\n","    </tr>\n","    <tr>\n","      <th>4650</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>1.352582e-12</td>\n","      <td>1.000000</td>\n","      <td>1.352582e-12</td>\n","    </tr>\n","    <tr>\n","      <th>4651</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>7.211986e-13</td>\n","      <td>1.000000</td>\n","      <td>7.211986e-13</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4652 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a8f3484-b3a2-48b6-838b-246d3ecb4521')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8a8f3484-b3a2-48b6-838b-246d3ecb4521 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8a8f3484-b3a2-48b6-838b-246d3ecb4521');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":[""],"metadata":{"id":"d6frnOv-L24r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Neural Network 2**"],"metadata":{"id":"fMdqVtYLwwy4"}},{"cell_type":"code","source":["\n","import keras\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","def model_a(x_train, x_val, y_train, y_val, opt, n, early_stopping_monitor):\n","\n","  n_cols = x_train.shape[1]\n","\n","  #create model\n","  model_2 = Sequential()\n","  model_2.add(Dense(30, activation='sigmoid', input_shape=(n_cols,)))\n","  model_2.add(Dense(25, activation='sigmoid'))\n","  model_2.add(Dense(20, activation='sigmoid'))\n","  model_2.add(Dense(15, activation='sigmoid'))\n","  model_2.add(Dense(10, activation='sigmoid'))\n","  model_2.add(Dense(1, activation = 'sigmoid'))\n","\n","  #compile model using mse as a measure of model performance\n","  model_2.compile(optimizer='adam', loss='mean_squared_error')\n","\n","\n","\n","  history = model_2.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping_monitor])\n","\n","\n","  # plt.plot(history.history['loss'])\n","  # plt.plot(history.history['val_loss'])\n","  # plt.title('model loss')\n","  # plt.ylabel('Loss')\n","  # plt.xlabel('Epoch')\n","  # plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n","  # plt.show()\n","\n","\n","  print('Validation Accuracy: ')\n","  # Predicting the Test set results\n","  y_pred = model_2.predict(x_val)\n","  y_pred = (y_pred > 0.5)\n","\n","\n","  print(classification_report(y_val, y_pred))\n","\n","  # Model Accuracy, how often is the classifier correct?\n","  print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","\n","  # Creating the Confusion Matrix\n","  cm = confusion_matrix(y_val, y_pred)\n","  print(cm)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred))\n","\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed URL-HTML/NN_2/model_'+str(n)+'.h5'\n","  pickle.dump(model_2, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","\n","  return metrics.accuracy_score(y_val, y_pred)\n","\n"],"metadata":{"id":"L8ZhB8W9tVQS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_a(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n, early_stopping_monitor)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osCV0Uo5wqac","executionInfo":{"status":"ok","timestamp":1656476911978,"user_tz":-330,"elapsed":270349,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"01be2af8-5c99-4076-9e1a-2ac1f68d88fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","160/160 [==============================] - 2s 6ms/step - loss: 0.2466 - val_loss: 0.2479\n","Epoch 2/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2463 - val_loss: 0.2469\n","Epoch 3/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2421 - val_loss: 0.2347\n","Epoch 4/100\n","160/160 [==============================] - 1s 5ms/step - loss: 0.2065 - val_loss: 0.1862\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1825 - val_loss: 0.1769\n","Epoch 6/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1800 - val_loss: 0.1823\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1851 - val_loss: 0.1795\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1793 - val_loss: 0.1730\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1781 - val_loss: 0.1691\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1668 - val_loss: 0.1672\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1680 - val_loss: 0.1686\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1723 - val_loss: 0.1781\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1739 - val_loss: 0.1752\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1693 - val_loss: 0.1694\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1654 - val_loss: 0.1657\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1636 - val_loss: 0.1655\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1617 - val_loss: 0.1614\n","Epoch 18/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1570 - val_loss: 0.1564\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1578 - val_loss: 0.1706\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1560 - val_loss: 0.1579\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1541 - val_loss: 0.1560\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1536 - val_loss: 0.1479\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1474 - val_loss: 0.1438\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1474 - val_loss: 0.1557\n","Epoch 25/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1604 - val_loss: 0.1458\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1502 - val_loss: 0.1502\n","Epoch 27/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1503 - val_loss: 0.1444\n","Epoch 28/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1508 - val_loss: 0.1517\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1546 - val_loss: 0.1486\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1469 - val_loss: 0.1386\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1507 - val_loss: 0.1475\n","Epoch 32/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1463 - val_loss: 0.1503\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1560 - val_loss: 0.1444\n","Epoch 34/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1494 - val_loss: 0.1484\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1499 - val_loss: 0.1434\n","Epoch 36/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1462 - val_loss: 0.1401\n","Epoch 37/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1431 - val_loss: 0.1397\n","Epoch 38/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1424 - val_loss: 0.1478\n","Epoch 39/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1508 - val_loss: 0.1455\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1492 - val_loss: 0.1527\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.95      0.81       310\n","           1       0.91      0.52      0.66       259\n","\n","    accuracy                           0.76       569\n","   macro avg       0.80      0.74      0.73       569\n","weighted avg       0.80      0.76      0.74       569\n","\n","Accuracy: 0.7557117750439367\n","[[296  14]\n"," [125 134]]\n","Precision: 0.9054\n","Recall: 0.5174\n","F1 Score: 0.6585\n","INFO:tensorflow:Assets written to: ram://0185979e-aba5-491d-ba30-fbeb4e5bd302/assets\n","model 0 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2471 - val_loss: 0.2430\n","Epoch 2/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.2355 - val_loss: 0.2101\n","Epoch 3/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1950 - val_loss: 0.1728\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1793 - val_loss: 0.1666\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1764 - val_loss: 0.1646\n","Epoch 6/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1737 - val_loss: 0.1630\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1705 - val_loss: 0.1629\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1702 - val_loss: 0.1628\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1721 - val_loss: 0.1603\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1712 - val_loss: 0.1600\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1709 - val_loss: 0.1671\n","Epoch 12/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1728 - val_loss: 0.1635\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1685 - val_loss: 0.1621\n","Epoch 14/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1658 - val_loss: 0.1586\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1617 - val_loss: 0.1594\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1545 - val_loss: 0.1575\n","Epoch 17/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1725 - val_loss: 0.1549\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1670 - val_loss: 0.1632\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1741 - val_loss: 0.1730\n","Epoch 20/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1775 - val_loss: 0.1633\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1645 - val_loss: 0.1583\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1558 - val_loss: 0.1509\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1610 - val_loss: 0.1571\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1538 - val_loss: 0.1478\n","Epoch 25/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1486 - val_loss: 0.1442\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1478 - val_loss: 0.1582\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1647 - val_loss: 0.1566\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1683 - val_loss: 0.1640\n","Epoch 29/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1620 - val_loss: 0.1601\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1636 - val_loss: 0.1672\n","Epoch 31/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1630 - val_loss: 0.1598\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1607 - val_loss: 0.1573\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1573 - val_loss: 0.1595\n","Epoch 34/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1671 - val_loss: 0.1620\n","Epoch 35/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1658 - val_loss: 0.1587\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.98      0.83       330\n","           1       0.96      0.48      0.64       239\n","\n","    accuracy                           0.77       569\n","   macro avg       0.84      0.73      0.74       569\n","weighted avg       0.82      0.77      0.75       569\n","\n","Accuracy: 0.773286467486819\n","[[325   5]\n"," [124 115]]\n","Precision: 0.9583\n","Recall: 0.4812\n","F1 Score: 0.6407\n","INFO:tensorflow:Assets written to: ram://3a75e148-c5cb-479f-8692-e94a109a4fb6/assets\n","model 1 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2500 - val_loss: 0.2462\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2435 - val_loss: 0.2370\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2183 - val_loss: 0.2014\n","Epoch 4/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1932 - val_loss: 0.1937\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1865 - val_loss: 0.1925\n","Epoch 6/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1833 - val_loss: 0.1842\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1748 - val_loss: 0.1763\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1730 - val_loss: 0.1780\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1774 - val_loss: 0.1881\n","Epoch 10/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1807 - val_loss: 0.1895\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1776 - val_loss: 0.1868\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1748 - val_loss: 0.1756\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1706 - val_loss: 0.1754\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1670 - val_loss: 0.1751\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1652 - val_loss: 0.1709\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1669 - val_loss: 0.1660\n","Epoch 17/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1655 - val_loss: 0.1658\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1555 - val_loss: 0.1559\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1558 - val_loss: 0.1666\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1579 - val_loss: 0.1722\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1648 - val_loss: 0.1670\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1594 - val_loss: 0.1618\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1586 - val_loss: 0.1692\n","Epoch 24/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1578 - val_loss: 0.1628\n","Epoch 25/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1575 - val_loss: 0.1566\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1527 - val_loss: 0.1589\n","Epoch 27/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1468 - val_loss: 0.1516\n","Epoch 28/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1487 - val_loss: 0.1592\n","Epoch 29/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1600\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1601 - val_loss: 0.1708\n","Epoch 31/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1593 - val_loss: 0.1601\n","Epoch 32/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1508\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1485 - val_loss: 0.1595\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1542 - val_loss: 0.1615\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1543 - val_loss: 0.1587\n","Epoch 36/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1550 - val_loss: 0.1656\n","Epoch 37/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1626 - val_loss: 0.1602\n","Epoch 38/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1565 - val_loss: 0.1712\n","Epoch 39/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1563 - val_loss: 0.1611\n","Epoch 40/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1623 - val_loss: 0.1659\n","Epoch 41/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1624 - val_loss: 0.1536\n","Epoch 42/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1559 - val_loss: 0.1609\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.89      0.81       316\n","           1       0.82      0.62      0.71       253\n","\n","    accuracy                           0.77       569\n","   macro avg       0.78      0.75      0.76       569\n","weighted avg       0.78      0.77      0.76       569\n","\n","Accuracy: 0.7697715289982425\n","[[281  35]\n"," [ 96 157]]\n","Precision: 0.8177\n","Recall: 0.6206\n","F1 Score: 0.7056\n","INFO:tensorflow:Assets written to: ram://5d35daab-6b8b-4830-a8d2-02995e406614/assets\n","model 2 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2469 - val_loss: 0.2507\n","Epoch 2/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.2376 - val_loss: 0.2286\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1969 - val_loss: 0.1912\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1783 - val_loss: 0.1930\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1776 - val_loss: 0.1852\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1684 - val_loss: 0.1795\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1633 - val_loss: 0.1569\n","Epoch 8/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1616 - val_loss: 0.1825\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1703 - val_loss: 0.1806\n","Epoch 10/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1738 - val_loss: 0.1731\n","Epoch 11/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1665 - val_loss: 0.1628\n","Epoch 12/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1690 - val_loss: 0.1751\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1729 - val_loss: 0.1761\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1612 - val_loss: 0.1705\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1610 - val_loss: 0.1718\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1563 - val_loss: 0.1782\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1699 - val_loss: 0.1762\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.69      0.92      0.79       295\n","           1       0.86      0.56      0.68       274\n","\n","    accuracy                           0.75       569\n","   macro avg       0.78      0.74      0.73       569\n","weighted avg       0.77      0.75      0.74       569\n","\n","Accuracy: 0.7451669595782073\n","[[270  25]\n"," [120 154]]\n","Precision: 0.8603\n","Recall: 0.5620\n","F1 Score: 0.6799\n","INFO:tensorflow:Assets written to: ram://000aecb6-b108-4ad1-b517-5e9759daaf3c/assets\n","model 3 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2467 - val_loss: 0.2458\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2448 - val_loss: 0.2427\n","Epoch 3/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.2270 - val_loss: 0.2067\n","Epoch 4/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1927 - val_loss: 0.1835\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1857 - val_loss: 0.1763\n","Epoch 6/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1761 - val_loss: 0.1718\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1676 - val_loss: 0.1503\n","Epoch 8/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1589 - val_loss: 0.1594\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1637 - val_loss: 0.1554\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1566 - val_loss: 0.1556\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1554 - val_loss: 0.1494\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1488 - val_loss: 0.1398\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1494\n","Epoch 14/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1459 - val_loss: 0.1383\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1581 - val_loss: 0.1648\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1577 - val_loss: 0.1553\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1517 - val_loss: 0.1494\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1506 - val_loss: 0.1569\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1543 - val_loss: 0.1582\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1515 - val_loss: 0.1521\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1639 - val_loss: 0.1666\n","Epoch 22/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1600 - val_loss: 0.1618\n","Epoch 23/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1494 - val_loss: 0.1463\n","Epoch 24/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1454 - val_loss: 0.1367\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1449 - val_loss: 0.1611\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1472 - val_loss: 0.1474\n","Epoch 27/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1420 - val_loss: 0.1424\n","Epoch 28/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1354 - val_loss: 0.1457\n","Epoch 29/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1350 - val_loss: 0.1446\n","Epoch 30/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1466 - val_loss: 0.1571\n","Epoch 31/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1525 - val_loss: 0.1342\n","Epoch 32/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1298 - val_loss: 0.1367\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1391 - val_loss: 0.1259\n","Epoch 34/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1332 - val_loss: 0.1402\n","Epoch 35/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1386 - val_loss: 0.1447\n","Epoch 36/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1561 - val_loss: 0.1552\n","Epoch 37/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1528 - val_loss: 0.1496\n","Epoch 38/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.1499\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1463 - val_loss: 0.1453\n","Epoch 40/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1427 - val_loss: 0.1384\n","Epoch 41/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1434 - val_loss: 0.1384\n","Epoch 42/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1406 - val_loss: 0.1357\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1403 - val_loss: 0.1321\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.97      0.85       319\n","           1       0.93      0.60      0.73       250\n","\n","    accuracy                           0.81       569\n","   macro avg       0.84      0.78      0.79       569\n","weighted avg       0.83      0.81      0.80       569\n","\n","Accuracy: 0.8066783831282952\n","[[308  11]\n"," [ 99 151]]\n","Precision: 0.9321\n","Recall: 0.6040\n","F1 Score: 0.7330\n","INFO:tensorflow:Assets written to: ram://8165a503-05ec-4faf-adb3-dfeaf64f6750/assets\n","model 4 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2469 - val_loss: 0.2453\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2443 - val_loss: 0.2390\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2204 - val_loss: 0.1988\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1888 - val_loss: 0.1831\n","Epoch 5/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1795 - val_loss: 0.1772\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1766 - val_loss: 0.1693\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1690 - val_loss: 0.1773\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1701 - val_loss: 0.1770\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1664 - val_loss: 0.1733\n","Epoch 10/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1612 - val_loss: 0.1659\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1629 - val_loss: 0.1732\n","Epoch 12/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1550 - val_loss: 0.1504\n","Epoch 13/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1570 - val_loss: 0.1602\n","Epoch 14/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1629 - val_loss: 0.1626\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1582 - val_loss: 0.1540\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1601 - val_loss: 0.1684\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1597 - val_loss: 0.1771\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1511 - val_loss: 0.1559\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1531 - val_loss: 0.1811\n","Epoch 20/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1579 - val_loss: 0.1590\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1499 - val_loss: 0.1861\n","Epoch 22/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1631 - val_loss: 0.1614\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.90      0.80       321\n","           1       0.81      0.55      0.66       247\n","\n","    accuracy                           0.75       568\n","   macro avg       0.77      0.73      0.73       568\n","weighted avg       0.76      0.75      0.74       568\n","\n","Accuracy: 0.75\n","[[289  32]\n"," [110 137]]\n","Precision: 0.8107\n","Recall: 0.5547\n","F1 Score: 0.6587\n","INFO:tensorflow:Assets written to: ram://96f840b8-75cc-4fc1-8c30-ad895ccc98f9/assets\n","model 5 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2455 - val_loss: 0.2424\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2354 - val_loss: 0.2195\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1994 - val_loss: 0.1820\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1823 - val_loss: 0.1736\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1780 - val_loss: 0.1780\n","Epoch 6/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1662 - val_loss: 0.1552\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1615 - val_loss: 0.1557\n","Epoch 8/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1577 - val_loss: 0.1525\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1504 - val_loss: 0.1696\n","Epoch 10/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1500 - val_loss: 0.1403\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1431 - val_loss: 0.1510\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1495 - val_loss: 0.1511\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1479 - val_loss: 0.1534\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1482 - val_loss: 0.1478\n","Epoch 15/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1421 - val_loss: 0.1559\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1445 - val_loss: 0.1612\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1509 - val_loss: 0.1586\n","Epoch 18/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1560 - val_loss: 0.1518\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1484 - val_loss: 0.1663\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1559 - val_loss: 0.1498\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.91      0.84       322\n","           1       0.85      0.64      0.73       246\n","\n","    accuracy                           0.80       568\n","   macro avg       0.81      0.78      0.78       568\n","weighted avg       0.80      0.80      0.79       568\n","\n","Accuracy: 0.795774647887324\n","[[294  28]\n"," [ 88 158]]\n","Precision: 0.8495\n","Recall: 0.6423\n","F1 Score: 0.7315\n","INFO:tensorflow:Assets written to: ram://98fd52ee-b024-4b2e-9e84-10e853adbc49/assets\n","model 6 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2468 - val_loss: 0.2475\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2425 - val_loss: 0.2377\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2197 - val_loss: 0.2042\n","Epoch 4/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1950 - val_loss: 0.1926\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1848 - val_loss: 0.1870\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1809 - val_loss: 0.1791\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1691 - val_loss: 0.1784\n","Epoch 8/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1598 - val_loss: 0.1730\n","Epoch 9/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1567 - val_loss: 0.1688\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1653 - val_loss: 0.1717\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1575 - val_loss: 0.1601\n","Epoch 12/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1520 - val_loss: 0.1614\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1509 - val_loss: 0.1621\n","Epoch 14/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1524 - val_loss: 0.1688\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1569 - val_loss: 0.1695\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1475 - val_loss: 0.1572\n","Epoch 17/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1523 - val_loss: 0.1688\n","Epoch 18/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1818 - val_loss: 0.1796\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1613 - val_loss: 0.1599\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1469 - val_loss: 0.1494\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1423 - val_loss: 0.1452\n","Epoch 22/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1401 - val_loss: 0.1586\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1470 - val_loss: 0.1496\n","Epoch 24/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1457 - val_loss: 0.1520\n","Epoch 25/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1421 - val_loss: 0.1504\n","Epoch 26/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1460 - val_loss: 0.1515\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1418 - val_loss: 0.1471\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1432 - val_loss: 0.1483\n","Epoch 29/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1413 - val_loss: 0.1428\n","Epoch 30/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1473 - val_loss: 0.1521\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1415 - val_loss: 0.1416\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1389 - val_loss: 0.1464\n","Epoch 33/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1402 - val_loss: 0.1390\n","Epoch 34/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1365 - val_loss: 0.1430\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1387 - val_loss: 0.1431\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1410 - val_loss: 0.1390\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1351 - val_loss: 0.1395\n","Epoch 38/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1354 - val_loss: 0.1527\n","Epoch 39/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1439 - val_loss: 0.1493\n","Epoch 40/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1462 - val_loss: 0.1553\n","Epoch 41/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1522 - val_loss: 0.1607\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1474 - val_loss: 0.1409\n","Epoch 43/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1352 - val_loss: 0.1473\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1409 - val_loss: 0.1514\n","Epoch 45/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1453 - val_loss: 0.1533\n","Epoch 46/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1505 - val_loss: 0.1498\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.86      0.80       305\n","           1       0.81      0.68      0.74       263\n","\n","    accuracy                           0.78       568\n","   macro avg       0.78      0.77      0.77       568\n","weighted avg       0.78      0.78      0.77       568\n","\n","Accuracy: 0.7764084507042254\n","[[262  43]\n"," [ 84 179]]\n","Precision: 0.8063\n","Recall: 0.6806\n","F1 Score: 0.7381\n","INFO:tensorflow:Assets written to: ram://a18cf457-09b5-46b6-936e-8d961808531b/assets\n","model 7 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2477 - val_loss: 0.2403\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2390 - val_loss: 0.2223\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2000 - val_loss: 0.1888\n","Epoch 4/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1824 - val_loss: 0.1687\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1738 - val_loss: 0.1662\n","Epoch 6/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1766 - val_loss: 0.1657\n","Epoch 7/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1695 - val_loss: 0.1649\n","Epoch 8/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1662 - val_loss: 0.1658\n","Epoch 9/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1615 - val_loss: 0.1553\n","Epoch 10/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1647 - val_loss: 0.1574\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1652 - val_loss: 0.1747\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1698 - val_loss: 0.1618\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1549 - val_loss: 0.1532\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1582 - val_loss: 0.1467\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1456 - val_loss: 0.1364\n","Epoch 16/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1452 - val_loss: 0.1375\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1438 - val_loss: 0.1447\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1587 - val_loss: 0.1518\n","Epoch 19/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1531 - val_loss: 0.1509\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1528 - val_loss: 0.1467\n","Epoch 21/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1482 - val_loss: 0.1486\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1505 - val_loss: 0.1441\n","Epoch 23/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1465 - val_loss: 0.1400\n","Epoch 24/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1429 - val_loss: 0.1313\n","Epoch 25/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1407 - val_loss: 0.1342\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1501 - val_loss: 0.1503\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1522 - val_loss: 0.1495\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1576 - val_loss: 0.1504\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1528 - val_loss: 0.1481\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1455 - val_loss: 0.1435\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1430 - val_loss: 0.1444\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1456 - val_loss: 0.1444\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1413 - val_loss: 0.1494\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1476 - val_loss: 0.1363\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.91      0.84       337\n","           1       0.82      0.63      0.71       231\n","\n","    accuracy                           0.79       568\n","   macro avg       0.80      0.77      0.77       568\n","weighted avg       0.80      0.79      0.79       568\n","\n","Accuracy: 0.7922535211267606\n","[[305  32]\n"," [ 86 145]]\n","Precision: 0.8192\n","Recall: 0.6277\n","F1 Score: 0.7108\n","INFO:tensorflow:Assets written to: ram://14380bbe-7bae-44c1-8880-42b0149557b4/assets\n","model 8 saved\n","Epoch 1/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.2469 - val_loss: 0.2447\n","Epoch 2/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.2369 - val_loss: 0.2191\n","Epoch 3/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1994 - val_loss: 0.1855\n","Epoch 4/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1831 - val_loss: 0.1779\n","Epoch 5/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1800 - val_loss: 0.1741\n","Epoch 6/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1809 - val_loss: 0.1737\n","Epoch 7/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1747 - val_loss: 0.1722\n","Epoch 8/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1735 - val_loss: 0.1648\n","Epoch 9/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1643 - val_loss: 0.1559\n","Epoch 10/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1645 - val_loss: 0.1748\n","Epoch 11/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1653 - val_loss: 0.1619\n","Epoch 12/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1587 - val_loss: 0.1522\n","Epoch 13/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1572 - val_loss: 0.1575\n","Epoch 14/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1535 - val_loss: 0.1534\n","Epoch 15/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1512 - val_loss: 0.1452\n","Epoch 16/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1470\n","Epoch 17/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1661 - val_loss: 0.1684\n","Epoch 18/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1676 - val_loss: 0.1524\n","Epoch 19/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1626 - val_loss: 0.1540\n","Epoch 20/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1538 - val_loss: 0.1507\n","Epoch 21/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1555 - val_loss: 0.1461\n","Epoch 22/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1540 - val_loss: 0.1500\n","Epoch 23/100\n","160/160 [==============================] - 0s 3ms/step - loss: 0.1496 - val_loss: 0.1468\n","Epoch 24/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1478 - val_loss: 0.1411\n","Epoch 25/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1455 - val_loss: 0.1415\n","Epoch 26/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1518 - val_loss: 0.1587\n","Epoch 27/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1626 - val_loss: 0.1651\n","Epoch 28/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1613 - val_loss: 0.1534\n","Epoch 29/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1483 - val_loss: 0.1548\n","Epoch 30/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1462 - val_loss: 0.1412\n","Epoch 31/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1423 - val_loss: 0.1486\n","Epoch 32/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1621 - val_loss: 0.1584\n","Epoch 33/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1549 - val_loss: 0.1355\n","Epoch 34/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1499 - val_loss: 0.1500\n","Epoch 35/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1547 - val_loss: 0.1432\n","Epoch 36/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1598 - val_loss: 0.1550\n","Epoch 37/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1579 - val_loss: 0.1466\n","Epoch 38/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1553 - val_loss: 0.1464\n","Epoch 39/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1491 - val_loss: 0.1467\n","Epoch 40/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1454 - val_loss: 0.1408\n","Epoch 41/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1563 - val_loss: 0.1516\n","Epoch 42/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1478 - val_loss: 0.1407\n","Epoch 43/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1413 - val_loss: 0.1329\n","Epoch 44/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1381 - val_loss: 0.1402\n","Epoch 45/100\n","160/160 [==============================] - 1s 4ms/step - loss: 0.1453 - val_loss: 0.1348\n","Epoch 46/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1337 - val_loss: 0.1371\n","Epoch 47/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1414 - val_loss: 0.1413\n","Epoch 48/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1557 - val_loss: 0.1469\n","Epoch 49/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1448 - val_loss: 0.1257\n","Epoch 50/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1418 - val_loss: 0.1411\n","Epoch 51/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1420 - val_loss: 0.1414\n","Epoch 52/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1519 - val_loss: 0.1503\n","Epoch 53/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1458 - val_loss: 0.1306\n","Epoch 54/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1413 - val_loss: 0.1298\n","Epoch 55/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1374 - val_loss: 0.1259\n","Epoch 56/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1351 - val_loss: 0.1366\n","Epoch 57/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1471 - val_loss: 0.1657\n","Epoch 58/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1529 - val_loss: 0.1397\n","Epoch 59/100\n","160/160 [==============================] - 1s 3ms/step - loss: 0.1421 - val_loss: 0.1322\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.97      0.85       318\n","           1       0.93      0.60      0.73       250\n","\n","    accuracy                           0.80       568\n","   macro avg       0.84      0.78      0.79       568\n","weighted avg       0.83      0.80      0.79       568\n","\n","Accuracy: 0.8028169014084507\n","[[307  11]\n"," [101 149]]\n","Precision: 0.9313\n","Recall: 0.5960\n","F1 Score: 0.7268\n","INFO:tensorflow:Assets written to: ram://2adbcf60-bb06-469f-851e-03a8d0fa0b36/assets\n","model 9 saved\n","Average Validation Accuracy: 0.7767868635362262\n"]}]},{"cell_type":"code","source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/PhishTank/Models/preprocessed URL-HTML/NN_2/model_4.h5'\n","\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","def predict_prob(number):\n","  return [number[0],1-number[0]]\n","\n","y_prob = np.array(list(map(predict_prob, loaded_model.predict(x_test))))\n","y_prob \n","\n","# y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['nn2_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['nn2_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545},"id":"JPT9oIQ0wuZf","executionInfo":{"status":"ok","timestamp":1656477458378,"user_tz":-330,"elapsed":1540,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"ddc9efff-9279-4c4a-9f6a-19680f0e867e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[9.99989064e-01 1.09358504e-05]\n"," [1.00000000e+00 5.71218323e-20]\n"," [1.00000000e+00 1.80439015e-83]\n"," ...\n"," [9.99999999e-01 1.36435856e-09]\n"," [1.00000000e+00 1.35258179e-12]\n"," [1.00000000e+00 7.21198602e-13]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  nn_prediction_non  \\\n","0          0            0.999989          1.093585e-05           0.999989   \n","1          0            1.000000          5.712183e-20           1.000000   \n","2          0            1.000000          1.804390e-83           1.000000   \n","3          0            0.991853          8.147189e-03           0.991853   \n","4          0            0.998126          1.874161e-03           0.998126   \n","...      ...                 ...                   ...                ...   \n","4647       1            0.010479          9.895206e-01           0.010479   \n","4648       0            0.999998          1.553756e-06           0.999998   \n","4649       0            1.000000          1.364359e-09           1.000000   \n","4650       0            1.000000          1.352582e-12           1.000000   \n","4651       0            1.000000          7.211986e-13           1.000000   \n","\n","      nn_prediction_phish  nn2_prediction_non  nn2_prediction_phish  \n","0            1.093585e-05            0.999989          1.093585e-05  \n","1            5.712183e-20            1.000000          5.712183e-20  \n","2            1.804390e-83            1.000000          1.804390e-83  \n","3            8.147189e-03            0.991853          8.147189e-03  \n","4            1.874161e-03            0.998126          1.874161e-03  \n","...                   ...                 ...                   ...  \n","4647         9.895206e-01            0.010479          9.895206e-01  \n","4648         1.553756e-06            0.999998          1.553756e-06  \n","4649         1.364359e-09            1.000000          1.364359e-09  \n","4650         1.352582e-12            1.000000          1.352582e-12  \n","4651         7.211986e-13            1.000000          7.211986e-13  \n","\n","[4652 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-6df4045f-3524-452d-b2bf-6af8efc2684b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","      <th>nn2_prediction_non</th>\n","      <th>nn2_prediction_phish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.999989</td>\n","      <td>1.093585e-05</td>\n","      <td>0.999989</td>\n","      <td>1.093585e-05</td>\n","      <td>0.999989</td>\n","      <td>1.093585e-05</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>5.712183e-20</td>\n","      <td>1.000000</td>\n","      <td>5.712183e-20</td>\n","      <td>1.000000</td>\n","      <td>5.712183e-20</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>1.804390e-83</td>\n","      <td>1.000000</td>\n","      <td>1.804390e-83</td>\n","      <td>1.000000</td>\n","      <td>1.804390e-83</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.991853</td>\n","      <td>8.147189e-03</td>\n","      <td>0.991853</td>\n","      <td>8.147189e-03</td>\n","      <td>0.991853</td>\n","      <td>8.147189e-03</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0.998126</td>\n","      <td>1.874161e-03</td>\n","      <td>0.998126</td>\n","      <td>1.874161e-03</td>\n","      <td>0.998126</td>\n","      <td>1.874161e-03</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4647</th>\n","      <td>1</td>\n","      <td>0.010479</td>\n","      <td>9.895206e-01</td>\n","      <td>0.010479</td>\n","      <td>9.895206e-01</td>\n","      <td>0.010479</td>\n","      <td>9.895206e-01</td>\n","    </tr>\n","    <tr>\n","      <th>4648</th>\n","      <td>0</td>\n","      <td>0.999998</td>\n","      <td>1.553756e-06</td>\n","      <td>0.999998</td>\n","      <td>1.553756e-06</td>\n","      <td>0.999998</td>\n","      <td>1.553756e-06</td>\n","    </tr>\n","    <tr>\n","      <th>4649</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>1.364359e-09</td>\n","      <td>1.000000</td>\n","      <td>1.364359e-09</td>\n","      <td>1.000000</td>\n","      <td>1.364359e-09</td>\n","    </tr>\n","    <tr>\n","      <th>4650</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>1.352582e-12</td>\n","      <td>1.000000</td>\n","      <td>1.352582e-12</td>\n","      <td>1.000000</td>\n","      <td>1.352582e-12</td>\n","    </tr>\n","    <tr>\n","      <th>4651</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>7.211986e-13</td>\n","      <td>1.000000</td>\n","      <td>7.211986e-13</td>\n","      <td>1.000000</td>\n","      <td>7.211986e-13</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4652 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6df4045f-3524-452d-b2bf-6af8efc2684b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6df4045f-3524-452d-b2bf-6af8efc2684b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6df4045f-3524-452d-b2bf-6af8efc2684b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":[""],"metadata":{"id":"NEihgjKWtVK_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KDYz8o5ytVIu","executionInfo":{"status":"ok","timestamp":1656411483379,"user_tz":-330,"elapsed":550,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"6b0cf392-98bd-4f38-b6be-f3af295c18ec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4652, 7)"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsQkUbz6AiTx"},"outputs":[],"source":["# Storing the data in CSV file\n","output.to_csv('/content/drive/MyDrive/Phishing/PhishTank/Base_classifier_result(pre URL-HTML cross)(3).csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RN_-swX0JdhP"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W9DI0WYaJde9"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49lwyWNz0mSo"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_9Vdw_Wx2NEo"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Base Classifiers(3).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}