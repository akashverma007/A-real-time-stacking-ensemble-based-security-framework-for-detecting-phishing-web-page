{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Base Classifiers(3)(HTML).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"PH13wfswmyDv"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Aiz0olfdKb4b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656570191723,"user_tz":-330,"elapsed":29753,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"54ccc083-25a1-4e95-dfa9-de67e1c75e72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["urldata = pd.read_csv(\"/content/drive/MyDrive/Phishing/UNB/URL-HTML/preprocessed_url_features(multi).csv\")\n","urldata\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":485},"id":"Dw-EEymHAGNs","outputId":"012efbdc-abdb-49f4-b56e-0b1bda6009d7","executionInfo":{"status":"ok","timestamp":1656570192934,"user_tz":-330,"elapsed":1218,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Unnamed: 0  Have IP  Have @  URL Length  URL Depth  Redirection  \\\n","0               0        0       0           1          1            0   \n","1               1        0       0           1          1            1   \n","2               2        0       0           1          1            0   \n","3               3        0       0           1          3            0   \n","4               4        0       0           1          3            0   \n","...           ...      ...     ...         ...        ...          ...   \n","15319       23429        0       0           1          1            0   \n","15320       23430        0       0           1          1            0   \n","15321       23431        0       0           1          1            0   \n","15322       23432        0       0           1          1            0   \n","15323       23433        0       0           1          1            0   \n","\n","       https Domain  TinyURL  Prefix/Suffix  Have client  ...  Num Embeds  \\\n","0                 0        0              0            0  ...           0   \n","1                 0        0              0            0  ...           0   \n","2                 1        0              0            0  ...           0   \n","3                 0        0              0            0  ...           0   \n","4                 0        0              0            0  ...           0   \n","...             ...      ...            ...          ...  ...         ...   \n","15319             0        0              0            0  ...           0   \n","15320             0        0              0            0  ...           0   \n","15321             0        0              0            0  ...           0   \n","15322             0        0              0            0  ...           0   \n","15323             0        0              0            0  ...           0   \n","\n","       Num Images  Num Links  Num Titles  Num Script  Special Characters  \\\n","0              49        691          42       13135                6400   \n","1               4         66           3        2034                 818   \n","2               1        100          27       32987               10451   \n","3               0          0           1           0                  52   \n","4             117        219          23        7944                3468   \n","...           ...        ...         ...         ...                 ...   \n","15319           0          0           1           0                   4   \n","15320           0          0           1           0                   4   \n","15321           0          0           1           0                   4   \n","15322           0          0           1           0                   4   \n","15323           0          0           1           0                   4   \n","\n","       Script To Special Chars Ratio  Script To body Ratio  \\\n","0                           2.052344              0.528869   \n","1                           2.486553              0.676197   \n","2                           3.156349              0.836681   \n","3                           0.000000              0.000000   \n","4                           2.290657              0.524460   \n","...                              ...                   ...   \n","15319                       0.000000              0.000000   \n","15320                       0.000000              0.000000   \n","15321                       0.000000              0.000000   \n","15322                       0.000000              0.000000   \n","15323                       0.000000              0.000000   \n","\n","       Body To Special Char Ratio  Label  \n","0                        0.257690      0  \n","1                        0.271941      0  \n","2                        0.265079      0  \n","3                        0.227074      0  \n","4                        0.228956      0  \n","...                           ...    ...  \n","15319                    0.121212      4  \n","15320                    0.121212      4  \n","15321                    0.121212      4  \n","15322                    0.121212      4  \n","15323                    0.121212      4  \n","\n","[15324 rows x 46 columns]"],"text/html":["\n","  <div id=\"df-d2e8cbd8-2d63-423c-ace2-16a802f7b83d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>691</td>\n","      <td>42</td>\n","      <td>13135</td>\n","      <td>6400</td>\n","      <td>2.052344</td>\n","      <td>0.528869</td>\n","      <td>0.257690</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>66</td>\n","      <td>3</td>\n","      <td>2034</td>\n","      <td>818</td>\n","      <td>2.486553</td>\n","      <td>0.676197</td>\n","      <td>0.271941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>27</td>\n","      <td>32987</td>\n","      <td>10451</td>\n","      <td>3.156349</td>\n","      <td>0.836681</td>\n","      <td>0.265079</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.227074</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>117</td>\n","      <td>219</td>\n","      <td>23</td>\n","      <td>7944</td>\n","      <td>3468</td>\n","      <td>2.290657</td>\n","      <td>0.524460</td>\n","      <td>0.228956</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>15319</th>\n","      <td>23429</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.121212</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>15320</th>\n","      <td>23430</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.121212</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>15321</th>\n","      <td>23431</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.121212</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>15322</th>\n","      <td>23432</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.121212</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>15323</th>\n","      <td>23433</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.121212</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>15324 rows × 46 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2e8cbd8-2d63-423c-ace2-16a802f7b83d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d2e8cbd8-2d63-423c-ace2-16a802f7b83d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d2e8cbd8-2d63-423c-ace2-16a802f7b83d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["urldata.columns"],"metadata":{"id":"JQ4_qEulWybT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c4e1f73e-d6f3-4d27-da03-69f14535d43e","executionInfo":{"status":"ok","timestamp":1656570197560,"user_tz":-330,"elapsed":382,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Unnamed: 0', 'Have IP', 'Have @', 'URL Length', 'URL Depth',\n","       'Redirection', 'https Domain', 'TinyURL', 'Prefix/Suffix',\n","       'Have client', 'Have admin', 'Have login', 'Have server', '.php',\n","       '.html', '.info', '.txt', '.js', '.exe', 'Num of periods', 'Is encoded',\n","       'Num of encoded char', 'Num of parameters', 'Num of digits',\n","       'Num of spec char', 'iFrame', 'Mouse Over', 'Right Click',\n","       'Web Forwards', 'Number of page tokens', 'number of sentences',\n","       'number of html tags', 'number of whitespace', 'url Is Live',\n","       'HTML Length', 'Num Objects', 'Num Embeds', 'Num Images', 'Num Links',\n","       'Num Titles', 'Num Script', 'Special Characters',\n","       'Script To Special Chars Ratio', 'Script To body Ratio',\n","       'Body To Special Char Ratio', 'Label'],\n","      dtype='object')"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["urldata = urldata.drop(['Unnamed: 0', 'Have IP', 'Have @', 'URL Length', 'URL Depth',\n","       'Redirection', 'https Domain', 'TinyURL', 'Prefix/Suffix',\n","       'Have client', 'Have admin', 'Have login', 'Have server', '.php',\n","       '.html', '.info', '.txt', '.js', '.exe', 'Num of periods', 'Is encoded',\n","       'Num of encoded char', 'Num of parameters', 'Num of digits',\n","       'Num of spec char'], axis = 1).copy()\n","# urldata = urldata.drop(['Domain'], axis = 1).copy()\n","urldata.shape\n","urldata.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":314},"id":"qwye89TwRTOH","executionInfo":{"status":"ok","timestamp":1656570198039,"user_tz":-330,"elapsed":16,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"373f6b20-ebd2-43c0-b4eb-8d0b5103e7b2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   iFrame  Mouse Over  Right Click  Web Forwards  Number of page tokens  \\\n","0       1           0            0             1                  21444   \n","1       1           0            0             1                   1075   \n","2       1           0            0             1                   4531   \n","3       1           0            0             1                     32   \n","4       1           0            0             1                   4880   \n","\n","   number of sentences  number of html tags  number of whitespace  \\\n","0                 1853                 3247                     0   \n","1                  136                  236                     0   \n","2                 2634                  486                     0   \n","3                    9                    8                     0   \n","4                  981                 1412                     0   \n","\n","   url Is Live  HTML Length  ...  Num Embeds  Num Images  Num Links  \\\n","0            1        24836  ...           0          49        691   \n","1            1         3008  ...           0           4         66   \n","2            1        39426  ...           0           1        100   \n","3            0          229  ...           0           0          0   \n","4            1        15147  ...           0         117        219   \n","\n","   Num Titles  Num Script  Special Characters  Script To Special Chars Ratio  \\\n","0          42       13135                6400                       2.052344   \n","1           3        2034                 818                       2.486553   \n","2          27       32987               10451                       3.156349   \n","3           1           0                  52                       0.000000   \n","4          23        7944                3468                       2.290657   \n","\n","   Script To body Ratio  Body To Special Char Ratio  Label  \n","0              0.528869                    0.257690      0  \n","1              0.676197                    0.271941      0  \n","2              0.836681                    0.265079      0  \n","3              0.000000                    0.227074      0  \n","4              0.524460                    0.228956      0  \n","\n","[5 rows x 21 columns]"],"text/html":["\n","  <div id=\"df-217f347a-78d3-4ec2-938f-9a88010c9de4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>iFrame</th>\n","      <th>Mouse Over</th>\n","      <th>Right Click</th>\n","      <th>Web Forwards</th>\n","      <th>Number of page tokens</th>\n","      <th>number of sentences</th>\n","      <th>number of html tags</th>\n","      <th>number of whitespace</th>\n","      <th>url Is Live</th>\n","      <th>HTML Length</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>21444</td>\n","      <td>1853</td>\n","      <td>3247</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>24836</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>691</td>\n","      <td>42</td>\n","      <td>13135</td>\n","      <td>6400</td>\n","      <td>2.052344</td>\n","      <td>0.528869</td>\n","      <td>0.257690</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1075</td>\n","      <td>136</td>\n","      <td>236</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3008</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>66</td>\n","      <td>3</td>\n","      <td>2034</td>\n","      <td>818</td>\n","      <td>2.486553</td>\n","      <td>0.676197</td>\n","      <td>0.271941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4531</td>\n","      <td>2634</td>\n","      <td>486</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>39426</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>27</td>\n","      <td>32987</td>\n","      <td>10451</td>\n","      <td>3.156349</td>\n","      <td>0.836681</td>\n","      <td>0.265079</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>32</td>\n","      <td>9</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>229</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.227074</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4880</td>\n","      <td>981</td>\n","      <td>1412</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>15147</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>117</td>\n","      <td>219</td>\n","      <td>23</td>\n","      <td>7944</td>\n","      <td>3468</td>\n","      <td>2.290657</td>\n","      <td>0.524460</td>\n","      <td>0.228956</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-217f347a-78d3-4ec2-938f-9a88010c9de4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-217f347a-78d3-4ec2-938f-9a88010c9de4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-217f347a-78d3-4ec2-938f-9a88010c9de4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["urldata.info()"],"metadata":{"id":"kKvKkmUNP5Cx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a3e9d4c-21b6-4167-d04a-7ef606535add","executionInfo":{"status":"ok","timestamp":1656570199593,"user_tz":-330,"elapsed":23,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 15324 entries, 0 to 15323\n","Data columns (total 21 columns):\n"," #   Column                         Non-Null Count  Dtype  \n","---  ------                         --------------  -----  \n"," 0   iFrame                         15324 non-null  int64  \n"," 1   Mouse Over                     15324 non-null  int64  \n"," 2   Right Click                    15324 non-null  int64  \n"," 3   Web Forwards                   15324 non-null  int64  \n"," 4   Number of page tokens          15324 non-null  int64  \n"," 5   number of sentences            15324 non-null  int64  \n"," 6   number of html tags            15324 non-null  int64  \n"," 7   number of whitespace           15324 non-null  int64  \n"," 8   url Is Live                    15324 non-null  int64  \n"," 9   HTML Length                    15324 non-null  int64  \n"," 10  Num Objects                    15324 non-null  int64  \n"," 11  Num Embeds                     15324 non-null  int64  \n"," 12  Num Images                     15324 non-null  int64  \n"," 13  Num Links                      15324 non-null  int64  \n"," 14  Num Titles                     15324 non-null  int64  \n"," 15  Num Script                     15324 non-null  int64  \n"," 16  Special Characters             15324 non-null  int64  \n"," 17  Script To Special Chars Ratio  15324 non-null  float64\n"," 18  Script To body Ratio           15324 non-null  float64\n"," 19  Body To Special Char Ratio     15324 non-null  float64\n"," 20  Label                          15324 non-null  int64  \n","dtypes: float64(3), int64(18)\n","memory usage: 2.5 MB\n"]}]},{"cell_type":"code","source":["# Class Distribution of Labels\n","urldata.groupby('Label').size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvS3OQHTSHDt","executionInfo":{"status":"ok","timestamp":1656570200643,"user_tz":-330,"elapsed":5,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"33cf8232-4b20-48b0-8928-a621a7b96c81"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Label\n","0    4954\n","1    1573\n","2    3002\n","3    3543\n","4    2252\n","dtype: int64"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["\n","import numpy as np\n"],"metadata":{"id":"eLm1720QSaAv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["urldata.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"id":"WX-8Xbm3cfFf","outputId":"2c5c8ed3-e0f7-44c4-fdfd-c94ef2fd8469","executionInfo":{"status":"ok","timestamp":1656570208281,"user_tz":-330,"elapsed":47,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["             iFrame    Mouse Over  Right Click  Web Forwards  \\\n","count  15324.000000  15324.000000      15324.0  15324.000000   \n","mean       0.993148      0.000131          0.0      0.910598   \n","std        0.082495      0.011424          0.0      0.285333   \n","min        0.000000      0.000000          0.0      0.000000   \n","25%        1.000000      0.000000          0.0      1.000000   \n","50%        1.000000      0.000000          0.0      1.000000   \n","75%        1.000000      0.000000          0.0      1.000000   \n","max        1.000000      1.000000          0.0      1.000000   \n","\n","       Number of page tokens  number of sentences  number of html tags  \\\n","count           15324.000000         15324.000000         15324.000000   \n","mean             2916.589076          1156.923845           316.643892   \n","std              5841.863156          2952.857402           644.355934   \n","min                 1.000000             1.000000             1.000000   \n","25%                27.000000             7.000000             8.000000   \n","50%               423.000000            83.000000            42.000000   \n","75%              3239.000000          1415.000000           416.000000   \n","max            127712.000000         43777.000000         14280.000000   \n","\n","       number of whitespace   url Is Live   HTML Length  ...    Num Embeds  \\\n","count               15324.0  15324.000000  1.532400e+04  ...  15324.000000   \n","mean                    0.0      0.412621  3.038154e+04  ...      0.000261   \n","std                     0.0      0.499298  8.331941e+04  ...      0.016155   \n","min                     0.0     -1.000000  0.000000e+00  ...      0.000000   \n","25%                     0.0      0.000000  7.100000e+01  ...      0.000000   \n","50%                     0.0      0.000000  2.257000e+03  ...      0.000000   \n","75%                     0.0      1.000000  3.259600e+04  ...      0.000000   \n","max                     0.0      1.000000  2.107635e+06  ...      1.000000   \n","\n","         Num Images     Num Links    Num Titles    Num Script  \\\n","count  15324.000000  15324.000000  15324.000000  1.532400e+04   \n","mean       9.431480     53.732642      8.138476  1.907060e+04   \n","std       31.982449    105.014700     30.703307  6.790900e+04   \n","min        0.000000     -1.000000     -1.000000 -1.000000e+00   \n","25%        0.000000      0.000000      0.000000  0.000000e+00   \n","50%        0.000000      2.000000      1.000000  7.770000e+02   \n","75%        4.000000     66.000000      4.000000  1.592400e+04   \n","max      816.000000   1740.000000   1042.000000  2.076633e+06   \n","\n","       Special Characters  Script To Special Chars Ratio  \\\n","count        15324.000000                   15324.000000   \n","mean          7416.632407                       3.722576   \n","std          18369.465282                      17.536106   \n","min              0.000000                      -1.000000   \n","25%             12.000000                       0.000000   \n","50%            557.000000                       1.324700   \n","75%           8311.000000                       2.625806   \n","max         359290.000000                     381.227732   \n","\n","       Script To body Ratio  Body To Special Char Ratio         Label  \n","count          15324.000000                15324.000000  15324.000000  \n","mean               0.367024                    0.192536      1.775907  \n","std                0.375838                    0.112498      1.471309  \n","min               -1.000000                    0.000000      0.000000  \n","25%                0.000000                    0.141286      0.000000  \n","50%                0.312289                    0.225350      2.000000  \n","75%                0.718077                    0.263237      3.000000  \n","max                1.005038                    0.733333      4.000000  \n","\n","[8 rows x 21 columns]"],"text/html":["\n","  <div id=\"df-bf8d3b7b-e168-43e3-8269-e632490d1e1d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>iFrame</th>\n","      <th>Mouse Over</th>\n","      <th>Right Click</th>\n","      <th>Web Forwards</th>\n","      <th>Number of page tokens</th>\n","      <th>number of sentences</th>\n","      <th>number of html tags</th>\n","      <th>number of whitespace</th>\n","      <th>url Is Live</th>\n","      <th>HTML Length</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.0</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.0</td>\n","      <td>15324.000000</td>\n","      <td>1.532400e+04</td>\n","      <td>...</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>1.532400e+04</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.993148</td>\n","      <td>0.000131</td>\n","      <td>0.0</td>\n","      <td>0.910598</td>\n","      <td>2916.589076</td>\n","      <td>1156.923845</td>\n","      <td>316.643892</td>\n","      <td>0.0</td>\n","      <td>0.412621</td>\n","      <td>3.038154e+04</td>\n","      <td>...</td>\n","      <td>0.000261</td>\n","      <td>9.431480</td>\n","      <td>53.732642</td>\n","      <td>8.138476</td>\n","      <td>1.907060e+04</td>\n","      <td>7416.632407</td>\n","      <td>3.722576</td>\n","      <td>0.367024</td>\n","      <td>0.192536</td>\n","      <td>1.775907</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.082495</td>\n","      <td>0.011424</td>\n","      <td>0.0</td>\n","      <td>0.285333</td>\n","      <td>5841.863156</td>\n","      <td>2952.857402</td>\n","      <td>644.355934</td>\n","      <td>0.0</td>\n","      <td>0.499298</td>\n","      <td>8.331941e+04</td>\n","      <td>...</td>\n","      <td>0.016155</td>\n","      <td>31.982449</td>\n","      <td>105.014700</td>\n","      <td>30.703307</td>\n","      <td>6.790900e+04</td>\n","      <td>18369.465282</td>\n","      <td>17.536106</td>\n","      <td>0.375838</td>\n","      <td>0.112498</td>\n","      <td>1.471309</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.0</td>\n","      <td>-1.000000</td>\n","      <td>0.000000e+00</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-1.000000</td>\n","      <td>-1.000000</td>\n","      <td>-1.000000e+00</td>\n","      <td>0.000000</td>\n","      <td>-1.000000</td>\n","      <td>-1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>27.000000</td>\n","      <td>7.000000</td>\n","      <td>8.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>7.100000e+01</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000e+00</td>\n","      <td>12.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.141286</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>423.000000</td>\n","      <td>83.000000</td>\n","      <td>42.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>2.257000e+03</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>7.770000e+02</td>\n","      <td>557.000000</td>\n","      <td>1.324700</td>\n","      <td>0.312289</td>\n","      <td>0.225350</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>3239.000000</td>\n","      <td>1415.000000</td>\n","      <td>416.000000</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>3.259600e+04</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>4.000000</td>\n","      <td>66.000000</td>\n","      <td>4.000000</td>\n","      <td>1.592400e+04</td>\n","      <td>8311.000000</td>\n","      <td>2.625806</td>\n","      <td>0.718077</td>\n","      <td>0.263237</td>\n","      <td>3.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>127712.000000</td>\n","      <td>43777.000000</td>\n","      <td>14280.000000</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>2.107635e+06</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>816.000000</td>\n","      <td>1740.000000</td>\n","      <td>1042.000000</td>\n","      <td>2.076633e+06</td>\n","      <td>359290.000000</td>\n","      <td>381.227732</td>\n","      <td>1.005038</td>\n","      <td>0.733333</td>\n","      <td>4.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 21 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf8d3b7b-e168-43e3-8269-e632490d1e1d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bf8d3b7b-e168-43e3-8269-e632490d1e1d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bf8d3b7b-e168-43e3-8269-e632490d1e1d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[""],"metadata":{"id":"bUPfWi4TcfIA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#checking the data for null or missing values\n","urldata.isnull().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3PEbrTLcfXg","outputId":"3fbf71e9-cb0b-4e00-d544-569df2940ad3","executionInfo":{"status":"ok","timestamp":1656570208286,"user_tz":-330,"elapsed":48,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["iFrame                           0\n","Mouse Over                       0\n","Right Click                      0\n","Web Forwards                     0\n","Number of page tokens            0\n","number of sentences              0\n","number of html tags              0\n","number of whitespace             0\n","url Is Live                      0\n","HTML Length                      0\n","Num Objects                      0\n","Num Embeds                       0\n","Num Images                       0\n","Num Links                        0\n","Num Titles                       0\n","Num Script                       0\n","Special Characters               0\n","Script To Special Chars Ratio    0\n","Script To body Ratio             0\n","Body To Special Char Ratio       0\n","Label                            0\n","dtype: int64"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# shuffling the rows in the dataset so that when splitting the train and test set are equally distributed\n","urldata = urldata.sample(frac=1).reset_index(drop=True)\n","urldata.head()"],"metadata":{"id":"n6YfGa82P5JZ","colab":{"base_uri":"https://localhost:8080/","height":314},"outputId":"9171e67e-61c6-4432-8469-7ba59a5894db","executionInfo":{"status":"ok","timestamp":1656570208287,"user_tz":-330,"elapsed":45,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   iFrame  Mouse Over  Right Click  Web Forwards  Number of page tokens  \\\n","0       1           0            0             1                   1417   \n","1       1           0            0             1                    723   \n","2       1           0            0             1                    111   \n","3       1           0            0             1                    395   \n","4       1           0            0             1                   5899   \n","\n","   number of sentences  number of html tags  number of whitespace  \\\n","0                  247                  205                     0   \n","1                  163                  243                     0   \n","2                    7                   14                     0   \n","3                   49                   55                     0   \n","4                 2029                  528                     0   \n","\n","   url Is Live  HTML Length  ...  Num Embeds  Num Images  Num Links  \\\n","0            1         6676  ...           0           9          5   \n","1            1         2087  ...           0          14         62   \n","2            0          268  ...           0           0          1   \n","3            1         1946  ...           0           0          6   \n","4            1        69543  ...           0           2        134   \n","\n","   Num Titles  Num Script  Special Characters  Script To Special Chars Ratio  \\\n","0          10        4709                1812                       2.598786   \n","1           0        1049                 536                       1.957090   \n","2           2           0                  52                       0.000000   \n","3           1         149                 555                       0.268468   \n","4           1       63854               20085                       3.179188   \n","\n","   Script To body Ratio  Body To Special Char Ratio  Label  \n","0              0.705362                    0.271420      4  \n","1              0.502635                    0.256828      4  \n","2              0.000000                    0.194030      3  \n","3              0.076567                    0.285200      1  \n","4              0.918194                    0.288814      2  \n","\n","[5 rows x 21 columns]"],"text/html":["\n","  <div id=\"df-8f38f688-110d-4543-9ab1-ab0be3b6633a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>iFrame</th>\n","      <th>Mouse Over</th>\n","      <th>Right Click</th>\n","      <th>Web Forwards</th>\n","      <th>Number of page tokens</th>\n","      <th>number of sentences</th>\n","      <th>number of html tags</th>\n","      <th>number of whitespace</th>\n","      <th>url Is Live</th>\n","      <th>HTML Length</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1417</td>\n","      <td>247</td>\n","      <td>205</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6676</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>10</td>\n","      <td>4709</td>\n","      <td>1812</td>\n","      <td>2.598786</td>\n","      <td>0.705362</td>\n","      <td>0.271420</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>723</td>\n","      <td>163</td>\n","      <td>243</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2087</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>62</td>\n","      <td>0</td>\n","      <td>1049</td>\n","      <td>536</td>\n","      <td>1.957090</td>\n","      <td>0.502635</td>\n","      <td>0.256828</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>111</td>\n","      <td>7</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>268</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.194030</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>395</td>\n","      <td>49</td>\n","      <td>55</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1946</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>149</td>\n","      <td>555</td>\n","      <td>0.268468</td>\n","      <td>0.076567</td>\n","      <td>0.285200</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5899</td>\n","      <td>2029</td>\n","      <td>528</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>69543</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>134</td>\n","      <td>1</td>\n","      <td>63854</td>\n","      <td>20085</td>\n","      <td>3.179188</td>\n","      <td>0.918194</td>\n","      <td>0.288814</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f38f688-110d-4543-9ab1-ab0be3b6633a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8f38f688-110d-4543-9ab1-ab0be3b6633a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8f38f688-110d-4543-9ab1-ab0be3b6633a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["import numpy as np\n","# Sepratating & assigning features and target columns to X & y\n","y = urldata['Label'].values\n","x = np.array(urldata.drop('Label',axis=1))\n","\n"],"metadata":{"id":"Lasv_YzlP5L6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Splitting the dataset into train and test sets: 80-20 split\n","from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, \n","                                                    test_size = 0.45, random_state = 12)\n","print(x_train.shape, x_test.shape)\n","print(y_train.shape, y_test.shape)\n","\n"],"metadata":{"id":"in9C2ArWP5O0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d6b697d1-b859-408b-9aa8-640fd30df791","executionInfo":{"status":"ok","timestamp":1656570208290,"user_tz":-330,"elapsed":45,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(8428, 20) (6896, 20)\n","(8428,) (6896,)\n"]}]},{"cell_type":"code","source":["output = {}\n","output['labels'] = y_test"],"metadata":{"id":"jv6Y5m8ddMHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"fg4rdoEnUE0O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOV9VybfNIgE"},"source":["**MLP**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mr-AOgJ1JtXY"},"outputs":[],"source":["import keras\n","\n","from sklearn.neural_network import MLPClassifier\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","import pickle\n","\n","def model_mlp(x_train, x_val, y_train, y_val, opt, n):\n","  mlpclassifier = MLPClassifier(alpha=0.0001, hidden_layer_sizes=([100,100,100]))\n","  #compile model using mse as a measure of model performance\n","  mlpclassifier.fit(x_train, y_train)\n","\n","  y_pred = mlpclassifier.predict(x_val)\n","\n","  conf_matrix = confusion_matrix(y_val, y_pred)\n","  print(conf_matrix)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred, average='weighted'))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred, average='weighted'))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred, average='weighted'))\n","\n","  \n","  print(\"Validation Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/HTML/MLP/model_'+str(n)+'.h5'\n","  pickle.dump(mlpclassifier, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","  return metrics.accuracy_score(y_val, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUCxdcapJtXZ","executionInfo":{"status":"ok","timestamp":1656570384868,"user_tz":-330,"elapsed":139804,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"59a65398-b0f7-4a9f-a667-80aadef08707"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[204   1  33   5  43]\n"," [ 19  19  15  16  32]\n"," [ 18   2 120   0  11]\n"," [  8   5  12 162  12]\n"," [  6  11  13   5  71]]\n","Precision: 0.6989\n","Recall: 0.6833\n","F1 Score: 0.6761\n","Validation Accuracy: 0.6832740213523132\n","model 0 saved\n","[[162   7  63  22  21]\n"," [ 14  30  20  12  33]\n"," [ 10   0 127   2   9]\n"," [  5   2  16 167   9]\n"," [  6   8  23   5  70]]\n","Precision: 0.6954\n","Recall: 0.6595\n","F1 Score: 0.6529\n","Validation Accuracy: 0.6595492289442467\n","model 1 saved\n","[[209   8  19   7  28]\n"," [ 16  33  11   6  25]\n"," [ 13   6 117   7   9]\n"," [  6   4   1 170  12]\n"," [  9  11   0   4 112]]\n","Precision: 0.7633\n","Recall: 0.7604\n","F1 Score: 0.7570\n","Validation Accuracy: 0.7603795966785291\n","model 2 saved\n","[[211  11  12   7  25]\n"," [ 14  43  13   8  12]\n"," [ 11  18 146   3   8]\n"," [  2  15   3 156   3]\n"," [  6  19   9   6  82]]\n","Precision: 0.7675\n","Recall: 0.7568\n","F1 Score: 0.7613\n","Validation Accuracy: 0.7568208778173191\n","model 3 saved\n","[[243  16   5  13   6]\n"," [ 17  30   2  11  16]\n"," [ 13  20 115   4   9]\n"," [ 13  10   1 169   5]\n"," [  7   9   3   4 102]]\n","Precision: 0.7916\n","Recall: 0.7817\n","F1 Score: 0.7839\n","Validation Accuracy: 0.7817319098457889\n","model 4 saved\n","[[194  20  38  12   1]\n"," [ 23  39  15   8   5]\n"," [ 12   8 145   4   1]\n"," [ 18  10   9 157   1]\n"," [ 37  20  27   6  33]]\n","Precision: 0.6943\n","Recall: 0.6738\n","F1 Score: 0.6603\n","Validation Accuracy: 0.6737841043890866\n","model 5 saved\n","[[158  12  27  17  70]\n"," [ 14   8  10   9  41]\n"," [  7   6 124   1  28]\n"," [  0   2   5 174  13]\n"," [  4   1   5   2 105]]\n","Precision: 0.7145\n","Recall: 0.6750\n","F1 Score: 0.6666\n","Validation Accuracy: 0.67497034400949\n","model 6 saved\n","[[205   9  19   8  16]\n"," [ 15  51   3  17  14]\n"," [ 23   3 144   1  10]\n"," [  3   7   2 169   8]\n"," [ 10  25   4   2  75]]\n","Precision: 0.7638\n","Recall: 0.7639\n","F1 Score: 0.7636\n","Validation Accuracy: 0.763938315539739\n","model 7 saved\n","[[203  33  24  16  11]\n"," [ 21  31   6  15   9]\n"," [ 20   6 121   4   2]\n"," [  5  21   4 172   7]\n"," [ 24  23   6  12  46]]\n","Precision: 0.6923\n","Recall: 0.6805\n","F1 Score: 0.6827\n","Validation Accuracy: 0.6805225653206651\n","model 8 saved\n","[[221  16  21   8  20]\n"," [ 14  31   7   3   9]\n"," [ 39   8 103   5   8]\n"," [  6  13   2 179   5]\n"," [ 18  20   3  18  65]]\n","Precision: 0.7194\n","Recall: 0.7114\n","F1 Score: 0.7129\n","Validation Accuracy: 0.7114014251781473\n","model 9 saved\n","Average Validation Accuracy: 0.7146372389075324\n"]}],"source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_mlp(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":649},"executionInfo":{"elapsed":617,"status":"ok","timestamp":1656570439833,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"6DA16IlPJtXZ","outputId":"fdb304fc-5fde-4df2-faab-c39a7f87c918"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[3.28595502e-008 2.27595203e-038 9.99999967e-001 3.53644837e-103\n","  5.45258001e-062]\n"," [9.87170919e-001 1.40065769e-005 8.88707177e-004 3.09404654e-004\n","  1.16169622e-002]\n"," [5.43199900e-003 7.26519788e-003 9.75126111e-001 1.06356829e-002\n","  1.54100894e-003]\n"," ...\n"," [1.95654589e-064 3.95504084e-062 4.27920447e-132 1.00000000e+000\n","  2.77532688e-194]\n"," [1.44909380e-001 2.97695615e-001 3.11118892e-001 1.09381100e-001\n","  1.36895013e-001]\n"," [9.38118847e-001 6.25375208e-004 6.04173309e-002 2.58007396e-005\n","  8.12646395e-004]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  mlp_prediction_spam  \\\n","0          2        3.285955e-08          2.275952e-38         1.000000e+00   \n","1          0        9.871709e-01          1.400658e-05         8.887072e-04   \n","2          2        5.431999e-03          7.265198e-03         9.751261e-01   \n","3          3        6.821167e-02          8.999669e-02         4.175485e-02   \n","4          0        1.000000e+00          9.884499e-29         3.997525e-14   \n","...      ...                 ...                   ...                  ...   \n","6891       2        1.120535e-12          1.117325e-44         1.000000e+00   \n","6892       2        8.522478e-04          1.933313e-04         9.989540e-01   \n","6893       3        1.956546e-64          3.955041e-62        4.279204e-132   \n","6894       0        1.449094e-01          2.976956e-01         3.111189e-01   \n","6895       0        9.381188e-01          6.253752e-04         6.041733e-02   \n","\n","      mlp_prediction_malware  mlp_prediction_defacemen  \n","0              3.536448e-103              5.452580e-62  \n","1               3.094047e-04              1.161696e-02  \n","2               1.063568e-02              1.541009e-03  \n","3               7.832318e-01              1.680500e-02  \n","4               4.412196e-13              2.773055e-33  \n","...                      ...                       ...  \n","6891           9.068879e-112              2.337164e-60  \n","6892            4.423567e-07              4.685219e-15  \n","6893            1.000000e+00             2.775327e-194  \n","6894            1.093811e-01              1.368950e-01  \n","6895            2.580074e-05              8.126464e-04  \n","\n","[6896 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-aa9374cf-aad0-4afa-abdb-91418162c97e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>mlp_prediction_spam</th>\n","      <th>mlp_prediction_malware</th>\n","      <th>mlp_prediction_defacemen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>3.285955e-08</td>\n","      <td>2.275952e-38</td>\n","      <td>1.000000e+00</td>\n","      <td>3.536448e-103</td>\n","      <td>5.452580e-62</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>9.871709e-01</td>\n","      <td>1.400658e-05</td>\n","      <td>8.887072e-04</td>\n","      <td>3.094047e-04</td>\n","      <td>1.161696e-02</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5.431999e-03</td>\n","      <td>7.265198e-03</td>\n","      <td>9.751261e-01</td>\n","      <td>1.063568e-02</td>\n","      <td>1.541009e-03</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>6.821167e-02</td>\n","      <td>8.999669e-02</td>\n","      <td>4.175485e-02</td>\n","      <td>7.832318e-01</td>\n","      <td>1.680500e-02</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>9.884499e-29</td>\n","      <td>3.997525e-14</td>\n","      <td>4.412196e-13</td>\n","      <td>2.773055e-33</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6891</th>\n","      <td>2</td>\n","      <td>1.120535e-12</td>\n","      <td>1.117325e-44</td>\n","      <td>1.000000e+00</td>\n","      <td>9.068879e-112</td>\n","      <td>2.337164e-60</td>\n","    </tr>\n","    <tr>\n","      <th>6892</th>\n","      <td>2</td>\n","      <td>8.522478e-04</td>\n","      <td>1.933313e-04</td>\n","      <td>9.989540e-01</td>\n","      <td>4.423567e-07</td>\n","      <td>4.685219e-15</td>\n","    </tr>\n","    <tr>\n","      <th>6893</th>\n","      <td>3</td>\n","      <td>1.956546e-64</td>\n","      <td>3.955041e-62</td>\n","      <td>4.279204e-132</td>\n","      <td>1.000000e+00</td>\n","      <td>2.775327e-194</td>\n","    </tr>\n","    <tr>\n","      <th>6894</th>\n","      <td>0</td>\n","      <td>1.449094e-01</td>\n","      <td>2.976956e-01</td>\n","      <td>3.111189e-01</td>\n","      <td>1.093811e-01</td>\n","      <td>1.368950e-01</td>\n","    </tr>\n","    <tr>\n","      <th>6895</th>\n","      <td>0</td>\n","      <td>9.381188e-01</td>\n","      <td>6.253752e-04</td>\n","      <td>6.041733e-02</td>\n","      <td>2.580074e-05</td>\n","      <td>8.126464e-04</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6896 rows × 6 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa9374cf-aad0-4afa-abdb-91418162c97e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-aa9374cf-aad0-4afa-abdb-91418162c97e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-aa9374cf-aad0-4afa-abdb-91418162c97e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}],"source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/HTML/MLP/model_4.h5'\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['mlp_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['mlp_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output['mlp_prediction_spam'] = [i[2] for i in y_pred_prob];\n","output['mlp_prediction_malware'] = [i[3] for i in y_pred_prob];\n","output['mlp_prediction_defacemen'] = [i[4] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output\n"]},{"cell_type":"markdown","source":["**Neural Network**"],"metadata":{"id":"iLF4sz5NsSZ6"}},{"cell_type":"code","source":["\n","import keras\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","def model_aa(x_train, x_val, y_train, y_val, opt, n, early_stopping_monitor):\n","\n","  n_cols = x_train.shape[1]\n","  # print(\"check point\")\n","  #create model\n","  model = Sequential()\n","  model.add(Dense(30, activation='relu', input_shape=(n_cols,)))\n","  model.add(Dense(10, activation='relu'))\n","\n","  model.add(Dense(1, activation = 'sigmoid'))\n","  # softmax\n","  #compile model using mse as a measure of model performance\n","  model.compile(optimizer = opt, loss= 'binary_crossentropy', metrics=[\"accuracy\"])\n","\n","  history = model.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping_monitor])\n","\n","\n","  # plt.plot(history.history['loss'])\n","  # plt.plot(history.history['val_loss'])\n","  # plt.title('model loss')\n","  # plt.ylabel('Loss')\n","  # plt.xlabel('Epoch')\n","  # plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n","  # plt.show()\n","\n","\n","  print('Validation Accuracy: ')\n","  # Predicting the Test set results\n","  y_pred = model.predict(x_val)\n","  y_pred = (y_pred > 0.5)\n","\n","\n","  print(classification_report(y_val, y_pred))\n","\n","  # Model Accuracy, how often is the classifier correct?\n","  print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","\n","  # Creating the Confusion Matrix\n","  cm = confusion_matrix(y_val, y_pred)\n","  print(cm)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred, average='weighted'))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred, average='weighted'))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred, average='weighted'))\n","\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/HTML/NN/model_'+str(n)+'.h5'\n","  pickle.dump(model, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","\n","  return metrics.accuracy_score(y_val, y_pred)\n","\n"],"metadata":{"id":"UfilmHKnL3LC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_aa(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n, early_stopping_monitor)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_OHdM1HNDio","executionInfo":{"status":"ok","timestamp":1656571261465,"user_tz":-330,"elapsed":815779,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"669e348a-a94f-4f79-b107-50df58c42372"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","238/238 [==============================] - 5s 5ms/step - loss: 556.1033 - accuracy: 0.1034 - val_loss: 798.4049 - val_accuracy: 0.1198\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -336.1695 - accuracy: 0.1188 - val_loss: -135.1720 - val_accuracy: 0.2183\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -841.2561 - accuracy: 0.1332 - val_loss: -285.2514 - val_accuracy: 0.2052\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1605.4834 - accuracy: 0.1288 - val_loss: -99.3229 - val_accuracy: 0.2076\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2588.7893 - accuracy: 0.1346 - val_loss: -641.0293 - val_accuracy: 0.2147\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3913.5723 - accuracy: 0.1351 - val_loss: -775.1376 - val_accuracy: 0.2064\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5784.5952 - accuracy: 0.1312 - val_loss: -1324.1055 - val_accuracy: 0.1340\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8432.4404 - accuracy: 0.1243 - val_loss: -1771.1632 - val_accuracy: 0.1305\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12083.4541 - accuracy: 0.1198 - val_loss: -1873.3591 - val_accuracy: 0.1222\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -16248.9082 - accuracy: 0.1158 - val_loss: -3816.8801 - val_accuracy: 0.1317\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -21404.9473 - accuracy: 0.1281 - val_loss: -5855.2812 - val_accuracy: 0.2135\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -27349.6719 - accuracy: 0.1299 - val_loss: -7343.3350 - val_accuracy: 0.1305\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -34405.9766 - accuracy: 0.1225 - val_loss: -9001.0186 - val_accuracy: 0.1257\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -42611.9648 - accuracy: 0.1289 - val_loss: -11014.3193 - val_accuracy: 0.1281\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -51969.1562 - accuracy: 0.1270 - val_loss: -14599.0889 - val_accuracy: 0.1281\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -62485.0156 - accuracy: 0.1337 - val_loss: -18054.3145 - val_accuracy: 0.1281\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -75284.5859 - accuracy: 0.1270 - val_loss: -22193.3770 - val_accuracy: 0.2017\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -90226.8359 - accuracy: 0.1289 - val_loss: -27005.9141 - val_accuracy: 0.1305\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -105473.8281 - accuracy: 0.1295 - val_loss: -32648.5977 - val_accuracy: 0.1293\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -121927.6875 - accuracy: 0.1278 - val_loss: -38373.8164 - val_accuracy: 0.1293\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -139765.5469 - accuracy: 0.1326 - val_loss: -45027.9961 - val_accuracy: 0.1305\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -159745.0156 - accuracy: 0.1260 - val_loss: -52235.5117 - val_accuracy: 0.1281\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -181989.0469 - accuracy: 0.1216 - val_loss: -60964.0234 - val_accuracy: 0.2028\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -205625.2344 - accuracy: 0.1367 - val_loss: -69164.6797 - val_accuracy: 0.2005\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -231748.4062 - accuracy: 0.1395 - val_loss: -77734.3984 - val_accuracy: 0.1412\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -259931.8750 - accuracy: 0.1454 - val_loss: -88553.5781 - val_accuracy: 0.1412\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -289925.2500 - accuracy: 0.1396 - val_loss: -99425.6250 - val_accuracy: 0.1981\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -320598.1875 - accuracy: 0.1533 - val_loss: -104869.5312 - val_accuracy: 0.1293\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -354574.6875 - accuracy: 0.1409 - val_loss: -121130.8438 - val_accuracy: 0.1447\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -389209.3438 - accuracy: 0.1457 - val_loss: -134724.6875 - val_accuracy: 0.2017\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -425959.5312 - accuracy: 0.1516 - val_loss: -146299.5156 - val_accuracy: 0.1447\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -466732.9688 - accuracy: 0.1473 - val_loss: -159680.1562 - val_accuracy: 0.1447\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -506896.7812 - accuracy: 0.1527 - val_loss: -169093.6875 - val_accuracy: 0.1329\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -550976.0625 - accuracy: 0.1423 - val_loss: -193211.4688 - val_accuracy: 0.2112\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -597628.1875 - accuracy: 0.1558 - val_loss: -203083.2812 - val_accuracy: 0.1329\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -647354.1875 - accuracy: 0.1436 - val_loss: -224870.4688 - val_accuracy: 0.1447\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -699349.1250 - accuracy: 0.1491 - val_loss: -243636.4219 - val_accuracy: 0.1447\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -753772.3125 - accuracy: 0.1477 - val_loss: -262788.9062 - val_accuracy: 0.1447\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -810260.8750 - accuracy: 0.1548 - val_loss: -281525.2188 - val_accuracy: 0.1352\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -868217.0000 - accuracy: 0.1392 - val_loss: -306115.5938 - val_accuracy: 0.2028\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -928607.6875 - accuracy: 0.1448 - val_loss: -327276.0000 - val_accuracy: 0.2159\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -994153.5000 - accuracy: 0.1467 - val_loss: -345335.9062 - val_accuracy: 0.1447\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1062707.5000 - accuracy: 0.1504 - val_loss: -375167.2812 - val_accuracy: 0.1459\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1134820.0000 - accuracy: 0.1429 - val_loss: -402420.0000 - val_accuracy: 0.1874\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1208744.5000 - accuracy: 0.1473 - val_loss: -424915.4062 - val_accuracy: 0.1447\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1286915.0000 - accuracy: 0.1475 - val_loss: -457201.8125 - val_accuracy: 0.1886\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1368789.1250 - accuracy: 0.1500 - val_loss: -482297.5312 - val_accuracy: 0.1447\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1455058.8750 - accuracy: 0.1465 - val_loss: -509306.1250 - val_accuracy: 0.1459\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1543126.7500 - accuracy: 0.1391 - val_loss: -549358.8125 - val_accuracy: 0.2052\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1634546.3750 - accuracy: 0.1423 - val_loss: -585421.9375 - val_accuracy: 0.2147\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1727026.3750 - accuracy: 0.1465 - val_loss: -605583.5000 - val_accuracy: 0.1471\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1790231.0000 - accuracy: 0.1403 - val_loss: -636858.0000 - val_accuracy: 0.2052\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1857745.7500 - accuracy: 0.1487 - val_loss: -660959.5625 - val_accuracy: 0.1483\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1933760.7500 - accuracy: 0.1367 - val_loss: -680453.6875 - val_accuracy: 0.1352\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2010796.8750 - accuracy: 0.1336 - val_loss: -721508.5000 - val_accuracy: 0.1886\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2094980.8750 - accuracy: 0.1390 - val_loss: -753182.7500 - val_accuracy: 0.1471\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2181843.2500 - accuracy: 0.1517 - val_loss: -780232.2500 - val_accuracy: 0.1471\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2272380.5000 - accuracy: 0.1420 - val_loss: -818389.5625 - val_accuracy: 0.1471\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2370893.5000 - accuracy: 0.1456 - val_loss: -848808.5625 - val_accuracy: 0.1352\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2476522.5000 - accuracy: 0.1363 - val_loss: -908273.7500 - val_accuracy: 0.2064\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2584965.2500 - accuracy: 0.1478 - val_loss: -941477.4375 - val_accuracy: 0.1471\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2703318.2500 - accuracy: 0.1437 - val_loss: -965144.5000 - val_accuracy: 0.1364\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2801592.7500 - accuracy: 0.1205 - val_loss: -1034183.6875 - val_accuracy: 0.1483\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2937824.7500 - accuracy: 0.1419 - val_loss: -1071669.8750 - val_accuracy: 0.1471\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3058891.7500 - accuracy: 0.1420 - val_loss: -1113477.2500 - val_accuracy: 0.1471\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3186813.0000 - accuracy: 0.1445 - val_loss: -1146481.1250 - val_accuracy: 0.1364\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3320092.2500 - accuracy: 0.1471 - val_loss: -1178755.2500 - val_accuracy: 0.1352\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3451728.2500 - accuracy: 0.1357 - val_loss: -1262835.3750 - val_accuracy: 0.1471\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3597759.2500 - accuracy: 0.1394 - val_loss: -1318561.7500 - val_accuracy: 0.1886\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3747047.7500 - accuracy: 0.1420 - val_loss: -1382924.7500 - val_accuracy: 0.2076\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3897087.5000 - accuracy: 0.1459 - val_loss: -1433442.3750 - val_accuracy: 0.1483\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4061139.5000 - accuracy: 0.1491 - val_loss: -1482264.5000 - val_accuracy: 0.1364\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4227789.5000 - accuracy: 0.1405 - val_loss: -1549511.2500 - val_accuracy: 0.1471\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4411343.0000 - accuracy: 0.1449 - val_loss: -1578820.0000 - val_accuracy: 0.1352\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4580647.5000 - accuracy: 0.1365 - val_loss: -1682215.7500 - val_accuracy: 0.1471\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4761997.5000 - accuracy: 0.1345 - val_loss: -1758225.6250 - val_accuracy: 0.1910\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4940300.0000 - accuracy: 0.1503 - val_loss: -1813938.5000 - val_accuracy: 0.1471\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5123938.5000 - accuracy: 0.1415 - val_loss: -1891390.0000 - val_accuracy: 0.1483\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5310307.0000 - accuracy: 0.1599 - val_loss: -1917502.8750 - val_accuracy: 0.1352\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5498382.0000 - accuracy: 0.1312 - val_loss: -2028550.2500 - val_accuracy: 0.1483\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5704827.5000 - accuracy: 0.1358 - val_loss: -2096778.8750 - val_accuracy: 0.1471\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5901702.5000 - accuracy: 0.1376 - val_loss: -2179069.5000 - val_accuracy: 0.1910\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6103106.5000 - accuracy: 0.1450 - val_loss: -2248442.7500 - val_accuracy: 0.1483\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6316908.0000 - accuracy: 0.1384 - val_loss: -2337574.0000 - val_accuracy: 0.1898\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6531593.0000 - accuracy: 0.1436 - val_loss: -2405157.0000 - val_accuracy: 0.1471\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6754151.0000 - accuracy: 0.1359 - val_loss: -2504420.2500 - val_accuracy: 0.2052\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6965115.5000 - accuracy: 0.1539 - val_loss: -2563486.0000 - val_accuracy: 0.1471\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7208619.5000 - accuracy: 0.1328 - val_loss: -2655730.2500 - val_accuracy: 0.1483\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7441183.5000 - accuracy: 0.1421 - val_loss: -2746394.0000 - val_accuracy: 0.1483\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7682952.5000 - accuracy: 0.1320 - val_loss: -2843882.2500 - val_accuracy: 0.1898\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7929306.5000 - accuracy: 0.1413 - val_loss: -2924855.2500 - val_accuracy: 0.1483\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8181491.5000 - accuracy: 0.1328 - val_loss: -3017944.0000 - val_accuracy: 0.1483\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8450699.0000 - accuracy: 0.1500 - val_loss: -3036085.0000 - val_accuracy: 0.1352\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8704338.0000 - accuracy: 0.1313 - val_loss: -3209640.5000 - val_accuracy: 0.1471\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8975411.0000 - accuracy: 0.1378 - val_loss: -3301031.7500 - val_accuracy: 0.1376\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9251767.0000 - accuracy: 0.1382 - val_loss: -3427943.0000 - val_accuracy: 0.1483\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9518019.0000 - accuracy: 0.1382 - val_loss: -3548068.0000 - val_accuracy: 0.1910\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9800150.0000 - accuracy: 0.1440 - val_loss: -3599915.7500 - val_accuracy: 0.1376\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10089454.0000 - accuracy: 0.1375 - val_loss: -3753388.2500 - val_accuracy: 0.1495\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10384610.0000 - accuracy: 0.1461 - val_loss: -3777247.5000 - val_accuracy: 0.1352\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.05      0.09       286\n","           1       0.12      0.99      0.22       101\n","           2       0.00      0.00      0.00       151\n","           3       0.00      0.00      0.00       199\n","           4       0.00      0.00      0.00       106\n","\n","    accuracy                           0.14       843\n","   macro avg       0.17      0.21      0.06       843\n","weighted avg       0.26      0.14      0.06       843\n","\n","Accuracy: 0.13523131672597866\n","[[ 14 272   0   0   0]\n"," [  1 100   0   0   0]\n"," [  0 151   0   0   0]\n"," [  4 195   0   0   0]\n"," [  0 106   0   0   0]]\n","Precision: 0.2645\n","Recall: 0.1352\n","F1 Score: 0.0571\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://bc77b786-686f-442f-9fe1-2af8d3779387/assets\n","model 0 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 108.9928 - accuracy: 0.1225 - val_loss: -512.5244 - val_accuracy: 0.2064\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -980.0496 - accuracy: 0.1463 - val_loss: -1209.2523 - val_accuracy: 0.2123\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1929.6737 - accuracy: 0.1390 - val_loss: -2027.9550 - val_accuracy: 0.2195\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3164.0654 - accuracy: 0.1363 - val_loss: -3153.6836 - val_accuracy: 0.1376\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5060.2163 - accuracy: 0.1359 - val_loss: -5056.8765 - val_accuracy: 0.2112\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7555.4634 - accuracy: 0.1508 - val_loss: -7434.6265 - val_accuracy: 0.1329\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10609.9463 - accuracy: 0.1345 - val_loss: -10179.0459 - val_accuracy: 0.1376\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14327.2773 - accuracy: 0.1320 - val_loss: -13644.7422 - val_accuracy: 0.2052\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -18531.1328 - accuracy: 0.1394 - val_loss: -17650.0352 - val_accuracy: 0.1317\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -23544.1699 - accuracy: 0.1465 - val_loss: -21714.4043 - val_accuracy: 0.1352\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -29206.5566 - accuracy: 0.1270 - val_loss: -26941.8027 - val_accuracy: 0.1578\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -35417.7109 - accuracy: 0.1371 - val_loss: -32577.7930 - val_accuracy: 0.2112\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -42686.3789 - accuracy: 0.1424 - val_loss: -38897.7617 - val_accuracy: 0.1435\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -50900.9297 - accuracy: 0.1376 - val_loss: -46708.9219 - val_accuracy: 0.1352\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -60293.2656 - accuracy: 0.1370 - val_loss: -55206.2305 - val_accuracy: 0.1554\n","Epoch 16/100\n","238/238 [==============================] - 1s 5ms/step - loss: -70455.6484 - accuracy: 0.1272 - val_loss: -64367.8008 - val_accuracy: 0.2005\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -81178.6719 - accuracy: 0.1372 - val_loss: -73756.3203 - val_accuracy: 0.1530\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -92559.1172 - accuracy: 0.1412 - val_loss: -83882.2891 - val_accuracy: 0.1388\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -105309.1953 - accuracy: 0.1259 - val_loss: -95048.1719 - val_accuracy: 0.2064\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -118433.9922 - accuracy: 0.1421 - val_loss: -106728.0703 - val_accuracy: 0.1352\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -132179.8281 - accuracy: 0.1401 - val_loss: -119583.2109 - val_accuracy: 0.2088\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -147799.5156 - accuracy: 0.1540 - val_loss: -132155.7344 - val_accuracy: 0.1305\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -164868.5625 - accuracy: 0.1354 - val_loss: -149651.0312 - val_accuracy: 0.1352\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -185105.8594 - accuracy: 0.1346 - val_loss: -170142.9062 - val_accuracy: 0.1495\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -208686.5469 - accuracy: 0.1279 - val_loss: -192642.6562 - val_accuracy: 0.1388\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -233476.0312 - accuracy: 0.1363 - val_loss: -214515.4531 - val_accuracy: 0.1352\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -259320.3438 - accuracy: 0.1330 - val_loss: -238875.4844 - val_accuracy: 0.1507\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -286207.4375 - accuracy: 0.1336 - val_loss: -263507.8438 - val_accuracy: 0.1554\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -314159.3438 - accuracy: 0.1420 - val_loss: -288346.4062 - val_accuracy: 0.1340\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -343836.4062 - accuracy: 0.1371 - val_loss: -315877.2812 - val_accuracy: 0.1578\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -375508.6875 - accuracy: 0.1324 - val_loss: -344651.0312 - val_accuracy: 0.2088\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -409025.7500 - accuracy: 0.1520 - val_loss: -375186.9062 - val_accuracy: 0.1542\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -444334.0625 - accuracy: 0.1366 - val_loss: -407041.0938 - val_accuracy: 0.1376\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -480884.5312 - accuracy: 0.1400 - val_loss: -441375.6250 - val_accuracy: 0.1518\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -519417.0938 - accuracy: 0.1481 - val_loss: -475933.1562 - val_accuracy: 0.2064\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -559462.5000 - accuracy: 0.1548 - val_loss: -512152.4688 - val_accuracy: 0.1518\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -602814.8750 - accuracy: 0.1492 - val_loss: -550931.6875 - val_accuracy: 0.1483\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -645422.6250 - accuracy: 0.1423 - val_loss: -590847.1875 - val_accuracy: 0.2040\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -691987.0625 - accuracy: 0.1565 - val_loss: -628308.3750 - val_accuracy: 0.1340\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -739113.0000 - accuracy: 0.1354 - val_loss: -676665.6875 - val_accuracy: 0.2040\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -786844.9375 - accuracy: 0.1539 - val_loss: -720099.0625 - val_accuracy: 0.2064\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -836952.2500 - accuracy: 0.1558 - val_loss: -764428.6875 - val_accuracy: 0.1542\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -889631.6250 - accuracy: 0.1312 - val_loss: -813853.3125 - val_accuracy: 0.1910\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -944631.5000 - accuracy: 0.1486 - val_loss: -863180.5000 - val_accuracy: 0.1340\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1003175.9375 - accuracy: 0.1270 - val_loss: -916532.2500 - val_accuracy: 0.2064\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1063631.3750 - accuracy: 0.1612 - val_loss: -972615.8125 - val_accuracy: 0.1423\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1126146.6250 - accuracy: 0.1386 - val_loss: -1030706.6875 - val_accuracy: 0.1435\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1192728.1250 - accuracy: 0.1214 - val_loss: -1092631.8750 - val_accuracy: 0.2040\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1264417.0000 - accuracy: 0.1301 - val_loss: -1157489.0000 - val_accuracy: 0.2064\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1335528.6250 - accuracy: 0.1363 - val_loss: -1221639.6250 - val_accuracy: 0.2088\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1408722.5000 - accuracy: 0.1408 - val_loss: -1292945.0000 - val_accuracy: 0.2064\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1485899.8750 - accuracy: 0.1463 - val_loss: -1361321.6250 - val_accuracy: 0.1447\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1564260.7500 - accuracy: 0.1345 - val_loss: -1435523.6250 - val_accuracy: 0.1412\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1645736.8750 - accuracy: 0.1281 - val_loss: -1511044.5000 - val_accuracy: 0.1400\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1730410.3750 - accuracy: 0.1301 - val_loss: -1590554.3750 - val_accuracy: 0.1388\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1818989.7500 - accuracy: 0.1210 - val_loss: -1663634.1250 - val_accuracy: 0.2088\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1904596.2500 - accuracy: 0.1458 - val_loss: -1754419.7500 - val_accuracy: 0.1388\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2002983.1250 - accuracy: 0.1229 - val_loss: -1844716.3750 - val_accuracy: 0.1578\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2102111.2500 - accuracy: 0.1278 - val_loss: -1927742.5000 - val_accuracy: 0.2064\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2198451.2500 - accuracy: 0.1456 - val_loss: -2025533.2500 - val_accuracy: 0.1400\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2302691.5000 - accuracy: 0.1339 - val_loss: -2122482.5000 - val_accuracy: 0.1412\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2405532.0000 - accuracy: 0.1386 - val_loss: -2220061.5000 - val_accuracy: 0.1376\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2519750.0000 - accuracy: 0.1231 - val_loss: -2311115.0000 - val_accuracy: 0.2088\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2629824.2500 - accuracy: 0.1502 - val_loss: -2426091.0000 - val_accuracy: 0.1423\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2745640.5000 - accuracy: 0.1214 - val_loss: -2533468.2500 - val_accuracy: 0.1423\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2862929.5000 - accuracy: 0.1285 - val_loss: -2641179.7500 - val_accuracy: 0.1412\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2984604.5000 - accuracy: 0.1258 - val_loss: -2754444.2500 - val_accuracy: 0.1578\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3111082.0000 - accuracy: 0.1216 - val_loss: -2871136.2500 - val_accuracy: 0.1566\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3241389.7500 - accuracy: 0.1301 - val_loss: -2993446.0000 - val_accuracy: 0.1412\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3375808.5000 - accuracy: 0.1220 - val_loss: -3121495.7500 - val_accuracy: 0.1412\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3514957.2500 - accuracy: 0.1184 - val_loss: -3248511.0000 - val_accuracy: 0.1412\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3656856.7500 - accuracy: 0.1222 - val_loss: -3383027.0000 - val_accuracy: 0.1412\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3803526.0000 - accuracy: 0.1259 - val_loss: -3519016.0000 - val_accuracy: 0.1412\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3953212.5000 - accuracy: 0.1288 - val_loss: -3647084.0000 - val_accuracy: 0.2064\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4106901.5000 - accuracy: 0.1218 - val_loss: -3800710.2500 - val_accuracy: 0.1578\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4265040.5000 - accuracy: 0.1214 - val_loss: -3946565.5000 - val_accuracy: 0.1578\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4429164.5000 - accuracy: 0.1213 - val_loss: -4097308.7500 - val_accuracy: 0.1578\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4597735.0000 - accuracy: 0.1220 - val_loss: -4257797.5000 - val_accuracy: 0.1423\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4765968.5000 - accuracy: 0.1230 - val_loss: -4414844.0000 - val_accuracy: 0.1423\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4940286.5000 - accuracy: 0.1432 - val_loss: -4577733.0000 - val_accuracy: 0.1400\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5116867.5000 - accuracy: 0.1164 - val_loss: -4742848.5000 - val_accuracy: 0.1412\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5302802.0000 - accuracy: 0.1292 - val_loss: -4917009.0000 - val_accuracy: 0.1400\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5496514.5000 - accuracy: 0.1279 - val_loss: -5098858.0000 - val_accuracy: 0.1400\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5702396.5000 - accuracy: 0.1167 - val_loss: -5291834.5000 - val_accuracy: 0.1412\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5914374.0000 - accuracy: 0.1171 - val_loss: -5483932.0000 - val_accuracy: 0.1566\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6125754.5000 - accuracy: 0.1276 - val_loss: -5688277.0000 - val_accuracy: 0.1400\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6345566.0000 - accuracy: 0.1165 - val_loss: -5890154.5000 - val_accuracy: 0.1400\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6567440.5000 - accuracy: 0.1169 - val_loss: -6083975.5000 - val_accuracy: 0.1423\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6788655.0000 - accuracy: 0.1163 - val_loss: -6292242.5000 - val_accuracy: 0.1566\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7027402.5000 - accuracy: 0.1163 - val_loss: -6519868.0000 - val_accuracy: 0.1400\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7256589.5000 - accuracy: 0.1201 - val_loss: -6735131.0000 - val_accuracy: 0.1400\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7497885.0000 - accuracy: 0.1196 - val_loss: -6955164.5000 - val_accuracy: 0.1400\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7747606.0000 - accuracy: 0.1188 - val_loss: -7195900.0000 - val_accuracy: 0.1400\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8015364.0000 - accuracy: 0.1191 - val_loss: -7438526.0000 - val_accuracy: 0.1400\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8291249.0000 - accuracy: 0.1202 - val_loss: -7682272.0000 - val_accuracy: 0.1590\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8559445.0000 - accuracy: 0.1196 - val_loss: -7929050.0000 - val_accuracy: 0.1578\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8835633.0000 - accuracy: 0.1243 - val_loss: -8195647.0000 - val_accuracy: 0.1400\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9104852.0000 - accuracy: 0.1292 - val_loss: -8438088.0000 - val_accuracy: 0.1412\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9379112.0000 - accuracy: 0.1188 - val_loss: -8698262.0000 - val_accuracy: 0.1423\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9666199.0000 - accuracy: 0.1229 - val_loss: -8950212.0000 - val_accuracy: 0.1590\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.11      0.19       275\n","           1       0.13      0.95      0.23       109\n","           2       0.00      0.00      0.00       148\n","           3       0.00      0.00      0.00       199\n","           4       0.00      0.00      0.00       112\n","\n","    accuracy                           0.16       843\n","   macro avg       0.19      0.21      0.08       843\n","weighted avg       0.29      0.16      0.09       843\n","\n","Accuracy: 0.15895610913404506\n","[[ 30 245   0   0   0]\n"," [  5 104   0   0   0]\n"," [  0 148   0   0   0]\n"," [  1 198   0   0   0]\n"," [  0 112   0   0   0]]\n","Precision: 0.2885\n","Recall: 0.1590\n","F1 Score: 0.0923\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://37c249c7-6ab9-48cd-8c45-7daf075b9ba1/assets\n","model 1 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: -145.5618 - accuracy: 0.1354 - val_loss: -551.9398 - val_accuracy: 0.1934\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -557.1210 - accuracy: 0.1383 - val_loss: -871.3253 - val_accuracy: 0.1234\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -919.8246 - accuracy: 0.1342 - val_loss: -1384.3962 - val_accuracy: 0.1945\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1415.5052 - accuracy: 0.1450 - val_loss: -1889.6941 - val_accuracy: 0.1222\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2003.9774 - accuracy: 0.1366 - val_loss: -2380.1460 - val_accuracy: 0.1079\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2729.9075 - accuracy: 0.1310 - val_loss: -3497.4780 - val_accuracy: 0.1993\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3541.6519 - accuracy: 0.1322 - val_loss: -4505.8384 - val_accuracy: 0.1981\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4590.3188 - accuracy: 0.1506 - val_loss: -5725.5469 - val_accuracy: 0.1934\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5784.7998 - accuracy: 0.1213 - val_loss: -7483.9146 - val_accuracy: 0.1186\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7349.1836 - accuracy: 0.1421 - val_loss: -9346.5400 - val_accuracy: 0.1222\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8921.6533 - accuracy: 0.1457 - val_loss: -10691.6143 - val_accuracy: 0.1103\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10637.5742 - accuracy: 0.1413 - val_loss: -13095.3525 - val_accuracy: 0.1981\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12700.6992 - accuracy: 0.1474 - val_loss: -14811.2783 - val_accuracy: 0.1103\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -15028.3701 - accuracy: 0.1496 - val_loss: -18422.9043 - val_accuracy: 0.1981\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -18477.4766 - accuracy: 0.1334 - val_loss: -24179.5391 - val_accuracy: 0.1934\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -22968.6719 - accuracy: 0.1272 - val_loss: -28617.7109 - val_accuracy: 0.1198\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -26758.6309 - accuracy: 0.1146 - val_loss: -33856.4453 - val_accuracy: 0.1388\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -31236.8125 - accuracy: 0.1289 - val_loss: -37892.9570 - val_accuracy: 0.1257\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -35533.4805 - accuracy: 0.1204 - val_loss: -42468.0195 - val_accuracy: 0.1198\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -40017.8594 - accuracy: 0.1189 - val_loss: -48959.1211 - val_accuracy: 0.1376\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -45310.2266 - accuracy: 0.1278 - val_loss: -54732.3672 - val_accuracy: 0.1376\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -50787.6680 - accuracy: 0.1321 - val_loss: -60458.1445 - val_accuracy: 0.1210\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -57040.3477 - accuracy: 0.1251 - val_loss: -68660.0703 - val_accuracy: 0.1364\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -63897.6875 - accuracy: 0.1280 - val_loss: -76775.2422 - val_accuracy: 0.1364\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -71660.8047 - accuracy: 0.1334 - val_loss: -85977.0938 - val_accuracy: 0.1376\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -79017.4766 - accuracy: 0.1454 - val_loss: -92500.4531 - val_accuracy: 0.1210\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -88007.3594 - accuracy: 0.1231 - val_loss: -105193.9609 - val_accuracy: 0.1720\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -97724.3125 - accuracy: 0.1314 - val_loss: -115700.1953 - val_accuracy: 0.1246\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -107683.7031 - accuracy: 0.1324 - val_loss: -126370.4609 - val_accuracy: 0.1210\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -118761.3438 - accuracy: 0.1375 - val_loss: -138586.5938 - val_accuracy: 0.1234\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -130810.1172 - accuracy: 0.1213 - val_loss: -153996.0312 - val_accuracy: 0.1234\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -143585.2656 - accuracy: 0.1318 - val_loss: -168550.1250 - val_accuracy: 0.1234\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -157489.1719 - accuracy: 0.1221 - val_loss: -184331.8438 - val_accuracy: 0.1234\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -170427.0312 - accuracy: 0.1317 - val_loss: -199477.9844 - val_accuracy: 0.1234\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -184536.6250 - accuracy: 0.1334 - val_loss: -215211.6875 - val_accuracy: 0.1246\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -199176.5625 - accuracy: 0.1242 - val_loss: -234416.0938 - val_accuracy: 0.1364\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -215728.9375 - accuracy: 0.1279 - val_loss: -253192.4844 - val_accuracy: 0.1720\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -232378.5625 - accuracy: 0.1262 - val_loss: -271008.0312 - val_accuracy: 0.1246\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -250687.2344 - accuracy: 0.1246 - val_loss: -289867.6875 - val_accuracy: 0.1222\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -269609.7812 - accuracy: 0.1191 - val_loss: -314282.5312 - val_accuracy: 0.1257\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -287790.0938 - accuracy: 0.1380 - val_loss: -330936.4062 - val_accuracy: 0.1222\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -307186.0312 - accuracy: 0.1314 - val_loss: -357295.9062 - val_accuracy: 0.1257\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -328315.4375 - accuracy: 0.1303 - val_loss: -381516.9062 - val_accuracy: 0.1246\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -349395.1562 - accuracy: 0.1424 - val_loss: -403567.7188 - val_accuracy: 0.1234\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -372153.4688 - accuracy: 0.1308 - val_loss: -431680.8438 - val_accuracy: 0.1246\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -396214.0312 - accuracy: 0.1338 - val_loss: -461693.3125 - val_accuracy: 0.1257\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -420298.4062 - accuracy: 0.1249 - val_loss: -488371.4375 - val_accuracy: 0.1246\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -447449.3125 - accuracy: 0.1180 - val_loss: -521192.0625 - val_accuracy: 0.1364\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -474424.7812 - accuracy: 0.1227 - val_loss: -549951.0000 - val_accuracy: 0.1246\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -502097.0312 - accuracy: 0.1276 - val_loss: -582571.5625 - val_accuracy: 0.1246\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -530148.5000 - accuracy: 0.1337 - val_loss: -612864.8125 - val_accuracy: 0.1246\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -559557.6250 - accuracy: 0.1266 - val_loss: -643775.1875 - val_accuracy: 0.1246\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -585132.2500 - accuracy: 0.1177 - val_loss: -677328.3750 - val_accuracy: 0.1246\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -618129.7500 - accuracy: 0.1204 - val_loss: -714567.0000 - val_accuracy: 0.1257\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -649086.5625 - accuracy: 0.1308 - val_loss: -742845.5625 - val_accuracy: 0.1234\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -680430.8125 - accuracy: 0.1194 - val_loss: -782765.5625 - val_accuracy: 0.1246\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -714523.5000 - accuracy: 0.1218 - val_loss: -828642.7500 - val_accuracy: 0.1898\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -748105.7500 - accuracy: 0.1378 - val_loss: -857398.0625 - val_accuracy: 0.1234\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -780664.8750 - accuracy: 0.1169 - val_loss: -905820.3125 - val_accuracy: 0.1234\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -819609.8125 - accuracy: 0.1358 - val_loss: -934845.5625 - val_accuracy: 0.1210\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -853517.6875 - accuracy: 0.1177 - val_loss: -980718.2500 - val_accuracy: 0.1246\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -892985.2500 - accuracy: 0.1191 - val_loss: -1030228.2500 - val_accuracy: 0.1246\n","Epoch 63/100\n","238/238 [==============================] - 1s 4ms/step - loss: -933621.0000 - accuracy: 0.1197 - val_loss: -1080748.8750 - val_accuracy: 0.1364\n","Epoch 64/100\n","238/238 [==============================] - 1s 4ms/step - loss: -970982.3125 - accuracy: 0.1218 - val_loss: -1117601.3750 - val_accuracy: 0.1246\n","Epoch 65/100\n","238/238 [==============================] - 1s 5ms/step - loss: -1011720.1875 - accuracy: 0.1201 - val_loss: -1165059.0000 - val_accuracy: 0.1246\n","Epoch 66/100\n","238/238 [==============================] - 1s 4ms/step - loss: -1054016.1250 - accuracy: 0.1189 - val_loss: -1211745.3750 - val_accuracy: 0.1246\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1096613.0000 - accuracy: 0.1246 - val_loss: -1263343.5000 - val_accuracy: 0.1246\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1143564.5000 - accuracy: 0.1200 - val_loss: -1323979.6250 - val_accuracy: 0.1364\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1191771.3750 - accuracy: 0.1217 - val_loss: -1376896.0000 - val_accuracy: 0.1257\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1243050.5000 - accuracy: 0.1237 - val_loss: -1423711.7500 - val_accuracy: 0.1246\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1291283.1250 - accuracy: 0.1225 - val_loss: -1472584.0000 - val_accuracy: 0.1210\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1343532.0000 - accuracy: 0.1193 - val_loss: -1551653.3750 - val_accuracy: 0.1257\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1399060.1250 - accuracy: 0.1192 - val_loss: -1610778.7500 - val_accuracy: 0.1257\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1454178.2500 - accuracy: 0.1212 - val_loss: -1683151.3750 - val_accuracy: 0.1364\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1510497.3750 - accuracy: 0.1230 - val_loss: -1733885.0000 - val_accuracy: 0.1246\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1567233.5000 - accuracy: 0.1218 - val_loss: -1789813.8750 - val_accuracy: 0.1222\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1627982.5000 - accuracy: 0.1187 - val_loss: -1865990.6250 - val_accuracy: 0.1246\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1688040.0000 - accuracy: 0.1192 - val_loss: -1931088.1250 - val_accuracy: 0.1246\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1753648.6250 - accuracy: 0.1196 - val_loss: -2018151.0000 - val_accuracy: 0.1257\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1815488.6250 - accuracy: 0.1181 - val_loss: -2076571.3750 - val_accuracy: 0.1246\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1883421.8750 - accuracy: 0.1200 - val_loss: -2156177.2500 - val_accuracy: 0.1246\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1950214.1250 - accuracy: 0.1191 - val_loss: -2239241.0000 - val_accuracy: 0.1246\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2016562.1250 - accuracy: 0.1179 - val_loss: -2306470.5000 - val_accuracy: 0.1246\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2087307.8750 - accuracy: 0.1180 - val_loss: -2394380.5000 - val_accuracy: 0.1257\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2153206.0000 - accuracy: 0.1205 - val_loss: -2469171.7500 - val_accuracy: 0.1246\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2228491.2500 - accuracy: 0.1191 - val_loss: -2563429.0000 - val_accuracy: 0.1257\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2300561.7500 - accuracy: 0.1292 - val_loss: -2598361.7500 - val_accuracy: 0.1198\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2380609.7500 - accuracy: 0.1177 - val_loss: -2737112.2500 - val_accuracy: 0.1257\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2454391.0000 - accuracy: 0.1247 - val_loss: -2805440.0000 - val_accuracy: 0.1246\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2534988.2500 - accuracy: 0.1206 - val_loss: -2875595.5000 - val_accuracy: 0.1222\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2619374.5000 - accuracy: 0.1179 - val_loss: -3011227.0000 - val_accuracy: 0.1257\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2699761.5000 - accuracy: 0.1233 - val_loss: -3061892.0000 - val_accuracy: 0.1222\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2775466.0000 - accuracy: 0.1194 - val_loss: -3166102.2500 - val_accuracy: 0.1246\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2860277.7500 - accuracy: 0.1191 - val_loss: -3264779.0000 - val_accuracy: 0.1246\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2948496.7500 - accuracy: 0.1187 - val_loss: -3387889.0000 - val_accuracy: 0.1257\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3028563.7500 - accuracy: 0.1276 - val_loss: -3452944.5000 - val_accuracy: 0.1257\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3109706.0000 - accuracy: 0.1204 - val_loss: -3560637.0000 - val_accuracy: 0.1257\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3192903.7500 - accuracy: 0.1214 - val_loss: -3639183.0000 - val_accuracy: 0.1257\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3279581.2500 - accuracy: 0.1192 - val_loss: -3739313.0000 - val_accuracy: 0.1257\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3366096.7500 - accuracy: 0.1193 - val_loss: -3837419.2500 - val_accuracy: 0.1257\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.06      0.11       271\n","           1       0.11      0.99      0.20        91\n","           2       0.00      0.00      0.00       152\n","           3       0.00      0.00      0.00       193\n","           4       0.00      0.00      0.00       136\n","\n","    accuracy                           0.13       843\n","   macro avg       0.19      0.21      0.06       843\n","weighted avg       0.28      0.13      0.06       843\n","\n","Accuracy: 0.1257413997627521\n","[[ 16 255   0   0   0]\n"," [  1  90   0   0   0]\n"," [  0 152   0   0   0]\n"," [  2 191   0   0   0]\n"," [  0 136   0   0   0]]\n","Precision: 0.2825\n","Recall: 0.1257\n","F1 Score: 0.0567\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://d3c112c6-0fc3-419a-ad1c-078a0d96d616/assets\n","model 2 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 4ms/step - loss: 58.1056 - accuracy: 0.1136 - val_loss: -62.8636 - val_accuracy: 0.1068\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -126.9797 - accuracy: 0.1049 - val_loss: -382.8535 - val_accuracy: 0.1068\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -373.9973 - accuracy: 0.1048 - val_loss: -942.3461 - val_accuracy: 0.1044\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -752.2592 - accuracy: 0.1072 - val_loss: -1710.4470 - val_accuracy: 0.1044\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1292.1948 - accuracy: 0.1092 - val_loss: -2809.3396 - val_accuracy: 0.1091\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2033.6929 - accuracy: 0.1122 - val_loss: -4271.2007 - val_accuracy: 0.1079\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2995.0859 - accuracy: 0.1102 - val_loss: -6276.6855 - val_accuracy: 0.1079\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4227.3594 - accuracy: 0.1093 - val_loss: -8616.2695 - val_accuracy: 0.1068\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5692.3335 - accuracy: 0.1110 - val_loss: -11353.1055 - val_accuracy: 0.1139\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7341.5117 - accuracy: 0.1115 - val_loss: -14407.0879 - val_accuracy: 0.1151\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9237.2422 - accuracy: 0.1131 - val_loss: -17948.0312 - val_accuracy: 0.1127\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11495.2412 - accuracy: 0.1160 - val_loss: -22299.5938 - val_accuracy: 0.1151\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13951.5498 - accuracy: 0.1188 - val_loss: -27139.2344 - val_accuracy: 0.1317\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -16790.8828 - accuracy: 0.1227 - val_loss: -32368.9688 - val_accuracy: 0.1257\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -19782.5625 - accuracy: 0.1204 - val_loss: -37733.5898 - val_accuracy: 0.1174\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -22970.8281 - accuracy: 0.1205 - val_loss: -43542.9141 - val_accuracy: 0.1115\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -25985.1367 - accuracy: 0.1205 - val_loss: -48210.0078 - val_accuracy: 0.1340\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -29203.2539 - accuracy: 0.1249 - val_loss: -54650.3398 - val_accuracy: 0.1139\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -32736.2441 - accuracy: 0.1220 - val_loss: -61107.8945 - val_accuracy: 0.1174\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -36460.8516 - accuracy: 0.1223 - val_loss: -68022.5469 - val_accuracy: 0.1376\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -40559.7578 - accuracy: 0.1243 - val_loss: -75524.7344 - val_accuracy: 0.1435\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -44953.4297 - accuracy: 0.1252 - val_loss: -83346.0234 - val_accuracy: 0.1198\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -49639.5508 - accuracy: 0.1266 - val_loss: -92013.7969 - val_accuracy: 0.1186\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -54531.4102 - accuracy: 0.1231 - val_loss: -101449.3359 - val_accuracy: 0.1174\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -59859.5078 - accuracy: 0.1270 - val_loss: -110520.3828 - val_accuracy: 0.1174\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -65398.8555 - accuracy: 0.1270 - val_loss: -121355.4062 - val_accuracy: 0.1139\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -71339.0859 - accuracy: 0.1258 - val_loss: -131932.8750 - val_accuracy: 0.1103\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -77698.5469 - accuracy: 0.1212 - val_loss: -143274.4844 - val_accuracy: 0.1174\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -84395.3125 - accuracy: 0.1245 - val_loss: -155196.8594 - val_accuracy: 0.1115\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -91288.7344 - accuracy: 0.1233 - val_loss: -167634.7656 - val_accuracy: 0.1115\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -98339.8672 - accuracy: 0.1222 - val_loss: -180894.5781 - val_accuracy: 0.1163\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -105952.0469 - accuracy: 0.1205 - val_loss: -194647.2812 - val_accuracy: 0.1376\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -113983.8516 - accuracy: 0.1247 - val_loss: -209739.2344 - val_accuracy: 0.1376\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -122192.6562 - accuracy: 0.1246 - val_loss: -224999.8906 - val_accuracy: 0.1376\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -130893.5625 - accuracy: 0.1234 - val_loss: -241021.9688 - val_accuracy: 0.1400\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -139905.2344 - accuracy: 0.1194 - val_loss: -257433.1875 - val_accuracy: 0.1174\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -149188.0312 - accuracy: 0.1194 - val_loss: -273878.5938 - val_accuracy: 0.1352\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -159654.7188 - accuracy: 0.1213 - val_loss: -291259.9688 - val_accuracy: 0.1115\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -169203.7031 - accuracy: 0.1147 - val_loss: -309242.5625 - val_accuracy: 0.1269\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -179229.0156 - accuracy: 0.1196 - val_loss: -327901.3438 - val_accuracy: 0.1115\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -189643.8438 - accuracy: 0.1155 - val_loss: -346322.2188 - val_accuracy: 0.1246\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -200563.8281 - accuracy: 0.1181 - val_loss: -366156.3125 - val_accuracy: 0.1174\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -211926.6562 - accuracy: 0.1216 - val_loss: -386789.8125 - val_accuracy: 0.1127\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -223722.4375 - accuracy: 0.1179 - val_loss: -407887.8750 - val_accuracy: 0.1127\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -235972.8281 - accuracy: 0.1176 - val_loss: -429060.6250 - val_accuracy: 0.1222\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -248943.6875 - accuracy: 0.1216 - val_loss: -453973.5938 - val_accuracy: 0.1139\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -262194.1250 - accuracy: 0.1173 - val_loss: -478137.6875 - val_accuracy: 0.1210\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -276161.8438 - accuracy: 0.1179 - val_loss: -503354.8750 - val_accuracy: 0.1222\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -290464.6875 - accuracy: 0.1210 - val_loss: -528784.1250 - val_accuracy: 0.1222\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -303999.1250 - accuracy: 0.1193 - val_loss: -544417.6250 - val_accuracy: 0.1139\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -310374.4062 - accuracy: 0.1171 - val_loss: -554605.4375 - val_accuracy: 0.1186\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -316998.4688 - accuracy: 0.1176 - val_loss: -567333.7500 - val_accuracy: 0.1186\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -324403.0625 - accuracy: 0.1191 - val_loss: -579985.5000 - val_accuracy: 0.1257\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -332753.5938 - accuracy: 0.1227 - val_loss: -594466.4375 - val_accuracy: 0.1257\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -341616.6875 - accuracy: 0.1204 - val_loss: -609882.5625 - val_accuracy: 0.1222\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -351742.5938 - accuracy: 0.1188 - val_loss: -628780.4375 - val_accuracy: 0.1234\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -362692.8438 - accuracy: 0.1212 - val_loss: -649288.0625 - val_accuracy: 0.1139\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -374658.3750 - accuracy: 0.1177 - val_loss: -671580.3125 - val_accuracy: 0.1139\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -387586.9375 - accuracy: 0.1191 - val_loss: -694673.6875 - val_accuracy: 0.1222\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -401735.1562 - accuracy: 0.1189 - val_loss: -721156.5000 - val_accuracy: 0.1174\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -416674.1875 - accuracy: 0.1160 - val_loss: -747590.0625 - val_accuracy: 0.1198\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -432683.4062 - accuracy: 0.1202 - val_loss: -776783.3125 - val_accuracy: 0.1257\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -449534.8438 - accuracy: 0.1164 - val_loss: -808350.5000 - val_accuracy: 0.1246\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -467296.8750 - accuracy: 0.1229 - val_loss: -841658.6250 - val_accuracy: 0.1174\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -485998.7500 - accuracy: 0.1185 - val_loss: -873746.5000 - val_accuracy: 0.1139\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -505634.2812 - accuracy: 0.1171 - val_loss: -908490.6250 - val_accuracy: 0.1234\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -525775.7500 - accuracy: 0.1227 - val_loss: -944115.7500 - val_accuracy: 0.1151\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -546987.7500 - accuracy: 0.1147 - val_loss: -985327.3125 - val_accuracy: 0.1151\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -568956.5625 - accuracy: 0.1180 - val_loss: -1026015.0000 - val_accuracy: 0.1222\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -591534.5625 - accuracy: 0.1229 - val_loss: -1063237.3750 - val_accuracy: 0.1222\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -614352.5625 - accuracy: 0.1193 - val_loss: -1107133.6250 - val_accuracy: 0.1186\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -637773.9375 - accuracy: 0.1209 - val_loss: -1147593.0000 - val_accuracy: 0.1210\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -661857.5625 - accuracy: 0.1212 - val_loss: -1190083.3750 - val_accuracy: 0.1127\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -686518.1250 - accuracy: 0.1158 - val_loss: -1234705.1250 - val_accuracy: 0.1234\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -712173.0625 - accuracy: 0.1255 - val_loss: -1281348.5000 - val_accuracy: 0.1257\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -738432.1250 - accuracy: 0.1208 - val_loss: -1329066.8750 - val_accuracy: 0.1257\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -765732.5625 - accuracy: 0.1235 - val_loss: -1375784.8750 - val_accuracy: 0.1246\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -793615.6875 - accuracy: 0.1217 - val_loss: -1426621.5000 - val_accuracy: 0.1210\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -821957.5625 - accuracy: 0.1212 - val_loss: -1476785.2500 - val_accuracy: 0.1257\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -851090.1250 - accuracy: 0.1192 - val_loss: -1531083.1250 - val_accuracy: 0.1127\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -880624.8125 - accuracy: 0.1208 - val_loss: -1581611.1250 - val_accuracy: 0.1234\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -911190.9375 - accuracy: 0.1202 - val_loss: -1640345.0000 - val_accuracy: 0.1246\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -942556.7500 - accuracy: 0.1202 - val_loss: -1695175.5000 - val_accuracy: 0.1151\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -974459.6250 - accuracy: 0.1198 - val_loss: -1749078.2500 - val_accuracy: 0.1198\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1007018.3125 - accuracy: 0.1210 - val_loss: -1805799.0000 - val_accuracy: 0.1269\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1039731.1875 - accuracy: 0.1210 - val_loss: -1867730.8750 - val_accuracy: 0.1234\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1072981.7500 - accuracy: 0.1231 - val_loss: -1924398.6250 - val_accuracy: 0.1163\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1107350.5000 - accuracy: 0.1210 - val_loss: -1986372.0000 - val_accuracy: 0.1257\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1141655.6250 - accuracy: 0.1231 - val_loss: -2049060.2500 - val_accuracy: 0.1234\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1177720.2500 - accuracy: 0.1179 - val_loss: -2115661.0000 - val_accuracy: 0.1210\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1213067.1250 - accuracy: 0.1246 - val_loss: -2179483.0000 - val_accuracy: 0.1246\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1249391.5000 - accuracy: 0.1254 - val_loss: -2241025.2500 - val_accuracy: 0.1210\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1286403.8750 - accuracy: 0.1218 - val_loss: -2307249.5000 - val_accuracy: 0.1257\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1324243.8750 - accuracy: 0.1206 - val_loss: -2377572.7500 - val_accuracy: 0.1234\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1362150.3750 - accuracy: 0.1223 - val_loss: -2442653.0000 - val_accuracy: 0.1222\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1401329.8750 - accuracy: 0.1217 - val_loss: -2513318.0000 - val_accuracy: 0.1139\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1441196.6250 - accuracy: 0.1223 - val_loss: -2583437.2500 - val_accuracy: 0.1234\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1481912.2500 - accuracy: 0.1218 - val_loss: -2649325.5000 - val_accuracy: 0.1257\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1522738.3750 - accuracy: 0.1249 - val_loss: -2724721.5000 - val_accuracy: 0.1246\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1564669.7500 - accuracy: 0.1227 - val_loss: -2801857.5000 - val_accuracy: 0.1222\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.06      0.10       266\n","           1       0.11      0.98      0.19        90\n","           2       0.00      0.00      0.00       186\n","           3       0.00      0.00      0.00       179\n","           4       0.00      0.00      0.00       122\n","\n","    accuracy                           0.12       843\n","   macro avg       0.16      0.21      0.06       843\n","weighted avg       0.23      0.12      0.05       843\n","\n","Accuracy: 0.1221826809015421\n","[[ 15 251   0   0   0]\n"," [  2  88   0   0   0]\n"," [  3 183   0   0   0]\n"," [  0 179   0   0   0]\n"," [  2 120   0   0   0]]\n","Precision: 0.2266\n","Recall: 0.1222\n","F1 Score: 0.0535\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://1d153a16-1a03-42b7-abc8-91c1742998cf/assets\n","model 3 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 4.7957 - accuracy: 0.1446 - val_loss: 46.8994 - val_accuracy: 0.2633\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -256.5463 - accuracy: 0.1549 - val_loss: -547.7361 - val_accuracy: 0.0949\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -702.7317 - accuracy: 0.1601 - val_loss: -1078.0341 - val_accuracy: 0.2005\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1334.1093 - accuracy: 0.1595 - val_loss: -2164.8662 - val_accuracy: 0.1708\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2265.2305 - accuracy: 0.1635 - val_loss: -3544.0305 - val_accuracy: 0.1637\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3530.2529 - accuracy: 0.1504 - val_loss: -5487.3062 - val_accuracy: 0.1032\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5344.4219 - accuracy: 0.1495 - val_loss: -8286.2266 - val_accuracy: 0.1079\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7840.0859 - accuracy: 0.1403 - val_loss: -11715.7939 - val_accuracy: 0.0949\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10651.8936 - accuracy: 0.1368 - val_loss: -15684.4355 - val_accuracy: 0.0996\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14072.4209 - accuracy: 0.1345 - val_loss: -19950.2793 - val_accuracy: 0.1198\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -18108.0664 - accuracy: 0.1334 - val_loss: -25656.6660 - val_accuracy: 0.1056\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -22596.1367 - accuracy: 0.1341 - val_loss: -31807.5137 - val_accuracy: 0.1079\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -28287.8965 - accuracy: 0.1266 - val_loss: -39014.3398 - val_accuracy: 0.1079\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -34403.4961 - accuracy: 0.1281 - val_loss: -47488.1680 - val_accuracy: 0.1091\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -41488.7773 - accuracy: 0.1312 - val_loss: -56730.2266 - val_accuracy: 0.1079\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -49634.7188 - accuracy: 0.1259 - val_loss: -67065.0312 - val_accuracy: 0.1091\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -58766.3516 - accuracy: 0.1274 - val_loss: -78532.0703 - val_accuracy: 0.1091\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -68689.8281 - accuracy: 0.1289 - val_loss: -92447.5469 - val_accuracy: 0.1056\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -79747.0469 - accuracy: 0.1218 - val_loss: -106193.9297 - val_accuracy: 0.1079\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -91964.1719 - accuracy: 0.1231 - val_loss: -122119.3828 - val_accuracy: 0.1056\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -105015.1250 - accuracy: 0.1238 - val_loss: -138192.3750 - val_accuracy: 0.1079\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -119023.9141 - accuracy: 0.1229 - val_loss: -156472.8125 - val_accuracy: 0.1079\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -134452.9375 - accuracy: 0.1242 - val_loss: -177123.6875 - val_accuracy: 0.1079\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -151289.5469 - accuracy: 0.1225 - val_loss: -197472.2500 - val_accuracy: 0.1079\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -169279.5469 - accuracy: 0.1304 - val_loss: -220678.5938 - val_accuracy: 0.1056\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -188211.4219 - accuracy: 0.1214 - val_loss: -241580.1250 - val_accuracy: 0.1115\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -208505.5000 - accuracy: 0.1237 - val_loss: -269199.9688 - val_accuracy: 0.1079\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -230647.9062 - accuracy: 0.1330 - val_loss: -298246.5312 - val_accuracy: 0.1079\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -253740.0156 - accuracy: 0.1222 - val_loss: -325361.3438 - val_accuracy: 0.1079\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -279186.7500 - accuracy: 0.1271 - val_loss: -361278.7812 - val_accuracy: 0.1044\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -305510.5938 - accuracy: 0.1264 - val_loss: -391228.6250 - val_accuracy: 0.1079\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -333190.2500 - accuracy: 0.1284 - val_loss: -427285.5000 - val_accuracy: 0.1079\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -361911.3750 - accuracy: 0.1214 - val_loss: -460608.1875 - val_accuracy: 0.1079\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -393263.5625 - accuracy: 0.1227 - val_loss: -498628.6562 - val_accuracy: 0.1079\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -424185.1250 - accuracy: 0.1185 - val_loss: -536362.7500 - val_accuracy: 0.1079\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -454044.0000 - accuracy: 0.1271 - val_loss: -569343.6875 - val_accuracy: 0.1091\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -490447.6562 - accuracy: 0.1221 - val_loss: -619925.1875 - val_accuracy: 0.1079\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -524817.3750 - accuracy: 0.1214 - val_loss: -651407.6875 - val_accuracy: 0.1186\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -560708.8125 - accuracy: 0.1255 - val_loss: -697725.6250 - val_accuracy: 0.1091\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -599187.8750 - accuracy: 0.1241 - val_loss: -751176.2500 - val_accuracy: 0.1079\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -640882.4375 - accuracy: 0.1249 - val_loss: -803260.4375 - val_accuracy: 0.1079\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -682857.1250 - accuracy: 0.1255 - val_loss: -854219.9375 - val_accuracy: 0.1079\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -728033.8750 - accuracy: 0.1229 - val_loss: -906188.0625 - val_accuracy: 0.1079\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -777111.6250 - accuracy: 0.1237 - val_loss: -974048.8750 - val_accuracy: 0.1056\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -823952.0625 - accuracy: 0.1220 - val_loss: -1027653.7500 - val_accuracy: 0.1079\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -874797.5000 - accuracy: 0.1214 - val_loss: -1085489.3750 - val_accuracy: 0.1079\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -929966.0000 - accuracy: 0.1291 - val_loss: -1165070.7500 - val_accuracy: 0.1056\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -983125.7500 - accuracy: 0.1222 - val_loss: -1221257.1250 - val_accuracy: 0.1079\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1042296.9375 - accuracy: 0.1205 - val_loss: -1287893.6250 - val_accuracy: 0.1079\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1101046.8750 - accuracy: 0.1230 - val_loss: -1359603.3750 - val_accuracy: 0.1079\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1161632.0000 - accuracy: 0.1231 - val_loss: -1437610.0000 - val_accuracy: 0.1079\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1224324.7500 - accuracy: 0.1213 - val_loss: -1512668.0000 - val_accuracy: 0.1079\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1290563.2500 - accuracy: 0.1231 - val_loss: -1583715.0000 - val_accuracy: 0.1091\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1357957.1250 - accuracy: 0.1239 - val_loss: -1675863.1250 - val_accuracy: 0.1079\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1426509.6250 - accuracy: 0.1218 - val_loss: -1754120.2500 - val_accuracy: 0.1079\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1499397.7500 - accuracy: 0.1229 - val_loss: -1833814.8750 - val_accuracy: 0.1091\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1572459.0000 - accuracy: 0.1275 - val_loss: -1940734.6250 - val_accuracy: 0.1079\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1651415.0000 - accuracy: 0.1234 - val_loss: -2037301.0000 - val_accuracy: 0.1079\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1730081.0000 - accuracy: 0.1234 - val_loss: -2126923.5000 - val_accuracy: 0.1079\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1813250.7500 - accuracy: 0.1229 - val_loss: -2228176.7500 - val_accuracy: 0.1079\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1899346.7500 - accuracy: 0.1227 - val_loss: -2328064.5000 - val_accuracy: 0.1079\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1989454.7500 - accuracy: 0.1225 - val_loss: -2434658.7500 - val_accuracy: 0.1079\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2079607.1250 - accuracy: 0.1238 - val_loss: -2551198.2500 - val_accuracy: 0.1079\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2176639.5000 - accuracy: 0.1209 - val_loss: -2678659.2500 - val_accuracy: 0.1079\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2268488.2500 - accuracy: 0.1227 - val_loss: -2773605.5000 - val_accuracy: 0.1079\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2366880.2500 - accuracy: 0.1223 - val_loss: -2885528.2500 - val_accuracy: 0.1079\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2470069.2500 - accuracy: 0.1234 - val_loss: -3001657.7500 - val_accuracy: 0.1079\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2572196.2500 - accuracy: 0.1239 - val_loss: -3140725.7500 - val_accuracy: 0.1079\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2677715.5000 - accuracy: 0.1222 - val_loss: -3263496.0000 - val_accuracy: 0.1079\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2786770.7500 - accuracy: 0.1227 - val_loss: -3379159.0000 - val_accuracy: 0.1079\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2894970.7500 - accuracy: 0.1237 - val_loss: -3527315.0000 - val_accuracy: 0.1079\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3009604.5000 - accuracy: 0.1230 - val_loss: -3669096.2500 - val_accuracy: 0.1079\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3132602.5000 - accuracy: 0.1205 - val_loss: -3786450.2500 - val_accuracy: 0.1091\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3250837.2500 - accuracy: 0.1233 - val_loss: -3925996.2500 - val_accuracy: 0.1091\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3379917.2500 - accuracy: 0.1239 - val_loss: -4109063.2500 - val_accuracy: 0.1079\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3503643.2500 - accuracy: 0.1206 - val_loss: -4257835.5000 - val_accuracy: 0.1079\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3638311.5000 - accuracy: 0.1225 - val_loss: -4401687.5000 - val_accuracy: 0.1079\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3773637.7500 - accuracy: 0.1226 - val_loss: -4569077.5000 - val_accuracy: 0.1079\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3911811.2500 - accuracy: 0.1222 - val_loss: -4707377.0000 - val_accuracy: 0.1091\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4037323.5000 - accuracy: 0.1234 - val_loss: -4873983.5000 - val_accuracy: 0.1091\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4184358.0000 - accuracy: 0.1238 - val_loss: -5071643.5000 - val_accuracy: 0.1079\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4322484.0000 - accuracy: 0.1221 - val_loss: -5243633.5000 - val_accuracy: 0.1079\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4473044.0000 - accuracy: 0.1229 - val_loss: -5422458.0000 - val_accuracy: 0.1079\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4635873.5000 - accuracy: 0.1229 - val_loss: -5599242.5000 - val_accuracy: 0.1079\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4778569.0000 - accuracy: 0.1231 - val_loss: -5786926.0000 - val_accuracy: 0.1079\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4931868.5000 - accuracy: 0.1223 - val_loss: -5946967.0000 - val_accuracy: 0.1091\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5097036.0000 - accuracy: 0.1231 - val_loss: -6146071.5000 - val_accuracy: 0.1079\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5262359.0000 - accuracy: 0.1229 - val_loss: -6378600.0000 - val_accuracy: 0.1079\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5428771.5000 - accuracy: 0.1212 - val_loss: -6540721.0000 - val_accuracy: 0.1079\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5585803.0000 - accuracy: 0.1223 - val_loss: -6726723.0000 - val_accuracy: 0.1079\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5761573.5000 - accuracy: 0.1233 - val_loss: -6957034.0000 - val_accuracy: 0.1079\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5937081.5000 - accuracy: 0.1222 - val_loss: -7149099.0000 - val_accuracy: 0.1079\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6108317.0000 - accuracy: 0.1231 - val_loss: -7364834.5000 - val_accuracy: 0.1079\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6301258.5000 - accuracy: 0.1226 - val_loss: -7568472.5000 - val_accuracy: 0.1079\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6492932.0000 - accuracy: 0.1238 - val_loss: -7800292.0000 - val_accuracy: 0.1079\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6679995.0000 - accuracy: 0.1230 - val_loss: -8018222.0000 - val_accuracy: 0.1079\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6869153.0000 - accuracy: 0.1235 - val_loss: -8253449.5000 - val_accuracy: 0.1079\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7065361.5000 - accuracy: 0.1230 - val_loss: -8491705.0000 - val_accuracy: 0.1079\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7275099.0000 - accuracy: 0.1238 - val_loss: -8766831.0000 - val_accuracy: 0.1079\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7474148.5000 - accuracy: 0.1221 - val_loss: -8985627.0000 - val_accuracy: 0.1079\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.05      0.10       283\n","           1       0.09      1.00      0.17        76\n","           2       0.00      0.00      0.00       161\n","           3       0.00      0.00      0.00       198\n","           4       0.00      0.00      0.00       125\n","\n","    accuracy                           0.11       843\n","   macro avg       0.16      0.21      0.05       843\n","weighted avg       0.25      0.11      0.05       843\n","\n","Accuracy: 0.10794780545670225\n","[[ 15 268   0   0   0]\n"," [  0  76   0   0   0]\n"," [  0 161   0   0   0]\n"," [  6 192   0   0   0]\n"," [  0 125   0   0   0]]\n","Precision: 0.2481\n","Recall: 0.1079\n","F1 Score: 0.0484\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://129f95c2-607f-4bfe-9ce0-44f7147d138f/assets\n","model 4 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 444.4575 - accuracy: 0.1643 - val_loss: -289.5561 - val_accuracy: 0.2040\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -386.0880 - accuracy: 0.1678 - val_loss: -967.6592 - val_accuracy: 0.1684\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -860.5122 - accuracy: 0.1697 - val_loss: -1789.8811 - val_accuracy: 0.1684\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1476.2579 - accuracy: 0.1721 - val_loss: -2872.0149 - val_accuracy: 0.1708\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2313.0657 - accuracy: 0.1719 - val_loss: -4467.2109 - val_accuracy: 0.1139\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3488.2510 - accuracy: 0.1764 - val_loss: -6542.7441 - val_accuracy: 0.1139\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4956.1743 - accuracy: 0.1672 - val_loss: -8934.0264 - val_accuracy: 0.1163\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6788.1670 - accuracy: 0.1577 - val_loss: -12161.6572 - val_accuracy: 0.1862\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8945.9355 - accuracy: 0.1673 - val_loss: -15821.6777 - val_accuracy: 0.1151\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11452.5547 - accuracy: 0.1540 - val_loss: -19975.1191 - val_accuracy: 0.1756\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14435.4707 - accuracy: 0.1572 - val_loss: -24675.1758 - val_accuracy: 0.1661\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -17782.9609 - accuracy: 0.1442 - val_loss: -30493.2480 - val_accuracy: 0.1708\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -21522.6504 - accuracy: 0.1594 - val_loss: -36693.6328 - val_accuracy: 0.1115\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -25691.1543 - accuracy: 0.1448 - val_loss: -43443.8008 - val_accuracy: 0.1127\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -30372.3438 - accuracy: 0.1403 - val_loss: -50782.3438 - val_accuracy: 0.1756\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -35661.6875 - accuracy: 0.1413 - val_loss: -59542.8750 - val_accuracy: 0.1174\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -41652.1484 - accuracy: 0.1378 - val_loss: -68949.7500 - val_accuracy: 0.1234\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -48337.1133 - accuracy: 0.1400 - val_loss: -79293.2422 - val_accuracy: 0.1246\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -55341.1719 - accuracy: 0.1426 - val_loss: -90890.8906 - val_accuracy: 0.1210\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -62974.2305 - accuracy: 0.1395 - val_loss: -102485.1094 - val_accuracy: 0.1234\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -71415.1875 - accuracy: 0.1400 - val_loss: -115791.9062 - val_accuracy: 0.1234\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -80499.0547 - accuracy: 0.1386 - val_loss: -129679.2031 - val_accuracy: 0.1210\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -89867.6328 - accuracy: 0.1383 - val_loss: -144604.9531 - val_accuracy: 0.1257\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -100267.0078 - accuracy: 0.1415 - val_loss: -160050.2188 - val_accuracy: 0.1340\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -111169.9609 - accuracy: 0.1400 - val_loss: -176798.1562 - val_accuracy: 0.1222\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -122498.9609 - accuracy: 0.1312 - val_loss: -193432.7500 - val_accuracy: 0.1791\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -134905.7031 - accuracy: 0.1579 - val_loss: -213931.0469 - val_accuracy: 0.1257\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -148275.6562 - accuracy: 0.1426 - val_loss: -232829.8594 - val_accuracy: 0.1340\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -161857.5469 - accuracy: 0.1339 - val_loss: -254277.2969 - val_accuracy: 0.1317\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -176593.9688 - accuracy: 0.1459 - val_loss: -276736.1875 - val_accuracy: 0.1210\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -191796.8750 - accuracy: 0.1424 - val_loss: -300437.8438 - val_accuracy: 0.1234\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -208110.0938 - accuracy: 0.1380 - val_loss: -323884.3438 - val_accuracy: 0.1708\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -225372.1406 - accuracy: 0.1312 - val_loss: -350343.7812 - val_accuracy: 0.1340\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -243551.7812 - accuracy: 0.1342 - val_loss: -377362.5312 - val_accuracy: 0.1791\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -262515.4062 - accuracy: 0.1436 - val_loss: -405935.5000 - val_accuracy: 0.1791\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -282620.1875 - accuracy: 0.1491 - val_loss: -437348.0000 - val_accuracy: 0.1269\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -303494.7812 - accuracy: 0.1299 - val_loss: -465716.6250 - val_accuracy: 0.1791\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -325018.1250 - accuracy: 0.1362 - val_loss: -501167.7188 - val_accuracy: 0.1246\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -347750.5000 - accuracy: 0.1275 - val_loss: -532345.9375 - val_accuracy: 0.1518\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -370981.2500 - accuracy: 0.1303 - val_loss: -569124.5000 - val_accuracy: 0.1246\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -395344.1875 - accuracy: 0.1304 - val_loss: -606694.9375 - val_accuracy: 0.1246\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -421290.2188 - accuracy: 0.1329 - val_loss: -644518.3125 - val_accuracy: 0.1269\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -448365.5938 - accuracy: 0.1271 - val_loss: -685323.1875 - val_accuracy: 0.1234\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -475827.4062 - accuracy: 0.1254 - val_loss: -727043.8125 - val_accuracy: 0.1257\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -504599.3438 - accuracy: 0.1276 - val_loss: -768367.3125 - val_accuracy: 0.1352\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -534635.1250 - accuracy: 0.1292 - val_loss: -815525.1875 - val_accuracy: 0.1234\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -566170.5000 - accuracy: 0.1287 - val_loss: -862683.5000 - val_accuracy: 0.1234\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -598615.1250 - accuracy: 0.1284 - val_loss: -911521.5625 - val_accuracy: 0.1234\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -632183.1875 - accuracy: 0.1284 - val_loss: -955992.8750 - val_accuracy: 0.1246\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -667048.3750 - accuracy: 0.1237 - val_loss: -1010524.6875 - val_accuracy: 0.1269\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -703578.1250 - accuracy: 0.1280 - val_loss: -1062870.5000 - val_accuracy: 0.1269\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -740823.8125 - accuracy: 0.1289 - val_loss: -1120409.5000 - val_accuracy: 0.1269\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -772098.8125 - accuracy: 0.1109 - val_loss: -1176923.3750 - val_accuracy: 0.1222\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -812131.6875 - accuracy: 0.1179 - val_loss: -1227398.2500 - val_accuracy: 0.1234\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -845958.6875 - accuracy: 0.1185 - val_loss: -1274691.8750 - val_accuracy: 0.1234\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -881250.5000 - accuracy: 0.1208 - val_loss: -1325399.0000 - val_accuracy: 0.1246\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -917861.8750 - accuracy: 0.1214 - val_loss: -1381257.1250 - val_accuracy: 0.1246\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -956782.8750 - accuracy: 0.1218 - val_loss: -1438409.5000 - val_accuracy: 0.1246\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -996999.0000 - accuracy: 0.1200 - val_loss: -1496061.7500 - val_accuracy: 0.1257\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1038506.8750 - accuracy: 0.1221 - val_loss: -1561596.0000 - val_accuracy: 0.1246\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1082301.5000 - accuracy: 0.1213 - val_loss: -1626112.0000 - val_accuracy: 0.1246\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1127357.8750 - accuracy: 0.1205 - val_loss: -1692879.6250 - val_accuracy: 0.1246\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1175075.2500 - accuracy: 0.1214 - val_loss: -1761979.2500 - val_accuracy: 0.1246\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1224129.3750 - accuracy: 0.1212 - val_loss: -1836021.3750 - val_accuracy: 0.1246\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1277167.0000 - accuracy: 0.1285 - val_loss: -1918523.5000 - val_accuracy: 0.1234\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1328858.3750 - accuracy: 0.1200 - val_loss: -1992711.5000 - val_accuracy: 0.1246\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1379736.5000 - accuracy: 0.1213 - val_loss: -2045927.2500 - val_accuracy: 0.1269\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1409326.1250 - accuracy: 0.1220 - val_loss: -2087152.0000 - val_accuracy: 0.1246\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1438824.5000 - accuracy: 0.1231 - val_loss: -2126894.7500 - val_accuracy: 0.1269\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1468793.5000 - accuracy: 0.1333 - val_loss: -2168797.7500 - val_accuracy: 0.1269\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1502724.1250 - accuracy: 0.1223 - val_loss: -2219492.0000 - val_accuracy: 0.1269\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1540077.3750 - accuracy: 0.1272 - val_loss: -2274613.2500 - val_accuracy: 0.1257\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1580098.2500 - accuracy: 0.1243 - val_loss: -2334838.5000 - val_accuracy: 0.1246\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1624642.7500 - accuracy: 0.1223 - val_loss: -2398798.2500 - val_accuracy: 0.1246\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1670817.6250 - accuracy: 0.1197 - val_loss: -2468195.7500 - val_accuracy: 0.1234\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1721440.6250 - accuracy: 0.1268 - val_loss: -2542945.2500 - val_accuracy: 0.1234\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1776163.5000 - accuracy: 0.1317 - val_loss: -2626858.2500 - val_accuracy: 0.1198\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1830595.6250 - accuracy: 0.1192 - val_loss: -2703751.2500 - val_accuracy: 0.1246\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1892654.3750 - accuracy: 0.1216 - val_loss: -2795548.7500 - val_accuracy: 0.1246\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1955533.8750 - accuracy: 0.1198 - val_loss: -2881603.5000 - val_accuracy: 0.1246\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2021387.2500 - accuracy: 0.1279 - val_loss: -2987410.0000 - val_accuracy: 0.1234\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2090943.7500 - accuracy: 0.1210 - val_loss: -3085144.0000 - val_accuracy: 0.1246\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2162149.2500 - accuracy: 0.1222 - val_loss: -3189975.2500 - val_accuracy: 0.1246\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2235578.0000 - accuracy: 0.1210 - val_loss: -3297605.0000 - val_accuracy: 0.1246\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2311193.7500 - accuracy: 0.1297 - val_loss: -3411927.0000 - val_accuracy: 0.1246\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2390148.0000 - accuracy: 0.1200 - val_loss: -3522930.5000 - val_accuracy: 0.1246\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2470639.5000 - accuracy: 0.1337 - val_loss: -3648639.5000 - val_accuracy: 0.1246\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2549397.5000 - accuracy: 0.1445 - val_loss: -3769139.2500 - val_accuracy: 0.1246\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2630885.0000 - accuracy: 0.1250 - val_loss: -3863279.0000 - val_accuracy: 0.1708\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2713243.7500 - accuracy: 0.1452 - val_loss: -4004400.2500 - val_accuracy: 0.1246\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2802122.0000 - accuracy: 0.1214 - val_loss: -4127693.5000 - val_accuracy: 0.1329\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2890987.2500 - accuracy: 0.1308 - val_loss: -4262279.0000 - val_accuracy: 0.1246\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2982740.5000 - accuracy: 0.1459 - val_loss: -4399533.0000 - val_accuracy: 0.1246\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3076215.2500 - accuracy: 0.1293 - val_loss: -4542668.5000 - val_accuracy: 0.1246\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3172558.2500 - accuracy: 0.1205 - val_loss: -4677860.0000 - val_accuracy: 0.1246\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3270256.5000 - accuracy: 0.1213 - val_loss: -4821042.5000 - val_accuracy: 0.1246\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3370906.5000 - accuracy: 0.1206 - val_loss: -4960472.0000 - val_accuracy: 0.1246\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3474349.2500 - accuracy: 0.1254 - val_loss: -5113360.0000 - val_accuracy: 0.1246\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3578911.7500 - accuracy: 0.1209 - val_loss: -5268011.5000 - val_accuracy: 0.1246\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3687812.7500 - accuracy: 0.1254 - val_loss: -5430425.0000 - val_accuracy: 0.1246\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.06      0.10       265\n","           1       0.11      1.00      0.20        90\n","           2       0.00      0.00      0.00       170\n","           3       0.00      0.00      0.00       195\n","           4       0.00      0.00      0.00       123\n","\n","    accuracy                           0.12       843\n","   macro avg       0.16      0.21      0.06       843\n","weighted avg       0.23      0.12      0.05       843\n","\n","Accuracy: 0.12455516014234876\n","[[ 15 250   0   0   0]\n"," [  0  90   0   0   0]\n"," [  0 170   0   0   0]\n"," [  7 188   0   0   0]\n"," [  0 123   0   0   0]]\n","Precision: 0.2260\n","Recall: 0.1246\n","F1 Score: 0.0540\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://05976e5a-36ca-463c-bec5-bd836bd6c949/assets\n","model 5 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: -295.7018 - accuracy: 0.1462 - val_loss: -479.0841 - val_accuracy: 0.1044\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1525.2767 - accuracy: 0.1438 - val_loss: -1112.1831 - val_accuracy: 0.0996\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3122.1465 - accuracy: 0.1432 - val_loss: -2042.0131 - val_accuracy: 0.1732\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5448.1226 - accuracy: 0.1454 - val_loss: -3090.1094 - val_accuracy: 0.0973\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8343.1035 - accuracy: 0.1357 - val_loss: -4794.4565 - val_accuracy: 0.1779\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12361.3848 - accuracy: 0.1494 - val_loss: -7813.0693 - val_accuracy: 0.1779\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -18246.7598 - accuracy: 0.1531 - val_loss: -11717.3828 - val_accuracy: 0.0985\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -24554.7363 - accuracy: 0.1565 - val_loss: -15870.0918 - val_accuracy: 0.0996\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -32628.0293 - accuracy: 0.1604 - val_loss: -20601.8125 - val_accuracy: 0.1803\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -41786.1016 - accuracy: 0.1777 - val_loss: -25047.1914 - val_accuracy: 0.0985\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -51275.7539 - accuracy: 0.1535 - val_loss: -32338.0312 - val_accuracy: 0.1744\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -62701.3398 - accuracy: 0.1632 - val_loss: -39269.6562 - val_accuracy: 0.1744\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -75222.1797 - accuracy: 0.1582 - val_loss: -46684.5234 - val_accuracy: 0.1744\n","Epoch 14/100\n","238/238 [==============================] - 1s 4ms/step - loss: -88850.6406 - accuracy: 0.1491 - val_loss: -53533.3867 - val_accuracy: 0.1803\n","Epoch 15/100\n","238/238 [==============================] - 1s 4ms/step - loss: -102831.8594 - accuracy: 0.1688 - val_loss: -63548.9766 - val_accuracy: 0.1756\n","Epoch 16/100\n","238/238 [==============================] - 1s 4ms/step - loss: -118976.2266 - accuracy: 0.1645 - val_loss: -72862.5078 - val_accuracy: 0.0996\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -136455.6562 - accuracy: 0.1459 - val_loss: -83263.2578 - val_accuracy: 0.1756\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -155252.2031 - accuracy: 0.1499 - val_loss: -94259.3438 - val_accuracy: 0.1767\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -174646.8750 - accuracy: 0.1560 - val_loss: -106749.9688 - val_accuracy: 0.1756\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -196136.7812 - accuracy: 0.1575 - val_loss: -119659.9688 - val_accuracy: 0.1447\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -219609.5938 - accuracy: 0.1599 - val_loss: -133734.0781 - val_accuracy: 0.1186\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -244594.7031 - accuracy: 0.1573 - val_loss: -147750.5469 - val_accuracy: 0.1044\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -271343.5312 - accuracy: 0.1548 - val_loss: -161901.4219 - val_accuracy: 0.1044\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -298232.5000 - accuracy: 0.1486 - val_loss: -181625.5312 - val_accuracy: 0.1637\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -328029.2188 - accuracy: 0.1590 - val_loss: -199477.1406 - val_accuracy: 0.1779\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -357896.7500 - accuracy: 0.1655 - val_loss: -217138.4844 - val_accuracy: 0.1186\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -390697.8125 - accuracy: 0.1487 - val_loss: -237679.2969 - val_accuracy: 0.1779\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -425413.7812 - accuracy: 0.1471 - val_loss: -255727.7500 - val_accuracy: 0.1068\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -459427.2500 - accuracy: 0.1354 - val_loss: -278202.3125 - val_accuracy: 0.1637\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -497777.6250 - accuracy: 0.1502 - val_loss: -297565.1562 - val_accuracy: 0.1068\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -536373.0000 - accuracy: 0.1361 - val_loss: -323026.0000 - val_accuracy: 0.1803\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -576069.1250 - accuracy: 0.1593 - val_loss: -345028.8438 - val_accuracy: 0.1068\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -621589.0000 - accuracy: 0.1309 - val_loss: -374021.9062 - val_accuracy: 0.1767\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -664320.5625 - accuracy: 0.1419 - val_loss: -399438.2812 - val_accuracy: 0.1803\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -712348.3125 - accuracy: 0.1628 - val_loss: -428418.6562 - val_accuracy: 0.1637\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -762662.9375 - accuracy: 0.1535 - val_loss: -454349.3125 - val_accuracy: 0.1068\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -814687.5000 - accuracy: 0.1469 - val_loss: -489432.4062 - val_accuracy: 0.1068\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -870974.1250 - accuracy: 0.1346 - val_loss: -522973.8750 - val_accuracy: 0.1068\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -930545.7500 - accuracy: 0.1366 - val_loss: -560877.3125 - val_accuracy: 0.1661\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -988789.4375 - accuracy: 0.1466 - val_loss: -596104.8750 - val_accuracy: 0.1186\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1050207.7500 - accuracy: 0.1514 - val_loss: -631790.1875 - val_accuracy: 0.1068\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1115670.0000 - accuracy: 0.1303 - val_loss: -672688.0625 - val_accuracy: 0.1803\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1181374.0000 - accuracy: 0.1520 - val_loss: -711841.2500 - val_accuracy: 0.1068\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1250889.6250 - accuracy: 0.1310 - val_loss: -757550.2500 - val_accuracy: 0.1210\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1325154.5000 - accuracy: 0.1429 - val_loss: -802166.8750 - val_accuracy: 0.1803\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1394732.3750 - accuracy: 0.1433 - val_loss: -845165.1875 - val_accuracy: 0.1210\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1471871.6250 - accuracy: 0.1337 - val_loss: -893425.4375 - val_accuracy: 0.1684\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1550694.6250 - accuracy: 0.1391 - val_loss: -940784.8750 - val_accuracy: 0.1495\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1633747.2500 - accuracy: 0.1289 - val_loss: -991421.1875 - val_accuracy: 0.1684\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1719878.0000 - accuracy: 0.1429 - val_loss: -1041692.0000 - val_accuracy: 0.1068\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1801843.5000 - accuracy: 0.1391 - val_loss: -1095380.6250 - val_accuracy: 0.1210\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1893031.3750 - accuracy: 0.1425 - val_loss: -1149178.8750 - val_accuracy: 0.1186\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1988717.1250 - accuracy: 0.1465 - val_loss: -1198983.5000 - val_accuracy: 0.1068\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2080358.5000 - accuracy: 0.1299 - val_loss: -1268364.0000 - val_accuracy: 0.1186\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2181736.5000 - accuracy: 0.1301 - val_loss: -1327914.2500 - val_accuracy: 0.1684\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2282496.2500 - accuracy: 0.1477 - val_loss: -1386796.5000 - val_accuracy: 0.1068\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2389809.7500 - accuracy: 0.1457 - val_loss: -1448470.1250 - val_accuracy: 0.1068\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2497530.0000 - accuracy: 0.1281 - val_loss: -1516387.8750 - val_accuracy: 0.1068\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2590125.5000 - accuracy: 0.1305 - val_loss: -1576850.6250 - val_accuracy: 0.1210\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2687248.2500 - accuracy: 0.1345 - val_loss: -1640937.1250 - val_accuracy: 0.1186\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2793979.0000 - accuracy: 0.1383 - val_loss: -1708583.3750 - val_accuracy: 0.1068\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2903812.0000 - accuracy: 0.1358 - val_loss: -1780767.7500 - val_accuracy: 0.1186\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3025537.2500 - accuracy: 0.1419 - val_loss: -1840182.0000 - val_accuracy: 0.1068\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3139440.2500 - accuracy: 0.1249 - val_loss: -1925705.5000 - val_accuracy: 0.1068\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3264720.2500 - accuracy: 0.1303 - val_loss: -2002745.3750 - val_accuracy: 0.1068\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3388470.5000 - accuracy: 0.1362 - val_loss: -2083339.1250 - val_accuracy: 0.1186\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3521606.0000 - accuracy: 0.1333 - val_loss: -2165570.2500 - val_accuracy: 0.1459\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3659657.7500 - accuracy: 0.1390 - val_loss: -2249918.7500 - val_accuracy: 0.1661\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3797306.2500 - accuracy: 0.1527 - val_loss: -2330246.5000 - val_accuracy: 0.1068\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3940727.5000 - accuracy: 0.1293 - val_loss: -2427985.0000 - val_accuracy: 0.1186\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4091998.5000 - accuracy: 0.1421 - val_loss: -2514839.5000 - val_accuracy: 0.1068\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4247397.0000 - accuracy: 0.1234 - val_loss: -2618132.2500 - val_accuracy: 0.1471\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4397394.0000 - accuracy: 0.1502 - val_loss: -2708746.7500 - val_accuracy: 0.1068\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4565897.0000 - accuracy: 0.1473 - val_loss: -2805912.2500 - val_accuracy: 0.1068\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4725042.0000 - accuracy: 0.1250 - val_loss: -2911820.0000 - val_accuracy: 0.1068\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4886323.5000 - accuracy: 0.1312 - val_loss: -2995815.7500 - val_accuracy: 0.1649\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4996946.5000 - accuracy: 0.1545 - val_loss: -3060691.2500 - val_accuracy: 0.1068\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5108974.5000 - accuracy: 0.1281 - val_loss: -3152177.0000 - val_accuracy: 0.1684\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5227757.5000 - accuracy: 0.1441 - val_loss: -3234138.5000 - val_accuracy: 0.1068\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5357206.5000 - accuracy: 0.1374 - val_loss: -3318805.0000 - val_accuracy: 0.1068\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5492725.0000 - accuracy: 0.1383 - val_loss: -3420528.2500 - val_accuracy: 0.1459\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5636885.0000 - accuracy: 0.1376 - val_loss: -3516451.0000 - val_accuracy: 0.1661\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5786875.0000 - accuracy: 0.1342 - val_loss: -3616506.7500 - val_accuracy: 0.1447\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5950489.5000 - accuracy: 0.1623 - val_loss: -3692423.2500 - val_accuracy: 0.1068\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6108871.0000 - accuracy: 0.1359 - val_loss: -3820421.2500 - val_accuracy: 0.1068\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6299951.0000 - accuracy: 0.1355 - val_loss: -3939628.7500 - val_accuracy: 0.1068\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6481649.0000 - accuracy: 0.1309 - val_loss: -4063038.5000 - val_accuracy: 0.1186\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6667659.5000 - accuracy: 0.1514 - val_loss: -4162080.7500 - val_accuracy: 0.1068\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6849689.0000 - accuracy: 0.1184 - val_loss: -4307569.5000 - val_accuracy: 0.1068\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7054750.0000 - accuracy: 0.1209 - val_loss: -4430691.0000 - val_accuracy: 0.1186\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7261805.0000 - accuracy: 0.1270 - val_loss: -4561580.0000 - val_accuracy: 0.1068\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7469422.0000 - accuracy: 0.1243 - val_loss: -4699343.0000 - val_accuracy: 0.1447\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7684514.5000 - accuracy: 0.1289 - val_loss: -4835464.5000 - val_accuracy: 0.1447\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7918459.5000 - accuracy: 0.1289 - val_loss: -4975578.5000 - val_accuracy: 0.1447\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8132838.0000 - accuracy: 0.1409 - val_loss: -5120899.0000 - val_accuracy: 0.1186\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8364424.5000 - accuracy: 0.1453 - val_loss: -5253756.5000 - val_accuracy: 0.1068\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8591521.0000 - accuracy: 0.1358 - val_loss: -5397261.0000 - val_accuracy: 0.1068\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8834131.0000 - accuracy: 0.1305 - val_loss: -5559525.5000 - val_accuracy: 0.1068\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9073141.0000 - accuracy: 0.1357 - val_loss: -5708427.5000 - val_accuracy: 0.1186\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9322517.0000 - accuracy: 0.1325 - val_loss: -5861413.5000 - val_accuracy: 0.1068\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.03      0.06       284\n","           1       0.10      0.99      0.18        82\n","           2       0.00      0.00      0.00       166\n","           3       0.00      0.00      0.00       194\n","           4       0.00      0.00      0.00       117\n","\n","    accuracy                           0.11       843\n","   macro avg       0.17      0.20      0.05       843\n","weighted avg       0.26      0.11      0.04       843\n","\n","Accuracy: 0.10676156583629894\n","[[  9 275   0   0   0]\n"," [  1  81   0   0   0]\n"," [  0 166   0   0   0]\n"," [  2 192   0   0   0]\n"," [  0 117   0   0   0]]\n","Precision: 0.2622\n","Recall: 0.1068\n","F1 Score: 0.0377\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://dfbc0b6c-ba5d-43dd-a598-afd074051072/assets\n","model 6 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 54.8897 - accuracy: 0.1035 - val_loss: -1289.5909 - val_accuracy: 0.1186\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2457.4062 - accuracy: 0.1035 - val_loss: -3398.3726 - val_accuracy: 0.1186\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5272.5552 - accuracy: 0.1035 - val_loss: -6425.5420 - val_accuracy: 0.1186\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9305.8320 - accuracy: 0.1035 - val_loss: -10511.9668 - val_accuracy: 0.1186\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14361.7559 - accuracy: 0.1035 - val_loss: -16038.5693 - val_accuracy: 0.1186\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -20665.8594 - accuracy: 0.1035 - val_loss: -22409.7305 - val_accuracy: 0.1186\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -28538.0957 - accuracy: 0.1035 - val_loss: -29765.8594 - val_accuracy: 0.1186\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -37493.9375 - accuracy: 0.1035 - val_loss: -38525.2539 - val_accuracy: 0.1186\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -47699.0391 - accuracy: 0.1035 - val_loss: -49087.8828 - val_accuracy: 0.1186\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -59492.0938 - accuracy: 0.1035 - val_loss: -60375.8867 - val_accuracy: 0.1186\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -72812.1406 - accuracy: 0.1035 - val_loss: -74302.8828 - val_accuracy: 0.1186\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -87494.3672 - accuracy: 0.1035 - val_loss: -89100.0234 - val_accuracy: 0.1186\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -103506.8984 - accuracy: 0.1035 - val_loss: -104961.3438 - val_accuracy: 0.1186\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -121943.6953 - accuracy: 0.1035 - val_loss: -124000.1484 - val_accuracy: 0.1186\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -143534.5781 - accuracy: 0.1035 - val_loss: -148111.7500 - val_accuracy: 0.1186\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -168021.8594 - accuracy: 0.1035 - val_loss: -174655.0312 - val_accuracy: 0.1186\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -193577.4531 - accuracy: 0.1035 - val_loss: -201803.2812 - val_accuracy: 0.1186\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -221592.0781 - accuracy: 0.1035 - val_loss: -230994.5938 - val_accuracy: 0.1186\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -252068.5312 - accuracy: 0.1035 - val_loss: -260443.9375 - val_accuracy: 0.1186\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -284850.7188 - accuracy: 0.1035 - val_loss: -297645.6562 - val_accuracy: 0.1186\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -320662.3750 - accuracy: 0.1035 - val_loss: -335460.2500 - val_accuracy: 0.1186\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -359481.8125 - accuracy: 0.1035 - val_loss: -374679.8438 - val_accuracy: 0.1186\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -399171.4375 - accuracy: 0.1035 - val_loss: -418366.2188 - val_accuracy: 0.1186\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -443524.1875 - accuracy: 0.1035 - val_loss: -463674.5000 - val_accuracy: 0.1186\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -489879.5000 - accuracy: 0.1035 - val_loss: -511199.0625 - val_accuracy: 0.1186\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -537993.1250 - accuracy: 0.1035 - val_loss: -563244.3750 - val_accuracy: 0.1186\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -589949.8125 - accuracy: 0.1035 - val_loss: -614736.1875 - val_accuracy: 0.1186\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -643824.8750 - accuracy: 0.1035 - val_loss: -673205.0625 - val_accuracy: 0.1186\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -688394.0000 - accuracy: 0.1035 - val_loss: -712734.8125 - val_accuracy: 0.1186\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -735491.1875 - accuracy: 0.1035 - val_loss: -762975.7500 - val_accuracy: 0.1186\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -788854.0000 - accuracy: 0.1035 - val_loss: -819264.0625 - val_accuracy: 0.1186\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -839758.5000 - accuracy: 0.1035 - val_loss: -868331.7500 - val_accuracy: 0.1186\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -899034.5625 - accuracy: 0.1035 - val_loss: -930194.8750 - val_accuracy: 0.1186\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -961832.6875 - accuracy: 0.1035 - val_loss: -996624.1875 - val_accuracy: 0.1186\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1025966.2500 - accuracy: 0.1035 - val_loss: -1064721.0000 - val_accuracy: 0.1186\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1098823.8750 - accuracy: 0.1035 - val_loss: -1138437.1250 - val_accuracy: 0.1186\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1172334.2500 - accuracy: 0.1035 - val_loss: -1216775.3750 - val_accuracy: 0.1186\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1251551.8750 - accuracy: 0.1035 - val_loss: -1299370.3750 - val_accuracy: 0.1186\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1335283.6250 - accuracy: 0.1035 - val_loss: -1383934.8750 - val_accuracy: 0.1186\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1424269.7500 - accuracy: 0.1035 - val_loss: -1480476.3750 - val_accuracy: 0.1186\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1517492.3750 - accuracy: 0.1035 - val_loss: -1577726.1250 - val_accuracy: 0.1186\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1618443.6250 - accuracy: 0.1035 - val_loss: -1678559.5000 - val_accuracy: 0.1186\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1716997.7500 - accuracy: 0.1035 - val_loss: -1790048.7500 - val_accuracy: 0.1186\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1820128.6250 - accuracy: 0.1035 - val_loss: -1896717.5000 - val_accuracy: 0.1186\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1931040.1250 - accuracy: 0.1035 - val_loss: -2012128.8750 - val_accuracy: 0.1186\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2045256.7500 - accuracy: 0.1035 - val_loss: -2128238.5000 - val_accuracy: 0.1186\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2164276.0000 - accuracy: 0.1035 - val_loss: -2256006.5000 - val_accuracy: 0.1186\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2287387.7500 - accuracy: 0.1035 - val_loss: -2391794.5000 - val_accuracy: 0.1186\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2417342.5000 - accuracy: 0.1035 - val_loss: -2513822.2500 - val_accuracy: 0.1186\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2550340.7500 - accuracy: 0.1035 - val_loss: -2663464.5000 - val_accuracy: 0.1186\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2687666.7500 - accuracy: 0.1035 - val_loss: -2806954.7500 - val_accuracy: 0.1186\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2833596.5000 - accuracy: 0.1035 - val_loss: -2963365.0000 - val_accuracy: 0.1186\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2977104.2500 - accuracy: 0.1035 - val_loss: -3114334.5000 - val_accuracy: 0.1186\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3127139.2500 - accuracy: 0.1035 - val_loss: -3260386.7500 - val_accuracy: 0.1186\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3281574.7500 - accuracy: 0.1035 - val_loss: -3407907.7500 - val_accuracy: 0.1186\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3436952.2500 - accuracy: 0.1035 - val_loss: -3573091.5000 - val_accuracy: 0.1186\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3599241.2500 - accuracy: 0.1035 - val_loss: -3748722.0000 - val_accuracy: 0.1186\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3771374.7500 - accuracy: 0.1035 - val_loss: -3914362.0000 - val_accuracy: 0.1186\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3935842.0000 - accuracy: 0.1035 - val_loss: -4097982.7500 - val_accuracy: 0.1186\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4114307.5000 - accuracy: 0.1035 - val_loss: -4291376.0000 - val_accuracy: 0.1186\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4301218.0000 - accuracy: 0.1035 - val_loss: -4455269.5000 - val_accuracy: 0.1186\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4484234.5000 - accuracy: 0.1035 - val_loss: -4680557.0000 - val_accuracy: 0.1186\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4678457.5000 - accuracy: 0.1035 - val_loss: -4880567.0000 - val_accuracy: 0.1186\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4879722.0000 - accuracy: 0.1035 - val_loss: -5080793.5000 - val_accuracy: 0.1186\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5083162.5000 - accuracy: 0.1035 - val_loss: -5294059.5000 - val_accuracy: 0.1186\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5290261.5000 - accuracy: 0.1035 - val_loss: -5516241.0000 - val_accuracy: 0.1186\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5507973.0000 - accuracy: 0.1035 - val_loss: -5734509.5000 - val_accuracy: 0.1186\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5731200.0000 - accuracy: 0.1035 - val_loss: -5952925.0000 - val_accuracy: 0.1186\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5951880.5000 - accuracy: 0.1035 - val_loss: -6186848.5000 - val_accuracy: 0.1186\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6181238.0000 - accuracy: 0.1035 - val_loss: -6440646.0000 - val_accuracy: 0.1186\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6414267.0000 - accuracy: 0.1035 - val_loss: -6685939.0000 - val_accuracy: 0.1186\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6651343.5000 - accuracy: 0.1035 - val_loss: -6924276.5000 - val_accuracy: 0.1186\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6902343.0000 - accuracy: 0.1035 - val_loss: -7165022.0000 - val_accuracy: 0.1186\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7151110.5000 - accuracy: 0.1035 - val_loss: -7429720.5000 - val_accuracy: 0.1186\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7412392.0000 - accuracy: 0.1035 - val_loss: -7727120.5000 - val_accuracy: 0.1186\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7674749.0000 - accuracy: 0.1035 - val_loss: -7992033.5000 - val_accuracy: 0.1186\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7944580.0000 - accuracy: 0.1035 - val_loss: -8268235.0000 - val_accuracy: 0.1186\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8220224.0000 - accuracy: 0.1035 - val_loss: -8542626.0000 - val_accuracy: 0.1186\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8496294.0000 - accuracy: 0.1035 - val_loss: -8846555.0000 - val_accuracy: 0.1186\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8783592.0000 - accuracy: 0.1035 - val_loss: -9154025.0000 - val_accuracy: 0.1186\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9078834.0000 - accuracy: 0.1035 - val_loss: -9476884.0000 - val_accuracy: 0.1186\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9384791.0000 - accuracy: 0.1035 - val_loss: -9747748.0000 - val_accuracy: 0.1186\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9688652.0000 - accuracy: 0.1035 - val_loss: -10109739.0000 - val_accuracy: 0.1186\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10012930.0000 - accuracy: 0.1035 - val_loss: -10428109.0000 - val_accuracy: 0.1186\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10338035.0000 - accuracy: 0.1035 - val_loss: -10772615.0000 - val_accuracy: 0.1186\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10664752.0000 - accuracy: 0.1035 - val_loss: -11133584.0000 - val_accuracy: 0.1186\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11013605.0000 - accuracy: 0.1035 - val_loss: -11466994.0000 - val_accuracy: 0.1186\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11358949.0000 - accuracy: 0.1035 - val_loss: -11818621.0000 - val_accuracy: 0.1186\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11706276.0000 - accuracy: 0.1035 - val_loss: -12184111.0000 - val_accuracy: 0.1186\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12061275.0000 - accuracy: 0.1035 - val_loss: -12563887.0000 - val_accuracy: 0.1186\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12436536.0000 - accuracy: 0.1035 - val_loss: -12842261.0000 - val_accuracy: 0.1186\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12789792.0000 - accuracy: 0.1035 - val_loss: -13335558.0000 - val_accuracy: 0.1186\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13160829.0000 - accuracy: 0.1035 - val_loss: -13727618.0000 - val_accuracy: 0.1186\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13550146.0000 - accuracy: 0.1035 - val_loss: -14122455.0000 - val_accuracy: 0.1186\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13938747.0000 - accuracy: 0.1035 - val_loss: -14527997.0000 - val_accuracy: 0.1186\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14348515.0000 - accuracy: 0.1035 - val_loss: -14968681.0000 - val_accuracy: 0.1186\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14742903.0000 - accuracy: 0.1035 - val_loss: -15370558.0000 - val_accuracy: 0.1186\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -15165346.0000 - accuracy: 0.1035 - val_loss: -15767316.0000 - val_accuracy: 0.1186\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -15582631.0000 - accuracy: 0.1035 - val_loss: -16222938.0000 - val_accuracy: 0.1186\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -16002398.0000 - accuracy: 0.1035 - val_loss: -16670845.0000 - val_accuracy: 0.1186\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       257\n","           1       0.12      1.00      0.21       100\n","           2       0.00      0.00      0.00       181\n","           3       0.00      0.00      0.00       189\n","           4       0.00      0.00      0.00       116\n","\n","    accuracy                           0.12       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.12      0.03       843\n","\n","Accuracy: 0.11862396204033215\n","[[  0 257   0   0   0]\n"," [  0 100   0   0   0]\n"," [  0 181   0   0   0]\n"," [  0 189   0   0   0]\n"," [  0 116   0   0   0]]\n","Precision: 0.0141\n","Recall: 0.1186\n","F1 Score: 0.0252\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://411c06d8-770a-4216-9111-a7b09e445eec/assets\n","model 7 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: -338.4665 - accuracy: 0.1428 - val_loss: -917.4303 - val_accuracy: 0.1556\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1311.3701 - accuracy: 0.1627 - val_loss: -1791.6987 - val_accuracy: 0.1188\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2375.3245 - accuracy: 0.1523 - val_loss: -3152.4680 - val_accuracy: 0.1615\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3861.8403 - accuracy: 0.1588 - val_loss: -5096.8823 - val_accuracy: 0.1556\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5840.6226 - accuracy: 0.1575 - val_loss: -7272.6006 - val_accuracy: 0.1580\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8100.1890 - accuracy: 0.1616 - val_loss: -9482.9453 - val_accuracy: 0.1603\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10727.3115 - accuracy: 0.1615 - val_loss: -12850.2324 - val_accuracy: 0.1663\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14066.9883 - accuracy: 0.1636 - val_loss: -15966.6377 - val_accuracy: 0.0986\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -18771.2617 - accuracy: 0.1389 - val_loss: -21301.7891 - val_accuracy: 0.1663\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -24178.0762 - accuracy: 0.1345 - val_loss: -26572.2539 - val_accuracy: 0.1698\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -30279.9551 - accuracy: 0.1407 - val_loss: -32277.5898 - val_accuracy: 0.1485\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -36879.8398 - accuracy: 0.1555 - val_loss: -38973.7188 - val_accuracy: 0.1722\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -43973.5938 - accuracy: 0.1491 - val_loss: -45830.3125 - val_accuracy: 0.1722\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -51855.1562 - accuracy: 0.1503 - val_loss: -53854.9727 - val_accuracy: 0.1247\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -60714.9453 - accuracy: 0.1569 - val_loss: -62561.2227 - val_accuracy: 0.1698\n","Epoch 16/100\n","238/238 [==============================] - 1s 4ms/step - loss: -70367.7031 - accuracy: 0.1529 - val_loss: -72126.8203 - val_accuracy: 0.1734\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -81113.2109 - accuracy: 0.1577 - val_loss: -83527.5625 - val_accuracy: 0.1473\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -93027.9375 - accuracy: 0.1552 - val_loss: -93685.6641 - val_accuracy: 0.1021\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -106153.2031 - accuracy: 0.1412 - val_loss: -107141.7266 - val_accuracy: 0.1686\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -120443.7969 - accuracy: 0.1507 - val_loss: -121489.3281 - val_accuracy: 0.1734\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -135501.3438 - accuracy: 0.1538 - val_loss: -135555.4062 - val_accuracy: 0.1734\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -151893.8281 - accuracy: 0.1504 - val_loss: -151730.3281 - val_accuracy: 0.1698\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -169163.1250 - accuracy: 0.1488 - val_loss: -169405.0938 - val_accuracy: 0.1686\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -188171.0000 - accuracy: 0.1540 - val_loss: -185726.9531 - val_accuracy: 0.0998\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -208258.8281 - accuracy: 0.1407 - val_loss: -204684.9219 - val_accuracy: 0.1128\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -230382.9062 - accuracy: 0.1410 - val_loss: -227201.0312 - val_accuracy: 0.1128\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -252748.2812 - accuracy: 0.1337 - val_loss: -249165.0156 - val_accuracy: 0.1271\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -277824.8125 - accuracy: 0.1508 - val_loss: -268341.1250 - val_accuracy: 0.1128\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -303199.9375 - accuracy: 0.1414 - val_loss: -295767.8750 - val_accuracy: 0.1128\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -331114.9062 - accuracy: 0.1393 - val_loss: -321377.0312 - val_accuracy: 0.1140\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -359717.3125 - accuracy: 0.1327 - val_loss: -349849.8750 - val_accuracy: 0.1306\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -390956.4375 - accuracy: 0.1474 - val_loss: -376869.1250 - val_accuracy: 0.1128\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -423148.1875 - accuracy: 0.1343 - val_loss: -409106.2812 - val_accuracy: 0.1318\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -458197.2812 - accuracy: 0.1341 - val_loss: -440478.0625 - val_accuracy: 0.1128\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -494176.8125 - accuracy: 0.1298 - val_loss: -476666.3125 - val_accuracy: 0.1271\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -531940.1250 - accuracy: 0.1465 - val_loss: -511091.8125 - val_accuracy: 0.1128\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -571439.0625 - accuracy: 0.1349 - val_loss: -549071.6875 - val_accuracy: 0.1128\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -612552.4375 - accuracy: 0.1413 - val_loss: -585967.7500 - val_accuracy: 0.1128\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -655656.5000 - accuracy: 0.1288 - val_loss: -624938.0625 - val_accuracy: 0.1128\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -701222.2500 - accuracy: 0.1283 - val_loss: -672724.1250 - val_accuracy: 0.1722\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -747539.5000 - accuracy: 0.1293 - val_loss: -718077.0625 - val_accuracy: 0.1639\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -797632.6875 - accuracy: 0.1617 - val_loss: -756420.8750 - val_accuracy: 0.1128\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -850334.8125 - accuracy: 0.1372 - val_loss: -809210.3750 - val_accuracy: 0.1116\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -904444.3125 - accuracy: 0.1291 - val_loss: -854650.4375 - val_accuracy: 0.1128\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -960177.3125 - accuracy: 0.1322 - val_loss: -913276.9375 - val_accuracy: 0.1722\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1017160.1875 - accuracy: 0.1329 - val_loss: -964292.0000 - val_accuracy: 0.1306\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1076445.5000 - accuracy: 0.1309 - val_loss: -1018677.9375 - val_accuracy: 0.1128\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1138713.5000 - accuracy: 0.1342 - val_loss: -1076692.5000 - val_accuracy: 0.1164\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1205909.6250 - accuracy: 0.1301 - val_loss: -1139045.5000 - val_accuracy: 0.1164\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1272827.3750 - accuracy: 0.1233 - val_loss: -1202729.8750 - val_accuracy: 0.1306\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1336814.3750 - accuracy: 0.1359 - val_loss: -1253477.0000 - val_accuracy: 0.1116\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1403594.7500 - accuracy: 0.1308 - val_loss: -1319048.2500 - val_accuracy: 0.1116\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1476769.8750 - accuracy: 0.1293 - val_loss: -1381696.6250 - val_accuracy: 0.1116\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1551549.0000 - accuracy: 0.1206 - val_loss: -1456210.3750 - val_accuracy: 0.1128\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1627577.2500 - accuracy: 0.1434 - val_loss: -1514260.1250 - val_accuracy: 0.1128\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1706868.3750 - accuracy: 0.1204 - val_loss: -1601588.8750 - val_accuracy: 0.1295\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1790703.0000 - accuracy: 0.1236 - val_loss: -1676728.3750 - val_accuracy: 0.1686\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1875189.6250 - accuracy: 0.1304 - val_loss: -1760979.1250 - val_accuracy: 0.1271\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1961472.2500 - accuracy: 0.1372 - val_loss: -1831827.8750 - val_accuracy: 0.1116\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2052643.5000 - accuracy: 0.1326 - val_loss: -1916869.0000 - val_accuracy: 0.1128\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2148054.5000 - accuracy: 0.1407 - val_loss: -1998252.7500 - val_accuracy: 0.1116\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2242389.0000 - accuracy: 0.1280 - val_loss: -2094915.0000 - val_accuracy: 0.1140\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2342503.0000 - accuracy: 0.1320 - val_loss: -2192677.2500 - val_accuracy: 0.1271\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2444798.7500 - accuracy: 0.1480 - val_loss: -2278236.0000 - val_accuracy: 0.1116\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2548617.5000 - accuracy: 0.1225 - val_loss: -2376323.0000 - val_accuracy: 0.1259\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2654357.2500 - accuracy: 0.1349 - val_loss: -2477070.5000 - val_accuracy: 0.1128\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2765962.5000 - accuracy: 0.1217 - val_loss: -2580143.2500 - val_accuracy: 0.1259\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2880729.0000 - accuracy: 0.1320 - val_loss: -2686401.7500 - val_accuracy: 0.1271\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2998337.2500 - accuracy: 0.1277 - val_loss: -2794466.0000 - val_accuracy: 0.1259\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3116259.0000 - accuracy: 0.1225 - val_loss: -2893578.7500 - val_accuracy: 0.1295\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3233017.2500 - accuracy: 0.1530 - val_loss: -3006286.5000 - val_accuracy: 0.1128\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3363343.5000 - accuracy: 0.1380 - val_loss: -3123821.7500 - val_accuracy: 0.1116\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3501968.2500 - accuracy: 0.1201 - val_loss: -3270121.5000 - val_accuracy: 0.1247\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3650875.2500 - accuracy: 0.1289 - val_loss: -3413546.2500 - val_accuracy: 0.1105\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3810560.0000 - accuracy: 0.1222 - val_loss: -3563487.2500 - val_accuracy: 0.1235\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3979849.0000 - accuracy: 0.1293 - val_loss: -3711901.5000 - val_accuracy: 0.1603\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4135898.2500 - accuracy: 0.1292 - val_loss: -3848796.0000 - val_accuracy: 0.1235\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4299076.0000 - accuracy: 0.1314 - val_loss: -3982901.0000 - val_accuracy: 0.1105\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4468010.5000 - accuracy: 0.1236 - val_loss: -4148516.2500 - val_accuracy: 0.1603\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4637449.0000 - accuracy: 0.1558 - val_loss: -4257806.5000 - val_accuracy: 0.1105\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4770809.5000 - accuracy: 0.1210 - val_loss: -4387572.5000 - val_accuracy: 0.1235\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4906706.5000 - accuracy: 0.1442 - val_loss: -4517810.0000 - val_accuracy: 0.1235\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5060707.0000 - accuracy: 0.1418 - val_loss: -4651255.0000 - val_accuracy: 0.1235\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5217448.5000 - accuracy: 0.1256 - val_loss: -4771915.5000 - val_accuracy: 0.1105\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5381646.5000 - accuracy: 0.1364 - val_loss: -4897438.5000 - val_accuracy: 0.1105\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5549924.0000 - accuracy: 0.1207 - val_loss: -5081688.0000 - val_accuracy: 0.1235\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5722452.5000 - accuracy: 0.1352 - val_loss: -5235578.0000 - val_accuracy: 0.1235\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5896713.5000 - accuracy: 0.1291 - val_loss: -5385930.5000 - val_accuracy: 0.1105\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6085281.0000 - accuracy: 0.1260 - val_loss: -5562381.5000 - val_accuracy: 0.1105\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6272057.0000 - accuracy: 0.1449 - val_loss: -5715970.0000 - val_accuracy: 0.1105\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6464170.0000 - accuracy: 0.1177 - val_loss: -5904797.5000 - val_accuracy: 0.1235\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6663830.0000 - accuracy: 0.1349 - val_loss: -6086004.0000 - val_accuracy: 0.1247\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6868687.0000 - accuracy: 0.1277 - val_loss: -6271140.0000 - val_accuracy: 0.1235\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7081116.5000 - accuracy: 0.1264 - val_loss: -6475501.0000 - val_accuracy: 0.1615\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7288770.0000 - accuracy: 0.1388 - val_loss: -6644382.5000 - val_accuracy: 0.1116\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7508021.0000 - accuracy: 0.1320 - val_loss: -6844612.5000 - val_accuracy: 0.1247\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7723992.0000 - accuracy: 0.1515 - val_loss: -7040666.0000 - val_accuracy: 0.1116\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7949426.0000 - accuracy: 0.1190 - val_loss: -7253591.5000 - val_accuracy: 0.1247\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8184761.0000 - accuracy: 0.1293 - val_loss: -7446611.5000 - val_accuracy: 0.1116\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8426542.0000 - accuracy: 0.1337 - val_loss: -7646942.5000 - val_accuracy: 0.1116\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.05      0.09       287\n","           1       0.10      0.98      0.18        82\n","           2       0.00      0.00      0.00       153\n","           3       0.00      0.00      0.00       209\n","           4       0.00      0.00      0.00       111\n","\n","    accuracy                           0.11       842\n","   macro avg       0.16      0.20      0.05       842\n","weighted avg       0.25      0.11      0.05       842\n","\n","Accuracy: 0.11163895486935867\n","[[ 14 273   0   0   0]\n"," [  2  80   0   0   0]\n"," [  0 153   0   0   0]\n"," [  4 205   0   0   0]\n"," [  0 111   0   0   0]]\n","Precision: 0.2481\n","Recall: 0.1116\n","F1 Score: 0.0483\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://0051f48c-49bd-4aec-9cce-c858109448ca/assets\n","model 8 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 4ms/step - loss: -483.3956 - accuracy: 0.1720 - val_loss: -961.0836 - val_accuracy: 0.1865\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1546.1383 - accuracy: 0.1793 - val_loss: -2445.8770 - val_accuracy: 0.1544\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2804.0999 - accuracy: 0.1756 - val_loss: -3562.1228 - val_accuracy: 0.1556\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4354.6055 - accuracy: 0.1820 - val_loss: -5469.9175 - val_accuracy: 0.1568\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6204.0103 - accuracy: 0.1649 - val_loss: -7435.9443 - val_accuracy: 0.1520\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8501.1279 - accuracy: 0.1711 - val_loss: -9782.3916 - val_accuracy: 0.0855\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11388.6104 - accuracy: 0.1484 - val_loss: -11800.9326 - val_accuracy: 0.1663\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14574.3311 - accuracy: 0.1606 - val_loss: -15208.5557 - val_accuracy: 0.1675\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -18965.5547 - accuracy: 0.1657 - val_loss: -20381.5781 - val_accuracy: 0.1425\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -23643.1738 - accuracy: 0.1545 - val_loss: -25404.1328 - val_accuracy: 0.0831\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -28881.1719 - accuracy: 0.1592 - val_loss: -30576.0039 - val_accuracy: 0.0855\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -34856.1367 - accuracy: 0.1421 - val_loss: -35496.8984 - val_accuracy: 0.1651\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -41457.8984 - accuracy: 0.1616 - val_loss: -42235.1289 - val_accuracy: 0.1651\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -48940.2070 - accuracy: 0.1511 - val_loss: -51102.6992 - val_accuracy: 0.0855\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -56504.8398 - accuracy: 0.1429 - val_loss: -59309.8516 - val_accuracy: 0.0808\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -65180.0469 - accuracy: 0.1468 - val_loss: -65910.7812 - val_accuracy: 0.1591\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -74479.2422 - accuracy: 0.1526 - val_loss: -74055.1172 - val_accuracy: 0.1639\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -84669.7109 - accuracy: 0.1615 - val_loss: -85809.8594 - val_accuracy: 0.0938\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -95322.9922 - accuracy: 0.1439 - val_loss: -95120.4297 - val_accuracy: 0.1591\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -107057.0781 - accuracy: 0.1581 - val_loss: -107087.6484 - val_accuracy: 0.1105\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -119310.4531 - accuracy: 0.1525 - val_loss: -118893.3750 - val_accuracy: 0.1105\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -132472.0938 - accuracy: 0.1359 - val_loss: -131758.8750 - val_accuracy: 0.0962\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -146470.5000 - accuracy: 0.1474 - val_loss: -144411.7656 - val_accuracy: 0.1116\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -161104.4844 - accuracy: 0.1515 - val_loss: -159151.5469 - val_accuracy: 0.1591\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -177633.9688 - accuracy: 0.1511 - val_loss: -175797.9844 - val_accuracy: 0.1105\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -195073.5312 - accuracy: 0.1486 - val_loss: -192649.5781 - val_accuracy: 0.1425\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -213045.5156 - accuracy: 0.1491 - val_loss: -211262.0312 - val_accuracy: 0.1390\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -231555.4531 - accuracy: 0.1447 - val_loss: -226709.0000 - val_accuracy: 0.1413\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -247182.6719 - accuracy: 0.1495 - val_loss: -242149.5156 - val_accuracy: 0.1116\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -264694.2188 - accuracy: 0.1569 - val_loss: -261732.2344 - val_accuracy: 0.0950\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -283170.5312 - accuracy: 0.1482 - val_loss: -277740.1562 - val_accuracy: 0.1413\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -303257.9375 - accuracy: 0.1579 - val_loss: -302000.7500 - val_accuracy: 0.0938\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -323836.1875 - accuracy: 0.1404 - val_loss: -315928.1875 - val_accuracy: 0.1651\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -345869.3438 - accuracy: 0.1552 - val_loss: -345360.3750 - val_accuracy: 0.0938\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -370322.0938 - accuracy: 0.1552 - val_loss: -366544.8750 - val_accuracy: 0.0962\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -394660.8438 - accuracy: 0.1362 - val_loss: -390057.6562 - val_accuracy: 0.1413\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -420592.8438 - accuracy: 0.1624 - val_loss: -413089.0312 - val_accuracy: 0.1580\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -448299.8125 - accuracy: 0.1519 - val_loss: -436985.2812 - val_accuracy: 0.1580\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -476567.1562 - accuracy: 0.1488 - val_loss: -470333.0000 - val_accuracy: 0.0962\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -506572.5938 - accuracy: 0.1507 - val_loss: -501321.0312 - val_accuracy: 0.0950\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -536906.0000 - accuracy: 0.1534 - val_loss: -533044.5000 - val_accuracy: 0.0950\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -569598.5000 - accuracy: 0.1461 - val_loss: -557539.7500 - val_accuracy: 0.1413\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -602666.5000 - accuracy: 0.1494 - val_loss: -587445.3750 - val_accuracy: 0.1591\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -638319.5625 - accuracy: 0.1492 - val_loss: -620775.6250 - val_accuracy: 0.1591\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -674928.6875 - accuracy: 0.1482 - val_loss: -663954.8750 - val_accuracy: 0.1105\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -714753.5625 - accuracy: 0.1507 - val_loss: -697713.1875 - val_accuracy: 0.1580\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -755304.0625 - accuracy: 0.1511 - val_loss: -742684.5625 - val_accuracy: 0.0974\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -797578.7500 - accuracy: 0.1412 - val_loss: -771664.5625 - val_accuracy: 0.1461\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -840327.3750 - accuracy: 0.1633 - val_loss: -830626.2500 - val_accuracy: 0.0938\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -884476.5000 - accuracy: 0.1330 - val_loss: -855947.3750 - val_accuracy: 0.1591\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -929900.7500 - accuracy: 0.1513 - val_loss: -907354.1250 - val_accuracy: 0.1105\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -978286.8125 - accuracy: 0.1453 - val_loss: -950596.8125 - val_accuracy: 0.1461\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1028249.0625 - accuracy: 0.1445 - val_loss: -1003103.4375 - val_accuracy: 0.1105\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1079738.5000 - accuracy: 0.1443 - val_loss: -1058620.3750 - val_accuracy: 0.0962\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1133337.5000 - accuracy: 0.1397 - val_loss: -1094938.8750 - val_accuracy: 0.1580\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1188280.0000 - accuracy: 0.1519 - val_loss: -1158623.5000 - val_accuracy: 0.1413\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1244790.0000 - accuracy: 0.1474 - val_loss: -1209468.0000 - val_accuracy: 0.1413\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1303433.3750 - accuracy: 0.1443 - val_loss: -1268850.2500 - val_accuracy: 0.1105\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1362517.0000 - accuracy: 0.1537 - val_loss: -1337485.2500 - val_accuracy: 0.0950\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1422514.5000 - accuracy: 0.1504 - val_loss: -1406169.5000 - val_accuracy: 0.0938\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1483278.2500 - accuracy: 0.1766 - val_loss: -1448818.8750 - val_accuracy: 0.0938\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1541645.0000 - accuracy: 0.1317 - val_loss: -1506104.1250 - val_accuracy: 0.0962\n","Epoch 63/100\n","238/238 [==============================] - 1s 5ms/step - loss: -1606684.5000 - accuracy: 0.1451 - val_loss: -1567034.5000 - val_accuracy: 0.0962\n","Epoch 64/100\n","238/238 [==============================] - 1s 5ms/step - loss: -1670515.6250 - accuracy: 0.1403 - val_loss: -1629361.2500 - val_accuracy: 0.0962\n","Epoch 65/100\n","238/238 [==============================] - 1s 5ms/step - loss: -1736884.5000 - accuracy: 0.1474 - val_loss: -1686747.5000 - val_accuracy: 0.1105\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1805430.0000 - accuracy: 0.1375 - val_loss: -1763075.5000 - val_accuracy: 0.0950\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1874882.6250 - accuracy: 0.1465 - val_loss: -1831357.0000 - val_accuracy: 0.0950\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1946933.1250 - accuracy: 0.1364 - val_loss: -1892065.1250 - val_accuracy: 0.1105\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2021573.8750 - accuracy: 0.1436 - val_loss: -1949091.1250 - val_accuracy: 0.1603\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2099060.7500 - accuracy: 0.1562 - val_loss: -2040262.8750 - val_accuracy: 0.1105\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2177176.2500 - accuracy: 0.1438 - val_loss: -2119115.0000 - val_accuracy: 0.1105\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2262968.0000 - accuracy: 0.1375 - val_loss: -2178290.7500 - val_accuracy: 0.1615\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2343775.2500 - accuracy: 0.1504 - val_loss: -2271605.7500 - val_accuracy: 0.1413\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2430776.2500 - accuracy: 0.1526 - val_loss: -2367095.2500 - val_accuracy: 0.0962\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2515850.7500 - accuracy: 0.1436 - val_loss: -2449894.2500 - val_accuracy: 0.1105\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2611770.2500 - accuracy: 0.1561 - val_loss: -2542919.2500 - val_accuracy: 0.0938\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2704083.7500 - accuracy: 0.1467 - val_loss: -2635442.7500 - val_accuracy: 0.1081\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2800902.7500 - accuracy: 0.1408 - val_loss: -2693828.7500 - val_accuracy: 0.1603\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2897530.0000 - accuracy: 0.1553 - val_loss: -2827313.0000 - val_accuracy: 0.0938\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2995856.5000 - accuracy: 0.1404 - val_loss: -2881399.0000 - val_accuracy: 0.1580\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3100649.7500 - accuracy: 0.1624 - val_loss: -3035787.2500 - val_accuracy: 0.0938\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3199889.7500 - accuracy: 0.1453 - val_loss: -3110373.0000 - val_accuracy: 0.1093\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3307524.2500 - accuracy: 0.1521 - val_loss: -3215961.5000 - val_accuracy: 0.1093\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3410223.2500 - accuracy: 0.1400 - val_loss: -3266937.2500 - val_accuracy: 0.1639\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3520605.7500 - accuracy: 0.1625 - val_loss: -3414906.5000 - val_accuracy: 0.1081\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3622516.5000 - accuracy: 0.1497 - val_loss: -3493096.0000 - val_accuracy: 0.1580\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3726736.2500 - accuracy: 0.1512 - val_loss: -3580209.5000 - val_accuracy: 0.1615\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3842018.7500 - accuracy: 0.1491 - val_loss: -3705402.5000 - val_accuracy: 0.1449\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3952990.2500 - accuracy: 0.1507 - val_loss: -3775084.5000 - val_accuracy: 0.1675\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4067615.0000 - accuracy: 0.1571 - val_loss: -3940659.0000 - val_accuracy: 0.1140\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4186474.5000 - accuracy: 0.1429 - val_loss: -4044352.2500 - val_accuracy: 0.1449\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4308822.0000 - accuracy: 0.1445 - val_loss: -4170419.5000 - val_accuracy: 0.1105\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4431676.5000 - accuracy: 0.1488 - val_loss: -4273482.0000 - val_accuracy: 0.1449\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4559994.5000 - accuracy: 0.1495 - val_loss: -4403279.5000 - val_accuracy: 0.1449\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4692241.0000 - accuracy: 0.1403 - val_loss: -4514813.5000 - val_accuracy: 0.1615\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4825620.5000 - accuracy: 0.1501 - val_loss: -4641942.5000 - val_accuracy: 0.1615\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4964607.0000 - accuracy: 0.1574 - val_loss: -4812502.0000 - val_accuracy: 0.1093\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5102078.0000 - accuracy: 0.1479 - val_loss: -4911147.5000 - val_accuracy: 0.1449\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5246003.0000 - accuracy: 0.1465 - val_loss: -5068290.5000 - val_accuracy: 0.1449\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5391882.0000 - accuracy: 0.1546 - val_loss: -5232660.5000 - val_accuracy: 0.1081\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.09      0.17       286\n","           1       0.08      1.00      0.15        64\n","           2       0.00      0.00      0.00       163\n","           3       0.00      0.00      0.00       205\n","           4       0.00      0.00      0.00       124\n","\n","    accuracy                           0.11       842\n","   macro avg       0.20      0.22      0.06       842\n","weighted avg       0.31      0.11      0.07       842\n","\n","Accuracy: 0.10807600950118765\n","[[ 27 259   0   0   0]\n"," [  0  64   0   0   0]\n"," [  0 163   0   0   0]\n"," [  3 202   0   0   0]\n"," [  0 124   0   0   0]]\n","Precision: 0.3117\n","Recall: 0.1081\n","F1 Score: 0.0692\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://6c4df2c2-5ddc-4528-983c-a8a1f233fdf5/assets\n","model 9 saved\n","Average Validation Accuracy: 0.12197149643705463\n"]}]},{"cell_type":"code","source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/HTML/NN/model_1.h5'\n","\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","def predict_prob(number):\n","  return [number[0],1-number[0]]\n","\n","y_prob = np.array(list(map(predict_prob, loaded_model.predict(x_test))))\n","y_prob \n","\n","# y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['nn_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['nn_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output['nn_prediction_spam'] = [i[2] for i in y_pred_prob];\n","output['nn_prediction_malware'] = [i[3] for i in y_pred_prob];\n","output['nn_prediction_defacemen'] = [i[4] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":693},"id":"dolEygpVsl_4","executionInfo":{"status":"ok","timestamp":1656571315583,"user_tz":-330,"elapsed":1810,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"8078b5e1-7119-42c1-fe04-f911de06fa5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[3.28595502e-008 2.27595203e-038 9.99999967e-001 3.53644837e-103\n","  5.45258001e-062]\n"," [9.87170919e-001 1.40065769e-005 8.88707177e-004 3.09404654e-004\n","  1.16169622e-002]\n"," [5.43199900e-003 7.26519788e-003 9.75126111e-001 1.06356829e-002\n","  1.54100894e-003]\n"," ...\n"," [1.95654589e-064 3.95504084e-062 4.27920447e-132 1.00000000e+000\n","  2.77532688e-194]\n"," [1.44909380e-001 2.97695615e-001 3.11118892e-001 1.09381100e-001\n","  1.36895013e-001]\n"," [9.38118847e-001 6.25375208e-004 6.04173309e-002 2.58007396e-005\n","  8.12646395e-004]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  mlp_prediction_spam  \\\n","0          2        3.285955e-08          2.275952e-38         1.000000e+00   \n","1          0        9.871709e-01          1.400658e-05         8.887072e-04   \n","2          2        5.431999e-03          7.265198e-03         9.751261e-01   \n","3          3        6.821167e-02          8.999669e-02         4.175485e-02   \n","4          0        1.000000e+00          9.884499e-29         3.997525e-14   \n","...      ...                 ...                   ...                  ...   \n","6891       2        1.120535e-12          1.117325e-44         1.000000e+00   \n","6892       2        8.522478e-04          1.933313e-04         9.989540e-01   \n","6893       3        1.956546e-64          3.955041e-62        4.279204e-132   \n","6894       0        1.449094e-01          2.976956e-01         3.111189e-01   \n","6895       0        9.381188e-01          6.253752e-04         6.041733e-02   \n","\n","      mlp_prediction_malware  mlp_prediction_defacemen  nn_prediction_non  \\\n","0              3.536448e-103              5.452580e-62       3.285955e-08   \n","1               3.094047e-04              1.161696e-02       9.871709e-01   \n","2               1.063568e-02              1.541009e-03       5.431999e-03   \n","3               7.832318e-01              1.680500e-02       6.821167e-02   \n","4               4.412196e-13              2.773055e-33       1.000000e+00   \n","...                      ...                       ...                ...   \n","6891           9.068879e-112              2.337164e-60       1.120535e-12   \n","6892            4.423567e-07              4.685219e-15       8.522478e-04   \n","6893            1.000000e+00             2.775327e-194       1.956546e-64   \n","6894            1.093811e-01              1.368950e-01       1.449094e-01   \n","6895            2.580074e-05              8.126464e-04       9.381188e-01   \n","\n","      nn_prediction_phish  nn_prediction_spam  nn_prediction_malware  \\\n","0            2.275952e-38        1.000000e+00          3.536448e-103   \n","1            1.400658e-05        8.887072e-04           3.094047e-04   \n","2            7.265198e-03        9.751261e-01           1.063568e-02   \n","3            8.999669e-02        4.175485e-02           7.832318e-01   \n","4            9.884499e-29        3.997525e-14           4.412196e-13   \n","...                   ...                 ...                    ...   \n","6891         1.117325e-44        1.000000e+00          9.068879e-112   \n","6892         1.933313e-04        9.989540e-01           4.423567e-07   \n","6893         3.955041e-62       4.279204e-132           1.000000e+00   \n","6894         2.976956e-01        3.111189e-01           1.093811e-01   \n","6895         6.253752e-04        6.041733e-02           2.580074e-05   \n","\n","      nn_prediction_defacemen  \n","0                5.452580e-62  \n","1                1.161696e-02  \n","2                1.541009e-03  \n","3                1.680500e-02  \n","4                2.773055e-33  \n","...                       ...  \n","6891             2.337164e-60  \n","6892             4.685219e-15  \n","6893            2.775327e-194  \n","6894             1.368950e-01  \n","6895             8.126464e-04  \n","\n","[6896 rows x 11 columns]"],"text/html":["\n","  <div id=\"df-3e4d3688-fc3e-4fe3-9c8c-3d5d3e4c0664\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>mlp_prediction_spam</th>\n","      <th>mlp_prediction_malware</th>\n","      <th>mlp_prediction_defacemen</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","      <th>nn_prediction_spam</th>\n","      <th>nn_prediction_malware</th>\n","      <th>nn_prediction_defacemen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>3.285955e-08</td>\n","      <td>2.275952e-38</td>\n","      <td>1.000000e+00</td>\n","      <td>3.536448e-103</td>\n","      <td>5.452580e-62</td>\n","      <td>3.285955e-08</td>\n","      <td>2.275952e-38</td>\n","      <td>1.000000e+00</td>\n","      <td>3.536448e-103</td>\n","      <td>5.452580e-62</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>9.871709e-01</td>\n","      <td>1.400658e-05</td>\n","      <td>8.887072e-04</td>\n","      <td>3.094047e-04</td>\n","      <td>1.161696e-02</td>\n","      <td>9.871709e-01</td>\n","      <td>1.400658e-05</td>\n","      <td>8.887072e-04</td>\n","      <td>3.094047e-04</td>\n","      <td>1.161696e-02</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5.431999e-03</td>\n","      <td>7.265198e-03</td>\n","      <td>9.751261e-01</td>\n","      <td>1.063568e-02</td>\n","      <td>1.541009e-03</td>\n","      <td>5.431999e-03</td>\n","      <td>7.265198e-03</td>\n","      <td>9.751261e-01</td>\n","      <td>1.063568e-02</td>\n","      <td>1.541009e-03</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>6.821167e-02</td>\n","      <td>8.999669e-02</td>\n","      <td>4.175485e-02</td>\n","      <td>7.832318e-01</td>\n","      <td>1.680500e-02</td>\n","      <td>6.821167e-02</td>\n","      <td>8.999669e-02</td>\n","      <td>4.175485e-02</td>\n","      <td>7.832318e-01</td>\n","      <td>1.680500e-02</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>9.884499e-29</td>\n","      <td>3.997525e-14</td>\n","      <td>4.412196e-13</td>\n","      <td>2.773055e-33</td>\n","      <td>1.000000e+00</td>\n","      <td>9.884499e-29</td>\n","      <td>3.997525e-14</td>\n","      <td>4.412196e-13</td>\n","      <td>2.773055e-33</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6891</th>\n","      <td>2</td>\n","      <td>1.120535e-12</td>\n","      <td>1.117325e-44</td>\n","      <td>1.000000e+00</td>\n","      <td>9.068879e-112</td>\n","      <td>2.337164e-60</td>\n","      <td>1.120535e-12</td>\n","      <td>1.117325e-44</td>\n","      <td>1.000000e+00</td>\n","      <td>9.068879e-112</td>\n","      <td>2.337164e-60</td>\n","    </tr>\n","    <tr>\n","      <th>6892</th>\n","      <td>2</td>\n","      <td>8.522478e-04</td>\n","      <td>1.933313e-04</td>\n","      <td>9.989540e-01</td>\n","      <td>4.423567e-07</td>\n","      <td>4.685219e-15</td>\n","      <td>8.522478e-04</td>\n","      <td>1.933313e-04</td>\n","      <td>9.989540e-01</td>\n","      <td>4.423567e-07</td>\n","      <td>4.685219e-15</td>\n","    </tr>\n","    <tr>\n","      <th>6893</th>\n","      <td>3</td>\n","      <td>1.956546e-64</td>\n","      <td>3.955041e-62</td>\n","      <td>4.279204e-132</td>\n","      <td>1.000000e+00</td>\n","      <td>2.775327e-194</td>\n","      <td>1.956546e-64</td>\n","      <td>3.955041e-62</td>\n","      <td>4.279204e-132</td>\n","      <td>1.000000e+00</td>\n","      <td>2.775327e-194</td>\n","    </tr>\n","    <tr>\n","      <th>6894</th>\n","      <td>0</td>\n","      <td>1.449094e-01</td>\n","      <td>2.976956e-01</td>\n","      <td>3.111189e-01</td>\n","      <td>1.093811e-01</td>\n","      <td>1.368950e-01</td>\n","      <td>1.449094e-01</td>\n","      <td>2.976956e-01</td>\n","      <td>3.111189e-01</td>\n","      <td>1.093811e-01</td>\n","      <td>1.368950e-01</td>\n","    </tr>\n","    <tr>\n","      <th>6895</th>\n","      <td>0</td>\n","      <td>9.381188e-01</td>\n","      <td>6.253752e-04</td>\n","      <td>6.041733e-02</td>\n","      <td>2.580074e-05</td>\n","      <td>8.126464e-04</td>\n","      <td>9.381188e-01</td>\n","      <td>6.253752e-04</td>\n","      <td>6.041733e-02</td>\n","      <td>2.580074e-05</td>\n","      <td>8.126464e-04</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6896 rows × 11 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e4d3688-fc3e-4fe3-9c8c-3d5d3e4c0664')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3e4d3688-fc3e-4fe3-9c8c-3d5d3e4c0664 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3e4d3688-fc3e-4fe3-9c8c-3d5d3e4c0664');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["**Neural Network 2**"],"metadata":{"id":"fMdqVtYLwwy4"}},{"cell_type":"code","source":["\n","import keras\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","def model_a(x_train, x_val, y_train, y_val, opt, n, early_stopping_monitor):\n","\n","  n_cols = x_train.shape[1]\n","\n","  #create model\n","  model_2 = Sequential()\n","  model_2.add(Dense(30, activation='sigmoid', input_shape=(n_cols,)))\n","  model_2.add(Dense(25, activation='sigmoid'))\n","  model_2.add(Dense(20, activation='sigmoid'))\n","  model_2.add(Dense(15, activation='sigmoid'))\n","  model_2.add(Dense(10, activation='sigmoid'))\n","  model_2.add(Dense(1, activation = 'sigmoid'))\n","\n","  #compile model using mse as a measure of model performance\n","  model_2.compile(optimizer='adam', loss='mean_squared_error')\n","\n","\n","\n","  history = model_2.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping_monitor])\n","\n","\n","  # plt.plot(history.history['loss'])\n","  # plt.plot(history.history['val_loss'])\n","  # plt.title('model loss')\n","  # plt.ylabel('Loss')\n","  # plt.xlabel('Epoch')\n","  # plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n","  # plt.show()\n","\n","\n","  print('Validation Accuracy: ')\n","  # Predicting the Test set results\n","  y_pred = model_2.predict(x_val)\n","  y_pred = (y_pred > 0.5)\n","\n","\n","  print(classification_report(y_val, y_pred))\n","\n","  # Model Accuracy, how often is the classifier correct?\n","  print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","\n","  # Creating the Confusion Matrix\n","  cm = confusion_matrix(y_val, y_pred)\n","  print(cm)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred, average='weighted'))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred, average='weighted'))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred, average='weighted'))\n","\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/HTML/NN_2/model_'+str(n)+'.h5'\n","  pickle.dump(model_2, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","\n","  return metrics.accuracy_score(y_val, y_pred)\n","\n"],"metadata":{"id":"L8ZhB8W9tVQS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_a(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n, early_stopping_monitor)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osCV0Uo5wqac","executionInfo":{"status":"ok","timestamp":1656572056628,"user_tz":-330,"elapsed":737169,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"bc94fd9a-d15f-4cf6-badb-f24405e80187"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","238/238 [==============================] - 1s 4ms/step - loss: 3.1442 - val_loss: 2.7094\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8174 - val_loss: 2.6390\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7740 - val_loss: 2.6171\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7582 - val_loss: 2.6081\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7511 - val_loss: 2.6037\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7474 - val_loss: 2.6011\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7451 - val_loss: 2.5995\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7436 - val_loss: 2.5983\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7426 - val_loss: 2.5975\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7418 - val_loss: 2.5969\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7412 - val_loss: 2.5965\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7408 - val_loss: 2.5961\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7404 - val_loss: 2.5958\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7401 - val_loss: 2.5956\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7399 - val_loss: 2.5954\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7397 - val_loss: 2.5953\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7396 - val_loss: 2.5951\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7394 - val_loss: 2.5950\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7393 - val_loss: 2.5949\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7392 - val_loss: 2.5949\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7391 - val_loss: 2.5948\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7391 - val_loss: 2.5947\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7390 - val_loss: 2.5947\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7389 - val_loss: 2.5946\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7389 - val_loss: 2.5946\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7389 - val_loss: 2.5946\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7388 - val_loss: 2.5945\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7388 - val_loss: 2.5945\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7388 - val_loss: 2.5945\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7387 - val_loss: 2.5945\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7387 - val_loss: 2.5944\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7387 - val_loss: 2.5944\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7387 - val_loss: 2.5944\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7387 - val_loss: 2.5944\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7387 - val_loss: 2.5944\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5944\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5944\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5944\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5944\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5944\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.5943\n","Validation Accuracy: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       286\n","           1       0.12      1.00      0.21       101\n","           2       0.00      0.00      0.00       151\n","           3       0.00      0.00      0.00       199\n","           4       0.00      0.00      0.00       106\n","\n","    accuracy                           0.12       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.12      0.03       843\n","\n","Accuracy: 0.11981020166073547\n","[[  0 286   0   0   0]\n"," [  0 101   0   0   0]\n"," [  0 151   0   0   0]\n"," [  0 199   0   0   0]\n"," [  0 106   0   0   0]]\n","Precision: 0.0144\n","Recall: 0.1198\n","F1 Score: 0.0256\n","INFO:tensorflow:Assets written to: ram://92d477f4-90f6-4bea-a092-bef39939c653/assets\n","model 0 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.3787 - val_loss: 2.8700\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8902 - val_loss: 2.7402\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8120 - val_loss: 2.6987\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7823 - val_loss: 2.6796\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7671 - val_loss: 2.6688\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7579 - val_loss: 2.6620\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7520 - val_loss: 2.6574\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7480 - val_loss: 2.6542\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7451 - val_loss: 2.6518\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7429 - val_loss: 2.6500\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7412 - val_loss: 2.6486\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7399 - val_loss: 2.6475\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7389 - val_loss: 2.6466\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7380 - val_loss: 2.6459\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7373 - val_loss: 2.6453\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7368 - val_loss: 2.6448\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7363 - val_loss: 2.6444\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7359 - val_loss: 2.6440\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7355 - val_loss: 2.6437\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7352 - val_loss: 2.6435\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7350 - val_loss: 2.6433\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7348 - val_loss: 2.6431\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7346 - val_loss: 2.6429\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7344 - val_loss: 2.6427\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7343 - val_loss: 2.6426\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7341 - val_loss: 2.6425\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7340 - val_loss: 2.6424\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7339 - val_loss: 2.6423\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7338 - val_loss: 2.6422\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7338 - val_loss: 2.6422\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7337 - val_loss: 2.6421\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7336 - val_loss: 2.6421\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7336 - val_loss: 2.6420\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7336 - val_loss: 2.6420\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7335 - val_loss: 2.6420\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7335 - val_loss: 2.6419\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7335 - val_loss: 2.6419\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7335 - val_loss: 2.6419\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7334 - val_loss: 2.6419\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7334 - val_loss: 2.6419\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7334 - val_loss: 2.6419\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7334 - val_loss: 2.6418\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7334 - val_loss: 2.6418\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7334 - val_loss: 2.6418\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7334 - val_loss: 2.6418\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7334 - val_loss: 2.6418\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7333 - val_loss: 2.6418\n","Validation Accuracy: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       275\n","           1       0.13      1.00      0.23       109\n","           2       0.00      0.00      0.00       148\n","           3       0.00      0.00      0.00       199\n","           4       0.00      0.00      0.00       112\n","\n","    accuracy                           0.13       843\n","   macro avg       0.03      0.20      0.05       843\n","weighted avg       0.02      0.13      0.03       843\n","\n","Accuracy: 0.12930011862396204\n","[[  0 275   0   0   0]\n"," [  0 109   0   0   0]\n"," [  0 148   0   0   0]\n"," [  0 199   0   0   0]\n"," [  0 112   0   0   0]]\n","Precision: 0.0167\n","Recall: 0.1293\n","F1 Score: 0.0296\n","INFO:tensorflow:Assets written to: ram://0f7ab600-42f0-45cd-be1d-387c9dbd8b92/assets\n","model 1 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.1458 - val_loss: 3.0329\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8059 - val_loss: 2.9362\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7551 - val_loss: 2.9072\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7366 - val_loss: 2.8941\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7274 - val_loss: 2.8869\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7221 - val_loss: 2.8825\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7187 - val_loss: 2.8795\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7164 - val_loss: 2.8775\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7147 - val_loss: 2.8759\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7134 - val_loss: 2.8748\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7125 - val_loss: 2.8739\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7117 - val_loss: 2.8732\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7111 - val_loss: 2.8726\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7107 - val_loss: 2.8721\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7102 - val_loss: 2.8717\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7099 - val_loss: 2.8714\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7096 - val_loss: 2.8711\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7094 - val_loss: 2.8709\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7092 - val_loss: 2.8707\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7090 - val_loss: 2.8705\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7089 - val_loss: 2.8704\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7087 - val_loss: 2.8703\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7086 - val_loss: 2.8702\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7085 - val_loss: 2.8701\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7085 - val_loss: 2.8700\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7084 - val_loss: 2.8699\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7084 - val_loss: 2.8699\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7083 - val_loss: 2.8698\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7083 - val_loss: 2.8698\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7082 - val_loss: 2.8698\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7082 - val_loss: 2.8697\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7082 - val_loss: 2.8697\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7082 - val_loss: 2.8697\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7081 - val_loss: 2.8697\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7081 - val_loss: 2.8697\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7081 - val_loss: 2.8696\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7081 - val_loss: 2.8696\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7081 - val_loss: 2.8696\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7081 - val_loss: 2.8696\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7081 - val_loss: 2.8696\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8696\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8696\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8696\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8696\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8696\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 51/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 52/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 53/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7080 - val_loss: 2.8695\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       271\n","           1       0.11      1.00      0.19        91\n","           2       0.00      0.00      0.00       152\n","           3       0.00      0.00      0.00       193\n","           4       0.00      0.00      0.00       136\n","\n","    accuracy                           0.11       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.11      0.02       843\n","\n","Accuracy: 0.10794780545670225\n","[[  0 271   0   0   0]\n"," [  0  91   0   0   0]\n"," [  0 152   0   0   0]\n"," [  0 193   0   0   0]\n"," [  0 136   0   0   0]]\n","Precision: 0.0117\n","Recall: 0.1079\n","F1 Score: 0.0210\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://19aa7e29-0379-4d9d-a0f1-125d2be51f60/assets\n","model 2 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.0944 - val_loss: 2.8117\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8075 - val_loss: 2.7420\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7693 - val_loss: 2.7202\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7541 - val_loss: 2.7095\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7461 - val_loss: 2.7035\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7414 - val_loss: 2.6997\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7384 - val_loss: 2.6971\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7362 - val_loss: 2.6953\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7346 - val_loss: 2.6939\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7334 - val_loss: 2.6929\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7325 - val_loss: 2.6921\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6914\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7312 - val_loss: 2.6909\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7308 - val_loss: 2.6905\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7304 - val_loss: 2.6901\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7301 - val_loss: 2.6898\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7298 - val_loss: 2.6896\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7296 - val_loss: 2.6894\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7294 - val_loss: 2.6892\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7292 - val_loss: 2.6891\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7291 - val_loss: 2.6889\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7290 - val_loss: 2.6888\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7289 - val_loss: 2.6887\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7288 - val_loss: 2.6886\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7287 - val_loss: 2.6886\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7286 - val_loss: 2.6885\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7286 - val_loss: 2.6884\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7285 - val_loss: 2.6884\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7285 - val_loss: 2.6883\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7285 - val_loss: 2.6883\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7284 - val_loss: 2.6883\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7284 - val_loss: 2.6882\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7284 - val_loss: 2.6882\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7283 - val_loss: 2.6882\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7283 - val_loss: 2.6882\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7283 - val_loss: 2.6882\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7283 - val_loss: 2.6881\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7283 - val_loss: 2.6881\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6881\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6881\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6881\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6881\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6881\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6881\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6881\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6881\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6881\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6881\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6880\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6880\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6880\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6880\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6880\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6880\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6880\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6880\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6880\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6880\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6880\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6880\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6880\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.6880\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.6880\n","Validation Accuracy: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       266\n","           1       0.11      1.00      0.19        90\n","           2       0.00      0.00      0.00       186\n","           3       0.00      0.00      0.00       179\n","           4       0.00      0.00      0.00       122\n","\n","    accuracy                           0.11       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.11      0.02       843\n","\n","Accuracy: 0.10676156583629894\n","[[  0 266   0   0   0]\n"," [  0  90   0   0   0]\n"," [  0 186   0   0   0]\n"," [  0 179   0   0   0]\n"," [  0 122   0   0   0]]\n","Precision: 0.0114\n","Recall: 0.1068\n","F1 Score: 0.0206\n","INFO:tensorflow:Assets written to: ram://a2f84ee8-06be-488f-aa11-94ba6f3193b7/assets\n","model 3 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.9339 - val_loss: 2.8776\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7659 - val_loss: 2.8353\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7419 - val_loss: 2.8214\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7323 - val_loss: 2.8146\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7272 - val_loss: 2.8107\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7241 - val_loss: 2.8082\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7221 - val_loss: 2.8066\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.8054\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7197 - val_loss: 2.8045\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7190 - val_loss: 2.8038\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7184 - val_loss: 2.8033\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7180 - val_loss: 2.8029\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7176 - val_loss: 2.8026\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7173 - val_loss: 2.8023\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7171 - val_loss: 2.8021\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7169 - val_loss: 2.8019\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7167 - val_loss: 2.8017\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7165 - val_loss: 2.8016\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7164 - val_loss: 2.8015\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7163 - val_loss: 2.8014\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7162 - val_loss: 2.8013\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7162 - val_loss: 2.8012\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7161 - val_loss: 2.8012\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7160 - val_loss: 2.8011\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7160 - val_loss: 2.8011\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7159 - val_loss: 2.8010\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7159 - val_loss: 2.8010\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7159 - val_loss: 2.8009\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7158 - val_loss: 2.8009\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7158 - val_loss: 2.8009\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7158 - val_loss: 2.8009\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7158 - val_loss: 2.8009\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7158 - val_loss: 2.8008\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7157 - val_loss: 2.8008\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7157 - val_loss: 2.8008\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7157 - val_loss: 2.8008\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7157 - val_loss: 2.8008\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7157 - val_loss: 2.8008\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7157 - val_loss: 2.8008\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7157 - val_loss: 2.8008\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7157 - val_loss: 2.8008\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7157 - val_loss: 2.8008\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7157 - val_loss: 2.8007\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7157 - val_loss: 2.8007\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7157 - val_loss: 2.8007\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 2.8007\n","Validation Accuracy: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       283\n","           1       0.09      1.00      0.17        76\n","           2       0.00      0.00      0.00       161\n","           3       0.00      0.00      0.00       198\n","           4       0.00      0.00      0.00       125\n","\n","    accuracy                           0.09       843\n","   macro avg       0.02      0.20      0.03       843\n","weighted avg       0.01      0.09      0.01       843\n","\n","Accuracy: 0.09015421115065243\n","[[  0 283   0   0   0]\n"," [  0  76   0   0   0]\n"," [  0 161   0   0   0]\n"," [  0 198   0   0   0]\n"," [  0 125   0   0   0]]\n","Precision: 0.0081\n","Recall: 0.0902\n","F1 Score: 0.0149\n","INFO:tensorflow:Assets written to: ram://d83bfa45-48e0-4527-ba82-9ea763cad872/assets\n","model 4 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.2012 - val_loss: 2.9192\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8272 - val_loss: 2.8307\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7770 - val_loss: 2.8002\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7565 - val_loss: 2.7852\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7457 - val_loss: 2.7766\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7392 - val_loss: 2.7712\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7349 - val_loss: 2.7675\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.7649\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7297 - val_loss: 2.7629\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7281 - val_loss: 2.7614\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7269 - val_loss: 2.7603\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7259 - val_loss: 2.7594\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7251 - val_loss: 2.7586\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7244 - val_loss: 2.7580\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7239 - val_loss: 2.7575\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7235 - val_loss: 2.7571\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7231 - val_loss: 2.7567\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7228 - val_loss: 2.7564\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7225 - val_loss: 2.7562\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7223 - val_loss: 2.7559\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7221 - val_loss: 2.7558\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7219 - val_loss: 2.7556\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7218 - val_loss: 2.7555\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7217 - val_loss: 2.7553\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7216 - val_loss: 2.7552\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7215 - val_loss: 2.7551\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7214 - val_loss: 2.7551\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7213 - val_loss: 2.7550\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7212 - val_loss: 2.7549\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7212 - val_loss: 2.7549\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7211 - val_loss: 2.7548\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7211 - val_loss: 2.7548\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7211 - val_loss: 2.7547\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7210 - val_loss: 2.7547\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7210 - val_loss: 2.7547\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7210 - val_loss: 2.7546\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7209 - val_loss: 2.7546\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7209 - val_loss: 2.7546\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7209 - val_loss: 2.7546\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7209 - val_loss: 2.7546\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7209 - val_loss: 2.7545\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7209 - val_loss: 2.7545\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7545\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7544\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7544\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7544\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7544\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7544\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7544\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7544\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7544\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7544\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7544\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7544\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7544\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7544\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7544\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7208 - val_loss: 2.7544\n","Validation Accuracy: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       265\n","           1       0.11      1.00      0.19        90\n","           2       0.00      0.00      0.00       170\n","           3       0.00      0.00      0.00       195\n","           4       0.00      0.00      0.00       123\n","\n","    accuracy                           0.11       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.11      0.02       843\n","\n","Accuracy: 0.10676156583629894\n","[[  0 265   0   0   0]\n"," [  0  90   0   0   0]\n"," [  0 170   0   0   0]\n"," [  0 195   0   0   0]\n"," [  0 123   0   0   0]]\n","Precision: 0.0114\n","Recall: 0.1068\n","F1 Score: 0.0206\n","INFO:tensorflow:Assets written to: ram://0e264365-ec5b-4b52-99a0-83f274bdd5b3/assets\n","model 5 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.1839 - val_loss: 2.8663\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8331 - val_loss: 2.7706\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7790 - val_loss: 2.7423\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7590 - val_loss: 2.7290\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7486 - val_loss: 2.7216\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7426 - val_loss: 2.7170\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.7138\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7358 - val_loss: 2.7114\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7337 - val_loss: 2.7097\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7322 - val_loss: 2.7084\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7310 - val_loss: 2.7075\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7302 - val_loss: 2.7067\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7295 - val_loss: 2.7062\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7290 - val_loss: 2.7058\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7286 - val_loss: 2.7054\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7283 - val_loss: 2.7051\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7280 - val_loss: 2.7049\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7278 - val_loss: 2.7047\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7276 - val_loss: 2.7045\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7275 - val_loss: 2.7044\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7273 - val_loss: 2.7043\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7272 - val_loss: 2.7042\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7271 - val_loss: 2.7041\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7270 - val_loss: 2.7040\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7270 - val_loss: 2.7039\n","Epoch 26/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.7269 - val_loss: 2.7039\n","Epoch 27/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.7268 - val_loss: 2.7038\n","Epoch 28/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.7268 - val_loss: 2.7038\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7267 - val_loss: 2.7037\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7267 - val_loss: 2.7037\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7267 - val_loss: 2.7037\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7267 - val_loss: 2.7036\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7036\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7036\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7036\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7036\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7035\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7265 - val_loss: 2.7035\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7265 - val_loss: 2.7035\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7265 - val_loss: 2.7035\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7265 - val_loss: 2.7035\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7265 - val_loss: 2.7035\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7265 - val_loss: 2.7035\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7265 - val_loss: 2.7035\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7265 - val_loss: 2.7035\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7265 - val_loss: 2.7035\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7265 - val_loss: 2.7035\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7265 - val_loss: 2.7035\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7265 - val_loss: 2.7035\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7265 - val_loss: 2.7035\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7265 - val_loss: 2.7035\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7265 - val_loss: 2.7035\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7035\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7035\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7035\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7035\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7264 - val_loss: 2.7034\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       284\n","           1       0.10      1.00      0.18        82\n","           2       0.00      0.00      0.00       166\n","           3       0.00      0.00      0.00       194\n","           4       0.00      0.00      0.00       117\n","\n","    accuracy                           0.10       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.10      0.02       843\n","\n","Accuracy: 0.09727164887307237\n","[[  0 284   0   0   0]\n"," [  0  82   0   0   0]\n"," [  0 166   0   0   0]\n"," [  0 194   0   0   0]\n"," [  0 117   0   0   0]]\n","Precision: 0.0095\n","Recall: 0.0973\n","F1 Score: 0.0172\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://92b422f2-58a6-4187-9242-2e36f230fe2a/assets\n","model 6 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.0819 - val_loss: 2.7730\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8031 - val_loss: 2.7012\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7657 - val_loss: 2.6808\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7523 - val_loss: 2.6717\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7457 - val_loss: 2.6667\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7419 - val_loss: 2.6637\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7395 - val_loss: 2.6616\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7378 - val_loss: 2.6602\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7366 - val_loss: 2.6592\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7357 - val_loss: 2.6584\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7350 - val_loss: 2.6577\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7345 - val_loss: 2.6573\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7341 - val_loss: 2.6569\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7337 - val_loss: 2.6566\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7334 - val_loss: 2.6563\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7332 - val_loss: 2.6561\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7330 - val_loss: 2.6559\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7329 - val_loss: 2.6558\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7327 - val_loss: 2.6556\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7326 - val_loss: 2.6555\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7325 - val_loss: 2.6554\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7324 - val_loss: 2.6554\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7324 - val_loss: 2.6553\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7323 - val_loss: 2.6552\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7322 - val_loss: 2.6552\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7322 - val_loss: 2.6551\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7321 - val_loss: 2.6551\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7321 - val_loss: 2.6551\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7321 - val_loss: 2.6550\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7321 - val_loss: 2.6550\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7320 - val_loss: 2.6550\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7320 - val_loss: 2.6550\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7320 - val_loss: 2.6549\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7320 - val_loss: 2.6549\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7320 - val_loss: 2.6549\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6549\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6549\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6549\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6549\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6549\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6549\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6549\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6548\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6548\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6548\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6548\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6548\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6548\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6548\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6548\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6548\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7319 - val_loss: 2.6548\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7318 - val_loss: 2.6548\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       257\n","           1       0.12      1.00      0.21       100\n","           2       0.00      0.00      0.00       181\n","           3       0.00      0.00      0.00       189\n","           4       0.00      0.00      0.00       116\n","\n","    accuracy                           0.12       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.12      0.03       843\n","\n","Accuracy: 0.11862396204033215\n","[[  0 257   0   0   0]\n"," [  0 100   0   0   0]\n"," [  0 181   0   0   0]\n"," [  0 189   0   0   0]\n"," [  0 116   0   0   0]]\n","Precision: 0.0141\n","Recall: 0.1186\n","F1 Score: 0.0252\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://34ca09b0-b8aa-4d5f-be47-82bf1d568024/assets\n","model 7 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 4ms/step - loss: 3.5398 - val_loss: 3.0679\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.9852 - val_loss: 2.8706\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8493 - val_loss: 2.7818\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7894 - val_loss: 2.7480\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7654 - val_loss: 2.7325\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7535 - val_loss: 2.7239\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7464 - val_loss: 2.7185\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7418 - val_loss: 2.7148\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7386 - val_loss: 2.7122\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7362 - val_loss: 2.7103\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7345 - val_loss: 2.7088\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7331 - val_loss: 2.7077\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7321 - val_loss: 2.7068\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7312 - val_loss: 2.7060\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7305 - val_loss: 2.7054\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7300 - val_loss: 2.7049\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7295 - val_loss: 2.7045\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7291 - val_loss: 2.7042\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7288 - val_loss: 2.7039\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7285 - val_loss: 2.7036\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7282 - val_loss: 2.7034\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7280 - val_loss: 2.7032\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7278 - val_loss: 2.7030\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7276 - val_loss: 2.7028\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7275 - val_loss: 2.7027\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7274 - val_loss: 2.7026\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7273 - val_loss: 2.7025\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7272 - val_loss: 2.7024\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7271 - val_loss: 2.7023\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7270 - val_loss: 2.7023\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7270 - val_loss: 2.7022\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7269 - val_loss: 2.7022\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7269 - val_loss: 2.7021\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7268 - val_loss: 2.7021\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7268 - val_loss: 2.7021\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7268 - val_loss: 2.7021\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7268 - val_loss: 2.7020\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7267 - val_loss: 2.7020\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7267 - val_loss: 2.7020\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7267 - val_loss: 2.7020\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7267 - val_loss: 2.7020\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7267 - val_loss: 2.7020\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7267 - val_loss: 2.7020\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7267 - val_loss: 2.7020\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7267 - val_loss: 2.7020\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7267 - val_loss: 2.7020\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7266 - val_loss: 2.7019\n","Validation Accuracy: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       287\n","           1       0.10      1.00      0.18        82\n","           2       0.00      0.00      0.00       153\n","           3       0.00      0.00      0.00       209\n","           4       0.00      0.00      0.00       111\n","\n","    accuracy                           0.10       842\n","   macro avg       0.02      0.20      0.04       842\n","weighted avg       0.01      0.10      0.02       842\n","\n","Accuracy: 0.09738717339667459\n","[[  0 287   0   0   0]\n"," [  0  82   0   0   0]\n"," [  0 153   0   0   0]\n"," [  0 209   0   0   0]\n"," [  0 111   0   0   0]]\n","Precision: 0.0095\n","Recall: 0.0974\n","F1 Score: 0.0173\n","INFO:tensorflow:Assets written to: ram://ee21c0e8-fb4f-463e-8fd1-b5023c4aab90/assets\n","model 8 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8481 - val_loss: 2.8696\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7338 - val_loss: 2.8466\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7222 - val_loss: 2.8405\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7183 - val_loss: 2.8378\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7164 - val_loss: 2.8363\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7153 - val_loss: 2.8354\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7145 - val_loss: 2.8348\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7140 - val_loss: 2.8343\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7136 - val_loss: 2.8340\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7134 - val_loss: 2.8337\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7132 - val_loss: 2.8335\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7130 - val_loss: 2.8334\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7128 - val_loss: 2.8333\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7127 - val_loss: 2.8332\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7126 - val_loss: 2.8331\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7126 - val_loss: 2.8330\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7125 - val_loss: 2.8329\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7125 - val_loss: 2.8329\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7124 - val_loss: 2.8328\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7124 - val_loss: 2.8328\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7123 - val_loss: 2.8328\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7123 - val_loss: 2.8327\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7123 - val_loss: 2.8327\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7123 - val_loss: 2.8327\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7122 - val_loss: 2.8327\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7122 - val_loss: 2.8327\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7122 - val_loss: 2.8326\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7122 - val_loss: 2.8326\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7122 - val_loss: 2.8326\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7122 - val_loss: 2.8326\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7122 - val_loss: 2.8326\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7122 - val_loss: 2.8326\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7122 - val_loss: 2.8326\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8326\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8326\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8326\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8326\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8326\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8326\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8326\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8326\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8326\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8326\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8326\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8326\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8326\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8326\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7121 - val_loss: 2.8325\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       286\n","           1       0.08      1.00      0.14        64\n","           2       0.00      0.00      0.00       163\n","           3       0.00      0.00      0.00       205\n","           4       0.00      0.00      0.00       124\n","\n","    accuracy                           0.08       842\n","   macro avg       0.02      0.20      0.03       842\n","weighted avg       0.01      0.08      0.01       842\n","\n","Accuracy: 0.07600950118764846\n","[[  0 286   0   0   0]\n"," [  0  64   0   0   0]\n"," [  0 163   0   0   0]\n"," [  0 205   0   0   0]\n"," [  0 124   0   0   0]]\n","Precision: 0.0058\n","Recall: 0.0760\n","F1 Score: 0.0107\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://0227e7cf-744f-4597-ba30-b2a03c8ab898/assets\n","model 9 saved\n","Average Validation Accuracy: 0.10500277540623774\n"]}]},{"cell_type":"code","source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/HTML/NN_2/model_1.h5'\n","\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","def predict_prob(number):\n","  return [number[0],1-number[0]]\n","\n","y_prob = np.array(list(map(predict_prob, loaded_model.predict(x_test))))\n","y_prob \n","\n","# y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['nn2_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['nn2_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output['nn2_prediction_spam'] = [i[2] for i in y_pred_prob];\n","output['nn2_prediction_malware'] = [i[3] for i in y_pred_prob];\n","output['nn2_prediction_defacemen'] = [i[4] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":713},"id":"JPT9oIQ0wuZf","executionInfo":{"status":"ok","timestamp":1656572100261,"user_tz":-330,"elapsed":788,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"1d4881ae-101f-4bf7-f9a4-9b3c4f831b65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[3.28595502e-008 2.27595203e-038 9.99999967e-001 3.53644837e-103\n","  5.45258001e-062]\n"," [9.87170919e-001 1.40065769e-005 8.88707177e-004 3.09404654e-004\n","  1.16169622e-002]\n"," [5.43199900e-003 7.26519788e-003 9.75126111e-001 1.06356829e-002\n","  1.54100894e-003]\n"," ...\n"," [1.95654589e-064 3.95504084e-062 4.27920447e-132 1.00000000e+000\n","  2.77532688e-194]\n"," [1.44909380e-001 2.97695615e-001 3.11118892e-001 1.09381100e-001\n","  1.36895013e-001]\n"," [9.38118847e-001 6.25375208e-004 6.04173309e-002 2.58007396e-005\n","  8.12646395e-004]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  mlp_prediction_spam  \\\n","0          2        3.285955e-08          2.275952e-38         1.000000e+00   \n","1          0        9.871709e-01          1.400658e-05         8.887072e-04   \n","2          2        5.431999e-03          7.265198e-03         9.751261e-01   \n","3          3        6.821167e-02          8.999669e-02         4.175485e-02   \n","4          0        1.000000e+00          9.884499e-29         3.997525e-14   \n","...      ...                 ...                   ...                  ...   \n","6891       2        1.120535e-12          1.117325e-44         1.000000e+00   \n","6892       2        8.522478e-04          1.933313e-04         9.989540e-01   \n","6893       3        1.956546e-64          3.955041e-62        4.279204e-132   \n","6894       0        1.449094e-01          2.976956e-01         3.111189e-01   \n","6895       0        9.381188e-01          6.253752e-04         6.041733e-02   \n","\n","      mlp_prediction_malware  mlp_prediction_defacemen  nn_prediction_non  \\\n","0              3.536448e-103              5.452580e-62       3.285955e-08   \n","1               3.094047e-04              1.161696e-02       9.871709e-01   \n","2               1.063568e-02              1.541009e-03       5.431999e-03   \n","3               7.832318e-01              1.680500e-02       6.821167e-02   \n","4               4.412196e-13              2.773055e-33       1.000000e+00   \n","...                      ...                       ...                ...   \n","6891           9.068879e-112              2.337164e-60       1.120535e-12   \n","6892            4.423567e-07              4.685219e-15       8.522478e-04   \n","6893            1.000000e+00             2.775327e-194       1.956546e-64   \n","6894            1.093811e-01              1.368950e-01       1.449094e-01   \n","6895            2.580074e-05              8.126464e-04       9.381188e-01   \n","\n","      nn_prediction_phish  nn_prediction_spam  nn_prediction_malware  \\\n","0            2.275952e-38        1.000000e+00          3.536448e-103   \n","1            1.400658e-05        8.887072e-04           3.094047e-04   \n","2            7.265198e-03        9.751261e-01           1.063568e-02   \n","3            8.999669e-02        4.175485e-02           7.832318e-01   \n","4            9.884499e-29        3.997525e-14           4.412196e-13   \n","...                   ...                 ...                    ...   \n","6891         1.117325e-44        1.000000e+00          9.068879e-112   \n","6892         1.933313e-04        9.989540e-01           4.423567e-07   \n","6893         3.955041e-62       4.279204e-132           1.000000e+00   \n","6894         2.976956e-01        3.111189e-01           1.093811e-01   \n","6895         6.253752e-04        6.041733e-02           2.580074e-05   \n","\n","      nn_prediction_defacemen  nn2_prediction_non  nn2_prediction_phish  \\\n","0                5.452580e-62        3.285955e-08          2.275952e-38   \n","1                1.161696e-02        9.871709e-01          1.400658e-05   \n","2                1.541009e-03        5.431999e-03          7.265198e-03   \n","3                1.680500e-02        6.821167e-02          8.999669e-02   \n","4                2.773055e-33        1.000000e+00          9.884499e-29   \n","...                       ...                 ...                   ...   \n","6891             2.337164e-60        1.120535e-12          1.117325e-44   \n","6892             4.685219e-15        8.522478e-04          1.933313e-04   \n","6893            2.775327e-194        1.956546e-64          3.955041e-62   \n","6894             1.368950e-01        1.449094e-01          2.976956e-01   \n","6895             8.126464e-04        9.381188e-01          6.253752e-04   \n","\n","      nn2_prediction_spam  nn2_prediction_malware  nn2_prediction_defacemen  \n","0            1.000000e+00           3.536448e-103              5.452580e-62  \n","1            8.887072e-04            3.094047e-04              1.161696e-02  \n","2            9.751261e-01            1.063568e-02              1.541009e-03  \n","3            4.175485e-02            7.832318e-01              1.680500e-02  \n","4            3.997525e-14            4.412196e-13              2.773055e-33  \n","...                   ...                     ...                       ...  \n","6891         1.000000e+00           9.068879e-112              2.337164e-60  \n","6892         9.989540e-01            4.423567e-07              4.685219e-15  \n","6893        4.279204e-132            1.000000e+00             2.775327e-194  \n","6894         3.111189e-01            1.093811e-01              1.368950e-01  \n","6895         6.041733e-02            2.580074e-05              8.126464e-04  \n","\n","[6896 rows x 16 columns]"],"text/html":["\n","  <div id=\"df-26cd1111-db1c-48d7-95b1-0731441a3026\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>mlp_prediction_spam</th>\n","      <th>mlp_prediction_malware</th>\n","      <th>mlp_prediction_defacemen</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","      <th>nn_prediction_spam</th>\n","      <th>nn_prediction_malware</th>\n","      <th>nn_prediction_defacemen</th>\n","      <th>nn2_prediction_non</th>\n","      <th>nn2_prediction_phish</th>\n","      <th>nn2_prediction_spam</th>\n","      <th>nn2_prediction_malware</th>\n","      <th>nn2_prediction_defacemen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>3.285955e-08</td>\n","      <td>2.275952e-38</td>\n","      <td>1.000000e+00</td>\n","      <td>3.536448e-103</td>\n","      <td>5.452580e-62</td>\n","      <td>3.285955e-08</td>\n","      <td>2.275952e-38</td>\n","      <td>1.000000e+00</td>\n","      <td>3.536448e-103</td>\n","      <td>5.452580e-62</td>\n","      <td>3.285955e-08</td>\n","      <td>2.275952e-38</td>\n","      <td>1.000000e+00</td>\n","      <td>3.536448e-103</td>\n","      <td>5.452580e-62</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>9.871709e-01</td>\n","      <td>1.400658e-05</td>\n","      <td>8.887072e-04</td>\n","      <td>3.094047e-04</td>\n","      <td>1.161696e-02</td>\n","      <td>9.871709e-01</td>\n","      <td>1.400658e-05</td>\n","      <td>8.887072e-04</td>\n","      <td>3.094047e-04</td>\n","      <td>1.161696e-02</td>\n","      <td>9.871709e-01</td>\n","      <td>1.400658e-05</td>\n","      <td>8.887072e-04</td>\n","      <td>3.094047e-04</td>\n","      <td>1.161696e-02</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5.431999e-03</td>\n","      <td>7.265198e-03</td>\n","      <td>9.751261e-01</td>\n","      <td>1.063568e-02</td>\n","      <td>1.541009e-03</td>\n","      <td>5.431999e-03</td>\n","      <td>7.265198e-03</td>\n","      <td>9.751261e-01</td>\n","      <td>1.063568e-02</td>\n","      <td>1.541009e-03</td>\n","      <td>5.431999e-03</td>\n","      <td>7.265198e-03</td>\n","      <td>9.751261e-01</td>\n","      <td>1.063568e-02</td>\n","      <td>1.541009e-03</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>6.821167e-02</td>\n","      <td>8.999669e-02</td>\n","      <td>4.175485e-02</td>\n","      <td>7.832318e-01</td>\n","      <td>1.680500e-02</td>\n","      <td>6.821167e-02</td>\n","      <td>8.999669e-02</td>\n","      <td>4.175485e-02</td>\n","      <td>7.832318e-01</td>\n","      <td>1.680500e-02</td>\n","      <td>6.821167e-02</td>\n","      <td>8.999669e-02</td>\n","      <td>4.175485e-02</td>\n","      <td>7.832318e-01</td>\n","      <td>1.680500e-02</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>9.884499e-29</td>\n","      <td>3.997525e-14</td>\n","      <td>4.412196e-13</td>\n","      <td>2.773055e-33</td>\n","      <td>1.000000e+00</td>\n","      <td>9.884499e-29</td>\n","      <td>3.997525e-14</td>\n","      <td>4.412196e-13</td>\n","      <td>2.773055e-33</td>\n","      <td>1.000000e+00</td>\n","      <td>9.884499e-29</td>\n","      <td>3.997525e-14</td>\n","      <td>4.412196e-13</td>\n","      <td>2.773055e-33</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6891</th>\n","      <td>2</td>\n","      <td>1.120535e-12</td>\n","      <td>1.117325e-44</td>\n","      <td>1.000000e+00</td>\n","      <td>9.068879e-112</td>\n","      <td>2.337164e-60</td>\n","      <td>1.120535e-12</td>\n","      <td>1.117325e-44</td>\n","      <td>1.000000e+00</td>\n","      <td>9.068879e-112</td>\n","      <td>2.337164e-60</td>\n","      <td>1.120535e-12</td>\n","      <td>1.117325e-44</td>\n","      <td>1.000000e+00</td>\n","      <td>9.068879e-112</td>\n","      <td>2.337164e-60</td>\n","    </tr>\n","    <tr>\n","      <th>6892</th>\n","      <td>2</td>\n","      <td>8.522478e-04</td>\n","      <td>1.933313e-04</td>\n","      <td>9.989540e-01</td>\n","      <td>4.423567e-07</td>\n","      <td>4.685219e-15</td>\n","      <td>8.522478e-04</td>\n","      <td>1.933313e-04</td>\n","      <td>9.989540e-01</td>\n","      <td>4.423567e-07</td>\n","      <td>4.685219e-15</td>\n","      <td>8.522478e-04</td>\n","      <td>1.933313e-04</td>\n","      <td>9.989540e-01</td>\n","      <td>4.423567e-07</td>\n","      <td>4.685219e-15</td>\n","    </tr>\n","    <tr>\n","      <th>6893</th>\n","      <td>3</td>\n","      <td>1.956546e-64</td>\n","      <td>3.955041e-62</td>\n","      <td>4.279204e-132</td>\n","      <td>1.000000e+00</td>\n","      <td>2.775327e-194</td>\n","      <td>1.956546e-64</td>\n","      <td>3.955041e-62</td>\n","      <td>4.279204e-132</td>\n","      <td>1.000000e+00</td>\n","      <td>2.775327e-194</td>\n","      <td>1.956546e-64</td>\n","      <td>3.955041e-62</td>\n","      <td>4.279204e-132</td>\n","      <td>1.000000e+00</td>\n","      <td>2.775327e-194</td>\n","    </tr>\n","    <tr>\n","      <th>6894</th>\n","      <td>0</td>\n","      <td>1.449094e-01</td>\n","      <td>2.976956e-01</td>\n","      <td>3.111189e-01</td>\n","      <td>1.093811e-01</td>\n","      <td>1.368950e-01</td>\n","      <td>1.449094e-01</td>\n","      <td>2.976956e-01</td>\n","      <td>3.111189e-01</td>\n","      <td>1.093811e-01</td>\n","      <td>1.368950e-01</td>\n","      <td>1.449094e-01</td>\n","      <td>2.976956e-01</td>\n","      <td>3.111189e-01</td>\n","      <td>1.093811e-01</td>\n","      <td>1.368950e-01</td>\n","    </tr>\n","    <tr>\n","      <th>6895</th>\n","      <td>0</td>\n","      <td>9.381188e-01</td>\n","      <td>6.253752e-04</td>\n","      <td>6.041733e-02</td>\n","      <td>2.580074e-05</td>\n","      <td>8.126464e-04</td>\n","      <td>9.381188e-01</td>\n","      <td>6.253752e-04</td>\n","      <td>6.041733e-02</td>\n","      <td>2.580074e-05</td>\n","      <td>8.126464e-04</td>\n","      <td>9.381188e-01</td>\n","      <td>6.253752e-04</td>\n","      <td>6.041733e-02</td>\n","      <td>2.580074e-05</td>\n","      <td>8.126464e-04</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6896 rows × 16 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26cd1111-db1c-48d7-95b1-0731441a3026')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-26cd1111-db1c-48d7-95b1-0731441a3026 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-26cd1111-db1c-48d7-95b1-0731441a3026');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["output.shape\n"],"metadata":{"id":"0lDqtfllUmwv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656572100262,"user_tz":-330,"elapsed":12,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"2ea5c533-0b66-47a4-aa22-9149eb2b910a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6896, 16)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["# Storing the data in CSV file\n","output.to_csv('/content/drive/MyDrive/Phishing/UNB/Multi/Base_classifier_result(HTML cross)(3).csv', index=False)"],"metadata":{"id":"ZsQkUbz6AiTx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"RN_-swX0JdhP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"W9DI0WYaJde9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"49lwyWNz0mSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"_9Vdw_Wx2NEo"},"execution_count":null,"outputs":[]}]}