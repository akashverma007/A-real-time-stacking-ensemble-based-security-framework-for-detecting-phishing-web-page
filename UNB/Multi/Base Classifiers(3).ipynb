{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Base Classifiers(3).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"PH13wfswmyDv"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Aiz0olfdKb4b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656566339135,"user_tz":-330,"elapsed":102585,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"28ecdb98-9b00-482f-aae1-8e9269e75a7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["urldata = pd.read_csv(\"/content/drive/MyDrive/Phishing/UNB/URL-HTML/preprocessed_url_features(multi).csv\")\n","urldata\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":485},"id":"Dw-EEymHAGNs","outputId":"5ab93c4f-3b2a-425a-9176-3bea5338aff7","executionInfo":{"status":"ok","timestamp":1656566376808,"user_tz":-330,"elapsed":1774,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Unnamed: 0  Have IP  Have @  URL Length  URL Depth  Redirection  \\\n","0               0        0       0           1          1            0   \n","1               1        0       0           1          1            1   \n","2               2        0       0           1          1            0   \n","3               3        0       0           1          3            0   \n","4               4        0       0           1          3            0   \n","...           ...      ...     ...         ...        ...          ...   \n","15319       23429        0       0           1          1            0   \n","15320       23430        0       0           1          1            0   \n","15321       23431        0       0           1          1            0   \n","15322       23432        0       0           1          1            0   \n","15323       23433        0       0           1          1            0   \n","\n","       https Domain  TinyURL  Prefix/Suffix  Have client  ...  Num Embeds  \\\n","0                 0        0              0            0  ...           0   \n","1                 0        0              0            0  ...           0   \n","2                 1        0              0            0  ...           0   \n","3                 0        0              0            0  ...           0   \n","4                 0        0              0            0  ...           0   \n","...             ...      ...            ...          ...  ...         ...   \n","15319             0        0              0            0  ...           0   \n","15320             0        0              0            0  ...           0   \n","15321             0        0              0            0  ...           0   \n","15322             0        0              0            0  ...           0   \n","15323             0        0              0            0  ...           0   \n","\n","       Num Images  Num Links  Num Titles  Num Script  Special Characters  \\\n","0              49        691          42       13135                6400   \n","1               4         66           3        2034                 818   \n","2               1        100          27       32987               10451   \n","3               0          0           1           0                  52   \n","4             117        219          23        7944                3468   \n","...           ...        ...         ...         ...                 ...   \n","15319           0          0           1           0                   4   \n","15320           0          0           1           0                   4   \n","15321           0          0           1           0                   4   \n","15322           0          0           1           0                   4   \n","15323           0          0           1           0                   4   \n","\n","       Script To Special Chars Ratio  Script To body Ratio  \\\n","0                           2.052344              0.528869   \n","1                           2.486553              0.676197   \n","2                           3.156349              0.836681   \n","3                           0.000000              0.000000   \n","4                           2.290657              0.524460   \n","...                              ...                   ...   \n","15319                       0.000000              0.000000   \n","15320                       0.000000              0.000000   \n","15321                       0.000000              0.000000   \n","15322                       0.000000              0.000000   \n","15323                       0.000000              0.000000   \n","\n","       Body To Special Char Ratio  Label  \n","0                        0.257690      0  \n","1                        0.271941      0  \n","2                        0.265079      0  \n","3                        0.227074      0  \n","4                        0.228956      0  \n","...                           ...    ...  \n","15319                    0.121212      4  \n","15320                    0.121212      4  \n","15321                    0.121212      4  \n","15322                    0.121212      4  \n","15323                    0.121212      4  \n","\n","[15324 rows x 46 columns]"],"text/html":["\n","  <div id=\"df-5e54cdc0-1b43-4a24-a801-94cc2fc87656\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>691</td>\n","      <td>42</td>\n","      <td>13135</td>\n","      <td>6400</td>\n","      <td>2.052344</td>\n","      <td>0.528869</td>\n","      <td>0.257690</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>66</td>\n","      <td>3</td>\n","      <td>2034</td>\n","      <td>818</td>\n","      <td>2.486553</td>\n","      <td>0.676197</td>\n","      <td>0.271941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>27</td>\n","      <td>32987</td>\n","      <td>10451</td>\n","      <td>3.156349</td>\n","      <td>0.836681</td>\n","      <td>0.265079</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.227074</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>117</td>\n","      <td>219</td>\n","      <td>23</td>\n","      <td>7944</td>\n","      <td>3468</td>\n","      <td>2.290657</td>\n","      <td>0.524460</td>\n","      <td>0.228956</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>15319</th>\n","      <td>23429</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.121212</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>15320</th>\n","      <td>23430</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.121212</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>15321</th>\n","      <td>23431</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.121212</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>15322</th>\n","      <td>23432</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.121212</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>15323</th>\n","      <td>23433</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.121212</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>15324 rows × 46 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e54cdc0-1b43-4a24-a801-94cc2fc87656')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5e54cdc0-1b43-4a24-a801-94cc2fc87656 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5e54cdc0-1b43-4a24-a801-94cc2fc87656');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["urldata.columns"],"metadata":{"id":"JQ4_qEulWybT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4fddad50-fcfa-490d-d5a7-fdb8b6764613","executionInfo":{"status":"ok","timestamp":1656566376811,"user_tz":-330,"elapsed":28,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Unnamed: 0', 'Have IP', 'Have @', 'URL Length', 'URL Depth',\n","       'Redirection', 'https Domain', 'TinyURL', 'Prefix/Suffix',\n","       'Have client', 'Have admin', 'Have login', 'Have server', '.php',\n","       '.html', '.info', '.txt', '.js', '.exe', 'Num of periods', 'Is encoded',\n","       'Num of encoded char', 'Num of parameters', 'Num of digits',\n","       'Num of spec char', 'iFrame', 'Mouse Over', 'Right Click',\n","       'Web Forwards', 'Number of page tokens', 'number of sentences',\n","       'number of html tags', 'number of whitespace', 'url Is Live',\n","       'HTML Length', 'Num Objects', 'Num Embeds', 'Num Images', 'Num Links',\n","       'Num Titles', 'Num Script', 'Special Characters',\n","       'Script To Special Chars Ratio', 'Script To body Ratio',\n","       'Body To Special Char Ratio', 'Label'],\n","      dtype='object')"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["urldata = urldata.drop(['Unnamed: 0'], axis = 1).copy()\n","\n","urldata.shape\n","urldata.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"qwye89TwRTOH","executionInfo":{"status":"ok","timestamp":1656566376815,"user_tz":-330,"elapsed":28,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"7b9e22eb-8390-4d89-f9c8-93b5cb5726a1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Have IP  Have @  URL Length  URL Depth  Redirection  https Domain  TinyURL  \\\n","0        0       0           1          1            0             0        0   \n","1        0       0           1          1            1             0        0   \n","2        0       0           1          1            0             1        0   \n","3        0       0           1          3            0             0        0   \n","4        0       0           1          3            0             0        0   \n","\n","   Prefix/Suffix  Have client  Have admin  ...  Num Embeds  Num Images  \\\n","0              0            0           0  ...           0          49   \n","1              0            0           0  ...           0           4   \n","2              0            0           0  ...           0           1   \n","3              0            0           0  ...           0           0   \n","4              0            0           0  ...           0         117   \n","\n","   Num Links  Num Titles  Num Script  Special Characters  \\\n","0        691          42       13135                6400   \n","1         66           3        2034                 818   \n","2        100          27       32987               10451   \n","3          0           1           0                  52   \n","4        219          23        7944                3468   \n","\n","   Script To Special Chars Ratio  Script To body Ratio  \\\n","0                       2.052344              0.528869   \n","1                       2.486553              0.676197   \n","2                       3.156349              0.836681   \n","3                       0.000000              0.000000   \n","4                       2.290657              0.524460   \n","\n","   Body To Special Char Ratio  Label  \n","0                    0.257690      0  \n","1                    0.271941      0  \n","2                    0.265079      0  \n","3                    0.227074      0  \n","4                    0.228956      0  \n","\n","[5 rows x 45 columns]"],"text/html":["\n","  <div id=\"df-4d4cb1df-7c2d-4a7d-9b3a-b247eb3e0c12\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>Have admin</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>691</td>\n","      <td>42</td>\n","      <td>13135</td>\n","      <td>6400</td>\n","      <td>2.052344</td>\n","      <td>0.528869</td>\n","      <td>0.257690</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>66</td>\n","      <td>3</td>\n","      <td>2034</td>\n","      <td>818</td>\n","      <td>2.486553</td>\n","      <td>0.676197</td>\n","      <td>0.271941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>27</td>\n","      <td>32987</td>\n","      <td>10451</td>\n","      <td>3.156349</td>\n","      <td>0.836681</td>\n","      <td>0.265079</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.227074</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>117</td>\n","      <td>219</td>\n","      <td>23</td>\n","      <td>7944</td>\n","      <td>3468</td>\n","      <td>2.290657</td>\n","      <td>0.524460</td>\n","      <td>0.228956</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 45 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d4cb1df-7c2d-4a7d-9b3a-b247eb3e0c12')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4d4cb1df-7c2d-4a7d-9b3a-b247eb3e0c12 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4d4cb1df-7c2d-4a7d-9b3a-b247eb3e0c12');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["urldata.info()"],"metadata":{"id":"kKvKkmUNP5Cx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"34b7338b-c0b4-416a-b7ea-3b6445c199dd","executionInfo":{"status":"ok","timestamp":1656566376817,"user_tz":-330,"elapsed":28,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 15324 entries, 0 to 15323\n","Data columns (total 45 columns):\n"," #   Column                         Non-Null Count  Dtype  \n","---  ------                         --------------  -----  \n"," 0   Have IP                        15324 non-null  int64  \n"," 1   Have @                         15324 non-null  int64  \n"," 2   URL Length                     15324 non-null  int64  \n"," 3   URL Depth                      15324 non-null  int64  \n"," 4   Redirection                    15324 non-null  int64  \n"," 5   https Domain                   15324 non-null  int64  \n"," 6   TinyURL                        15324 non-null  int64  \n"," 7   Prefix/Suffix                  15324 non-null  int64  \n"," 8   Have client                    15324 non-null  int64  \n"," 9   Have admin                     15324 non-null  int64  \n"," 10  Have login                     15324 non-null  int64  \n"," 11  Have server                    15324 non-null  int64  \n"," 12  .php                           15324 non-null  int64  \n"," 13  .html                          15324 non-null  int64  \n"," 14  .info                          15324 non-null  int64  \n"," 15  .txt                           15324 non-null  int64  \n"," 16  .js                            15324 non-null  int64  \n"," 17  .exe                           15324 non-null  int64  \n"," 18  Num of periods                 15324 non-null  int64  \n"," 19  Is encoded                     15324 non-null  int64  \n"," 20  Num of encoded char            15324 non-null  int64  \n"," 21  Num of parameters              15324 non-null  int64  \n"," 22  Num of digits                  15324 non-null  int64  \n"," 23  Num of spec char               15324 non-null  int64  \n"," 24  iFrame                         15324 non-null  int64  \n"," 25  Mouse Over                     15324 non-null  int64  \n"," 26  Right Click                    15324 non-null  int64  \n"," 27  Web Forwards                   15324 non-null  int64  \n"," 28  Number of page tokens          15324 non-null  int64  \n"," 29  number of sentences            15324 non-null  int64  \n"," 30  number of html tags            15324 non-null  int64  \n"," 31  number of whitespace           15324 non-null  int64  \n"," 32  url Is Live                    15324 non-null  int64  \n"," 33  HTML Length                    15324 non-null  int64  \n"," 34  Num Objects                    15324 non-null  int64  \n"," 35  Num Embeds                     15324 non-null  int64  \n"," 36  Num Images                     15324 non-null  int64  \n"," 37  Num Links                      15324 non-null  int64  \n"," 38  Num Titles                     15324 non-null  int64  \n"," 39  Num Script                     15324 non-null  int64  \n"," 40  Special Characters             15324 non-null  int64  \n"," 41  Script To Special Chars Ratio  15324 non-null  float64\n"," 42  Script To body Ratio           15324 non-null  float64\n"," 43  Body To Special Char Ratio     15324 non-null  float64\n"," 44  Label                          15324 non-null  int64  \n","dtypes: float64(3), int64(42)\n","memory usage: 5.3 MB\n"]}]},{"cell_type":"code","source":["# Class Distribution of Labels\n","urldata.groupby('Label').size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvS3OQHTSHDt","executionInfo":{"status":"ok","timestamp":1656566376819,"user_tz":-330,"elapsed":26,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"543b9881-6369-457f-c89f-2c2a68d1fe36"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Label\n","0    4954\n","1    1573\n","2    3002\n","3    3543\n","4    2252\n","dtype: int64"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["\n","import numpy as np\n"],"metadata":{"id":"eLm1720QSaAv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["urldata.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"id":"WX-8Xbm3cfFf","outputId":"d3791825-2b05-4ac8-b1c5-68210c08ded8","executionInfo":{"status":"ok","timestamp":1656566390573,"user_tz":-330,"elapsed":20,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Have IP        Have @    URL Length     URL Depth   Redirection  \\\n","count  15324.0  15324.000000  15324.000000  15324.000000  15324.000000   \n","mean       0.0      0.003067      0.897938      3.190029      0.027212   \n","std        0.0      0.055298      0.302740      2.526227      0.162707   \n","min        0.0      0.000000      0.000000      0.000000      0.000000   \n","25%        0.0      0.000000      1.000000      1.000000      0.000000   \n","50%        0.0      0.000000      1.000000      2.000000      0.000000   \n","75%        0.0      0.000000      1.000000      4.000000      0.000000   \n","max        0.0      1.000000      1.000000     18.000000      1.000000   \n","\n","       https Domain       TinyURL  Prefix/Suffix   Have client    Have admin  \\\n","count  15324.000000  15324.000000   15324.000000  15324.000000  15324.000000   \n","mean       0.027930      0.034978       0.073871      0.001305      0.010702   \n","std        0.164778      0.183730       0.261569      0.036104      0.102900   \n","min        0.000000      0.000000       0.000000      0.000000      0.000000   \n","25%        0.000000      0.000000       0.000000      0.000000      0.000000   \n","50%        0.000000      0.000000       0.000000      0.000000      0.000000   \n","75%        0.000000      0.000000       0.000000      0.000000      0.000000   \n","max        1.000000      1.000000       1.000000      1.000000      1.000000   \n","\n","       ...    Num Embeds    Num Images     Num Links    Num Titles  \\\n","count  ...  15324.000000  15324.000000  15324.000000  15324.000000   \n","mean   ...      0.000261      9.431480     53.732642      8.138476   \n","std    ...      0.016155     31.982449    105.014700     30.703307   \n","min    ...      0.000000      0.000000     -1.000000     -1.000000   \n","25%    ...      0.000000      0.000000      0.000000      0.000000   \n","50%    ...      0.000000      0.000000      2.000000      1.000000   \n","75%    ...      0.000000      4.000000     66.000000      4.000000   \n","max    ...      1.000000    816.000000   1740.000000   1042.000000   \n","\n","         Num Script  Special Characters  Script To Special Chars Ratio  \\\n","count  1.532400e+04        15324.000000                   15324.000000   \n","mean   1.907060e+04         7416.632407                       3.722576   \n","std    6.790900e+04        18369.465282                      17.536106   \n","min   -1.000000e+00            0.000000                      -1.000000   \n","25%    0.000000e+00           12.000000                       0.000000   \n","50%    7.770000e+02          557.000000                       1.324700   \n","75%    1.592400e+04         8311.000000                       2.625806   \n","max    2.076633e+06       359290.000000                     381.227732   \n","\n","       Script To body Ratio  Body To Special Char Ratio         Label  \n","count          15324.000000                15324.000000  15324.000000  \n","mean               0.367024                    0.192536      1.775907  \n","std                0.375838                    0.112498      1.471309  \n","min               -1.000000                    0.000000      0.000000  \n","25%                0.000000                    0.141286      0.000000  \n","50%                0.312289                    0.225350      2.000000  \n","75%                0.718077                    0.263237      3.000000  \n","max                1.005038                    0.733333      4.000000  \n","\n","[8 rows x 45 columns]"],"text/html":["\n","  <div id=\"df-3d58fe2b-970b-497e-b677-228cbc88e01d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>Have admin</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>15324.0</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>...</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>1.532400e+04</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.0</td>\n","      <td>0.003067</td>\n","      <td>0.897938</td>\n","      <td>3.190029</td>\n","      <td>0.027212</td>\n","      <td>0.027930</td>\n","      <td>0.034978</td>\n","      <td>0.073871</td>\n","      <td>0.001305</td>\n","      <td>0.010702</td>\n","      <td>...</td>\n","      <td>0.000261</td>\n","      <td>9.431480</td>\n","      <td>53.732642</td>\n","      <td>8.138476</td>\n","      <td>1.907060e+04</td>\n","      <td>7416.632407</td>\n","      <td>3.722576</td>\n","      <td>0.367024</td>\n","      <td>0.192536</td>\n","      <td>1.775907</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.0</td>\n","      <td>0.055298</td>\n","      <td>0.302740</td>\n","      <td>2.526227</td>\n","      <td>0.162707</td>\n","      <td>0.164778</td>\n","      <td>0.183730</td>\n","      <td>0.261569</td>\n","      <td>0.036104</td>\n","      <td>0.102900</td>\n","      <td>...</td>\n","      <td>0.016155</td>\n","      <td>31.982449</td>\n","      <td>105.014700</td>\n","      <td>30.703307</td>\n","      <td>6.790900e+04</td>\n","      <td>18369.465282</td>\n","      <td>17.536106</td>\n","      <td>0.375838</td>\n","      <td>0.112498</td>\n","      <td>1.471309</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-1.000000</td>\n","      <td>-1.000000</td>\n","      <td>-1.000000e+00</td>\n","      <td>0.000000</td>\n","      <td>-1.000000</td>\n","      <td>-1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000e+00</td>\n","      <td>12.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.141286</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>7.770000e+02</td>\n","      <td>557.000000</td>\n","      <td>1.324700</td>\n","      <td>0.312289</td>\n","      <td>0.225350</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>4.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>4.000000</td>\n","      <td>66.000000</td>\n","      <td>4.000000</td>\n","      <td>1.592400e+04</td>\n","      <td>8311.000000</td>\n","      <td>2.625806</td>\n","      <td>0.718077</td>\n","      <td>0.263237</td>\n","      <td>3.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>18.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>816.000000</td>\n","      <td>1740.000000</td>\n","      <td>1042.000000</td>\n","      <td>2.076633e+06</td>\n","      <td>359290.000000</td>\n","      <td>381.227732</td>\n","      <td>1.005038</td>\n","      <td>0.733333</td>\n","      <td>4.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 45 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d58fe2b-970b-497e-b677-228cbc88e01d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3d58fe2b-970b-497e-b677-228cbc88e01d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3d58fe2b-970b-497e-b677-228cbc88e01d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[""],"metadata":{"id":"bUPfWi4TcfIA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#checking the data for null or missing values\n","urldata.isnull().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3PEbrTLcfXg","outputId":"488aba09-8389-41ba-cf56-70ee24296f0c","executionInfo":{"status":"ok","timestamp":1656566393792,"user_tz":-330,"elapsed":15,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Have IP                          0\n","Have @                           0\n","URL Length                       0\n","URL Depth                        0\n","Redirection                      0\n","https Domain                     0\n","TinyURL                          0\n","Prefix/Suffix                    0\n","Have client                      0\n","Have admin                       0\n","Have login                       0\n","Have server                      0\n",".php                             0\n",".html                            0\n",".info                            0\n",".txt                             0\n",".js                              0\n",".exe                             0\n","Num of periods                   0\n","Is encoded                       0\n","Num of encoded char              0\n","Num of parameters                0\n","Num of digits                    0\n","Num of spec char                 0\n","iFrame                           0\n","Mouse Over                       0\n","Right Click                      0\n","Web Forwards                     0\n","Number of page tokens            0\n","number of sentences              0\n","number of html tags              0\n","number of whitespace             0\n","url Is Live                      0\n","HTML Length                      0\n","Num Objects                      0\n","Num Embeds                       0\n","Num Images                       0\n","Num Links                        0\n","Num Titles                       0\n","Num Script                       0\n","Special Characters               0\n","Script To Special Chars Ratio    0\n","Script To body Ratio             0\n","Body To Special Char Ratio       0\n","Label                            0\n","dtype: int64"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# shuffling the rows in the dataset so that when splitting the train and test set are equally distributed\n","urldata = urldata.sample(frac=1).reset_index(drop=True)\n","urldata.head()"],"metadata":{"id":"n6YfGa82P5JZ","colab":{"base_uri":"https://localhost:8080/","height":297},"outputId":"ea197259-c0a9-4817-b0c0-ab784986f97c","executionInfo":{"status":"ok","timestamp":1656566393793,"user_tz":-330,"elapsed":14,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Have IP  Have @  URL Length  URL Depth  Redirection  https Domain  TinyURL  \\\n","0        0       0           1          1            0             0        0   \n","1        0       0           1          1            1             0        0   \n","2        0       0           0          4            0             0        0   \n","3        0       0           1          1            0             0        0   \n","4        0       0           1          5            0             0        0   \n","\n","   Prefix/Suffix  Have client  Have admin  ...  Num Embeds  Num Images  \\\n","0              0            0           0  ...           0           0   \n","1              0            0           0  ...           0           0   \n","2              0            0           0  ...           0          29   \n","3              0            0           0  ...           0           1   \n","4              0            0           0  ...           0           0   \n","\n","   Num Links  Num Titles  Num Script  Special Characters  \\\n","0          1           0           0                   0   \n","1          0           0           0                   0   \n","2        166          38       68310               23419   \n","3          0           0           0                  12   \n","4          0           1           0                   4   \n","\n","   Script To Special Chars Ratio  Script To body Ratio  \\\n","0                       0.000000               0.00000   \n","1                       0.000000               0.00000   \n","2                       2.916862               0.88034   \n","3                       0.000000               0.00000   \n","4                       0.000000               0.00000   \n","\n","   Body To Special Char Ratio  Label  \n","0                    0.000000      3  \n","1                    0.000000      1  \n","2                    0.301811      2  \n","3                    0.162162      0  \n","4                    0.121212      3  \n","\n","[5 rows x 45 columns]"],"text/html":["\n","  <div id=\"df-61d61c86-6c79-4ec7-a06d-d3b3ea8a1add\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>Have admin</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>29</td>\n","      <td>166</td>\n","      <td>38</td>\n","      <td>68310</td>\n","      <td>23419</td>\n","      <td>2.916862</td>\n","      <td>0.88034</td>\n","      <td>0.301811</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.162162</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.121212</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 45 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61d61c86-6c79-4ec7-a06d-d3b3ea8a1add')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-61d61c86-6c79-4ec7-a06d-d3b3ea8a1add button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-61d61c86-6c79-4ec7-a06d-d3b3ea8a1add');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# Sepratating & assigning features and target columns to X & y\n","y = urldata['Label'].values\n","x = np.array(urldata.drop('Label',axis=1))\n","\n"],"metadata":{"id":"Lasv_YzlP5L6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Splitting the dataset into train and test sets: 80-20 split\n","from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, \n","                                                    test_size = 0.45, random_state = 12)\n","print(x_train.shape, x_test.shape)\n","print(y_train.shape, y_test.shape)\n","\n"],"metadata":{"id":"in9C2ArWP5O0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ca682e06-ef34-449f-f8c2-1b0c05754b84","executionInfo":{"status":"ok","timestamp":1656566394956,"user_tz":-330,"elapsed":8,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(8428, 44) (6896, 44)\n","(8428,) (6896,)\n"]}]},{"cell_type":"code","source":["output = {}\n","output['labels'] = y_test"],"metadata":{"id":"jv6Y5m8ddMHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"fg4rdoEnUE0O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOV9VybfNIgE"},"source":["**MLP**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mr-AOgJ1JtXY"},"outputs":[],"source":["import keras\n","\n","from sklearn.neural_network import MLPClassifier\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","import pickle\n","\n","def model_mlp(x_train, x_val, y_train, y_val, opt, n):\n","  mlpclassifier = MLPClassifier(alpha=0.0001, hidden_layer_sizes=([100,100,100]))\n","  #compile model using mse as a measure of model performance\n","  mlpclassifier.fit(x_train, y_train)\n","\n","  y_pred = mlpclassifier.predict(x_val)\n","\n","  conf_matrix = confusion_matrix(y_val, y_pred)\n","  print(conf_matrix)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred, average='weighted'))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred, average='weighted'))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred, average='weighted'))\n","\n","  \n","  print(\"Validation Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/URL-HTML/MLP/model_'+str(n)+'.h5'\n","  pickle.dump(mlpclassifier, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","  return metrics.accuracy_score(y_val, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUCxdcapJtXZ","executionInfo":{"status":"ok","timestamp":1656567144018,"user_tz":-330,"elapsed":122796,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"53e7a05c-9d9f-4caf-ec23-af8feeb7ecac"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[203   1   8  16  35]\n"," [  9  44   7   3  16]\n"," [ 11   0 137   2  14]\n"," [  2   5   0 177  12]\n"," [  4   1   4   1 131]]\n","Precision: 0.8404\n","Recall: 0.8209\n","F1 Score: 0.8214\n","Validation Accuracy: 0.8208778173190985\n","model 0 saved\n","[[241   1  30   4  15]\n"," [ 11  44   3   6  10]\n"," [  3   0 155   0  11]\n"," [  4   3   3 173   8]\n"," [  1   0   1   2 114]]\n","Precision: 0.8751\n","Recall: 0.8624\n","F1 Score: 0.8616\n","Validation Accuracy: 0.8623962040332147\n","model 1 saved\n","[[241   4  10   4  11]\n"," [ 20  45   4   4   2]\n"," [ 50   2 120   3   3]\n"," [ 11   6   4 159   2]\n"," [ 43   6  11   2  76]]\n","Precision: 0.7770\n","Recall: 0.7604\n","F1 Score: 0.7573\n","Validation Accuracy: 0.7603795966785291\n","model 2 saved\n","[[233  22  20  13   0]\n"," [ 14  61   5   6   0]\n"," [ 33  13 108   0   2]\n"," [  8  11   0 173   2]\n"," [ 19  32   6   1  61]]\n","Precision: 0.7866\n","Recall: 0.7544\n","F1 Score: 0.7577\n","Validation Accuracy: 0.7544483985765125\n","model 3 saved\n","[[211   1  29  10  12]\n"," [ 17  42   7  10   6]\n"," [  5   0 147   2   9]\n"," [  8   2   6 195   3]\n"," [ 14   0  14  11  82]]\n","Precision: 0.8112\n","Recall: 0.8031\n","F1 Score: 0.7988\n","Validation Accuracy: 0.8030842230130486\n","model 4 saved\n","[[241   9  21   8   3]\n"," [ 11  57   9   2   4]\n"," [ 36  31  75   2   4]\n"," [ 14  12   5 158   3]\n"," [ 25   6  11   2  94]]\n","Precision: 0.7559\n","Recall: 0.7414\n","F1 Score: 0.7422\n","Validation Accuracy: 0.741399762752076\n","model 5 saved\n","[[245   3  11   8  13]\n"," [ 15  63   5   2   8]\n"," [ 32   2 102   3  19]\n"," [ 18   3   4 166   5]\n"," [ 21   0   0   0  95]]\n","Precision: 0.8094\n","Recall: 0.7960\n","F1 Score: 0.7957\n","Validation Accuracy: 0.7959667852906287\n","model 6 saved\n","[[243   7  23   4   7]\n"," [ 10  64   6   3   8]\n"," [ 28   3 128   0   6]\n"," [ 12  10   1 167   4]\n"," [  8   1  10   0  90]]\n","Precision: 0.8244\n","Recall: 0.8209\n","F1 Score: 0.8216\n","Validation Accuracy: 0.8208778173190985\n","model 7 saved\n","[[252  13   2   9   3]\n"," [ 13  59   0   6   6]\n"," [ 33  11 106   1  12]\n"," [  6   4   1 186   1]\n"," [  5   6   0   5 102]]\n","Precision: 0.8484\n","Recall: 0.8373\n","F1 Score: 0.8355\n","Validation Accuracy: 0.83729216152019\n","model 8 saved\n","[[206  10  31  12  14]\n"," [  9  54   5   5   4]\n"," [  8  18 128   2  14]\n"," [  1  12   4 174   7]\n"," [  2   3  10   2 107]]\n","Precision: 0.8094\n","Recall: 0.7945\n","F1 Score: 0.7979\n","Validation Accuracy: 0.7945368171021377\n","model 9 saved\n","Average Validation Accuracy: 0.7991259583604535\n"]}],"source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_mlp(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":649},"executionInfo":{"elapsed":493,"status":"ok","timestamp":1656569829735,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"6DA16IlPJtXZ","outputId":"62814f49-c216-43cb-cfc7-7936e5ec2542"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[3.91553873e-060 2.68015846e-220 1.00000000e+000 0.00000000e+000\n","  0.00000000e+000]\n"," [2.88464362e-006 3.83570678e-005 2.71159524e-023 9.99958758e-001\n","  7.63722366e-026]\n"," [5.90508965e-001 2.19733288e-001 1.59528637e-002 1.40523164e-002\n","  1.59752567e-001]\n"," ...\n"," [1.68863697e-002 1.03265965e-008 2.13086729e-003 1.38728674e-016\n","  9.80982753e-001]\n"," [1.00000000e+000 1.98653622e-037 3.73134969e-032 1.15221709e-078\n","  3.13849159e-038]\n"," [3.10639870e-005 9.01686443e-005 8.75004392e-003 5.05086029e-006\n","  9.91123673e-001]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  nn_prediction_non  \\\n","0          0        3.915539e-60         2.680158e-220       3.915539e-60   \n","1          3        2.884644e-06          3.835707e-05       2.884644e-06   \n","2          0        5.905090e-01          2.197333e-01       5.905090e-01   \n","3          1        2.825485e-02          4.110084e-01       2.825485e-02   \n","4          1        1.825027e-43          3.029391e-36       1.825027e-43   \n","...      ...                 ...                   ...                ...   \n","6891       1        6.344460e-06          9.982762e-01       6.344460e-06   \n","6892       3        9.905528e-03          1.295311e-02       9.905528e-03   \n","6893       2        1.688637e-02          1.032660e-08       1.688637e-02   \n","6894       0        1.000000e+00          1.986536e-37       1.000000e+00   \n","6895       4        3.106399e-05          9.016864e-05       3.106399e-05   \n","\n","      nn_prediction_phish  nn2_prediction_non  nn2_prediction_phish  \\\n","0           2.680158e-220        3.915539e-60         2.680158e-220   \n","1            3.835707e-05        2.884644e-06          3.835707e-05   \n","2            2.197333e-01        5.905090e-01          2.197333e-01   \n","3            4.110084e-01        2.825485e-02          4.110084e-01   \n","4            3.029391e-36        1.825027e-43          3.029391e-36   \n","...                   ...                 ...                   ...   \n","6891         9.982762e-01        6.344460e-06          9.982762e-01   \n","6892         1.295311e-02        9.905528e-03          1.295311e-02   \n","6893         1.032660e-08        1.688637e-02          1.032660e-08   \n","6894         1.986536e-37        1.000000e+00          1.986536e-37   \n","6895         9.016864e-05        3.106399e-05          9.016864e-05   \n","\n","      mlp_prediction_spam  mlp_prediction_malware  mlp_prediction_defacemen  \n","0            1.000000e+00            0.000000e+00              0.000000e+00  \n","1            2.711595e-23            9.999588e-01              7.637224e-26  \n","2            1.595286e-02            1.405232e-02              1.597526e-01  \n","3            2.974864e-02            6.680746e-03              5.243073e-01  \n","4            1.000000e+00           3.531859e-183             6.471977e-232  \n","...                   ...                     ...                       ...  \n","6891         5.259414e-05            1.664911e-03              1.978808e-10  \n","6892         6.272989e-03            9.691422e-01              1.726208e-03  \n","6893         2.130867e-03            1.387287e-16              9.809828e-01  \n","6894         3.731350e-32            1.152217e-78              3.138492e-38  \n","6895         8.750044e-03            5.050860e-06              9.911237e-01  \n","\n","[6896 rows x 10 columns]"],"text/html":["\n","  <div id=\"df-7bc6b6fb-27fb-4a9c-835b-12286a918cbc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","      <th>nn2_prediction_non</th>\n","      <th>nn2_prediction_phish</th>\n","      <th>mlp_prediction_spam</th>\n","      <th>mlp_prediction_malware</th>\n","      <th>mlp_prediction_defacemen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>3.915539e-60</td>\n","      <td>2.680158e-220</td>\n","      <td>3.915539e-60</td>\n","      <td>2.680158e-220</td>\n","      <td>3.915539e-60</td>\n","      <td>2.680158e-220</td>\n","      <td>1.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>2.884644e-06</td>\n","      <td>3.835707e-05</td>\n","      <td>2.884644e-06</td>\n","      <td>3.835707e-05</td>\n","      <td>2.884644e-06</td>\n","      <td>3.835707e-05</td>\n","      <td>2.711595e-23</td>\n","      <td>9.999588e-01</td>\n","      <td>7.637224e-26</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>5.905090e-01</td>\n","      <td>2.197333e-01</td>\n","      <td>5.905090e-01</td>\n","      <td>2.197333e-01</td>\n","      <td>5.905090e-01</td>\n","      <td>2.197333e-01</td>\n","      <td>1.595286e-02</td>\n","      <td>1.405232e-02</td>\n","      <td>1.597526e-01</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>2.825485e-02</td>\n","      <td>4.110084e-01</td>\n","      <td>2.825485e-02</td>\n","      <td>4.110084e-01</td>\n","      <td>2.825485e-02</td>\n","      <td>4.110084e-01</td>\n","      <td>2.974864e-02</td>\n","      <td>6.680746e-03</td>\n","      <td>5.243073e-01</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1.825027e-43</td>\n","      <td>3.029391e-36</td>\n","      <td>1.825027e-43</td>\n","      <td>3.029391e-36</td>\n","      <td>1.825027e-43</td>\n","      <td>3.029391e-36</td>\n","      <td>1.000000e+00</td>\n","      <td>3.531859e-183</td>\n","      <td>6.471977e-232</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6891</th>\n","      <td>1</td>\n","      <td>6.344460e-06</td>\n","      <td>9.982762e-01</td>\n","      <td>6.344460e-06</td>\n","      <td>9.982762e-01</td>\n","      <td>6.344460e-06</td>\n","      <td>9.982762e-01</td>\n","      <td>5.259414e-05</td>\n","      <td>1.664911e-03</td>\n","      <td>1.978808e-10</td>\n","    </tr>\n","    <tr>\n","      <th>6892</th>\n","      <td>3</td>\n","      <td>9.905528e-03</td>\n","      <td>1.295311e-02</td>\n","      <td>9.905528e-03</td>\n","      <td>1.295311e-02</td>\n","      <td>9.905528e-03</td>\n","      <td>1.295311e-02</td>\n","      <td>6.272989e-03</td>\n","      <td>9.691422e-01</td>\n","      <td>1.726208e-03</td>\n","    </tr>\n","    <tr>\n","      <th>6893</th>\n","      <td>2</td>\n","      <td>1.688637e-02</td>\n","      <td>1.032660e-08</td>\n","      <td>1.688637e-02</td>\n","      <td>1.032660e-08</td>\n","      <td>1.688637e-02</td>\n","      <td>1.032660e-08</td>\n","      <td>2.130867e-03</td>\n","      <td>1.387287e-16</td>\n","      <td>9.809828e-01</td>\n","    </tr>\n","    <tr>\n","      <th>6894</th>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>1.986536e-37</td>\n","      <td>1.000000e+00</td>\n","      <td>1.986536e-37</td>\n","      <td>1.000000e+00</td>\n","      <td>1.986536e-37</td>\n","      <td>3.731350e-32</td>\n","      <td>1.152217e-78</td>\n","      <td>3.138492e-38</td>\n","    </tr>\n","    <tr>\n","      <th>6895</th>\n","      <td>4</td>\n","      <td>3.106399e-05</td>\n","      <td>9.016864e-05</td>\n","      <td>3.106399e-05</td>\n","      <td>9.016864e-05</td>\n","      <td>3.106399e-05</td>\n","      <td>9.016864e-05</td>\n","      <td>8.750044e-03</td>\n","      <td>5.050860e-06</td>\n","      <td>9.911237e-01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6896 rows × 10 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bc6b6fb-27fb-4a9c-835b-12286a918cbc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7bc6b6fb-27fb-4a9c-835b-12286a918cbc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7bc6b6fb-27fb-4a9c-835b-12286a918cbc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":35}],"source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/URL-HTML/MLP/model_1.h5'\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['mlp_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['mlp_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output['mlp_prediction_spam'] = [i[2] for i in y_pred_prob];\n","output['mlp_prediction_malware'] = [i[3] for i in y_pred_prob];\n","output['mlp_prediction_defacemen'] = [i[4] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output\n"]},{"cell_type":"markdown","source":["**Neural Network**"],"metadata":{"id":"iLF4sz5NsSZ6"}},{"cell_type":"code","source":["\n","import keras\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","def model_aa(x_train, x_val, y_train, y_val, opt, n, early_stopping_monitor):\n","\n","  n_cols = x_train.shape[1]\n","  # print(\"check point\")\n","  #create model\n","  model = Sequential()\n","  model.add(Dense(30, activation='relu', input_shape=(n_cols,)))\n","  model.add(Dense(10, activation='relu'))\n","\n","  model.add(Dense(1, activation = 'sigmoid'))\n","  # softmax\n","  #compile model using mse as a measure of model performance\n","  model.compile(optimizer = opt, loss= 'binary_crossentropy', metrics=[\"accuracy\"])\n","\n","  history = model.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping_monitor])\n","\n","\n","  # plt.plot(history.history['loss'])\n","  # plt.plot(history.history['val_loss'])\n","  # plt.title('model loss')\n","  # plt.ylabel('Loss')\n","  # plt.xlabel('Epoch')\n","  # plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n","  # plt.show()\n","\n","\n","  print('Validation Accuracy: ')\n","  # Predicting the Test set results\n","  y_pred = model.predict(x_val)\n","  y_pred = (y_pred > 0.5)\n","\n","\n","  print(classification_report(y_val, y_pred))\n","\n","  # Model Accuracy, how often is the classifier correct?\n","  print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","\n","  # Creating the Confusion Matrix\n","  cm = confusion_matrix(y_val, y_pred)\n","  print(cm)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred, average='weighted'))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred, average='weighted'))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred, average='weighted'))\n","\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/URL-HTML/NN/model_'+str(n)+'.h5'\n","  pickle.dump(model, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","\n","  return metrics.accuracy_score(y_val, y_pred)\n","\n"],"metadata":{"id":"UfilmHKnL3LC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_aa(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n, early_stopping_monitor)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_OHdM1HNDio","executionInfo":{"status":"ok","timestamp":1656568716439,"user_tz":-330,"elapsed":799974,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"58940c14-58a7-40d3-8762-a14e3fd247cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","238/238 [==============================] - 2s 6ms/step - loss: 126.3983 - accuracy: 0.1206 - val_loss: -52.9108 - val_accuracy: 0.0949\n","Epoch 2/100\n","238/238 [==============================] - 1s 5ms/step - loss: -139.7192 - accuracy: 0.1608 - val_loss: -373.5852 - val_accuracy: 0.0937\n","Epoch 3/100\n","238/238 [==============================] - 1s 4ms/step - loss: -414.3650 - accuracy: 0.1475 - val_loss: -947.5576 - val_accuracy: 0.1483\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -963.2092 - accuracy: 0.1511 - val_loss: -2007.5138 - val_accuracy: 0.1649\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1917.5194 - accuracy: 0.1556 - val_loss: -3562.3250 - val_accuracy: 0.1767\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3261.0491 - accuracy: 0.1544 - val_loss: -5656.6294 - val_accuracy: 0.1767\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5168.2524 - accuracy: 0.1510 - val_loss: -8830.0732 - val_accuracy: 0.1791\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7844.7373 - accuracy: 0.1601 - val_loss: -13550.6348 - val_accuracy: 0.0973\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11518.4600 - accuracy: 0.1372 - val_loss: -19717.0430 - val_accuracy: 0.1649\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -16546.9824 - accuracy: 0.1589 - val_loss: -27406.9922 - val_accuracy: 0.1661\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -22625.3926 - accuracy: 0.1610 - val_loss: -37419.5195 - val_accuracy: 0.1174\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -30358.4238 - accuracy: 0.1396 - val_loss: -49210.2930 - val_accuracy: 0.1661\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -39919.2227 - accuracy: 0.1515 - val_loss: -63501.8945 - val_accuracy: 0.0973\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -51184.6641 - accuracy: 0.1713 - val_loss: -80908.0156 - val_accuracy: 0.1637\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -64060.7461 - accuracy: 0.1520 - val_loss: -101723.0391 - val_accuracy: 0.0973\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -78703.3750 - accuracy: 0.1487 - val_loss: -124053.4844 - val_accuracy: 0.0973\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -95545.1172 - accuracy: 0.1498 - val_loss: -147729.9688 - val_accuracy: 0.1625\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -115275.6328 - accuracy: 0.1521 - val_loss: -178277.3281 - val_accuracy: 0.0961\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -135689.9219 - accuracy: 0.1544 - val_loss: -210214.9219 - val_accuracy: 0.1091\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -158592.6562 - accuracy: 0.1543 - val_loss: -243468.9375 - val_accuracy: 0.0973\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -182837.1406 - accuracy: 0.1512 - val_loss: -279568.0625 - val_accuracy: 0.1376\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -211446.6250 - accuracy: 0.1417 - val_loss: -318562.8438 - val_accuracy: 0.1673\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -241451.2344 - accuracy: 0.1587 - val_loss: -367071.5312 - val_accuracy: 0.1198\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -275478.2500 - accuracy: 0.1528 - val_loss: -415781.8125 - val_accuracy: 0.1068\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -310688.1875 - accuracy: 0.1490 - val_loss: -470978.9688 - val_accuracy: 0.1507\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -351368.1250 - accuracy: 0.1488 - val_loss: -532296.9375 - val_accuracy: 0.1115\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -393443.1875 - accuracy: 0.1517 - val_loss: -593401.1875 - val_accuracy: 0.1139\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -437824.0312 - accuracy: 0.1405 - val_loss: -657583.6250 - val_accuracy: 0.1246\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -484174.5938 - accuracy: 0.1601 - val_loss: -725993.0625 - val_accuracy: 0.1103\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -527550.2500 - accuracy: 0.1288 - val_loss: -793379.2500 - val_accuracy: 0.1103\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -580012.0000 - accuracy: 0.1339 - val_loss: -856875.9375 - val_accuracy: 0.1649\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -631747.3125 - accuracy: 0.1702 - val_loss: -940059.1875 - val_accuracy: 0.1079\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -684802.5625 - accuracy: 0.1365 - val_loss: -1007208.9375 - val_accuracy: 0.1673\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -743166.1875 - accuracy: 0.1581 - val_loss: -1102122.8750 - val_accuracy: 0.1625\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -809111.6250 - accuracy: 0.1337 - val_loss: -1185641.1250 - val_accuracy: 0.1673\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -868234.5000 - accuracy: 0.1549 - val_loss: -1284687.8750 - val_accuracy: 0.1613\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -934228.5000 - accuracy: 0.1475 - val_loss: -1383840.6250 - val_accuracy: 0.1542\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1004965.1250 - accuracy: 0.1568 - val_loss: -1486034.1250 - val_accuracy: 0.1186\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1078720.2500 - accuracy: 0.1433 - val_loss: -1573486.3750 - val_accuracy: 0.1673\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1154396.7500 - accuracy: 0.1602 - val_loss: -1706253.0000 - val_accuracy: 0.1471\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1238967.3750 - accuracy: 0.1452 - val_loss: -1833654.2500 - val_accuracy: 0.1103\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1321801.1250 - accuracy: 0.1624 - val_loss: -1961394.1250 - val_accuracy: 0.1079\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1414095.3750 - accuracy: 0.1503 - val_loss: -2087479.6250 - val_accuracy: 0.1613\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1510712.1250 - accuracy: 0.1630 - val_loss: -2230680.5000 - val_accuracy: 0.1613\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1607594.2500 - accuracy: 0.1603 - val_loss: -2378958.5000 - val_accuracy: 0.1400\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1713575.6250 - accuracy: 0.1488 - val_loss: -2511066.5000 - val_accuracy: 0.1673\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1819742.5000 - accuracy: 0.1631 - val_loss: -2692471.7500 - val_accuracy: 0.1447\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1934280.0000 - accuracy: 0.1507 - val_loss: -2856636.2500 - val_accuracy: 0.1613\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2057404.7500 - accuracy: 0.1656 - val_loss: -3035885.2500 - val_accuracy: 0.1103\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2173011.2500 - accuracy: 0.1566 - val_loss: -3205926.2500 - val_accuracy: 0.1459\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2294863.5000 - accuracy: 0.1640 - val_loss: -3389625.2500 - val_accuracy: 0.1257\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2421012.7500 - accuracy: 0.1637 - val_loss: -3572580.2500 - val_accuracy: 0.1459\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2555516.5000 - accuracy: 0.1656 - val_loss: -3769744.2500 - val_accuracy: 0.1340\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2686222.7500 - accuracy: 0.1672 - val_loss: -3964434.2500 - val_accuracy: 0.1222\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2827040.2500 - accuracy: 0.1566 - val_loss: -4151241.2500 - val_accuracy: 0.1673\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2969428.0000 - accuracy: 0.1697 - val_loss: -4361921.5000 - val_accuracy: 0.1673\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3125393.7500 - accuracy: 0.1632 - val_loss: -4592675.5000 - val_accuracy: 0.1661\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3283309.2500 - accuracy: 0.1637 - val_loss: -4828500.5000 - val_accuracy: 0.1673\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3443441.7500 - accuracy: 0.1707 - val_loss: -5076409.0000 - val_accuracy: 0.1613\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3610655.7500 - accuracy: 0.1639 - val_loss: -5316732.0000 - val_accuracy: 0.1625\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3784253.0000 - accuracy: 0.1637 - val_loss: -5583284.5000 - val_accuracy: 0.1459\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3955977.7500 - accuracy: 0.1694 - val_loss: -5838267.0000 - val_accuracy: 0.1483\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4143478.0000 - accuracy: 0.1655 - val_loss: -6106378.5000 - val_accuracy: 0.1459\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4322156.5000 - accuracy: 0.1680 - val_loss: -6370303.0000 - val_accuracy: 0.1590\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4517317.0000 - accuracy: 0.1664 - val_loss: -6650629.0000 - val_accuracy: 0.1625\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4703297.0000 - accuracy: 0.1539 - val_loss: -6896609.0000 - val_accuracy: 0.1673\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4903880.0000 - accuracy: 0.1726 - val_loss: -7215074.0000 - val_accuracy: 0.1625\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5116908.0000 - accuracy: 0.1697 - val_loss: -7539197.5000 - val_accuracy: 0.1186\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5328054.5000 - accuracy: 0.1677 - val_loss: -7852638.0000 - val_accuracy: 0.1222\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5539912.5000 - accuracy: 0.1473 - val_loss: -8163325.5000 - val_accuracy: 0.1459\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5768162.0000 - accuracy: 0.1703 - val_loss: -8491264.0000 - val_accuracy: 0.1435\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5989927.0000 - accuracy: 0.1657 - val_loss: -8807669.0000 - val_accuracy: 0.1625\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6214801.5000 - accuracy: 0.1672 - val_loss: -9148443.0000 - val_accuracy: 0.1625\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6459345.0000 - accuracy: 0.1670 - val_loss: -9490822.0000 - val_accuracy: 0.1625\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6716219.5000 - accuracy: 0.1558 - val_loss: -9835823.0000 - val_accuracy: 0.1673\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6955443.5000 - accuracy: 0.1736 - val_loss: -10239928.0000 - val_accuracy: 0.1222\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7184322.0000 - accuracy: 0.1412 - val_loss: -10567069.0000 - val_accuracy: 0.1649\n","Epoch 78/100\n","238/238 [==============================] - 1s 4ms/step - loss: -7449028.5000 - accuracy: 0.1673 - val_loss: -10939465.0000 - val_accuracy: 0.1625\n","Epoch 79/100\n","238/238 [==============================] - 1s 4ms/step - loss: -7713614.0000 - accuracy: 0.1635 - val_loss: -11344742.0000 - val_accuracy: 0.1257\n","Epoch 80/100\n","238/238 [==============================] - 1s 4ms/step - loss: -7970388.0000 - accuracy: 0.1691 - val_loss: -11722362.0000 - val_accuracy: 0.1340\n","Epoch 81/100\n","238/238 [==============================] - 1s 4ms/step - loss: -8234468.5000 - accuracy: 0.1578 - val_loss: -12104539.0000 - val_accuracy: 0.1637\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8525153.0000 - accuracy: 0.1732 - val_loss: -12539949.0000 - val_accuracy: 0.1435\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8814604.0000 - accuracy: 0.1645 - val_loss: -12957622.0000 - val_accuracy: 0.1637\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9105789.0000 - accuracy: 0.1633 - val_loss: -13389009.0000 - val_accuracy: 0.1625\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9414111.0000 - accuracy: 0.1682 - val_loss: -13840995.0000 - val_accuracy: 0.1495\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9728211.0000 - accuracy: 0.1645 - val_loss: -14293622.0000 - val_accuracy: 0.1625\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10032667.0000 - accuracy: 0.1633 - val_loss: -14753357.0000 - val_accuracy: 0.1210\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10350300.0000 - accuracy: 0.1620 - val_loss: -15173238.0000 - val_accuracy: 0.1649\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10679129.0000 - accuracy: 0.1681 - val_loss: -15702900.0000 - val_accuracy: 0.1530\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11019903.0000 - accuracy: 0.1666 - val_loss: -16199732.0000 - val_accuracy: 0.1388\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11352686.0000 - accuracy: 0.1751 - val_loss: -16662898.0000 - val_accuracy: 0.1625\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11704437.0000 - accuracy: 0.1674 - val_loss: -17158032.0000 - val_accuracy: 0.1637\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12027894.0000 - accuracy: 0.1751 - val_loss: -17629836.0000 - val_accuracy: 0.1625\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12388161.0000 - accuracy: 0.1608 - val_loss: -18152336.0000 - val_accuracy: 0.1661\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12738456.0000 - accuracy: 0.1731 - val_loss: -18692742.0000 - val_accuracy: 0.1518\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13095340.0000 - accuracy: 0.1574 - val_loss: -19259074.0000 - val_accuracy: 0.1210\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13466294.0000 - accuracy: 0.1614 - val_loss: -19774920.0000 - val_accuracy: 0.1222\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13841303.0000 - accuracy: 0.1612 - val_loss: -20240614.0000 - val_accuracy: 0.1661\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14219095.0000 - accuracy: 0.1710 - val_loss: -20852486.0000 - val_accuracy: 0.1471\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14613997.0000 - accuracy: 0.1539 - val_loss: -21414362.0000 - val_accuracy: 0.1625\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.95      0.22      0.36       263\n","           1       0.10      1.00      0.18        79\n","           2       0.00      0.00      0.00       164\n","           3       0.00      0.00      0.00       196\n","           4       0.00      0.00      0.00       141\n","\n","    accuracy                           0.16       843\n","   macro avg       0.21      0.24      0.11       843\n","weighted avg       0.31      0.16      0.13       843\n","\n","Accuracy: 0.16251482799525505\n","[[ 58 205   0   0   0]\n"," [  0  79   0   0   0]\n"," [  0 164   0   0   0]\n"," [  3 193   0   0   0]\n"," [  0 141   0   0   0]]\n","Precision: 0.3061\n","Recall: 0.1625\n","F1 Score: 0.1289\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://93fa8d61-41fc-4dbd-9441-2aa5cb344467/assets\n","model 0 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: -236.8557 - accuracy: 0.1171 - val_loss: -741.6003 - val_accuracy: 0.0878\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1126.0507 - accuracy: 0.1462 - val_loss: -1949.5227 - val_accuracy: 0.0902\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2646.3984 - accuracy: 0.1374 - val_loss: -3851.6465 - val_accuracy: 0.0878\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4859.3584 - accuracy: 0.1291 - val_loss: -6755.2104 - val_accuracy: 0.1874\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8342.0117 - accuracy: 0.1390 - val_loss: -11006.0186 - val_accuracy: 0.1791\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13522.3955 - accuracy: 0.1287 - val_loss: -16516.3516 - val_accuracy: 0.1945\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -19853.6641 - accuracy: 0.1380 - val_loss: -23281.8770 - val_accuracy: 0.1815\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -27348.8691 - accuracy: 0.1452 - val_loss: -30565.9160 - val_accuracy: 0.0973\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -35938.5352 - accuracy: 0.1458 - val_loss: -39994.8203 - val_accuracy: 0.1827\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -45802.0742 - accuracy: 0.1515 - val_loss: -50093.6562 - val_accuracy: 0.1791\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -57089.6445 - accuracy: 0.1579 - val_loss: -59547.2070 - val_accuracy: 0.0902\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -69595.2656 - accuracy: 0.1419 - val_loss: -73444.4219 - val_accuracy: 0.1827\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -83630.8828 - accuracy: 0.1535 - val_loss: -87352.0156 - val_accuracy: 0.1791\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -99475.0859 - accuracy: 0.1434 - val_loss: -103652.5859 - val_accuracy: 0.1803\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -116291.0312 - accuracy: 0.1533 - val_loss: -120344.7344 - val_accuracy: 0.1815\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -135081.5781 - accuracy: 0.1503 - val_loss: -139123.8750 - val_accuracy: 0.1815\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -155737.3750 - accuracy: 0.1498 - val_loss: -157036.7656 - val_accuracy: 0.1376\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -178473.4844 - accuracy: 0.1521 - val_loss: -179785.0938 - val_accuracy: 0.1803\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -203033.8594 - accuracy: 0.1521 - val_loss: -202593.1562 - val_accuracy: 0.1708\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -230413.3750 - accuracy: 0.1482 - val_loss: -221786.4531 - val_accuracy: 0.0925\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -257932.5312 - accuracy: 0.1305 - val_loss: -256552.4844 - val_accuracy: 0.1791\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -289197.3750 - accuracy: 0.1541 - val_loss: -279145.7812 - val_accuracy: 0.0949\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -321462.8750 - accuracy: 0.1396 - val_loss: -307333.5312 - val_accuracy: 0.0949\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -356304.8125 - accuracy: 0.1233 - val_loss: -345783.8750 - val_accuracy: 0.1720\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -393230.2500 - accuracy: 0.1411 - val_loss: -382194.0000 - val_accuracy: 0.1803\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -433950.5312 - accuracy: 0.1262 - val_loss: -416239.7188 - val_accuracy: 0.1720\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -472479.8750 - accuracy: 0.1498 - val_loss: -449032.8438 - val_accuracy: 0.0961\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -512945.1562 - accuracy: 0.1205 - val_loss: -492714.3125 - val_accuracy: 0.1803\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -558034.6250 - accuracy: 0.1463 - val_loss: -521356.7188 - val_accuracy: 0.0949\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -603810.5625 - accuracy: 0.1295 - val_loss: -573331.8750 - val_accuracy: 0.1186\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -655631.8750 - accuracy: 0.1379 - val_loss: -612934.6250 - val_accuracy: 0.0949\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -709081.4375 - accuracy: 0.1267 - val_loss: -671142.5625 - val_accuracy: 0.1756\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -763767.0000 - accuracy: 0.1399 - val_loss: -715114.1250 - val_accuracy: 0.0961\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -820356.8125 - accuracy: 0.1334 - val_loss: -769575.5000 - val_accuracy: 0.0961\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -882012.3125 - accuracy: 0.1239 - val_loss: -826990.7500 - val_accuracy: 0.1803\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -947665.7500 - accuracy: 0.1395 - val_loss: -879173.1875 - val_accuracy: 0.0961\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1013372.5625 - accuracy: 0.1303 - val_loss: -934721.5000 - val_accuracy: 0.0949\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1084924.5000 - accuracy: 0.1437 - val_loss: -1002786.9375 - val_accuracy: 0.0961\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1157181.1250 - accuracy: 0.1241 - val_loss: -1072139.5000 - val_accuracy: 0.1186\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1231915.5000 - accuracy: 0.1357 - val_loss: -1131433.6250 - val_accuracy: 0.0961\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1311060.8750 - accuracy: 0.1299 - val_loss: -1209771.2500 - val_accuracy: 0.1198\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1391135.7500 - accuracy: 0.1307 - val_loss: -1265963.0000 - val_accuracy: 0.0961\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1476612.7500 - accuracy: 0.1285 - val_loss: -1354468.2500 - val_accuracy: 0.1056\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1564312.8750 - accuracy: 0.1281 - val_loss: -1434682.7500 - val_accuracy: 0.1625\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1654841.3750 - accuracy: 0.1397 - val_loss: -1520726.7500 - val_accuracy: 0.1708\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1752188.6250 - accuracy: 0.1210 - val_loss: -1589100.0000 - val_accuracy: 0.0961\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1842750.6250 - accuracy: 0.1225 - val_loss: -1684771.1250 - val_accuracy: 0.1791\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1944900.3750 - accuracy: 0.1428 - val_loss: -1769359.0000 - val_accuracy: 0.1186\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2040378.6250 - accuracy: 0.1442 - val_loss: -1869860.6250 - val_accuracy: 0.1791\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2145593.0000 - accuracy: 0.1187 - val_loss: -1951818.8750 - val_accuracy: 0.1186\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2253349.5000 - accuracy: 0.1227 - val_loss: -2049877.5000 - val_accuracy: 0.1708\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2362731.2500 - accuracy: 0.1300 - val_loss: -2139230.5000 - val_accuracy: 0.0973\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2481432.7500 - accuracy: 0.1324 - val_loss: -2230566.0000 - val_accuracy: 0.0961\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2600932.2500 - accuracy: 0.1234 - val_loss: -2342799.2500 - val_accuracy: 0.0949\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2727426.7500 - accuracy: 0.1143 - val_loss: -2461874.7500 - val_accuracy: 0.1186\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2857049.7500 - accuracy: 0.1205 - val_loss: -2572490.7500 - val_accuracy: 0.0996\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2991624.7500 - accuracy: 0.1259 - val_loss: -2691231.5000 - val_accuracy: 0.0996\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3130589.7500 - accuracy: 0.1148 - val_loss: -2806226.5000 - val_accuracy: 0.0973\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3267716.7500 - accuracy: 0.1160 - val_loss: -2939301.0000 - val_accuracy: 0.1566\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3412511.0000 - accuracy: 0.1251 - val_loss: -3068602.5000 - val_accuracy: 0.1708\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3549851.7500 - accuracy: 0.1407 - val_loss: -3186638.5000 - val_accuracy: 0.1708\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3704662.0000 - accuracy: 0.1245 - val_loss: -3313150.2500 - val_accuracy: 0.1471\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3861245.2500 - accuracy: 0.1432 - val_loss: -3400154.2500 - val_accuracy: 0.0949\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4010152.0000 - accuracy: 0.1111 - val_loss: -3584570.2500 - val_accuracy: 0.0961\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4171641.0000 - accuracy: 0.1144 - val_loss: -3738069.5000 - val_accuracy: 0.1495\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4323218.5000 - accuracy: 0.1378 - val_loss: -3864535.5000 - val_accuracy: 0.0961\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4492017.0000 - accuracy: 0.1210 - val_loss: -4011803.7500 - val_accuracy: 0.1151\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4654311.5000 - accuracy: 0.1384 - val_loss: -4153345.0000 - val_accuracy: 0.0973\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4830542.0000 - accuracy: 0.1226 - val_loss: -4316089.5000 - val_accuracy: 0.1174\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5011513.5000 - accuracy: 0.1184 - val_loss: -4482294.5000 - val_accuracy: 0.1518\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5194164.0000 - accuracy: 0.1193 - val_loss: -4629134.0000 - val_accuracy: 0.0973\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5379998.0000 - accuracy: 0.1255 - val_loss: -4762664.0000 - val_accuracy: 0.0961\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5554124.5000 - accuracy: 0.1080 - val_loss: -4948117.0000 - val_accuracy: 0.0973\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5751086.5000 - accuracy: 0.1171 - val_loss: -5094672.0000 - val_accuracy: 0.0973\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5934296.5000 - accuracy: 0.1136 - val_loss: -5258195.5000 - val_accuracy: 0.0973\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6124536.5000 - accuracy: 0.1144 - val_loss: -5455294.5000 - val_accuracy: 0.1115\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6324068.5000 - accuracy: 0.1158 - val_loss: -5629848.5000 - val_accuracy: 0.0973\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6528080.0000 - accuracy: 0.1180 - val_loss: -5803291.0000 - val_accuracy: 0.0973\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6741142.5000 - accuracy: 0.1140 - val_loss: -5998666.0000 - val_accuracy: 0.0961\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6959347.0000 - accuracy: 0.1136 - val_loss: -6215569.0000 - val_accuracy: 0.1186\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7188060.0000 - accuracy: 0.1243 - val_loss: -6399677.0000 - val_accuracy: 0.1056\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7427910.0000 - accuracy: 0.1107 - val_loss: -6612211.0000 - val_accuracy: 0.1186\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7656214.0000 - accuracy: 0.1251 - val_loss: -6813973.0000 - val_accuracy: 0.0996\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7880566.5000 - accuracy: 0.1425 - val_loss: -7004150.5000 - val_accuracy: 0.1151\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8121431.0000 - accuracy: 0.1147 - val_loss: -7207449.0000 - val_accuracy: 0.0973\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8368987.0000 - accuracy: 0.1160 - val_loss: -7414916.0000 - val_accuracy: 0.0973\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8623741.0000 - accuracy: 0.1355 - val_loss: -7601768.0000 - val_accuracy: 0.0973\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8881502.0000 - accuracy: 0.1147 - val_loss: -7860593.5000 - val_accuracy: 0.0973\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9150879.0000 - accuracy: 0.1121 - val_loss: -8124031.5000 - val_accuracy: 0.1246\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9426324.0000 - accuracy: 0.1313 - val_loss: -8308972.5000 - val_accuracy: 0.0973\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9705317.0000 - accuracy: 0.1226 - val_loss: -8572633.0000 - val_accuracy: 0.0973\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9992962.0000 - accuracy: 0.1160 - val_loss: -8843395.0000 - val_accuracy: 0.1115\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10285637.0000 - accuracy: 0.1284 - val_loss: -9065250.0000 - val_accuracy: 0.0973\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10592634.0000 - accuracy: 0.1115 - val_loss: -9366028.0000 - val_accuracy: 0.1186\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10905734.0000 - accuracy: 0.1246 - val_loss: -9642938.0000 - val_accuracy: 0.1376\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11213400.0000 - accuracy: 0.1226 - val_loss: -9883331.0000 - val_accuracy: 0.1103\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11519222.0000 - accuracy: 0.1423 - val_loss: -10082652.0000 - val_accuracy: 0.0949\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11829396.0000 - accuracy: 0.1144 - val_loss: -10443744.0000 - val_accuracy: 0.1174\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12156216.0000 - accuracy: 0.1233 - val_loss: -10702592.0000 - val_accuracy: 0.0985\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12488466.0000 - accuracy: 0.1201 - val_loss: -10999156.0000 - val_accuracy: 0.1174\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.10      0.17       291\n","           1       0.09      0.96      0.16        74\n","           2       0.00      0.00      0.00       169\n","           3       0.00      0.00      0.00       191\n","           4       0.00      0.00      0.00       118\n","\n","    accuracy                           0.12       843\n","   macro avg       0.19      0.21      0.07       843\n","weighted avg       0.31      0.12      0.07       843\n","\n","Accuracy: 0.11743772241992882\n","[[ 28 263   0   0   0]\n"," [  3  71   0   0   0]\n"," [  0 169   0   0   0]\n"," [  1 190   0   0   0]\n"," [  0 118   0   0   0]]\n","Precision: 0.3097\n","Recall: 0.1174\n","F1 Score: 0.0739\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://7787b18d-fc72-4cfa-84c0-57ac6784a619/assets\n","model 1 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: -181.7656 - accuracy: 0.1035 - val_loss: -457.7724 - val_accuracy: 0.0890\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1219.2405 - accuracy: 0.0987 - val_loss: -1624.5643 - val_accuracy: 0.0890\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3380.4756 - accuracy: 0.0987 - val_loss: -4004.1689 - val_accuracy: 0.0890\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6931.4204 - accuracy: 0.0987 - val_loss: -7252.1045 - val_accuracy: 0.0890\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11937.0029 - accuracy: 0.0987 - val_loss: -11585.3145 - val_accuracy: 0.0890\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -18290.2109 - accuracy: 0.0987 - val_loss: -17481.3613 - val_accuracy: 0.0890\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -25778.5312 - accuracy: 0.0987 - val_loss: -23992.7812 - val_accuracy: 0.0890\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -34428.4102 - accuracy: 0.0987 - val_loss: -31565.2051 - val_accuracy: 0.0890\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -44611.5898 - accuracy: 0.0987 - val_loss: -40796.8008 - val_accuracy: 0.0890\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -56542.5000 - accuracy: 0.0987 - val_loss: -50879.1016 - val_accuracy: 0.0890\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -70393.9609 - accuracy: 0.0987 - val_loss: -63421.0469 - val_accuracy: 0.0890\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -86500.2656 - accuracy: 0.0987 - val_loss: -77726.0391 - val_accuracy: 0.0890\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -104602.3594 - accuracy: 0.0987 - val_loss: -94658.7109 - val_accuracy: 0.0890\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -124470.8359 - accuracy: 0.0987 - val_loss: -111553.6406 - val_accuracy: 0.0890\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -146740.0781 - accuracy: 0.0987 - val_loss: -127412.7422 - val_accuracy: 0.0890\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -172520.7188 - accuracy: 0.0987 - val_loss: -146580.1406 - val_accuracy: 0.0890\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -204391.3906 - accuracy: 0.0987 - val_loss: -177747.9844 - val_accuracy: 0.0890\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -236996.2500 - accuracy: 0.0987 - val_loss: -207552.8750 - val_accuracy: 0.0890\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -269249.5312 - accuracy: 0.0987 - val_loss: -236627.7969 - val_accuracy: 0.0890\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -303582.2500 - accuracy: 0.0987 - val_loss: -266887.0312 - val_accuracy: 0.0890\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -338961.2500 - accuracy: 0.0987 - val_loss: -301305.4375 - val_accuracy: 0.0890\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -380221.9062 - accuracy: 0.0987 - val_loss: -339494.2500 - val_accuracy: 0.0890\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -424587.0938 - accuracy: 0.0987 - val_loss: -380437.1875 - val_accuracy: 0.0890\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -472980.1562 - accuracy: 0.0987 - val_loss: -425109.8750 - val_accuracy: 0.0890\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -526140.8750 - accuracy: 0.0987 - val_loss: -472998.3438 - val_accuracy: 0.0890\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -580736.9375 - accuracy: 0.0987 - val_loss: -523713.1250 - val_accuracy: 0.0890\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -638266.6250 - accuracy: 0.0987 - val_loss: -575387.6250 - val_accuracy: 0.0890\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -698060.0000 - accuracy: 0.0987 - val_loss: -626896.6875 - val_accuracy: 0.0890\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -763487.6875 - accuracy: 0.0987 - val_loss: -686282.6250 - val_accuracy: 0.0890\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -830739.4375 - accuracy: 0.0987 - val_loss: -748176.5625 - val_accuracy: 0.0890\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -902183.0625 - accuracy: 0.0987 - val_loss: -813996.8125 - val_accuracy: 0.0890\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -977159.3750 - accuracy: 0.0987 - val_loss: -882494.2500 - val_accuracy: 0.0890\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1056286.0000 - accuracy: 0.0987 - val_loss: -956511.9375 - val_accuracy: 0.0890\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1139566.7500 - accuracy: 0.0987 - val_loss: -1034304.7500 - val_accuracy: 0.0890\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1225404.7500 - accuracy: 0.0987 - val_loss: -1120351.7500 - val_accuracy: 0.0890\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1316157.1250 - accuracy: 0.0987 - val_loss: -1206081.0000 - val_accuracy: 0.0890\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1411156.2500 - accuracy: 0.0987 - val_loss: -1295704.5000 - val_accuracy: 0.0890\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1509388.3750 - accuracy: 0.0987 - val_loss: -1385448.6250 - val_accuracy: 0.0890\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1613850.7500 - accuracy: 0.0987 - val_loss: -1480143.7500 - val_accuracy: 0.0890\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1721418.3750 - accuracy: 0.0987 - val_loss: -1583906.5000 - val_accuracy: 0.0890\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1829156.8750 - accuracy: 0.0987 - val_loss: -1684379.7500 - val_accuracy: 0.0890\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1947381.2500 - accuracy: 0.0987 - val_loss: -1792659.7500 - val_accuracy: 0.0890\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2068092.5000 - accuracy: 0.0987 - val_loss: -1901046.8750 - val_accuracy: 0.0890\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2193206.7500 - accuracy: 0.0987 - val_loss: -2016799.0000 - val_accuracy: 0.0890\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2322092.7500 - accuracy: 0.0987 - val_loss: -2131264.5000 - val_accuracy: 0.0890\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2459040.0000 - accuracy: 0.0987 - val_loss: -2264637.7500 - val_accuracy: 0.0890\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2601779.5000 - accuracy: 0.0987 - val_loss: -2401041.5000 - val_accuracy: 0.0890\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2748498.2500 - accuracy: 0.0987 - val_loss: -2539358.5000 - val_accuracy: 0.0890\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2900283.7500 - accuracy: 0.0987 - val_loss: -2679247.0000 - val_accuracy: 0.0890\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3058677.0000 - accuracy: 0.0987 - val_loss: -2826591.2500 - val_accuracy: 0.0890\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3220740.2500 - accuracy: 0.0987 - val_loss: -2981292.5000 - val_accuracy: 0.0890\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3393139.0000 - accuracy: 0.0987 - val_loss: -3141180.5000 - val_accuracy: 0.0890\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3570985.5000 - accuracy: 0.0987 - val_loss: -3313480.5000 - val_accuracy: 0.0890\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3752634.0000 - accuracy: 0.0987 - val_loss: -3481452.0000 - val_accuracy: 0.0890\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3942046.5000 - accuracy: 0.0987 - val_loss: -3666782.5000 - val_accuracy: 0.0890\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4143020.0000 - accuracy: 0.0987 - val_loss: -3840081.0000 - val_accuracy: 0.0890\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4335339.0000 - accuracy: 0.0987 - val_loss: -4027094.5000 - val_accuracy: 0.0890\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4533372.5000 - accuracy: 0.0987 - val_loss: -4219590.0000 - val_accuracy: 0.0890\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4739390.5000 - accuracy: 0.0987 - val_loss: -4427710.0000 - val_accuracy: 0.0890\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4947347.0000 - accuracy: 0.0987 - val_loss: -4612577.5000 - val_accuracy: 0.0890\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5166839.0000 - accuracy: 0.0987 - val_loss: -4832002.0000 - val_accuracy: 0.0890\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5397792.0000 - accuracy: 0.0987 - val_loss: -5057257.0000 - val_accuracy: 0.0890\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5634754.0000 - accuracy: 0.0987 - val_loss: -5271609.0000 - val_accuracy: 0.0890\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5876794.5000 - accuracy: 0.0987 - val_loss: -5527923.5000 - val_accuracy: 0.0890\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6131276.0000 - accuracy: 0.0987 - val_loss: -5767501.5000 - val_accuracy: 0.0890\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6386778.0000 - accuracy: 0.0987 - val_loss: -6007700.5000 - val_accuracy: 0.0890\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6659365.5000 - accuracy: 0.0987 - val_loss: -6238864.5000 - val_accuracy: 0.0890\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6925708.0000 - accuracy: 0.0987 - val_loss: -6506690.5000 - val_accuracy: 0.0890\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7212879.5000 - accuracy: 0.0987 - val_loss: -6776479.0000 - val_accuracy: 0.0890\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7495478.0000 - accuracy: 0.0987 - val_loss: -7055750.5000 - val_accuracy: 0.0890\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7786585.0000 - accuracy: 0.0987 - val_loss: -7325887.5000 - val_accuracy: 0.0890\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8085685.5000 - accuracy: 0.0987 - val_loss: -7622550.5000 - val_accuracy: 0.0890\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8382912.0000 - accuracy: 0.0987 - val_loss: -7909935.0000 - val_accuracy: 0.0890\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8692953.0000 - accuracy: 0.0987 - val_loss: -8201751.0000 - val_accuracy: 0.0890\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9005380.0000 - accuracy: 0.0987 - val_loss: -8511164.0000 - val_accuracy: 0.0890\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9333195.0000 - accuracy: 0.0987 - val_loss: -8813674.0000 - val_accuracy: 0.0890\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9667213.0000 - accuracy: 0.0987 - val_loss: -9146355.0000 - val_accuracy: 0.0890\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10008792.0000 - accuracy: 0.0987 - val_loss: -9482088.0000 - val_accuracy: 0.0890\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10360503.0000 - accuracy: 0.0987 - val_loss: -9798283.0000 - val_accuracy: 0.0890\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10715822.0000 - accuracy: 0.0987 - val_loss: -10150839.0000 - val_accuracy: 0.0890\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11072916.0000 - accuracy: 0.0987 - val_loss: -10540882.0000 - val_accuracy: 0.0890\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11444338.0000 - accuracy: 0.0987 - val_loss: -10915986.0000 - val_accuracy: 0.0890\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11819087.0000 - accuracy: 0.0987 - val_loss: -11269629.0000 - val_accuracy: 0.0890\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12211600.0000 - accuracy: 0.0987 - val_loss: -11610569.0000 - val_accuracy: 0.0890\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12606314.0000 - accuracy: 0.0987 - val_loss: -12038297.0000 - val_accuracy: 0.0890\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13012271.0000 - accuracy: 0.0987 - val_loss: -12433599.0000 - val_accuracy: 0.0890\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13379143.0000 - accuracy: 0.0987 - val_loss: -12827474.0000 - val_accuracy: 0.0890\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13833951.0000 - accuracy: 0.0987 - val_loss: -13213274.0000 - val_accuracy: 0.0890\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14264400.0000 - accuracy: 0.0987 - val_loss: -13591912.0000 - val_accuracy: 0.0890\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14689259.0000 - accuracy: 0.0987 - val_loss: -14013071.0000 - val_accuracy: 0.0890\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -15129678.0000 - accuracy: 0.0987 - val_loss: -14432216.0000 - val_accuracy: 0.0890\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -15581708.0000 - accuracy: 0.0987 - val_loss: -14856338.0000 - val_accuracy: 0.0890\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -16045608.0000 - accuracy: 0.0987 - val_loss: -15322017.0000 - val_accuracy: 0.0890\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -16517207.0000 - accuracy: 0.0987 - val_loss: -15752999.0000 - val_accuracy: 0.0890\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -17010422.0000 - accuracy: 0.0987 - val_loss: -16254901.0000 - val_accuracy: 0.0890\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -17510978.0000 - accuracy: 0.0987 - val_loss: -16705070.0000 - val_accuracy: 0.0890\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -18017432.0000 - accuracy: 0.0987 - val_loss: -17220966.0000 - val_accuracy: 0.0890\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -18524728.0000 - accuracy: 0.0987 - val_loss: -17692852.0000 - val_accuracy: 0.0890\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -19037054.0000 - accuracy: 0.0987 - val_loss: -18181306.0000 - val_accuracy: 0.0890\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -19575676.0000 - accuracy: 0.0987 - val_loss: -18692534.0000 - val_accuracy: 0.0890\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       270\n","           1       0.09      1.00      0.16        75\n","           2       0.00      0.00      0.00       178\n","           3       0.00      0.00      0.00       182\n","           4       0.00      0.00      0.00       138\n","\n","    accuracy                           0.09       843\n","   macro avg       0.02      0.20      0.03       843\n","weighted avg       0.01      0.09      0.01       843\n","\n","Accuracy: 0.08896797153024912\n","[[  0 270   0   0   0]\n"," [  0  75   0   0   0]\n"," [  0 178   0   0   0]\n"," [  0 182   0   0   0]\n"," [  0 138   0   0   0]]\n","Precision: 0.0079\n","Recall: 0.0890\n","F1 Score: 0.0145\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://fde02fee-babf-46ca-959e-05ebbade9244/assets\n","model 2 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 29.9379 - accuracy: 0.1231 - val_loss: -90.6780 - val_accuracy: 0.2444\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1890.2737 - accuracy: 0.1284 - val_loss: -1594.1606 - val_accuracy: 0.1590\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4056.1111 - accuracy: 0.1187 - val_loss: -2765.8674 - val_accuracy: 0.1020\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6929.2007 - accuracy: 0.1267 - val_loss: -4745.6758 - val_accuracy: 0.1922\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10768.5459 - accuracy: 0.1403 - val_loss: -6920.6689 - val_accuracy: 0.1020\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -15753.8584 - accuracy: 0.1295 - val_loss: -10820.1016 - val_accuracy: 0.1020\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -21807.7891 - accuracy: 0.1351 - val_loss: -14898.1396 - val_accuracy: 0.1234\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -29665.4980 - accuracy: 0.1304 - val_loss: -19742.0742 - val_accuracy: 0.1578\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -38899.9922 - accuracy: 0.1256 - val_loss: -24103.2402 - val_accuracy: 0.2005\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -49834.2344 - accuracy: 0.1368 - val_loss: -31486.5312 - val_accuracy: 0.1151\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -62539.0938 - accuracy: 0.1313 - val_loss: -38810.4844 - val_accuracy: 0.1115\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -76776.8906 - accuracy: 0.1187 - val_loss: -47640.1328 - val_accuracy: 0.1151\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -92344.2969 - accuracy: 0.1175 - val_loss: -57779.2773 - val_accuracy: 0.1234\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -109937.4453 - accuracy: 0.1328 - val_loss: -67424.7422 - val_accuracy: 0.1127\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -129414.3203 - accuracy: 0.1270 - val_loss: -79482.5938 - val_accuracy: 0.1151\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -152062.3594 - accuracy: 0.1378 - val_loss: -89112.0156 - val_accuracy: 0.1020\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -175413.0938 - accuracy: 0.1249 - val_loss: -108169.5391 - val_accuracy: 0.1246\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -202642.1562 - accuracy: 0.1341 - val_loss: -122618.8359 - val_accuracy: 0.1163\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -230632.5938 - accuracy: 0.1241 - val_loss: -139773.6406 - val_accuracy: 0.1756\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -262024.1875 - accuracy: 0.1246 - val_loss: -158293.8906 - val_accuracy: 0.1186\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -296130.9375 - accuracy: 0.1234 - val_loss: -178690.7188 - val_accuracy: 0.1210\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -333735.4688 - accuracy: 0.1191 - val_loss: -200478.2031 - val_accuracy: 0.1163\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -374384.5938 - accuracy: 0.1237 - val_loss: -224955.1719 - val_accuracy: 0.1186\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -416246.1250 - accuracy: 0.1242 - val_loss: -249082.6406 - val_accuracy: 0.1767\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -461711.4688 - accuracy: 0.1247 - val_loss: -276767.0000 - val_accuracy: 0.1198\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -511536.9688 - accuracy: 0.1176 - val_loss: -303908.6250 - val_accuracy: 0.1791\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -563274.7500 - accuracy: 0.1303 - val_loss: -332858.1562 - val_accuracy: 0.1151\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -618719.3125 - accuracy: 0.1169 - val_loss: -365712.9688 - val_accuracy: 0.1163\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -676082.8750 - accuracy: 0.1105 - val_loss: -399932.4688 - val_accuracy: 0.1210\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -737038.6875 - accuracy: 0.1208 - val_loss: -435090.8750 - val_accuracy: 0.1317\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -801033.8125 - accuracy: 0.1249 - val_loss: -473693.5625 - val_accuracy: 0.1198\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -862178.2500 - accuracy: 0.1275 - val_loss: -509953.2188 - val_accuracy: 0.1649\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -931671.1250 - accuracy: 0.1279 - val_loss: -548625.4375 - val_accuracy: 0.1186\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1001239.6875 - accuracy: 0.1136 - val_loss: -590437.0625 - val_accuracy: 0.1186\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1076071.6250 - accuracy: 0.1127 - val_loss: -632560.8125 - val_accuracy: 0.1542\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1155130.8750 - accuracy: 0.1288 - val_loss: -678918.8125 - val_accuracy: 0.1210\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1239885.8750 - accuracy: 0.1132 - val_loss: -726722.2500 - val_accuracy: 0.1198\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1326136.6250 - accuracy: 0.1169 - val_loss: -774886.4375 - val_accuracy: 0.1803\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1419578.3750 - accuracy: 0.1181 - val_loss: -830581.7500 - val_accuracy: 0.1388\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1515513.0000 - accuracy: 0.1162 - val_loss: -887221.2500 - val_accuracy: 0.1305\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1614321.6250 - accuracy: 0.1252 - val_loss: -939038.5000 - val_accuracy: 0.1163\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1718683.3750 - accuracy: 0.1223 - val_loss: -997956.8750 - val_accuracy: 0.1163\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1819749.5000 - accuracy: 0.1143 - val_loss: -1064928.6250 - val_accuracy: 0.1257\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1933340.6250 - accuracy: 0.1160 - val_loss: -1126963.7500 - val_accuracy: 0.1388\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2045396.2500 - accuracy: 0.1226 - val_loss: -1197175.8750 - val_accuracy: 0.1234\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2168072.2500 - accuracy: 0.1181 - val_loss: -1263643.8750 - val_accuracy: 0.1198\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2293845.7500 - accuracy: 0.1143 - val_loss: -1332238.2500 - val_accuracy: 0.1198\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2425172.2500 - accuracy: 0.1150 - val_loss: -1410864.2500 - val_accuracy: 0.1210\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2562702.7500 - accuracy: 0.1121 - val_loss: -1488602.6250 - val_accuracy: 0.1293\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2704027.2500 - accuracy: 0.1160 - val_loss: -1569884.3750 - val_accuracy: 0.1293\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2856549.2500 - accuracy: 0.1134 - val_loss: -1648804.0000 - val_accuracy: 0.1744\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3005149.5000 - accuracy: 0.1276 - val_loss: -1739698.7500 - val_accuracy: 0.1542\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3161214.5000 - accuracy: 0.1201 - val_loss: -1821390.6250 - val_accuracy: 0.1803\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3304661.0000 - accuracy: 0.1249 - val_loss: -1920118.6250 - val_accuracy: 0.1293\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3467166.2500 - accuracy: 0.1144 - val_loss: -2007504.8750 - val_accuracy: 0.1483\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3627981.0000 - accuracy: 0.1217 - val_loss: -2103064.5000 - val_accuracy: 0.1293\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3800181.0000 - accuracy: 0.1251 - val_loss: -2194491.2500 - val_accuracy: 0.1174\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3975893.5000 - accuracy: 0.1197 - val_loss: -2297401.5000 - val_accuracy: 0.1186\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4159677.2500 - accuracy: 0.1142 - val_loss: -2405864.2500 - val_accuracy: 0.1293\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4351290.5000 - accuracy: 0.1151 - val_loss: -2510847.5000 - val_accuracy: 0.1293\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4545428.5000 - accuracy: 0.1205 - val_loss: -2607836.2500 - val_accuracy: 0.1186\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4736962.5000 - accuracy: 0.1126 - val_loss: -2725154.5000 - val_accuracy: 0.1791\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4935796.5000 - accuracy: 0.1466 - val_loss: -2839602.7500 - val_accuracy: 0.1198\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5144490.5000 - accuracy: 0.1123 - val_loss: -2965564.5000 - val_accuracy: 0.1246\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5364767.0000 - accuracy: 0.1192 - val_loss: -3069680.0000 - val_accuracy: 0.1186\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5552705.5000 - accuracy: 0.1101 - val_loss: -3165775.7500 - val_accuracy: 0.1269\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5682436.5000 - accuracy: 0.1235 - val_loss: -3249003.2500 - val_accuracy: 0.1269\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5809760.0000 - accuracy: 0.1200 - val_loss: -3328178.5000 - val_accuracy: 0.1198\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5942336.0000 - accuracy: 0.1183 - val_loss: -3426428.5000 - val_accuracy: 0.1281\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6085835.0000 - accuracy: 0.1246 - val_loss: -3519445.5000 - val_accuracy: 0.1530\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6239917.5000 - accuracy: 0.1156 - val_loss: -3611338.0000 - val_accuracy: 0.1779\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6373401.0000 - accuracy: 0.1569 - val_loss: -3714426.5000 - val_accuracy: 0.1198\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6577610.0000 - accuracy: 0.1197 - val_loss: -3826466.2500 - val_accuracy: 0.1198\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6766580.0000 - accuracy: 0.1200 - val_loss: -3948746.7500 - val_accuracy: 0.1269\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6971218.0000 - accuracy: 0.1289 - val_loss: -4074475.7500 - val_accuracy: 0.1269\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7184486.5000 - accuracy: 0.1175 - val_loss: -4201759.0000 - val_accuracy: 0.1530\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7380816.5000 - accuracy: 0.1525 - val_loss: -4323339.0000 - val_accuracy: 0.1281\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7637076.5000 - accuracy: 0.1318 - val_loss: -4435346.0000 - val_accuracy: 0.1186\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7872034.5000 - accuracy: 0.1138 - val_loss: -4592041.0000 - val_accuracy: 0.1186\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8126456.0000 - accuracy: 0.1293 - val_loss: -4720157.0000 - val_accuracy: 0.1174\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8376076.5000 - accuracy: 0.1111 - val_loss: -4899078.0000 - val_accuracy: 0.1364\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8644637.0000 - accuracy: 0.1270 - val_loss: -5060526.5000 - val_accuracy: 0.1269\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8922840.0000 - accuracy: 0.1196 - val_loss: -5221486.5000 - val_accuracy: 0.1364\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9210525.0000 - accuracy: 0.1231 - val_loss: -5388541.5000 - val_accuracy: 0.1269\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9518542.0000 - accuracy: 0.1272 - val_loss: -5552333.5000 - val_accuracy: 0.1198\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9819308.0000 - accuracy: 0.1160 - val_loss: -5755691.5000 - val_accuracy: 0.1293\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10151051.0000 - accuracy: 0.1278 - val_loss: -5922748.0000 - val_accuracy: 0.1186\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10476074.0000 - accuracy: 0.1152 - val_loss: -6122083.5000 - val_accuracy: 0.1281\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10819499.0000 - accuracy: 0.1338 - val_loss: -6290835.5000 - val_accuracy: 0.1186\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11156991.0000 - accuracy: 0.1221 - val_loss: -6497826.5000 - val_accuracy: 0.1198\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11504793.0000 - accuracy: 0.1193 - val_loss: -6720470.5000 - val_accuracy: 0.1281\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11857471.0000 - accuracy: 0.1209 - val_loss: -6928379.5000 - val_accuracy: 0.1590\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12235380.0000 - accuracy: 0.1343 - val_loss: -7125716.0000 - val_accuracy: 0.1198\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12609036.0000 - accuracy: 0.1126 - val_loss: -7353008.5000 - val_accuracy: 0.1708\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12983372.0000 - accuracy: 0.1245 - val_loss: -7572547.0000 - val_accuracy: 0.1269\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13376802.0000 - accuracy: 0.1263 - val_loss: -7790832.5000 - val_accuracy: 0.1269\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13743429.0000 - accuracy: 0.1231 - val_loss: -8004186.0000 - val_accuracy: 0.1186\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14127194.0000 - accuracy: 0.1198 - val_loss: -8228638.5000 - val_accuracy: 0.1210\n","Epoch 99/100\n","238/238 [==============================] - 1s 4ms/step - loss: -14542942.0000 - accuracy: 0.1198 - val_loss: -8460097.0000 - val_accuracy: 0.1198\n","Epoch 100/100\n","238/238 [==============================] - 1s 4ms/step - loss: -14960381.0000 - accuracy: 0.1140 - val_loss: -8698917.0000 - val_accuracy: 0.1281\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.08      0.15       288\n","           1       0.10      0.99      0.19        86\n","           2       0.00      0.00      0.00       156\n","           3       0.00      0.00      0.00       194\n","           4       0.00      0.00      0.00       119\n","\n","    accuracy                           0.13       843\n","   macro avg       0.18      0.21      0.07       843\n","weighted avg       0.28      0.13      0.07       843\n","\n","Accuracy: 0.12811387900355872\n","[[ 23 265   0   0   0]\n"," [  1  85   0   0   0]\n"," [  0 156   0   0   0]\n"," [  5 189   0   0   0]\n"," [  0 119   0   0   0]]\n","Precision: 0.2816\n","Recall: 0.1281\n","F1 Score: 0.0688\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://1545fc7e-be0e-44ff-807e-5407e3abb7d4/assets\n","model 3 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: -67.2216 - accuracy: 0.1465 - val_loss: -28.8473 - val_accuracy: 0.0973\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -435.3719 - accuracy: 0.1337 - val_loss: -656.8365 - val_accuracy: 0.2147\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1106.6980 - accuracy: 0.1396 - val_loss: -1692.4261 - val_accuracy: 0.1922\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2339.3022 - accuracy: 0.1354 - val_loss: -3461.4058 - val_accuracy: 0.1910\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4374.8330 - accuracy: 0.1421 - val_loss: -6314.0083 - val_accuracy: 0.1234\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7192.8398 - accuracy: 0.1521 - val_loss: -9779.5518 - val_accuracy: 0.1079\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11045.1025 - accuracy: 0.1339 - val_loss: -14788.7891 - val_accuracy: 0.1803\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -15494.1279 - accuracy: 0.1486 - val_loss: -20165.7695 - val_accuracy: 0.1874\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -21168.6016 - accuracy: 0.1478 - val_loss: -26318.6895 - val_accuracy: 0.0996\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -28079.9375 - accuracy: 0.1453 - val_loss: -34060.7891 - val_accuracy: 0.1008\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -35621.6094 - accuracy: 0.1459 - val_loss: -43881.0430 - val_accuracy: 0.1091\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -44738.2773 - accuracy: 0.1521 - val_loss: -54581.5859 - val_accuracy: 0.1091\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -55322.7891 - accuracy: 0.1421 - val_loss: -66914.1875 - val_accuracy: 0.1815\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -67331.6953 - accuracy: 0.1531 - val_loss: -79612.6250 - val_accuracy: 0.1068\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -80291.0000 - accuracy: 0.1478 - val_loss: -95040.8750 - val_accuracy: 0.1851\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -95204.0234 - accuracy: 0.1391 - val_loss: -111906.6953 - val_accuracy: 0.1851\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -111321.1562 - accuracy: 0.1556 - val_loss: -130217.4609 - val_accuracy: 0.1708\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -129630.9844 - accuracy: 0.1466 - val_loss: -149649.9375 - val_accuracy: 0.1791\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -148257.3125 - accuracy: 0.1528 - val_loss: -171159.6875 - val_accuracy: 0.1234\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -169845.7188 - accuracy: 0.1508 - val_loss: -191847.6094 - val_accuracy: 0.1044\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -192294.8125 - accuracy: 0.1429 - val_loss: -218423.4844 - val_accuracy: 0.1091\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -216984.4844 - accuracy: 0.1392 - val_loss: -246424.1875 - val_accuracy: 0.1791\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -243737.2812 - accuracy: 0.1531 - val_loss: -273737.7188 - val_accuracy: 0.1091\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -272491.1875 - accuracy: 0.1387 - val_loss: -307069.2812 - val_accuracy: 0.1720\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -302895.6250 - accuracy: 0.1548 - val_loss: -340462.3438 - val_accuracy: 0.1791\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -336762.4375 - accuracy: 0.1454 - val_loss: -372327.7500 - val_accuracy: 0.1862\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -368157.2812 - accuracy: 0.1618 - val_loss: -409396.1250 - val_accuracy: 0.1234\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -404235.8125 - accuracy: 0.1321 - val_loss: -448388.2812 - val_accuracy: 0.1815\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -441325.5312 - accuracy: 0.1405 - val_loss: -488178.9688 - val_accuracy: 0.1803\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -481844.8750 - accuracy: 0.1403 - val_loss: -531378.0000 - val_accuracy: 0.1281\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -518126.0312 - accuracy: 0.1546 - val_loss: -572107.3750 - val_accuracy: 0.1234\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -560825.8125 - accuracy: 0.1366 - val_loss: -616482.1250 - val_accuracy: 0.1791\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -603365.3750 - accuracy: 0.1440 - val_loss: -663208.4375 - val_accuracy: 0.1246\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -649164.7500 - accuracy: 0.1479 - val_loss: -710909.0625 - val_accuracy: 0.1281\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -697443.6250 - accuracy: 0.1396 - val_loss: -760182.6875 - val_accuracy: 0.1091\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -746232.2500 - accuracy: 0.1338 - val_loss: -815965.0625 - val_accuracy: 0.1720\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -799590.3750 - accuracy: 0.1382 - val_loss: -872476.6250 - val_accuracy: 0.1246\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -855132.8125 - accuracy: 0.1370 - val_loss: -930311.0625 - val_accuracy: 0.1234\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -911726.3750 - accuracy: 0.1337 - val_loss: -990424.7500 - val_accuracy: 0.1791\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -972936.9375 - accuracy: 0.1514 - val_loss: -1050433.3750 - val_accuracy: 0.1091\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1036163.2500 - accuracy: 0.1330 - val_loss: -1116555.0000 - val_accuracy: 0.1091\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1102635.7500 - accuracy: 0.1358 - val_loss: -1189438.5000 - val_accuracy: 0.1091\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1169502.7500 - accuracy: 0.1390 - val_loss: -1262736.5000 - val_accuracy: 0.1423\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1240807.5000 - accuracy: 0.1324 - val_loss: -1337754.3750 - val_accuracy: 0.1234\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1314172.1250 - accuracy: 0.1444 - val_loss: -1410708.5000 - val_accuracy: 0.1091\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1388175.0000 - accuracy: 0.1233 - val_loss: -1495805.0000 - val_accuracy: 0.1246\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1467378.0000 - accuracy: 0.1469 - val_loss: -1570483.0000 - val_accuracy: 0.1091\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1546325.1250 - accuracy: 0.1339 - val_loss: -1659729.2500 - val_accuracy: 0.1720\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1629897.3750 - accuracy: 0.1411 - val_loss: -1744539.5000 - val_accuracy: 0.1234\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1717022.1250 - accuracy: 0.1288 - val_loss: -1840424.7500 - val_accuracy: 0.1720\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1809057.6250 - accuracy: 0.1341 - val_loss: -1930402.1250 - val_accuracy: 0.1234\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1894321.0000 - accuracy: 0.1487 - val_loss: -2014857.6250 - val_accuracy: 0.1091\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1983425.7500 - accuracy: 0.1342 - val_loss: -2112613.2500 - val_accuracy: 0.1091\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2079206.2500 - accuracy: 0.1259 - val_loss: -2216731.2500 - val_accuracy: 0.1720\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2166817.5000 - accuracy: 0.1502 - val_loss: -2312290.0000 - val_accuracy: 0.1578\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2270080.5000 - accuracy: 0.1278 - val_loss: -2416415.2500 - val_accuracy: 0.1803\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2370470.5000 - accuracy: 0.1384 - val_loss: -2523400.7500 - val_accuracy: 0.1246\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2482678.5000 - accuracy: 0.1426 - val_loss: -2631405.7500 - val_accuracy: 0.1091\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2594415.2500 - accuracy: 0.1217 - val_loss: -2758430.2500 - val_accuracy: 0.1281\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2712187.2500 - accuracy: 0.1354 - val_loss: -2878663.2500 - val_accuracy: 0.1590\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2826456.5000 - accuracy: 0.1446 - val_loss: -2999238.2500 - val_accuracy: 0.1246\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2952489.2500 - accuracy: 0.1351 - val_loss: -3128275.0000 - val_accuracy: 0.1578\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3073591.7500 - accuracy: 0.1363 - val_loss: -3262286.0000 - val_accuracy: 0.1720\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3198218.0000 - accuracy: 0.1399 - val_loss: -3389861.7500 - val_accuracy: 0.1673\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3329419.7500 - accuracy: 0.1359 - val_loss: -3518088.7500 - val_accuracy: 0.1234\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3460245.5000 - accuracy: 0.1379 - val_loss: -3661937.0000 - val_accuracy: 0.1423\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3589537.2500 - accuracy: 0.1383 - val_loss: -3800178.0000 - val_accuracy: 0.1578\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3727803.0000 - accuracy: 0.1458 - val_loss: -3929027.7500 - val_accuracy: 0.1115\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3871729.0000 - accuracy: 0.1259 - val_loss: -4088534.5000 - val_accuracy: 0.1507\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4018873.5000 - accuracy: 0.1487 - val_loss: -4225597.0000 - val_accuracy: 0.1091\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4170577.0000 - accuracy: 0.1434 - val_loss: -4381147.0000 - val_accuracy: 0.1091\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4323546.0000 - accuracy: 0.1320 - val_loss: -4543241.0000 - val_accuracy: 0.1091\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4478501.5000 - accuracy: 0.1297 - val_loss: -4717849.0000 - val_accuracy: 0.1246\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4640989.0000 - accuracy: 0.1321 - val_loss: -4891108.5000 - val_accuracy: 0.1601\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4806140.5000 - accuracy: 0.1456 - val_loss: -5056863.5000 - val_accuracy: 0.1246\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4980430.0000 - accuracy: 0.1371 - val_loss: -5226130.0000 - val_accuracy: 0.1091\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5157411.5000 - accuracy: 0.1245 - val_loss: -5422308.0000 - val_accuracy: 0.1720\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5337518.0000 - accuracy: 0.1392 - val_loss: -5603067.0000 - val_accuracy: 0.1744\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5502108.0000 - accuracy: 0.1401 - val_loss: -5780260.5000 - val_accuracy: 0.1246\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5686044.0000 - accuracy: 0.1293 - val_loss: -5960963.5000 - val_accuracy: 0.1578\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5867375.5000 - accuracy: 0.1152 - val_loss: -6135450.5000 - val_accuracy: 0.1578\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6051547.0000 - accuracy: 0.1239 - val_loss: -6326565.5000 - val_accuracy: 0.1744\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6234428.5000 - accuracy: 0.1540 - val_loss: -6510048.5000 - val_accuracy: 0.1091\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6430659.5000 - accuracy: 0.1303 - val_loss: -6730888.0000 - val_accuracy: 0.1601\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6631498.0000 - accuracy: 0.1419 - val_loss: -6920613.0000 - val_accuracy: 0.1091\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6829789.0000 - accuracy: 0.1293 - val_loss: -7156142.0000 - val_accuracy: 0.1423\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7042642.5000 - accuracy: 0.1346 - val_loss: -7357759.5000 - val_accuracy: 0.1115\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7262757.5000 - accuracy: 0.1284 - val_loss: -7592272.5000 - val_accuracy: 0.1744\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7480524.5000 - accuracy: 0.1394 - val_loss: -7818007.0000 - val_accuracy: 0.1246\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7713249.5000 - accuracy: 0.1342 - val_loss: -8037364.5000 - val_accuracy: 0.1091\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7918963.0000 - accuracy: 0.1151 - val_loss: -8266529.5000 - val_accuracy: 0.1257\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8154988.5000 - accuracy: 0.1390 - val_loss: -8495081.0000 - val_accuracy: 0.1246\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8361843.5000 - accuracy: 0.1514 - val_loss: -8719894.0000 - val_accuracy: 0.1756\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8594830.0000 - accuracy: 0.1408 - val_loss: -8960802.0000 - val_accuracy: 0.1257\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8839660.0000 - accuracy: 0.1242 - val_loss: -9213663.0000 - val_accuracy: 0.1234\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9070770.0000 - accuracy: 0.1291 - val_loss: -9455188.0000 - val_accuracy: 0.1329\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9304995.0000 - accuracy: 0.1399 - val_loss: -9698872.0000 - val_accuracy: 0.1601\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9551184.0000 - accuracy: 0.1321 - val_loss: -9963281.0000 - val_accuracy: 0.1696\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9801826.0000 - accuracy: 0.1337 - val_loss: -10230531.0000 - val_accuracy: 0.1732\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10063947.0000 - accuracy: 0.1461 - val_loss: -10464413.0000 - val_accuracy: 0.1091\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.69      0.04      0.08       263\n","           1       0.10      0.99      0.18        82\n","           2       0.00      0.00      0.00       163\n","           3       0.00      0.00      0.00       214\n","           4       0.00      0.00      0.00       121\n","\n","    accuracy                           0.11       843\n","   macro avg       0.16      0.21      0.05       843\n","weighted avg       0.22      0.11      0.04       843\n","\n","Accuracy: 0.10913404507710557\n","[[ 11 252   0   0   0]\n"," [  1  81   0   0   0]\n"," [  0 163   0   0   0]\n"," [  4 210   0   0   0]\n"," [  0 121   0   0   0]]\n","Precision: 0.2240\n","Recall: 0.1091\n","F1 Score: 0.0419\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://82e5b4f7-130b-4402-8a66-7dae7073d0e3/assets\n","model 4 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 4ms/step - loss: -175.5787 - accuracy: 0.1503 - val_loss: -665.0745 - val_accuracy: 0.1815\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1312.9534 - accuracy: 0.1606 - val_loss: -1869.5239 - val_accuracy: 0.1032\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3220.6890 - accuracy: 0.1602 - val_loss: -3913.9641 - val_accuracy: 0.1032\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5969.9565 - accuracy: 0.1678 - val_loss: -7118.5420 - val_accuracy: 0.1874\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9760.2764 - accuracy: 0.1661 - val_loss: -10878.5264 - val_accuracy: 0.2028\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14378.2646 - accuracy: 0.1465 - val_loss: -15350.1875 - val_accuracy: 0.1981\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -20088.8848 - accuracy: 0.1533 - val_loss: -20612.2090 - val_accuracy: 0.2076\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -27063.1367 - accuracy: 0.1516 - val_loss: -28375.0430 - val_accuracy: 0.2017\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -35885.6719 - accuracy: 0.1430 - val_loss: -35894.6562 - val_accuracy: 0.2028\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -46522.2734 - accuracy: 0.1429 - val_loss: -49024.9727 - val_accuracy: 0.0996\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -60378.9102 - accuracy: 0.1375 - val_loss: -61634.3203 - val_accuracy: 0.1957\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -75109.5938 - accuracy: 0.1461 - val_loss: -75776.7344 - val_accuracy: 0.1934\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -91768.4688 - accuracy: 0.1487 - val_loss: -92424.8438 - val_accuracy: 0.1139\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -109799.5781 - accuracy: 0.1535 - val_loss: -108541.4844 - val_accuracy: 0.1969\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -129447.6641 - accuracy: 0.1599 - val_loss: -126062.5859 - val_accuracy: 0.2017\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -151667.8438 - accuracy: 0.1577 - val_loss: -150392.4531 - val_accuracy: 0.1163\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -175602.9375 - accuracy: 0.1556 - val_loss: -174730.0938 - val_accuracy: 0.1008\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -202000.0000 - accuracy: 0.1390 - val_loss: -194153.2188 - val_accuracy: 0.2028\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -230846.2656 - accuracy: 0.1510 - val_loss: -225103.9375 - val_accuracy: 0.1969\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -261575.3594 - accuracy: 0.1386 - val_loss: -259003.4375 - val_accuracy: 0.1198\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -294972.2188 - accuracy: 0.1339 - val_loss: -290805.5312 - val_accuracy: 0.1803\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -330417.8750 - accuracy: 0.1420 - val_loss: -324419.5312 - val_accuracy: 0.1886\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -368591.0000 - accuracy: 0.1249 - val_loss: -352638.2812 - val_accuracy: 0.2052\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -408552.6562 - accuracy: 0.1473 - val_loss: -403537.3438 - val_accuracy: 0.1744\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -450943.8438 - accuracy: 0.1416 - val_loss: -442031.7188 - val_accuracy: 0.1969\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -496765.1250 - accuracy: 0.1368 - val_loss: -491061.2188 - val_accuracy: 0.1364\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -542539.4375 - accuracy: 0.1515 - val_loss: -529426.2500 - val_accuracy: 0.1969\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -592288.4375 - accuracy: 0.1548 - val_loss: -585479.1875 - val_accuracy: 0.1163\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -644669.2500 - accuracy: 0.1370 - val_loss: -630105.0625 - val_accuracy: 0.1969\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -699998.1250 - accuracy: 0.1550 - val_loss: -687719.9375 - val_accuracy: 0.1969\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -759485.0000 - accuracy: 0.1566 - val_loss: -752634.8125 - val_accuracy: 0.1091\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -820637.0000 - accuracy: 0.1470 - val_loss: -813660.6875 - val_accuracy: 0.1103\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -885832.5625 - accuracy: 0.1502 - val_loss: -876263.5625 - val_accuracy: 0.1127\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -950784.7500 - accuracy: 0.1507 - val_loss: -934926.8750 - val_accuracy: 0.1803\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1018421.3125 - accuracy: 0.1471 - val_loss: -1005059.5000 - val_accuracy: 0.1352\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1089723.1250 - accuracy: 0.1191 - val_loss: -1076327.1250 - val_accuracy: 0.1329\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1166376.8750 - accuracy: 0.1499 - val_loss: -1144587.7500 - val_accuracy: 0.1791\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1243688.1250 - accuracy: 0.1432 - val_loss: -1222674.6250 - val_accuracy: 0.1352\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1324957.1250 - accuracy: 0.1523 - val_loss: -1304623.8750 - val_accuracy: 0.1269\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1404974.5000 - accuracy: 0.1144 - val_loss: -1365998.1250 - val_accuracy: 0.1969\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1496115.3750 - accuracy: 0.1457 - val_loss: -1453838.8750 - val_accuracy: 0.1934\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1585465.6250 - accuracy: 0.1568 - val_loss: -1554540.0000 - val_accuracy: 0.1139\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1676654.1250 - accuracy: 0.1394 - val_loss: -1635654.1250 - val_accuracy: 0.1791\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1774820.0000 - accuracy: 0.1467 - val_loss: -1732917.7500 - val_accuracy: 0.1756\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1876766.0000 - accuracy: 0.1458 - val_loss: -1838536.0000 - val_accuracy: 0.1364\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1983331.6250 - accuracy: 0.1328 - val_loss: -1927630.2500 - val_accuracy: 0.1957\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2094252.3750 - accuracy: 0.1440 - val_loss: -2048307.0000 - val_accuracy: 0.1364\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2212052.5000 - accuracy: 0.1552 - val_loss: -2167570.7500 - val_accuracy: 0.1139\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2330590.2500 - accuracy: 0.1314 - val_loss: -2266961.2500 - val_accuracy: 0.1803\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2451767.7500 - accuracy: 0.1619 - val_loss: -2403251.5000 - val_accuracy: 0.1139\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2581951.0000 - accuracy: 0.1332 - val_loss: -2522034.2500 - val_accuracy: 0.1364\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2713513.7500 - accuracy: 0.1411 - val_loss: -2652470.2500 - val_accuracy: 0.1364\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2850557.0000 - accuracy: 0.1358 - val_loss: -2767547.7500 - val_accuracy: 0.1862\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2990385.7500 - accuracy: 0.1445 - val_loss: -2926319.5000 - val_accuracy: 0.1139\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3135538.0000 - accuracy: 0.1411 - val_loss: -3045962.5000 - val_accuracy: 0.1803\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3284696.2500 - accuracy: 0.1442 - val_loss: -3206160.5000 - val_accuracy: 0.1364\n","Epoch 57/100\n","238/238 [==============================] - 1s 4ms/step - loss: -3439396.5000 - accuracy: 0.1260 - val_loss: -3332181.7500 - val_accuracy: 0.1981\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3589468.2500 - accuracy: 0.1510 - val_loss: -3498219.0000 - val_accuracy: 0.1720\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3758180.7500 - accuracy: 0.1320 - val_loss: -3666786.5000 - val_accuracy: 0.1578\n","Epoch 60/100\n","238/238 [==============================] - 1s 4ms/step - loss: -3925722.5000 - accuracy: 0.1477 - val_loss: -3848417.0000 - val_accuracy: 0.1139\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4100328.5000 - accuracy: 0.1307 - val_loss: -4006938.5000 - val_accuracy: 0.1364\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4279925.0000 - accuracy: 0.1384 - val_loss: -4184054.0000 - val_accuracy: 0.1364\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4465181.5000 - accuracy: 0.1434 - val_loss: -4378314.5000 - val_accuracy: 0.1139\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4653231.0000 - accuracy: 0.1251 - val_loss: -4553650.5000 - val_accuracy: 0.1352\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4857148.0000 - accuracy: 0.1376 - val_loss: -4714972.0000 - val_accuracy: 0.1803\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5053962.5000 - accuracy: 0.1328 - val_loss: -4930443.5000 - val_accuracy: 0.1352\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5247413.0000 - accuracy: 0.1351 - val_loss: -5121361.0000 - val_accuracy: 0.1376\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5447818.0000 - accuracy: 0.1400 - val_loss: -5302481.5000 - val_accuracy: 0.1767\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5653321.5000 - accuracy: 0.1345 - val_loss: -5521871.0000 - val_accuracy: 0.1542\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5868339.0000 - accuracy: 0.1358 - val_loss: -5695386.5000 - val_accuracy: 0.1945\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6090606.5000 - accuracy: 0.1337 - val_loss: -5914603.5000 - val_accuracy: 0.1898\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6320431.0000 - accuracy: 0.1452 - val_loss: -6184551.5000 - val_accuracy: 0.1174\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6553687.5000 - accuracy: 0.1394 - val_loss: -6403729.0000 - val_accuracy: 0.1364\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6786488.0000 - accuracy: 0.1275 - val_loss: -6615781.0000 - val_accuracy: 0.1720\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7029557.5000 - accuracy: 0.1421 - val_loss: -6876258.0000 - val_accuracy: 0.1352\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7274859.5000 - accuracy: 0.1345 - val_loss: -7117580.0000 - val_accuracy: 0.1364\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7530283.5000 - accuracy: 0.1279 - val_loss: -7301924.0000 - val_accuracy: 0.1993\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7786529.0000 - accuracy: 0.1433 - val_loss: -7602012.5000 - val_accuracy: 0.1720\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8056664.5000 - accuracy: 0.1358 - val_loss: -7881450.5000 - val_accuracy: 0.1364\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8331854.0000 - accuracy: 0.1438 - val_loss: -8146240.0000 - val_accuracy: 0.1364\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8613046.0000 - accuracy: 0.1457 - val_loss: -8431332.0000 - val_accuracy: 0.1139\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8897452.0000 - accuracy: 0.1363 - val_loss: -8705327.0000 - val_accuracy: 0.1139\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9187941.0000 - accuracy: 0.1287 - val_loss: -8966819.0000 - val_accuracy: 0.1364\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9481432.0000 - accuracy: 0.1380 - val_loss: -9290105.0000 - val_accuracy: 0.1139\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9788571.0000 - accuracy: 0.1271 - val_loss: -9505418.0000 - val_accuracy: 0.1839\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10097804.0000 - accuracy: 0.1415 - val_loss: -9889636.0000 - val_accuracy: 0.1139\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10412866.0000 - accuracy: 0.1292 - val_loss: -10166305.0000 - val_accuracy: 0.1364\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10736030.0000 - accuracy: 0.1355 - val_loss: -10473643.0000 - val_accuracy: 0.1554\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11063217.0000 - accuracy: 0.1382 - val_loss: -10809391.0000 - val_accuracy: 0.1364\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11394465.0000 - accuracy: 0.1416 - val_loss: -11154183.0000 - val_accuracy: 0.1139\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11730847.0000 - accuracy: 0.1386 - val_loss: -11487558.0000 - val_accuracy: 0.1139\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12076520.0000 - accuracy: 0.1328 - val_loss: -11827615.0000 - val_accuracy: 0.1139\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12428950.0000 - accuracy: 0.1332 - val_loss: -12154599.0000 - val_accuracy: 0.1364\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12800105.0000 - accuracy: 0.1433 - val_loss: -12537198.0000 - val_accuracy: 0.1139\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13171730.0000 - accuracy: 0.1191 - val_loss: -12746484.0000 - val_accuracy: 0.1993\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13542280.0000 - accuracy: 0.1517 - val_loss: -13252199.0000 - val_accuracy: 0.1151\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13934070.0000 - accuracy: 0.1366 - val_loss: -13641252.0000 - val_accuracy: 0.1151\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14318270.0000 - accuracy: 0.1312 - val_loss: -14002368.0000 - val_accuracy: 0.1364\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14721236.0000 - accuracy: 0.1217 - val_loss: -14235676.0000 - val_accuracy: 0.1993\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -15124993.0000 - accuracy: 0.1537 - val_loss: -14802229.0000 - val_accuracy: 0.1151\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.05      0.10       282\n","           1       0.10      0.99      0.18        83\n","           2       0.00      0.00      0.00       148\n","           3       0.00      0.00      0.00       192\n","           4       0.00      0.00      0.00       138\n","\n","    accuracy                           0.12       843\n","   macro avg       0.17      0.21      0.06       843\n","weighted avg       0.26      0.12      0.05       843\n","\n","Accuracy: 0.11506524317912219\n","[[ 15 267   0   0   0]\n"," [  1  82   0   0   0]\n"," [  0 148   0   0   0]\n"," [  4 188   0   0   0]\n"," [  0 138   0   0   0]]\n","Precision: 0.2607\n","Recall: 0.1151\n","F1 Score: 0.0511\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://fc32f210-7a6c-428d-821a-24547aa28437/assets\n","model 5 saved\n","Epoch 1/100\n","238/238 [==============================] - 2s 4ms/step - loss: -36.2872 - accuracy: 0.1392 - val_loss: -417.5096 - val_accuracy: 0.1103\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -719.6921 - accuracy: 0.1314 - val_loss: -1148.1742 - val_accuracy: 0.1756\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1622.3390 - accuracy: 0.1446 - val_loss: -2360.5293 - val_accuracy: 0.1115\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3244.2068 - accuracy: 0.1329 - val_loss: -4480.1265 - val_accuracy: 0.1127\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5640.5093 - accuracy: 0.1171 - val_loss: -7228.7344 - val_accuracy: 0.1174\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8889.9561 - accuracy: 0.1245 - val_loss: -11010.0283 - val_accuracy: 0.1115\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12992.5449 - accuracy: 0.1237 - val_loss: -15903.3135 - val_accuracy: 0.1815\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -18252.2734 - accuracy: 0.1271 - val_loss: -21608.4336 - val_accuracy: 0.1127\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -24384.2695 - accuracy: 0.1268 - val_loss: -28701.0977 - val_accuracy: 0.1791\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -31653.9922 - accuracy: 0.1329 - val_loss: -36612.8984 - val_accuracy: 0.1791\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -38961.6719 - accuracy: 0.1416 - val_loss: -43953.2305 - val_accuracy: 0.1815\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -47470.1641 - accuracy: 0.1490 - val_loss: -53176.5703 - val_accuracy: 0.1803\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -57373.2969 - accuracy: 0.1483 - val_loss: -63444.5586 - val_accuracy: 0.1791\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -67104.6016 - accuracy: 0.1514 - val_loss: -74130.2344 - val_accuracy: 0.1803\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -78750.0312 - accuracy: 0.1549 - val_loss: -86006.3516 - val_accuracy: 0.1127\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -90684.1562 - accuracy: 0.1500 - val_loss: -99687.2969 - val_accuracy: 0.1732\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -104589.6094 - accuracy: 0.1357 - val_loss: -114611.1250 - val_accuracy: 0.1151\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -119841.1953 - accuracy: 0.1488 - val_loss: -130785.0234 - val_accuracy: 0.1151\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -136408.7031 - accuracy: 0.1303 - val_loss: -149559.6094 - val_accuracy: 0.1791\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -155077.3438 - accuracy: 0.1466 - val_loss: -170057.9688 - val_accuracy: 0.1791\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -175586.6562 - accuracy: 0.1536 - val_loss: -191109.7188 - val_accuracy: 0.1151\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -197645.0156 - accuracy: 0.1413 - val_loss: -216087.2812 - val_accuracy: 0.1293\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -221678.1094 - accuracy: 0.1434 - val_loss: -241729.9219 - val_accuracy: 0.1803\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -247189.2344 - accuracy: 0.1445 - val_loss: -268424.9688 - val_accuracy: 0.1151\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -275254.1562 - accuracy: 0.1262 - val_loss: -299624.7812 - val_accuracy: 0.1756\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -304602.2188 - accuracy: 0.1446 - val_loss: -329685.9062 - val_accuracy: 0.1163\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -335921.3438 - accuracy: 0.1458 - val_loss: -363663.0000 - val_accuracy: 0.1163\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -369418.5625 - accuracy: 0.1317 - val_loss: -400249.0625 - val_accuracy: 0.1803\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -403738.6250 - accuracy: 0.1426 - val_loss: -435362.9375 - val_accuracy: 0.1151\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -441165.0000 - accuracy: 0.1266 - val_loss: -476272.9688 - val_accuracy: 0.1163\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -479248.5625 - accuracy: 0.1424 - val_loss: -515293.5625 - val_accuracy: 0.1163\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -519786.6875 - accuracy: 0.1330 - val_loss: -560074.3750 - val_accuracy: 0.1779\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -562820.2500 - accuracy: 0.1452 - val_loss: -604818.5000 - val_accuracy: 0.1163\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -607240.3750 - accuracy: 0.1339 - val_loss: -654872.5000 - val_accuracy: 0.1293\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -654492.3750 - accuracy: 0.1300 - val_loss: -705525.6875 - val_accuracy: 0.1803\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -703462.1250 - accuracy: 0.1465 - val_loss: -757469.1250 - val_accuracy: 0.1163\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -755830.3750 - accuracy: 0.1316 - val_loss: -813399.1250 - val_accuracy: 0.1803\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -809186.2500 - accuracy: 0.1379 - val_loss: -868620.7500 - val_accuracy: 0.1163\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -866987.5625 - accuracy: 0.1189 - val_loss: -932077.1250 - val_accuracy: 0.1803\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -925486.5625 - accuracy: 0.1415 - val_loss: -994201.8750 - val_accuracy: 0.1293\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -986613.8750 - accuracy: 0.1456 - val_loss: -1058415.5000 - val_accuracy: 0.1163\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1051074.5000 - accuracy: 0.1187 - val_loss: -1127552.5000 - val_accuracy: 0.1281\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1118895.0000 - accuracy: 0.1363 - val_loss: -1194769.7500 - val_accuracy: 0.1163\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1185705.7500 - accuracy: 0.1332 - val_loss: -1269787.0000 - val_accuracy: 0.1163\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1258462.1250 - accuracy: 0.1291 - val_loss: -1348618.7500 - val_accuracy: 0.1815\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1336170.5000 - accuracy: 0.1619 - val_loss: -1409612.5000 - val_accuracy: 0.1151\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1405462.3750 - accuracy: 0.1258 - val_loss: -1503470.8750 - val_accuracy: 0.1174\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1481889.2500 - accuracy: 0.1333 - val_loss: -1584641.6250 - val_accuracy: 0.1163\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1563340.2500 - accuracy: 0.1266 - val_loss: -1670930.1250 - val_accuracy: 0.1293\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1645286.3750 - accuracy: 0.1288 - val_loss: -1756485.2500 - val_accuracy: 0.1163\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1732133.2500 - accuracy: 0.1274 - val_loss: -1849931.8750 - val_accuracy: 0.1198\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1820892.3750 - accuracy: 0.1241 - val_loss: -1948730.7500 - val_accuracy: 0.1293\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1917137.8750 - accuracy: 0.1288 - val_loss: -2048158.1250 - val_accuracy: 0.1163\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2013039.1250 - accuracy: 0.1368 - val_loss: -2143378.2500 - val_accuracy: 0.1163\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2109942.5000 - accuracy: 0.1164 - val_loss: -2256379.2500 - val_accuracy: 0.1163\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2219208.0000 - accuracy: 0.1198 - val_loss: -2371185.5000 - val_accuracy: 0.1827\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2320333.7500 - accuracy: 0.1424 - val_loss: -2482352.5000 - val_accuracy: 0.1756\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2430105.7500 - accuracy: 0.1392 - val_loss: -2595451.0000 - val_accuracy: 0.1815\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2540653.0000 - accuracy: 0.1305 - val_loss: -2711375.0000 - val_accuracy: 0.1495\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2654164.5000 - accuracy: 0.1498 - val_loss: -2816928.0000 - val_accuracy: 0.1163\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2769251.2500 - accuracy: 0.1442 - val_loss: -2923925.0000 - val_accuracy: 0.1163\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2883885.7500 - accuracy: 0.1085 - val_loss: -3078641.7500 - val_accuracy: 0.1234\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3009175.2500 - accuracy: 0.1358 - val_loss: -3207808.2500 - val_accuracy: 0.1163\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3135289.2500 - accuracy: 0.1184 - val_loss: -3340364.5000 - val_accuracy: 0.1163\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3267782.0000 - accuracy: 0.1259 - val_loss: -3479950.5000 - val_accuracy: 0.1163\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3405717.0000 - accuracy: 0.1109 - val_loss: -3631181.5000 - val_accuracy: 0.1601\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3541790.2500 - accuracy: 0.1368 - val_loss: -3776402.0000 - val_accuracy: 0.1293\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3685935.0000 - accuracy: 0.1459 - val_loss: -3916805.2500 - val_accuracy: 0.1163\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3835479.0000 - accuracy: 0.1266 - val_loss: -4088353.5000 - val_accuracy: 0.1744\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3971156.0000 - accuracy: 0.1512 - val_loss: -4221621.0000 - val_accuracy: 0.1163\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4117942.7500 - accuracy: 0.1136 - val_loss: -4391641.0000 - val_accuracy: 0.1423\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4276178.5000 - accuracy: 0.1453 - val_loss: -4530640.0000 - val_accuracy: 0.1163\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4425468.5000 - accuracy: 0.1214 - val_loss: -4704967.0000 - val_accuracy: 0.1305\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4579802.5000 - accuracy: 0.1359 - val_loss: -4860780.5000 - val_accuracy: 0.1163\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4731551.0000 - accuracy: 0.1202 - val_loss: -5031064.5000 - val_accuracy: 0.1222\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4894335.0000 - accuracy: 0.1169 - val_loss: -5203228.0000 - val_accuracy: 0.1174\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5052352.0000 - accuracy: 0.1249 - val_loss: -5364240.5000 - val_accuracy: 0.1174\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5221545.0000 - accuracy: 0.1299 - val_loss: -5531832.0000 - val_accuracy: 0.1163\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5388392.5000 - accuracy: 0.1150 - val_loss: -5726337.5000 - val_accuracy: 0.1305\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5568325.5000 - accuracy: 0.1287 - val_loss: -5911753.0000 - val_accuracy: 0.1281\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5749075.0000 - accuracy: 0.1281 - val_loss: -6105965.5000 - val_accuracy: 0.1293\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5938870.0000 - accuracy: 0.1243 - val_loss: -6305186.0000 - val_accuracy: 0.1198\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6132944.0000 - accuracy: 0.1291 - val_loss: -6492712.0000 - val_accuracy: 0.1163\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6328464.0000 - accuracy: 0.1234 - val_loss: -6714398.0000 - val_accuracy: 0.1163\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6531057.5000 - accuracy: 0.1254 - val_loss: -6942105.5000 - val_accuracy: 0.1293\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6742088.5000 - accuracy: 0.1183 - val_loss: -7163491.5000 - val_accuracy: 0.1293\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6957484.0000 - accuracy: 0.1284 - val_loss: -7394013.0000 - val_accuracy: 0.1625\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7176734.0000 - accuracy: 0.1284 - val_loss: -7626752.0000 - val_accuracy: 0.1661\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7391732.0000 - accuracy: 0.1370 - val_loss: -7851036.0000 - val_accuracy: 0.1293\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7624406.0000 - accuracy: 0.1291 - val_loss: -8087516.0000 - val_accuracy: 0.1293\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7856699.0000 - accuracy: 0.1249 - val_loss: -8333877.5000 - val_accuracy: 0.1163\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8089925.5000 - accuracy: 0.1235 - val_loss: -8573392.0000 - val_accuracy: 0.1163\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8337171.0000 - accuracy: 0.1317 - val_loss: -8844371.0000 - val_accuracy: 0.1234\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8587138.0000 - accuracy: 0.1183 - val_loss: -9114233.0000 - val_accuracy: 0.1601\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8835771.0000 - accuracy: 0.1268 - val_loss: -9386954.0000 - val_accuracy: 0.1601\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9094059.0000 - accuracy: 0.1310 - val_loss: -9640469.0000 - val_accuracy: 0.1163\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9359998.0000 - accuracy: 0.1249 - val_loss: -9936790.0000 - val_accuracy: 0.1684\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9618800.0000 - accuracy: 0.1242 - val_loss: -10213174.0000 - val_accuracy: 0.1554\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9890586.0000 - accuracy: 0.1400 - val_loss: -10485980.0000 - val_accuracy: 0.1163\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10167886.0000 - accuracy: 0.1129 - val_loss: -10789615.0000 - val_accuracy: 0.1554\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.14      0.23       280\n","           1       0.12      1.00      0.21        93\n","           2       0.00      0.00      0.00       158\n","           3       0.00      0.00      0.00       196\n","           4       0.00      0.00      0.00       116\n","\n","    accuracy                           0.16       843\n","   macro avg       0.20      0.23      0.09       843\n","weighted avg       0.30      0.16      0.10       843\n","\n","Accuracy: 0.1553973902728351\n","[[ 38 242   0   0   0]\n"," [  0  93   0   0   0]\n"," [  0 158   0   0   0]\n"," [  6 190   0   0   0]\n"," [  0 116   0   0   0]]\n","Precision: 0.2997\n","Recall: 0.1554\n","F1 Score: 0.1009\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://395166ac-a0ff-44aa-92c5-074f391639b9/assets\n","model 6 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: -68.0221 - accuracy: 0.1557 - val_loss: -418.6419 - val_accuracy: 0.1103\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -672.5538 - accuracy: 0.1503 - val_loss: -1071.8026 - val_accuracy: 0.1103\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1537.2386 - accuracy: 0.1463 - val_loss: -2156.7373 - val_accuracy: 0.1103\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2947.1536 - accuracy: 0.1388 - val_loss: -3892.3298 - val_accuracy: 0.1779\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5119.9009 - accuracy: 0.1280 - val_loss: -6350.9360 - val_accuracy: 0.1079\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8196.1699 - accuracy: 0.1345 - val_loss: -9821.2490 - val_accuracy: 0.1103\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12192.5947 - accuracy: 0.1317 - val_loss: -14207.9268 - val_accuracy: 0.1115\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -17060.4492 - accuracy: 0.1291 - val_loss: -19413.6270 - val_accuracy: 0.1198\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -23019.8105 - accuracy: 0.1266 - val_loss: -26023.2695 - val_accuracy: 0.1340\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -30037.6055 - accuracy: 0.1379 - val_loss: -33777.7227 - val_accuracy: 0.1851\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -38220.1172 - accuracy: 0.1254 - val_loss: -42493.1562 - val_accuracy: 0.1649\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -47220.8438 - accuracy: 0.1343 - val_loss: -52071.3516 - val_accuracy: 0.1163\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -57640.8438 - accuracy: 0.1212 - val_loss: -63506.6250 - val_accuracy: 0.1163\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -69363.0312 - accuracy: 0.1249 - val_loss: -75960.3594 - val_accuracy: 0.1151\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -82305.0938 - accuracy: 0.1155 - val_loss: -90845.0703 - val_accuracy: 0.1174\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -96740.0391 - accuracy: 0.1220 - val_loss: -111094.9219 - val_accuracy: 0.1174\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -119132.2969 - accuracy: 0.1130 - val_loss: -137874.7812 - val_accuracy: 0.1079\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -144310.9531 - accuracy: 0.1218 - val_loss: -165405.4219 - val_accuracy: 0.1103\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -171023.8438 - accuracy: 0.1071 - val_loss: -197027.9062 - val_accuracy: 0.1186\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -198507.6250 - accuracy: 0.1192 - val_loss: -227569.3438 - val_accuracy: 0.1400\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -228139.5938 - accuracy: 0.1129 - val_loss: -258404.4219 - val_accuracy: 0.1151\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -258961.7500 - accuracy: 0.1103 - val_loss: -293458.9688 - val_accuracy: 0.1163\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -291229.2188 - accuracy: 0.1086 - val_loss: -327817.0625 - val_accuracy: 0.1151\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -325728.5312 - accuracy: 0.1147 - val_loss: -368619.1562 - val_accuracy: 0.1163\n","Epoch 25/100\n","238/238 [==============================] - 1s 4ms/step - loss: -362600.8438 - accuracy: 0.1107 - val_loss: -408767.8750 - val_accuracy: 0.1851\n","Epoch 26/100\n","238/238 [==============================] - 1s 4ms/step - loss: -398303.5312 - accuracy: 0.1206 - val_loss: -447829.0625 - val_accuracy: 0.1163\n","Epoch 27/100\n","238/238 [==============================] - 1s 4ms/step - loss: -440253.5000 - accuracy: 0.1167 - val_loss: -495757.6562 - val_accuracy: 0.1305\n","Epoch 28/100\n","238/238 [==============================] - 1s 4ms/step - loss: -482129.9688 - accuracy: 0.1229 - val_loss: -541077.6875 - val_accuracy: 0.1163\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -526178.6875 - accuracy: 0.1097 - val_loss: -590424.1875 - val_accuracy: 0.1163\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -573977.8750 - accuracy: 0.1176 - val_loss: -642731.5000 - val_accuracy: 0.1163\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -623955.6875 - accuracy: 0.1179 - val_loss: -700028.0625 - val_accuracy: 0.1163\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -677645.8750 - accuracy: 0.1118 - val_loss: -760103.1250 - val_accuracy: 0.1767\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -733399.3750 - accuracy: 0.1188 - val_loss: -820642.4375 - val_accuracy: 0.1163\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -792709.3125 - accuracy: 0.1299 - val_loss: -881376.5000 - val_accuracy: 0.1151\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -855342.1875 - accuracy: 0.1090 - val_loss: -959902.4375 - val_accuracy: 0.1163\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -921494.4375 - accuracy: 0.1220 - val_loss: -1030127.3125 - val_accuracy: 0.1163\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -989808.5000 - accuracy: 0.1342 - val_loss: -1095056.0000 - val_accuracy: 0.1139\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1060758.8750 - accuracy: 0.1086 - val_loss: -1184066.0000 - val_accuracy: 0.1317\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1136596.6250 - accuracy: 0.1135 - val_loss: -1272405.7500 - val_accuracy: 0.1673\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1215185.3750 - accuracy: 0.1205 - val_loss: -1353999.1250 - val_accuracy: 0.1163\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1298888.8750 - accuracy: 0.1225 - val_loss: -1451597.5000 - val_accuracy: 0.1163\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1382191.3750 - accuracy: 0.1073 - val_loss: -1542310.1250 - val_accuracy: 0.1163\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1476183.6250 - accuracy: 0.1123 - val_loss: -1645919.5000 - val_accuracy: 0.1554\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1562983.6250 - accuracy: 0.1453 - val_loss: -1738742.1250 - val_accuracy: 0.1163\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1659252.5000 - accuracy: 0.1139 - val_loss: -1845680.8750 - val_accuracy: 0.1163\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1759175.1250 - accuracy: 0.1118 - val_loss: -1960074.6250 - val_accuracy: 0.1163\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1863807.5000 - accuracy: 0.1321 - val_loss: -2063759.7500 - val_accuracy: 0.1163\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1968116.7500 - accuracy: 0.1113 - val_loss: -2199547.2500 - val_accuracy: 0.1293\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2080508.3750 - accuracy: 0.1176 - val_loss: -2321664.0000 - val_accuracy: 0.1530\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2194217.7500 - accuracy: 0.1239 - val_loss: -2453108.5000 - val_accuracy: 0.1352\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2312940.7500 - accuracy: 0.1246 - val_loss: -2581708.2500 - val_accuracy: 0.1317\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2440355.0000 - accuracy: 0.1270 - val_loss: -2731582.2500 - val_accuracy: 0.1862\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2564480.7500 - accuracy: 0.1578 - val_loss: -2846139.2500 - val_accuracy: 0.1163\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2697942.0000 - accuracy: 0.1264 - val_loss: -3014561.2500 - val_accuracy: 0.1174\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2835037.2500 - accuracy: 0.1237 - val_loss: -3168268.7500 - val_accuracy: 0.1329\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2977770.5000 - accuracy: 0.1321 - val_loss: -3305090.5000 - val_accuracy: 0.1163\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3117804.0000 - accuracy: 0.1164 - val_loss: -3485655.0000 - val_accuracy: 0.1412\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3268837.2500 - accuracy: 0.1337 - val_loss: -3641755.7500 - val_accuracy: 0.1163\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3421337.0000 - accuracy: 0.1218 - val_loss: -3834443.0000 - val_accuracy: 0.1756\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3582026.5000 - accuracy: 0.1291 - val_loss: -4006874.0000 - val_accuracy: 0.1340\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3753461.0000 - accuracy: 0.1206 - val_loss: -4198670.0000 - val_accuracy: 0.1412\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3923798.5000 - accuracy: 0.1212 - val_loss: -4394995.0000 - val_accuracy: 0.1708\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4108632.2500 - accuracy: 0.1379 - val_loss: -4575116.0000 - val_accuracy: 0.1174\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4287673.5000 - accuracy: 0.1338 - val_loss: -4773965.0000 - val_accuracy: 0.1174\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4479917.0000 - accuracy: 0.1188 - val_loss: -5013061.0000 - val_accuracy: 0.1649\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4676813.0000 - accuracy: 0.1258 - val_loss: -5231757.5000 - val_accuracy: 0.1340\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4886312.5000 - accuracy: 0.1281 - val_loss: -5472769.0000 - val_accuracy: 0.1862\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5089438.0000 - accuracy: 0.1312 - val_loss: -5700694.0000 - val_accuracy: 0.1364\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5307713.5000 - accuracy: 0.1262 - val_loss: -5943462.0000 - val_accuracy: 0.1661\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5532394.0000 - accuracy: 0.1450 - val_loss: -6159154.0000 - val_accuracy: 0.1174\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5750540.5000 - accuracy: 0.1266 - val_loss: -6442232.5000 - val_accuracy: 0.1542\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5970276.5000 - accuracy: 0.1361 - val_loss: -6622334.5000 - val_accuracy: 0.1210\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6109012.0000 - accuracy: 0.1162 - val_loss: -6792481.0000 - val_accuracy: 0.1423\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6275749.0000 - accuracy: 0.1343 - val_loss: -6976931.0000 - val_accuracy: 0.1412\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6437502.0000 - accuracy: 0.1312 - val_loss: -7174607.5000 - val_accuracy: 0.1779\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6613939.5000 - accuracy: 0.1492 - val_loss: -7339411.5000 - val_accuracy: 0.1174\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6796837.5000 - accuracy: 0.1189 - val_loss: -7602741.5000 - val_accuracy: 0.1661\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7002153.0000 - accuracy: 0.1387 - val_loss: -7831812.5000 - val_accuracy: 0.1340\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7223533.5000 - accuracy: 0.1263 - val_loss: -8078355.0000 - val_accuracy: 0.1554\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7444533.5000 - accuracy: 0.1370 - val_loss: -8316068.5000 - val_accuracy: 0.1174\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7678204.5000 - accuracy: 0.1270 - val_loss: -8614472.0000 - val_accuracy: 0.1779\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7921290.0000 - accuracy: 0.1372 - val_loss: -8894327.0000 - val_accuracy: 0.1542\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8178906.0000 - accuracy: 0.1500 - val_loss: -9173670.0000 - val_accuracy: 0.1186\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8454733.0000 - accuracy: 0.1297 - val_loss: -9500990.0000 - val_accuracy: 0.1495\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8736403.0000 - accuracy: 0.1354 - val_loss: -9822153.0000 - val_accuracy: 0.1340\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9044611.0000 - accuracy: 0.1444 - val_loss: -10071472.0000 - val_accuracy: 0.1151\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9336924.0000 - accuracy: 0.1208 - val_loss: -10490631.0000 - val_accuracy: 0.1186\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9662553.0000 - accuracy: 0.1250 - val_loss: -10883297.0000 - val_accuracy: 0.1340\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9996294.0000 - accuracy: 0.1242 - val_loss: -11250247.0000 - val_accuracy: 0.1352\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10332852.0000 - accuracy: 0.1397 - val_loss: -11607301.0000 - val_accuracy: 0.1174\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10679321.0000 - accuracy: 0.1220 - val_loss: -12027408.0000 - val_accuracy: 0.1507\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11032440.0000 - accuracy: 0.1258 - val_loss: -12411632.0000 - val_accuracy: 0.1186\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11395890.0000 - accuracy: 0.1206 - val_loss: -12834894.0000 - val_accuracy: 0.1352\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11768032.0000 - accuracy: 0.1214 - val_loss: -13234115.0000 - val_accuracy: 0.1352\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12149436.0000 - accuracy: 0.1196 - val_loss: -13681841.0000 - val_accuracy: 0.1839\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12498848.0000 - accuracy: 0.1536 - val_loss: -14078107.0000 - val_accuracy: 0.1174\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12905559.0000 - accuracy: 0.1155 - val_loss: -14536171.0000 - val_accuracy: 0.1708\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13285372.0000 - accuracy: 0.1351 - val_loss: -14970114.0000 - val_accuracy: 0.1340\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13701405.0000 - accuracy: 0.1243 - val_loss: -15421894.0000 - val_accuracy: 0.1779\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14072256.0000 - accuracy: 0.1339 - val_loss: -15841487.0000 - val_accuracy: 0.1423\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.11      0.19       284\n","           1       0.11      0.99      0.20        91\n","           2       0.00      0.00      0.00       165\n","           3       0.00      0.00      0.00       194\n","           4       0.00      0.00      0.00       109\n","\n","    accuracy                           0.14       843\n","   macro avg       0.18      0.22      0.08       843\n","weighted avg       0.29      0.14      0.08       843\n","\n","Accuracy: 0.1423487544483986\n","[[ 30 254   0   0   0]\n"," [  1  90   0   0   0]\n"," [  0 165   0   0   0]\n"," [  6 188   0   0   0]\n"," [  0 109   0   0   0]]\n","Precision: 0.2852\n","Recall: 0.1423\n","F1 Score: 0.0846\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://db77090f-a8d7-436e-9335-fcd7348661e7/assets\n","model 7 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: -398.0439 - accuracy: 0.1391 - val_loss: -516.9250 - val_accuracy: 0.0998\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2063.7585 - accuracy: 0.1302 - val_loss: -2038.1974 - val_accuracy: 0.1698\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4433.9448 - accuracy: 0.1330 - val_loss: -4321.9780 - val_accuracy: 0.1734\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8036.3237 - accuracy: 0.1355 - val_loss: -7472.0444 - val_accuracy: 0.1746\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13340.3359 - accuracy: 0.1246 - val_loss: -11663.1885 - val_accuracy: 0.1045\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -20666.7305 - accuracy: 0.1169 - val_loss: -17494.0527 - val_accuracy: 0.1069\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -29580.1777 - accuracy: 0.1358 - val_loss: -24023.8477 - val_accuracy: 0.1010\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -41220.5312 - accuracy: 0.1152 - val_loss: -33820.4102 - val_accuracy: 0.1081\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -55717.6328 - accuracy: 0.1317 - val_loss: -44158.6094 - val_accuracy: 0.1069\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -72228.8125 - accuracy: 0.1260 - val_loss: -58158.3555 - val_accuracy: 0.1081\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -92314.7500 - accuracy: 0.1205 - val_loss: -73067.1562 - val_accuracy: 0.1081\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -113732.2422 - accuracy: 0.1243 - val_loss: -89623.5234 - val_accuracy: 0.1081\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -138805.6719 - accuracy: 0.1176 - val_loss: -107072.4453 - val_accuracy: 0.1081\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -167137.0469 - accuracy: 0.1136 - val_loss: -127063.3906 - val_accuracy: 0.1081\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -198992.9531 - accuracy: 0.1161 - val_loss: -151060.7812 - val_accuracy: 0.1081\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -234516.7969 - accuracy: 0.1131 - val_loss: -175957.7031 - val_accuracy: 0.1746\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -272517.2188 - accuracy: 0.1210 - val_loss: -204259.0781 - val_accuracy: 0.1081\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -314965.1875 - accuracy: 0.1201 - val_loss: -233951.7969 - val_accuracy: 0.1081\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -361171.0312 - accuracy: 0.1123 - val_loss: -265520.4062 - val_accuracy: 0.1081\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -411273.5938 - accuracy: 0.1157 - val_loss: -303478.4375 - val_accuracy: 0.1081\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -466595.9688 - accuracy: 0.1119 - val_loss: -344314.1875 - val_accuracy: 0.1081\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -525909.6875 - accuracy: 0.1234 - val_loss: -384237.2500 - val_accuracy: 0.1081\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -590254.5625 - accuracy: 0.1230 - val_loss: -422434.6250 - val_accuracy: 0.1081\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -655477.0625 - accuracy: 0.1189 - val_loss: -475356.7188 - val_accuracy: 0.1081\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -726506.1250 - accuracy: 0.1115 - val_loss: -526575.0000 - val_accuracy: 0.1580\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -800954.0000 - accuracy: 0.1200 - val_loss: -577860.9375 - val_accuracy: 0.1081\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -878562.7500 - accuracy: 0.1131 - val_loss: -629605.9375 - val_accuracy: 0.1081\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -961132.8125 - accuracy: 0.1157 - val_loss: -679594.5000 - val_accuracy: 0.1081\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1042548.8125 - accuracy: 0.1109 - val_loss: -747459.1875 - val_accuracy: 0.1081\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1136673.8750 - accuracy: 0.1111 - val_loss: -811727.4375 - val_accuracy: 0.1081\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1234849.1250 - accuracy: 0.1094 - val_loss: -873260.6875 - val_accuracy: 0.1081\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1331602.1250 - accuracy: 0.1122 - val_loss: -942242.7500 - val_accuracy: 0.1081\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1436128.6250 - accuracy: 0.1210 - val_loss: -1023901.7500 - val_accuracy: 0.1081\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1543924.0000 - accuracy: 0.1120 - val_loss: -1099258.8750 - val_accuracy: 0.1081\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1661405.6250 - accuracy: 0.1302 - val_loss: -1167941.0000 - val_accuracy: 0.1081\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1775544.0000 - accuracy: 0.1118 - val_loss: -1265639.1250 - val_accuracy: 0.1093\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1907021.8750 - accuracy: 0.1102 - val_loss: -1351939.7500 - val_accuracy: 0.1081\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2039010.2500 - accuracy: 0.1131 - val_loss: -1443462.2500 - val_accuracy: 0.1081\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2175073.5000 - accuracy: 0.1118 - val_loss: -1538441.8750 - val_accuracy: 0.1152\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2318107.7500 - accuracy: 0.1103 - val_loss: -1641360.1250 - val_accuracy: 0.1081\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2469889.0000 - accuracy: 0.1169 - val_loss: -1747645.1250 - val_accuracy: 0.1140\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2627497.0000 - accuracy: 0.1198 - val_loss: -1837632.5000 - val_accuracy: 0.1081\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2784890.7500 - accuracy: 0.1110 - val_loss: -1957503.3750 - val_accuracy: 0.1081\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2954461.5000 - accuracy: 0.1094 - val_loss: -2076439.3750 - val_accuracy: 0.1081\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3129442.2500 - accuracy: 0.1119 - val_loss: -2202010.5000 - val_accuracy: 0.1081\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3310590.0000 - accuracy: 0.1106 - val_loss: -2326845.5000 - val_accuracy: 0.1081\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3505116.7500 - accuracy: 0.1109 - val_loss: -2463717.0000 - val_accuracy: 0.1140\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3700248.0000 - accuracy: 0.1201 - val_loss: -2572077.2500 - val_accuracy: 0.1081\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3894698.7500 - accuracy: 0.1109 - val_loss: -2731955.5000 - val_accuracy: 0.1081\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4101067.0000 - accuracy: 0.1102 - val_loss: -2872498.2500 - val_accuracy: 0.1081\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4318791.5000 - accuracy: 0.1193 - val_loss: -2998683.0000 - val_accuracy: 0.1081\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4526964.5000 - accuracy: 0.1099 - val_loss: -3170774.7500 - val_accuracy: 0.1081\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4753680.0000 - accuracy: 0.1097 - val_loss: -3331008.2500 - val_accuracy: 0.1093\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4989689.5000 - accuracy: 0.1110 - val_loss: -3490127.0000 - val_accuracy: 0.1093\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5233139.5000 - accuracy: 0.1151 - val_loss: -3627059.5000 - val_accuracy: 0.1081\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5449002.5000 - accuracy: 0.1095 - val_loss: -3797347.5000 - val_accuracy: 0.1081\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5676972.5000 - accuracy: 0.1117 - val_loss: -3946777.7500 - val_accuracy: 0.1081\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5920969.5000 - accuracy: 0.1098 - val_loss: -4119089.0000 - val_accuracy: 0.1081\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6167931.5000 - accuracy: 0.1099 - val_loss: -4291396.5000 - val_accuracy: 0.1140\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6421047.5000 - accuracy: 0.1190 - val_loss: -4468805.5000 - val_accuracy: 0.1081\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6698278.5000 - accuracy: 0.1181 - val_loss: -4644110.0000 - val_accuracy: 0.1081\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6980305.0000 - accuracy: 0.1099 - val_loss: -4837196.5000 - val_accuracy: 0.1093\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7271078.0000 - accuracy: 0.1111 - val_loss: -5034321.0000 - val_accuracy: 0.1081\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7573477.5000 - accuracy: 0.1103 - val_loss: -5254858.5000 - val_accuracy: 0.1081\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7887369.5000 - accuracy: 0.1106 - val_loss: -5473859.5000 - val_accuracy: 0.1093\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8203273.5000 - accuracy: 0.1152 - val_loss: -5664419.5000 - val_accuracy: 0.1081\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8528256.0000 - accuracy: 0.1098 - val_loss: -5926669.5000 - val_accuracy: 0.1093\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8865993.0000 - accuracy: 0.1230 - val_loss: -6119440.0000 - val_accuracy: 0.1081\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9197961.0000 - accuracy: 0.1098 - val_loss: -6366037.5000 - val_accuracy: 0.1093\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9558724.0000 - accuracy: 0.1151 - val_loss: -6607292.0000 - val_accuracy: 0.1081\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9916971.0000 - accuracy: 0.1147 - val_loss: -6850897.5000 - val_accuracy: 0.1081\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10279511.0000 - accuracy: 0.1143 - val_loss: -7096734.0000 - val_accuracy: 0.1081\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10655025.0000 - accuracy: 0.1134 - val_loss: -7358317.5000 - val_accuracy: 0.1093\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11059994.0000 - accuracy: 0.1134 - val_loss: -7614510.0000 - val_accuracy: 0.1081\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11457279.0000 - accuracy: 0.1105 - val_loss: -7914361.5000 - val_accuracy: 0.1140\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11854725.0000 - accuracy: 0.1152 - val_loss: -8195772.5000 - val_accuracy: 0.1116\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12263328.0000 - accuracy: 0.1186 - val_loss: -8486259.0000 - val_accuracy: 0.1140\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12674755.0000 - accuracy: 0.1127 - val_loss: -8768285.0000 - val_accuracy: 0.1093\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13120574.0000 - accuracy: 0.1210 - val_loss: -9037375.0000 - val_accuracy: 0.1081\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13568196.0000 - accuracy: 0.1102 - val_loss: -9383882.0000 - val_accuracy: 0.1140\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14017769.0000 - accuracy: 0.1106 - val_loss: -9685404.0000 - val_accuracy: 0.1140\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14469385.0000 - accuracy: 0.1247 - val_loss: -9994451.0000 - val_accuracy: 0.1128\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14949518.0000 - accuracy: 0.1148 - val_loss: -10220241.0000 - val_accuracy: 0.1081\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -15419323.0000 - accuracy: 0.1107 - val_loss: -10603955.0000 - val_accuracy: 0.1081\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -15905483.0000 - accuracy: 0.1134 - val_loss: -10947657.0000 - val_accuracy: 0.1081\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -16407937.0000 - accuracy: 0.1106 - val_loss: -11313219.0000 - val_accuracy: 0.1093\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -16922974.0000 - accuracy: 0.1109 - val_loss: -11660146.0000 - val_accuracy: 0.1140\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -17442430.0000 - accuracy: 0.1182 - val_loss: -11994688.0000 - val_accuracy: 0.1081\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -17973462.0000 - accuracy: 0.1169 - val_loss: -12340233.0000 - val_accuracy: 0.1081\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -18512332.0000 - accuracy: 0.1146 - val_loss: -12725247.0000 - val_accuracy: 0.1081\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -19070322.0000 - accuracy: 0.1128 - val_loss: -13106782.0000 - val_accuracy: 0.1081\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -19632360.0000 - accuracy: 0.1189 - val_loss: -13481039.0000 - val_accuracy: 0.1081\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -20224176.0000 - accuracy: 0.1099 - val_loss: -13951640.0000 - val_accuracy: 0.1093\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -20818168.0000 - accuracy: 0.1143 - val_loss: -14357146.0000 - val_accuracy: 0.1128\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -21418694.0000 - accuracy: 0.1205 - val_loss: -14714206.0000 - val_accuracy: 0.1081\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -22018964.0000 - accuracy: 0.1130 - val_loss: -15179150.0000 - val_accuracy: 0.1140\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -22649988.0000 - accuracy: 0.1148 - val_loss: -15599076.0000 - val_accuracy: 0.1093\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -23285864.0000 - accuracy: 0.1169 - val_loss: -16018268.0000 - val_accuracy: 0.1093\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -23941668.0000 - accuracy: 0.1322 - val_loss: -16446212.0000 - val_accuracy: 0.1081\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -24586526.0000 - accuracy: 0.1126 - val_loss: -16972230.0000 - val_accuracy: 0.1116\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.69      0.04      0.07       279\n","           1       0.10      0.99      0.18        84\n","           2       0.00      0.00      0.00       163\n","           3       0.00      0.00      0.00       198\n","           4       0.00      0.00      0.00       118\n","\n","    accuracy                           0.11       842\n","   macro avg       0.16      0.21      0.05       842\n","weighted avg       0.24      0.11      0.04       842\n","\n","Accuracy: 0.11163895486935867\n","[[ 11 268   0   0   0]\n"," [  1  83   0   0   0]\n"," [  0 163   0   0   0]\n"," [  4 194   0   0   0]\n"," [  0 118   0   0   0]]\n","Precision: 0.2378\n","Recall: 0.1116\n","F1 Score: 0.0429\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://90d3604a-7c62-489a-af01-5f28770f1d5e/assets\n","model 8 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 4ms/step - loss: -471.2248 - accuracy: 0.1492 - val_loss: -1017.0510 - val_accuracy: 0.0914\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2539.3513 - accuracy: 0.1487 - val_loss: -4277.3184 - val_accuracy: 0.0914\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6425.3013 - accuracy: 0.1413 - val_loss: -8138.4194 - val_accuracy: 0.0914\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11375.5371 - accuracy: 0.1538 - val_loss: -13277.4062 - val_accuracy: 0.1615\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -17586.8398 - accuracy: 0.1559 - val_loss: -19389.5684 - val_accuracy: 0.1627\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -25039.8184 - accuracy: 0.1405 - val_loss: -26315.2559 - val_accuracy: 0.1627\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -34161.0273 - accuracy: 0.1479 - val_loss: -35235.1719 - val_accuracy: 0.0950\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -44923.6055 - accuracy: 0.1410 - val_loss: -44970.8594 - val_accuracy: 0.1639\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -57574.9844 - accuracy: 0.1512 - val_loss: -56923.5000 - val_accuracy: 0.0986\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -72090.2188 - accuracy: 0.1416 - val_loss: -71273.8750 - val_accuracy: 0.1093\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -88796.2109 - accuracy: 0.1314 - val_loss: -85815.1719 - val_accuracy: 0.0962\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -106899.1406 - accuracy: 0.1360 - val_loss: -103205.6250 - val_accuracy: 0.0986\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -128062.9844 - accuracy: 0.1350 - val_loss: -122481.0547 - val_accuracy: 0.0962\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -151317.7969 - accuracy: 0.1404 - val_loss: -142367.5781 - val_accuracy: 0.1651\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -175977.8281 - accuracy: 0.1416 - val_loss: -166523.7969 - val_accuracy: 0.0974\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -203570.2188 - accuracy: 0.1255 - val_loss: -190496.1094 - val_accuracy: 0.1615\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -233511.0781 - accuracy: 0.1410 - val_loss: -218521.3906 - val_accuracy: 0.0962\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -265764.3750 - accuracy: 0.1420 - val_loss: -248031.1562 - val_accuracy: 0.0962\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -301208.1875 - accuracy: 0.1376 - val_loss: -283208.9375 - val_accuracy: 0.0974\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -338990.9375 - accuracy: 0.1410 - val_loss: -315946.7500 - val_accuracy: 0.1615\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -381159.0312 - accuracy: 0.1360 - val_loss: -356177.4062 - val_accuracy: 0.1651\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -423778.5938 - accuracy: 0.1450 - val_loss: -394213.6250 - val_accuracy: 0.1069\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -470018.0000 - accuracy: 0.1417 - val_loss: -434314.4062 - val_accuracy: 0.1639\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -518613.2812 - accuracy: 0.1450 - val_loss: -480101.7500 - val_accuracy: 0.1485\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -570233.8750 - accuracy: 0.1446 - val_loss: -526846.4375 - val_accuracy: 0.1627\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -626263.3750 - accuracy: 0.1391 - val_loss: -579378.6250 - val_accuracy: 0.0962\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -684241.1875 - accuracy: 0.1443 - val_loss: -636191.0625 - val_accuracy: 0.0962\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -743961.0625 - accuracy: 0.1436 - val_loss: -687976.5625 - val_accuracy: 0.0962\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -810364.0625 - accuracy: 0.1268 - val_loss: -749612.0000 - val_accuracy: 0.1449\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -880265.0625 - accuracy: 0.1395 - val_loss: -804386.9375 - val_accuracy: 0.1663\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -950453.0000 - accuracy: 0.1474 - val_loss: -877162.8125 - val_accuracy: 0.0962\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1026580.8125 - accuracy: 0.1248 - val_loss: -948880.5000 - val_accuracy: 0.0962\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1106943.3750 - accuracy: 0.1401 - val_loss: -1018714.8125 - val_accuracy: 0.0962\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1188488.3750 - accuracy: 0.1260 - val_loss: -1096319.0000 - val_accuracy: 0.1081\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1273649.1250 - accuracy: 0.1430 - val_loss: -1165001.3750 - val_accuracy: 0.1663\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1361728.1250 - accuracy: 0.1454 - val_loss: -1249436.6250 - val_accuracy: 0.1449\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1457953.3750 - accuracy: 0.1349 - val_loss: -1342625.0000 - val_accuracy: 0.0962\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1554890.5000 - accuracy: 0.1217 - val_loss: -1434571.0000 - val_accuracy: 0.0962\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1658174.0000 - accuracy: 0.1309 - val_loss: -1530906.2500 - val_accuracy: 0.1093\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1764537.1250 - accuracy: 0.1314 - val_loss: -1627388.0000 - val_accuracy: 0.1615\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1876467.6250 - accuracy: 0.1410 - val_loss: -1730586.1250 - val_accuracy: 0.0962\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1989441.2500 - accuracy: 0.1285 - val_loss: -1834383.3750 - val_accuracy: 0.1449\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2108549.5000 - accuracy: 0.1401 - val_loss: -1950099.0000 - val_accuracy: 0.1093\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2232514.7500 - accuracy: 0.1381 - val_loss: -2065802.3750 - val_accuracy: 0.0962\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2364759.7500 - accuracy: 0.1172 - val_loss: -2184007.2500 - val_accuracy: 0.0974\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2499391.0000 - accuracy: 0.1323 - val_loss: -2314878.7500 - val_accuracy: 0.0962\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2636078.0000 - accuracy: 0.1254 - val_loss: -2428190.2500 - val_accuracy: 0.1615\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2778947.7500 - accuracy: 0.1322 - val_loss: -2566130.2500 - val_accuracy: 0.1093\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2929531.0000 - accuracy: 0.1488 - val_loss: -2712381.5000 - val_accuracy: 0.0962\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3081625.5000 - accuracy: 0.1260 - val_loss: -2852819.0000 - val_accuracy: 0.1176\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3239064.2500 - accuracy: 0.1176 - val_loss: -2990523.0000 - val_accuracy: 0.1615\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3398791.7500 - accuracy: 0.1616 - val_loss: -3143838.7500 - val_accuracy: 0.0974\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3566797.2500 - accuracy: 0.1236 - val_loss: -3291220.0000 - val_accuracy: 0.0974\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3748820.7500 - accuracy: 0.1302 - val_loss: -3461859.5000 - val_accuracy: 0.0962\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3918317.5000 - accuracy: 0.1238 - val_loss: -3607881.0000 - val_accuracy: 0.0974\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4060643.2500 - accuracy: 0.1176 - val_loss: -3729286.7500 - val_accuracy: 0.0986\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4201277.5000 - accuracy: 0.1358 - val_loss: -3859073.5000 - val_accuracy: 0.0974\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4349489.0000 - accuracy: 0.1242 - val_loss: -3997966.5000 - val_accuracy: 0.0974\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4508990.5000 - accuracy: 0.1271 - val_loss: -4136629.7500 - val_accuracy: 0.0974\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4674251.5000 - accuracy: 0.1214 - val_loss: -4286565.0000 - val_accuracy: 0.1473\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4853532.5000 - accuracy: 0.1417 - val_loss: -4459668.5000 - val_accuracy: 0.0974\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5041910.0000 - accuracy: 0.1417 - val_loss: -4639660.5000 - val_accuracy: 0.0974\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5239729.5000 - accuracy: 0.1217 - val_loss: -4815609.5000 - val_accuracy: 0.1081\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5451280.5000 - accuracy: 0.1248 - val_loss: -5007924.0000 - val_accuracy: 0.1437\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5669241.0000 - accuracy: 0.1308 - val_loss: -5208070.0000 - val_accuracy: 0.1615\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5887280.5000 - accuracy: 0.1449 - val_loss: -5401237.5000 - val_accuracy: 0.1615\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6115375.5000 - accuracy: 0.1380 - val_loss: -5622531.5000 - val_accuracy: 0.1437\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6344622.5000 - accuracy: 0.1268 - val_loss: -5849568.5000 - val_accuracy: 0.1330\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6589376.5000 - accuracy: 0.1728 - val_loss: -6061370.5000 - val_accuracy: 0.1057\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6842135.5000 - accuracy: 0.1234 - val_loss: -6287154.5000 - val_accuracy: 0.1081\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7095495.0000 - accuracy: 0.1425 - val_loss: -6534381.0000 - val_accuracy: 0.0974\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7357034.0000 - accuracy: 0.1242 - val_loss: -6774990.0000 - val_accuracy: 0.1081\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7623371.0000 - accuracy: 0.1289 - val_loss: -7013458.5000 - val_accuracy: 0.1057\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7905051.0000 - accuracy: 0.1320 - val_loss: -7263477.0000 - val_accuracy: 0.0998\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8192173.0000 - accuracy: 0.1436 - val_loss: -7544444.5000 - val_accuracy: 0.0974\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8488106.0000 - accuracy: 0.1293 - val_loss: -7824992.0000 - val_accuracy: 0.0974\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8799412.0000 - accuracy: 0.1416 - val_loss: -8115853.0000 - val_accuracy: 0.0974\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9107453.0000 - accuracy: 0.1284 - val_loss: -8391831.0000 - val_accuracy: 0.0974\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9416938.0000 - accuracy: 0.1330 - val_loss: -8675641.0000 - val_accuracy: 0.0998\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9744239.0000 - accuracy: 0.1254 - val_loss: -8977528.0000 - val_accuracy: 0.1093\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10074483.0000 - accuracy: 0.1256 - val_loss: -9268091.0000 - val_accuracy: 0.1164\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10403389.0000 - accuracy: 0.1380 - val_loss: -9581565.0000 - val_accuracy: 0.1093\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10755982.0000 - accuracy: 0.1339 - val_loss: -9901432.0000 - val_accuracy: 0.1081\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11108532.0000 - accuracy: 0.1160 - val_loss: -10223802.0000 - val_accuracy: 0.1485\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11471946.0000 - accuracy: 0.1343 - val_loss: -10557120.0000 - val_accuracy: 0.1057\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11827073.0000 - accuracy: 0.1298 - val_loss: -10901070.0000 - val_accuracy: 0.0974\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12186528.0000 - accuracy: 0.1310 - val_loss: -11213722.0000 - val_accuracy: 0.1603\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12564280.0000 - accuracy: 0.1297 - val_loss: -11573772.0000 - val_accuracy: 0.1330\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12940278.0000 - accuracy: 0.1422 - val_loss: -11927880.0000 - val_accuracy: 0.1069\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13340918.0000 - accuracy: 0.1327 - val_loss: -12270880.0000 - val_accuracy: 0.1615\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13733687.0000 - accuracy: 0.1511 - val_loss: -12651307.0000 - val_accuracy: 0.1093\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14142559.0000 - accuracy: 0.1422 - val_loss: -13032202.0000 - val_accuracy: 0.1247\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14568801.0000 - accuracy: 0.1420 - val_loss: -13432448.0000 - val_accuracy: 0.1093\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14991858.0000 - accuracy: 0.1254 - val_loss: -13809440.0000 - val_accuracy: 0.1247\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -15422741.0000 - accuracy: 0.1329 - val_loss: -14193856.0000 - val_accuracy: 0.1603\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -15873937.0000 - accuracy: 0.1255 - val_loss: -14636053.0000 - val_accuracy: 0.1093\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -16315013.0000 - accuracy: 0.1339 - val_loss: -15084414.0000 - val_accuracy: 0.1093\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -16769546.0000 - accuracy: 0.1338 - val_loss: -15499406.0000 - val_accuracy: 0.1093\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -17239482.0000 - accuracy: 0.1376 - val_loss: -15875177.0000 - val_accuracy: 0.1437\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -17713874.0000 - accuracy: 0.1291 - val_loss: -16316389.0000 - val_accuracy: 0.1425\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.16      0.27       273\n","           1       0.10      1.00      0.18        77\n","           2       0.00      0.00      0.00       170\n","           3       0.00      0.00      0.00       198\n","           4       0.00      0.00      0.00       124\n","\n","    accuracy                           0.14       842\n","   macro avg       0.21      0.23      0.09       842\n","weighted avg       0.32      0.14      0.10       842\n","\n","Accuracy: 0.14251781472684086\n","[[ 43 230   0   0   0]\n"," [  0  77   0   0   0]\n"," [  0 170   0   0   0]\n"," [  2 196   0   0   0]\n"," [  0 124   0   0   0]]\n","Precision: 0.3187\n","Recall: 0.1425\n","F1 Score: 0.1038\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://4075d837-89bb-495a-9b92-52924b6fafb2/assets\n","model 9 saved\n","Average Validation Accuracy: 0.12731366035226527\n"]}]},{"cell_type":"code","source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/URL-HTML/NN/model_0.h5'\n","\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","def predict_prob(number):\n","  return [number[0],1-number[0]]\n","\n","y_prob = np.array(list(map(predict_prob, loaded_model.predict(x_test))))\n","y_prob \n","\n","# y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['nn_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['nn_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output['nn_prediction_spam'] = [i[2] for i in y_pred_prob];\n","output['nn_prediction_malware'] = [i[3] for i in y_pred_prob];\n","output['nn_prediction_defacemen'] = [i[4] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":713},"id":"dolEygpVsl_4","executionInfo":{"status":"ok","timestamp":1656569839009,"user_tz":-330,"elapsed":1044,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"d9439c88-e75e-48e7-a1e3-e663150ba4b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[3.91553873e-060 2.68015846e-220 1.00000000e+000 0.00000000e+000\n","  0.00000000e+000]\n"," [2.88464362e-006 3.83570678e-005 2.71159524e-023 9.99958758e-001\n","  7.63722366e-026]\n"," [5.90508965e-001 2.19733288e-001 1.59528637e-002 1.40523164e-002\n","  1.59752567e-001]\n"," ...\n"," [1.68863697e-002 1.03265965e-008 2.13086729e-003 1.38728674e-016\n","  9.80982753e-001]\n"," [1.00000000e+000 1.98653622e-037 3.73134969e-032 1.15221709e-078\n","  3.13849159e-038]\n"," [3.10639870e-005 9.01686443e-005 8.75004392e-003 5.05086029e-006\n","  9.91123673e-001]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  nn_prediction_non  \\\n","0          0        3.915539e-60         2.680158e-220       3.915539e-60   \n","1          3        2.884644e-06          3.835707e-05       2.884644e-06   \n","2          0        5.905090e-01          2.197333e-01       5.905090e-01   \n","3          1        2.825485e-02          4.110084e-01       2.825485e-02   \n","4          1        1.825027e-43          3.029391e-36       1.825027e-43   \n","...      ...                 ...                   ...                ...   \n","6891       1        6.344460e-06          9.982762e-01       6.344460e-06   \n","6892       3        9.905528e-03          1.295311e-02       9.905528e-03   \n","6893       2        1.688637e-02          1.032660e-08       1.688637e-02   \n","6894       0        1.000000e+00          1.986536e-37       1.000000e+00   \n","6895       4        3.106399e-05          9.016864e-05       3.106399e-05   \n","\n","      nn_prediction_phish  nn2_prediction_non  nn2_prediction_phish  \\\n","0           2.680158e-220        3.915539e-60         2.680158e-220   \n","1            3.835707e-05        2.884644e-06          3.835707e-05   \n","2            2.197333e-01        5.905090e-01          2.197333e-01   \n","3            4.110084e-01        2.825485e-02          4.110084e-01   \n","4            3.029391e-36        1.825027e-43          3.029391e-36   \n","...                   ...                 ...                   ...   \n","6891         9.982762e-01        6.344460e-06          9.982762e-01   \n","6892         1.295311e-02        9.905528e-03          1.295311e-02   \n","6893         1.032660e-08        1.688637e-02          1.032660e-08   \n","6894         1.986536e-37        1.000000e+00          1.986536e-37   \n","6895         9.016864e-05        3.106399e-05          9.016864e-05   \n","\n","      mlp_prediction_spam  mlp_prediction_malware  mlp_prediction_defacemen  \\\n","0            1.000000e+00            0.000000e+00              0.000000e+00   \n","1            2.711595e-23            9.999588e-01              7.637224e-26   \n","2            1.595286e-02            1.405232e-02              1.597526e-01   \n","3            2.974864e-02            6.680746e-03              5.243073e-01   \n","4            1.000000e+00           3.531859e-183             6.471977e-232   \n","...                   ...                     ...                       ...   \n","6891         5.259414e-05            1.664911e-03              1.978808e-10   \n","6892         6.272989e-03            9.691422e-01              1.726208e-03   \n","6893         2.130867e-03            1.387287e-16              9.809828e-01   \n","6894         3.731350e-32            1.152217e-78              3.138492e-38   \n","6895         8.750044e-03            5.050860e-06              9.911237e-01   \n","\n","      nn_prediction_spam  nn_prediction_malware  nn_prediction_defacemen  \n","0           1.000000e+00           0.000000e+00             0.000000e+00  \n","1           2.711595e-23           9.999588e-01             7.637224e-26  \n","2           1.595286e-02           1.405232e-02             1.597526e-01  \n","3           2.974864e-02           6.680746e-03             5.243073e-01  \n","4           1.000000e+00          3.531859e-183            6.471977e-232  \n","...                  ...                    ...                      ...  \n","6891        5.259414e-05           1.664911e-03             1.978808e-10  \n","6892        6.272989e-03           9.691422e-01             1.726208e-03  \n","6893        2.130867e-03           1.387287e-16             9.809828e-01  \n","6894        3.731350e-32           1.152217e-78             3.138492e-38  \n","6895        8.750044e-03           5.050860e-06             9.911237e-01  \n","\n","[6896 rows x 13 columns]"],"text/html":["\n","  <div id=\"df-518b30f3-e522-4f98-805d-159c3280cff4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","      <th>nn2_prediction_non</th>\n","      <th>nn2_prediction_phish</th>\n","      <th>mlp_prediction_spam</th>\n","      <th>mlp_prediction_malware</th>\n","      <th>mlp_prediction_defacemen</th>\n","      <th>nn_prediction_spam</th>\n","      <th>nn_prediction_malware</th>\n","      <th>nn_prediction_defacemen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>3.915539e-60</td>\n","      <td>2.680158e-220</td>\n","      <td>3.915539e-60</td>\n","      <td>2.680158e-220</td>\n","      <td>3.915539e-60</td>\n","      <td>2.680158e-220</td>\n","      <td>1.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>2.884644e-06</td>\n","      <td>3.835707e-05</td>\n","      <td>2.884644e-06</td>\n","      <td>3.835707e-05</td>\n","      <td>2.884644e-06</td>\n","      <td>3.835707e-05</td>\n","      <td>2.711595e-23</td>\n","      <td>9.999588e-01</td>\n","      <td>7.637224e-26</td>\n","      <td>2.711595e-23</td>\n","      <td>9.999588e-01</td>\n","      <td>7.637224e-26</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>5.905090e-01</td>\n","      <td>2.197333e-01</td>\n","      <td>5.905090e-01</td>\n","      <td>2.197333e-01</td>\n","      <td>5.905090e-01</td>\n","      <td>2.197333e-01</td>\n","      <td>1.595286e-02</td>\n","      <td>1.405232e-02</td>\n","      <td>1.597526e-01</td>\n","      <td>1.595286e-02</td>\n","      <td>1.405232e-02</td>\n","      <td>1.597526e-01</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>2.825485e-02</td>\n","      <td>4.110084e-01</td>\n","      <td>2.825485e-02</td>\n","      <td>4.110084e-01</td>\n","      <td>2.825485e-02</td>\n","      <td>4.110084e-01</td>\n","      <td>2.974864e-02</td>\n","      <td>6.680746e-03</td>\n","      <td>5.243073e-01</td>\n","      <td>2.974864e-02</td>\n","      <td>6.680746e-03</td>\n","      <td>5.243073e-01</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1.825027e-43</td>\n","      <td>3.029391e-36</td>\n","      <td>1.825027e-43</td>\n","      <td>3.029391e-36</td>\n","      <td>1.825027e-43</td>\n","      <td>3.029391e-36</td>\n","      <td>1.000000e+00</td>\n","      <td>3.531859e-183</td>\n","      <td>6.471977e-232</td>\n","      <td>1.000000e+00</td>\n","      <td>3.531859e-183</td>\n","      <td>6.471977e-232</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6891</th>\n","      <td>1</td>\n","      <td>6.344460e-06</td>\n","      <td>9.982762e-01</td>\n","      <td>6.344460e-06</td>\n","      <td>9.982762e-01</td>\n","      <td>6.344460e-06</td>\n","      <td>9.982762e-01</td>\n","      <td>5.259414e-05</td>\n","      <td>1.664911e-03</td>\n","      <td>1.978808e-10</td>\n","      <td>5.259414e-05</td>\n","      <td>1.664911e-03</td>\n","      <td>1.978808e-10</td>\n","    </tr>\n","    <tr>\n","      <th>6892</th>\n","      <td>3</td>\n","      <td>9.905528e-03</td>\n","      <td>1.295311e-02</td>\n","      <td>9.905528e-03</td>\n","      <td>1.295311e-02</td>\n","      <td>9.905528e-03</td>\n","      <td>1.295311e-02</td>\n","      <td>6.272989e-03</td>\n","      <td>9.691422e-01</td>\n","      <td>1.726208e-03</td>\n","      <td>6.272989e-03</td>\n","      <td>9.691422e-01</td>\n","      <td>1.726208e-03</td>\n","    </tr>\n","    <tr>\n","      <th>6893</th>\n","      <td>2</td>\n","      <td>1.688637e-02</td>\n","      <td>1.032660e-08</td>\n","      <td>1.688637e-02</td>\n","      <td>1.032660e-08</td>\n","      <td>1.688637e-02</td>\n","      <td>1.032660e-08</td>\n","      <td>2.130867e-03</td>\n","      <td>1.387287e-16</td>\n","      <td>9.809828e-01</td>\n","      <td>2.130867e-03</td>\n","      <td>1.387287e-16</td>\n","      <td>9.809828e-01</td>\n","    </tr>\n","    <tr>\n","      <th>6894</th>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>1.986536e-37</td>\n","      <td>1.000000e+00</td>\n","      <td>1.986536e-37</td>\n","      <td>1.000000e+00</td>\n","      <td>1.986536e-37</td>\n","      <td>3.731350e-32</td>\n","      <td>1.152217e-78</td>\n","      <td>3.138492e-38</td>\n","      <td>3.731350e-32</td>\n","      <td>1.152217e-78</td>\n","      <td>3.138492e-38</td>\n","    </tr>\n","    <tr>\n","      <th>6895</th>\n","      <td>4</td>\n","      <td>3.106399e-05</td>\n","      <td>9.016864e-05</td>\n","      <td>3.106399e-05</td>\n","      <td>9.016864e-05</td>\n","      <td>3.106399e-05</td>\n","      <td>9.016864e-05</td>\n","      <td>8.750044e-03</td>\n","      <td>5.050860e-06</td>\n","      <td>9.911237e-01</td>\n","      <td>8.750044e-03</td>\n","      <td>5.050860e-06</td>\n","      <td>9.911237e-01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6896 rows × 13 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-518b30f3-e522-4f98-805d-159c3280cff4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-518b30f3-e522-4f98-805d-159c3280cff4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-518b30f3-e522-4f98-805d-159c3280cff4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["**Neural Network 2**"],"metadata":{"id":"fMdqVtYLwwy4"}},{"cell_type":"code","source":["\n","import keras\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","def model_a(x_train, x_val, y_train, y_val, opt, n, early_stopping_monitor):\n","\n","  n_cols = x_train.shape[1]\n","\n","  #create model\n","  model_2 = Sequential()\n","  model_2.add(Dense(30, activation='sigmoid', input_shape=(n_cols,)))\n","  model_2.add(Dense(25, activation='sigmoid'))\n","  model_2.add(Dense(20, activation='sigmoid'))\n","  model_2.add(Dense(15, activation='sigmoid'))\n","  model_2.add(Dense(10, activation='sigmoid'))\n","  model_2.add(Dense(1, activation = 'sigmoid'))\n","\n","  #compile model using mse as a measure of model performance\n","  model_2.compile(optimizer='adam', loss='mean_squared_error')\n","\n","\n","\n","  history = model_2.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping_monitor])\n","\n","\n","  # plt.plot(history.history['loss'])\n","  # plt.plot(history.history['val_loss'])\n","  # plt.title('model loss')\n","  # plt.ylabel('Loss')\n","  # plt.xlabel('Epoch')\n","  # plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n","  # plt.show()\n","\n","\n","  print('Validation Accuracy: ')\n","  # Predicting the Test set results\n","  y_pred = model_2.predict(x_val)\n","  y_pred = (y_pred > 0.5)\n","\n","\n","  print(classification_report(y_val, y_pred))\n","\n","  # Model Accuracy, how often is the classifier correct?\n","  print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","\n","  # Creating the Confusion Matrix\n","  cm = confusion_matrix(y_val, y_pred)\n","  print(cm)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred, average='weighted'))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred, average='weighted'))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred, average='weighted'))\n","\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/URL-HTML/NN_2/model_'+str(n)+'.h5'\n","  pickle.dump(model_2, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","\n","  return metrics.accuracy_score(y_val, y_pred)\n","\n"],"metadata":{"id":"L8ZhB8W9tVQS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_a(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n, early_stopping_monitor)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osCV0Uo5wqac","executionInfo":{"status":"ok","timestamp":1656569522706,"user_tz":-330,"elapsed":724521,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"d3986a56-075c-4819-a2ad-1746766e8cc5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.1673 - val_loss: 3.0985\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8466 - val_loss: 3.0040\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8005 - val_loss: 2.9767\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7839 - val_loss: 2.9645\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7758 - val_loss: 2.9578\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7711 - val_loss: 2.9537\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7681 - val_loss: 2.9510\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7660 - val_loss: 2.9490\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7645 - val_loss: 2.9475\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7632 - val_loss: 2.9463\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7622 - val_loss: 2.9453\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7614 - val_loss: 2.9445\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7609 - val_loss: 2.9440\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7605 - val_loss: 2.9437\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7602 - val_loss: 2.9434\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7600 - val_loss: 2.9431\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7598 - val_loss: 2.9429\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7596 - val_loss: 2.9428\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7595 - val_loss: 2.9427\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7594 - val_loss: 2.9425\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7593 - val_loss: 2.9425\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7592 - val_loss: 2.9424\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7592 - val_loss: 2.9423\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7591 - val_loss: 2.9423\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7591 - val_loss: 2.9422\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7590 - val_loss: 2.9422\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7590 - val_loss: 2.9421\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7590 - val_loss: 2.9421\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7589 - val_loss: 2.9421\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7589 - val_loss: 2.9421\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7589 - val_loss: 2.9420\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7589 - val_loss: 2.9420\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7589 - val_loss: 2.9420\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7588 - val_loss: 2.9420\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7588 - val_loss: 2.9420\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7588 - val_loss: 2.9420\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7588 - val_loss: 2.9420\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7588 - val_loss: 2.9419\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7588 - val_loss: 2.9419\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7588 - val_loss: 2.9419\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7588 - val_loss: 2.9419\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7588 - val_loss: 2.9419\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7588 - val_loss: 2.9419\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7588 - val_loss: 2.9419\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7588 - val_loss: 2.9419\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7588 - val_loss: 2.9419\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7588 - val_loss: 2.9419\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7588 - val_loss: 2.9419\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7587 - val_loss: 2.9419\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       263\n","           1       0.09      1.00      0.17        79\n","           2       0.00      0.00      0.00       164\n","           3       0.00      0.00      0.00       196\n","           4       0.00      0.00      0.00       141\n","\n","    accuracy                           0.09       843\n","   macro avg       0.02      0.20      0.03       843\n","weighted avg       0.01      0.09      0.02       843\n","\n","Accuracy: 0.0937129300118624\n","[[  0 263   0   0   0]\n"," [  0  79   0   0   0]\n"," [  0 164   0   0   0]\n"," [  0 196   0   0   0]\n"," [  0 141   0   0   0]]\n","Precision: 0.0088\n","Recall: 0.0937\n","F1 Score: 0.0161\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://cfd95568-27d8-4d2f-aa38-100def86b421/assets\n","model 0 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.3022 - val_loss: 2.8785\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8986 - val_loss: 2.7835\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8422 - val_loss: 2.7531\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8194 - val_loss: 2.7382\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8079 - val_loss: 2.7303\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8013 - val_loss: 2.7254\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7971 - val_loss: 2.7223\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7943 - val_loss: 2.7200\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7923 - val_loss: 2.7184\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7908 - val_loss: 2.7172\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7896 - val_loss: 2.7163\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7888 - val_loss: 2.7156\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7881 - val_loss: 2.7150\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7875 - val_loss: 2.7145\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.7141\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7866 - val_loss: 2.7138\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7863 - val_loss: 2.7135\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7860 - val_loss: 2.7133\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7858 - val_loss: 2.7131\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7856 - val_loss: 2.7129\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7855 - val_loss: 2.7127\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7853 - val_loss: 2.7126\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7852 - val_loss: 2.7125\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7851 - val_loss: 2.7124\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7850 - val_loss: 2.7123\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7849 - val_loss: 2.7123\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7848 - val_loss: 2.7122\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7848 - val_loss: 2.7122\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7847 - val_loss: 2.7121\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7847 - val_loss: 2.7121\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7846 - val_loss: 2.7120\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7846 - val_loss: 2.7120\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7846 - val_loss: 2.7120\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7845 - val_loss: 2.7119\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7845 - val_loss: 2.7119\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7845 - val_loss: 2.7119\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7845 - val_loss: 2.7119\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7844 - val_loss: 2.7119\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7844 - val_loss: 2.7119\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7844 - val_loss: 2.7118\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7844 - val_loss: 2.7118\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7844 - val_loss: 2.7118\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7844 - val_loss: 2.7118\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7844 - val_loss: 2.7118\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7844 - val_loss: 2.7118\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7844 - val_loss: 2.7118\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7844 - val_loss: 2.7118\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7844 - val_loss: 2.7118\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7118\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7118\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7118\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7118\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7118\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7118\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7118\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7118\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7118\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7118\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7118\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7118\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7118\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7118\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7118\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7117\n","Validation Accuracy: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       291\n","           1       0.09      1.00      0.16        74\n","           2       0.00      0.00      0.00       169\n","           3       0.00      0.00      0.00       191\n","           4       0.00      0.00      0.00       118\n","\n","    accuracy                           0.09       843\n","   macro avg       0.02      0.20      0.03       843\n","weighted avg       0.01      0.09      0.01       843\n","\n","Accuracy: 0.08778173190984578\n","[[  0 291   0   0   0]\n"," [  0  74   0   0   0]\n"," [  0 169   0   0   0]\n"," [  0 191   0   0   0]\n"," [  0 118   0   0   0]]\n","Precision: 0.0077\n","Recall: 0.0878\n","F1 Score: 0.0142\n","INFO:tensorflow:Assets written to: ram://380e1e23-c6cd-4524-ba0a-859268f8725f/assets\n","model 1 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.1608 - val_loss: 2.9896\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8390 - val_loss: 2.9176\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8019 - val_loss: 2.8963\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7884 - val_loss: 2.8868\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7815 - val_loss: 2.8814\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7776 - val_loss: 2.8781\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7750 - val_loss: 2.8759\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7732 - val_loss: 2.8743\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7720 - val_loss: 2.8732\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7711 - val_loss: 2.8723\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7703 - val_loss: 2.8716\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7698 - val_loss: 2.8711\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7693 - val_loss: 2.8707\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7690 - val_loss: 2.8703\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7687 - val_loss: 2.8700\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7684 - val_loss: 2.8698\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7682 - val_loss: 2.8696\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7680 - val_loss: 2.8694\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7679 - val_loss: 2.8693\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7678 - val_loss: 2.8692\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7677 - val_loss: 2.8691\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7676 - val_loss: 2.8690\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7675 - val_loss: 2.8689\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7674 - val_loss: 2.8688\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7674 - val_loss: 2.8688\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7673 - val_loss: 2.8687\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7673 - val_loss: 2.8687\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.8686\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.8686\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7671 - val_loss: 2.8686\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7671 - val_loss: 2.8685\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7671 - val_loss: 2.8685\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7671 - val_loss: 2.8685\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7671 - val_loss: 2.8685\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7670 - val_loss: 2.8685\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7670 - val_loss: 2.8684\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7670 - val_loss: 2.8684\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7670 - val_loss: 2.8684\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7670 - val_loss: 2.8684\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7670 - val_loss: 2.8684\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7670 - val_loss: 2.8684\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7670 - val_loss: 2.8684\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7670 - val_loss: 2.8684\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7670 - val_loss: 2.8684\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7670 - val_loss: 2.8684\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8684\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8684\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8684\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8684\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8683\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       270\n","           1       0.09      1.00      0.16        75\n","           2       0.00      0.00      0.00       178\n","           3       0.00      0.00      0.00       182\n","           4       0.00      0.00      0.00       138\n","\n","    accuracy                           0.09       843\n","   macro avg       0.02      0.20      0.03       843\n","weighted avg       0.01      0.09      0.01       843\n","\n","Accuracy: 0.08896797153024912\n","[[  0 270   0   0   0]\n"," [  0  75   0   0   0]\n"," [  0 178   0   0   0]\n"," [  0 182   0   0   0]\n"," [  0 138   0   0   0]]\n","Precision: 0.0079\n","Recall: 0.0890\n","F1 Score: 0.0145\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://8afc5b5d-ca7f-4663-99fa-0d4b7b104d2d/assets\n","model 2 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.0372 - val_loss: 2.7903\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8340 - val_loss: 2.7497\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8101 - val_loss: 2.7370\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8007 - val_loss: 2.7309\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7957 - val_loss: 2.7273\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7927 - val_loss: 2.7250\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7906 - val_loss: 2.7234\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7892 - val_loss: 2.7223\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7881 - val_loss: 2.7215\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7873 - val_loss: 2.7208\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7867 - val_loss: 2.7203\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7862 - val_loss: 2.7199\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7858 - val_loss: 2.7195\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7855 - val_loss: 2.7193\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7852 - val_loss: 2.7190\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7850 - val_loss: 2.7189\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7848 - val_loss: 2.7187\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7847 - val_loss: 2.7186\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7845 - val_loss: 2.7185\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7844 - val_loss: 2.7184\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7183\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7842 - val_loss: 2.7182\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7842 - val_loss: 2.7181\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7841 - val_loss: 2.7181\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7841 - val_loss: 2.7180\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7840 - val_loss: 2.7180\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7840 - val_loss: 2.7180\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7839 - val_loss: 2.7179\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7839 - val_loss: 2.7179\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7839 - val_loss: 2.7179\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7838 - val_loss: 2.7178\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7838 - val_loss: 2.7178\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7838 - val_loss: 2.7178\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7838 - val_loss: 2.7178\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7838 - val_loss: 2.7178\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7838 - val_loss: 2.7178\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7178\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 45/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 46/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 47/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7177\n","Validation Accuracy: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       288\n","           1       0.10      1.00      0.19        86\n","           2       0.00      0.00      0.00       156\n","           3       0.00      0.00      0.00       194\n","           4       0.00      0.00      0.00       119\n","\n","    accuracy                           0.10       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.10      0.02       843\n","\n","Accuracy: 0.10201660735468565\n","[[  0 288   0   0   0]\n"," [  0  86   0   0   0]\n"," [  0 156   0   0   0]\n"," [  0 194   0   0   0]\n"," [  0 119   0   0   0]]\n","Precision: 0.0104\n","Recall: 0.1020\n","F1 Score: 0.0189\n","INFO:tensorflow:Assets written to: ram://4f3f905e-60e0-446d-8079-52d01e28376d/assets\n","model 3 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 5ms/step - loss: 3.5885 - val_loss: 3.1475\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.9783 - val_loss: 2.9591\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8783 - val_loss: 2.8993\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8397 - val_loss: 2.8710\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8197 - val_loss: 2.8547\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8073 - val_loss: 2.8441\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7990 - val_loss: 2.8366\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7928 - val_loss: 2.8310\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7883 - val_loss: 2.8269\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7850 - val_loss: 2.8239\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.8217\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7809 - val_loss: 2.8201\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7796 - val_loss: 2.8189\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7785 - val_loss: 2.8179\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7777 - val_loss: 2.8171\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7770 - val_loss: 2.8164\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7764 - val_loss: 2.8159\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7760 - val_loss: 2.8154\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7756 - val_loss: 2.8150\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7752 - val_loss: 2.8147\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7750 - val_loss: 2.8144\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7747 - val_loss: 2.8142\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7745 - val_loss: 2.8140\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7744 - val_loss: 2.8138\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7742 - val_loss: 2.8137\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7741 - val_loss: 2.8135\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7740 - val_loss: 2.8134\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7738 - val_loss: 2.8133\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7738 - val_loss: 2.8132\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7737 - val_loss: 2.8132\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7736 - val_loss: 2.8131\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7736 - val_loss: 2.8130\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7735 - val_loss: 2.8130\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7735 - val_loss: 2.8129\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7734 - val_loss: 2.8129\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7734 - val_loss: 2.8129\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7734 - val_loss: 2.8128\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7733 - val_loss: 2.8128\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7733 - val_loss: 2.8128\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7733 - val_loss: 2.8127\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7733 - val_loss: 2.8127\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7732 - val_loss: 2.8127\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7732 - val_loss: 2.8127\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7732 - val_loss: 2.8127\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7732 - val_loss: 2.8127\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7732 - val_loss: 2.8127\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7732 - val_loss: 2.8127\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7732 - val_loss: 2.8126\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7732 - val_loss: 2.8126\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7732 - val_loss: 2.8126\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7732 - val_loss: 2.8126\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.8126\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       263\n","           1       0.10      1.00      0.18        82\n","           2       0.00      0.00      0.00       163\n","           3       0.00      0.00      0.00       214\n","           4       0.00      0.00      0.00       121\n","\n","    accuracy                           0.10       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.10      0.02       843\n","\n","Accuracy: 0.09727164887307237\n","[[  0 263   0   0   0]\n"," [  0  82   0   0   0]\n"," [  0 163   0   0   0]\n"," [  0 214   0   0   0]\n"," [  0 121   0   0   0]]\n","Precision: 0.0095\n","Recall: 0.0973\n","F1 Score: 0.0172\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://c95ae5cd-5cf5-405a-ba58-5c6b17b245b8/assets\n","model 4 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.9971 - val_loss: 2.9883\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8262 - val_loss: 2.9386\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7976 - val_loss: 2.9212\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7854 - val_loss: 2.9124\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7789 - val_loss: 2.9074\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7750 - val_loss: 2.9042\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7724 - val_loss: 2.9020\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7706 - val_loss: 2.9004\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7693 - val_loss: 2.8993\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7683 - val_loss: 2.8984\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7676 - val_loss: 2.8978\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7670 - val_loss: 2.8972\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7665 - val_loss: 2.8968\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7661 - val_loss: 2.8964\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7658 - val_loss: 2.8962\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7656 - val_loss: 2.8959\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7654 - val_loss: 2.8957\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7652 - val_loss: 2.8955\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7650 - val_loss: 2.8954\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7649 - val_loss: 2.8953\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7648 - val_loss: 2.8952\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7647 - val_loss: 2.8951\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7646 - val_loss: 2.8950\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7645 - val_loss: 2.8949\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7645 - val_loss: 2.8949\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7644 - val_loss: 2.8948\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7644 - val_loss: 2.8948\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7643 - val_loss: 2.8947\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7643 - val_loss: 2.8947\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7642 - val_loss: 2.8947\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7642 - val_loss: 2.8946\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7642 - val_loss: 2.8946\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7642 - val_loss: 2.8946\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7641 - val_loss: 2.8946\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7641 - val_loss: 2.8945\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7641 - val_loss: 2.8945\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7641 - val_loss: 2.8945\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7641 - val_loss: 2.8945\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7641 - val_loss: 2.8945\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7641 - val_loss: 2.8945\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7641 - val_loss: 2.8945\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7641 - val_loss: 2.8945\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8945\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8945\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8945\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8945\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8944\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       282\n","           1       0.10      1.00      0.18        83\n","           2       0.00      0.00      0.00       148\n","           3       0.00      0.00      0.00       192\n","           4       0.00      0.00      0.00       138\n","\n","    accuracy                           0.10       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.10      0.02       843\n","\n","Accuracy: 0.09845788849347568\n","[[  0 282   0   0   0]\n"," [  0  83   0   0   0]\n"," [  0 148   0   0   0]\n"," [  0 192   0   0   0]\n"," [  0 138   0   0   0]]\n","Precision: 0.0097\n","Recall: 0.0985\n","F1 Score: 0.0177\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://74c31276-4405-494b-a36b-46ee2aa8ca75/assets\n","model 5 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.6258 - val_loss: 3.0559\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.0615 - val_loss: 2.8748\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.9386 - val_loss: 2.7948\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8742 - val_loss: 2.7524\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8433 - val_loss: 2.7321\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8268 - val_loss: 2.7202\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8167 - val_loss: 2.7126\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8100 - val_loss: 2.7073\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8052 - val_loss: 2.7035\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8017 - val_loss: 2.7006\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7991 - val_loss: 2.6985\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7971 - val_loss: 2.6968\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7954 - val_loss: 2.6954\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7941 - val_loss: 2.6943\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7930 - val_loss: 2.6933\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7921 - val_loss: 2.6925\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7913 - val_loss: 2.6918\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7906 - val_loss: 2.6911\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7900 - val_loss: 2.6906\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7895 - val_loss: 2.6902\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7891 - val_loss: 2.6899\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7887 - val_loss: 2.6896\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7885 - val_loss: 2.6894\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7883 - val_loss: 2.6892\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7881 - val_loss: 2.6890\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7879 - val_loss: 2.6889\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7878 - val_loss: 2.6888\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7877 - val_loss: 2.6887\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7876 - val_loss: 2.6886\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7875 - val_loss: 2.6885\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7875 - val_loss: 2.6885\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7874 - val_loss: 2.6884\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7873 - val_loss: 2.6884\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7873 - val_loss: 2.6883\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7873 - val_loss: 2.6883\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7872 - val_loss: 2.6883\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7872 - val_loss: 2.6882\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7872 - val_loss: 2.6882\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7871 - val_loss: 2.6882\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7871 - val_loss: 2.6882\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7871 - val_loss: 2.6882\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7871 - val_loss: 2.6881\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7871 - val_loss: 2.6881\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7871 - val_loss: 2.6881\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6881\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6881\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6881\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6881\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6881\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6881\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6881\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6881\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6880\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6880\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6880\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6880\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6880\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6880\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6880\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6880\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6880\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6880\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6880\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6880\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6880\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6880\n","Validation Accuracy: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       280\n","           1       0.11      1.00      0.20        93\n","           2       0.00      0.00      0.00       158\n","           3       0.00      0.00      0.00       196\n","           4       0.00      0.00      0.00       116\n","\n","    accuracy                           0.11       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.11      0.02       843\n","\n","Accuracy: 0.1103202846975089\n","[[  0 280   0   0   0]\n"," [  0  93   0   0   0]\n"," [  0 158   0   0   0]\n"," [  0 196   0   0   0]\n"," [  0 116   0   0   0]]\n","Precision: 0.0122\n","Recall: 0.1103\n","F1 Score: 0.0219\n","INFO:tensorflow:Assets written to: ram://fe13eb14-82ea-43e6-94e8-53923c5bcb97/assets\n","model 6 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.1647 - val_loss: 2.7311\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8739 - val_loss: 2.6606\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8297 - val_loss: 2.6402\n","Epoch 4/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.8155 - val_loss: 2.6320\n","Epoch 5/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.8089 - val_loss: 2.6276\n","Epoch 6/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.8050 - val_loss: 2.6248\n","Epoch 7/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.8026 - val_loss: 2.6230\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8009 - val_loss: 2.6218\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7997 - val_loss: 2.6208\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7988 - val_loss: 2.6201\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7981 - val_loss: 2.6196\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7976 - val_loss: 2.6191\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7972 - val_loss: 2.6188\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7968 - val_loss: 2.6185\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7966 - val_loss: 2.6183\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7963 - val_loss: 2.6181\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7961 - val_loss: 2.6179\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7959 - val_loss: 2.6178\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7958 - val_loss: 2.6177\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7957 - val_loss: 2.6175\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7956 - val_loss: 2.6175\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7955 - val_loss: 2.6174\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7954 - val_loss: 2.6173\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7953 - val_loss: 2.6173\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7953 - val_loss: 2.6172\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7952 - val_loss: 2.6172\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7952 - val_loss: 2.6171\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7952 - val_loss: 2.6171\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7951 - val_loss: 2.6171\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7951 - val_loss: 2.6170\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7951 - val_loss: 2.6170\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7950 - val_loss: 2.6170\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7950 - val_loss: 2.6170\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7950 - val_loss: 2.6170\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7950 - val_loss: 2.6170\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7950 - val_loss: 2.6169\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7950 - val_loss: 2.6169\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6169\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7949 - val_loss: 2.6168\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       284\n","           1       0.11      1.00      0.19        91\n","           2       0.00      0.00      0.00       165\n","           3       0.00      0.00      0.00       194\n","           4       0.00      0.00      0.00       109\n","\n","    accuracy                           0.11       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.11      0.02       843\n","\n","Accuracy: 0.10794780545670225\n","[[  0 284   0   0   0]\n"," [  0  91   0   0   0]\n"," [  0 165   0   0   0]\n"," [  0 194   0   0   0]\n"," [  0 109   0   0   0]]\n","Precision: 0.0117\n","Recall: 0.1079\n","F1 Score: 0.0210\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://4aacd8a0-5a26-4468-91ea-57dc90fb27b8/assets\n","model 7 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.1138 - val_loss: 2.8463\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8634 - val_loss: 2.7795\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8243 - val_loss: 2.7582\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8091 - val_loss: 2.7480\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8011 - val_loss: 2.7421\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7962 - val_loss: 2.7383\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7931 - val_loss: 2.7358\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7908 - val_loss: 2.7340\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7892 - val_loss: 2.7326\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7880 - val_loss: 2.7316\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7871 - val_loss: 2.7308\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7864 - val_loss: 2.7302\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7858 - val_loss: 2.7297\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7853 - val_loss: 2.7292\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7849 - val_loss: 2.7289\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7846 - val_loss: 2.7286\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7843 - val_loss: 2.7284\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7841 - val_loss: 2.7282\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7839 - val_loss: 2.7280\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7279\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7836 - val_loss: 2.7277\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7835 - val_loss: 2.7276\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7834 - val_loss: 2.7275\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7833 - val_loss: 2.7274\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7832 - val_loss: 2.7274\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7831 - val_loss: 2.7273\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7831 - val_loss: 2.7272\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7830 - val_loss: 2.7272\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7830 - val_loss: 2.7272\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7829 - val_loss: 2.7271\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7829 - val_loss: 2.7271\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7829 - val_loss: 2.7271\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7828 - val_loss: 2.7270\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7828 - val_loss: 2.7270\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7828 - val_loss: 2.7270\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7828 - val_loss: 2.7270\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7828 - val_loss: 2.7270\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7827 - val_loss: 2.7269\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7827 - val_loss: 2.7269\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7827 - val_loss: 2.7269\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7827 - val_loss: 2.7269\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7827 - val_loss: 2.7269\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7827 - val_loss: 2.7269\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7827 - val_loss: 2.7269\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7827 - val_loss: 2.7269\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7827 - val_loss: 2.7269\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7827 - val_loss: 2.7269\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7827 - val_loss: 2.7269\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7269\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7269\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7269\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7269\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7269\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7269\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7269\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7269\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7268\n","Validation Accuracy: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       279\n","           1       0.10      1.00      0.18        84\n","           2       0.00      0.00      0.00       163\n","           3       0.00      0.00      0.00       198\n","           4       0.00      0.00      0.00       118\n","\n","    accuracy                           0.10       842\n","   macro avg       0.02      0.20      0.04       842\n","weighted avg       0.01      0.10      0.02       842\n","\n","Accuracy: 0.0997624703087886\n","[[  0 279   0   0   0]\n"," [  0  84   0   0   0]\n"," [  0 163   0   0   0]\n"," [  0 198   0   0   0]\n"," [  0 118   0   0   0]]\n","Precision: 0.0100\n","Recall: 0.0998\n","F1 Score: 0.0181\n","INFO:tensorflow:Assets written to: ram://9bf1f5eb-5c71-4f90-a0dc-c6e0844874f8/assets\n","model 8 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.5037 - val_loss: 3.1067\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.9891 - val_loss: 2.9485\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8959 - val_loss: 2.8892\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8525 - val_loss: 2.8555\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8264 - val_loss: 2.8354\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8113 - val_loss: 2.8236\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8022 - val_loss: 2.8161\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7961 - val_loss: 2.8110\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7918 - val_loss: 2.8073\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7887 - val_loss: 2.8045\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7863 - val_loss: 2.8024\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7845 - val_loss: 2.8007\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7830 - val_loss: 2.7994\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7819 - val_loss: 2.7983\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7809 - val_loss: 2.7974\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7801 - val_loss: 2.7967\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7795 - val_loss: 2.7961\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7789 - val_loss: 2.7955\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7785 - val_loss: 2.7951\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7781 - val_loss: 2.7947\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7777 - val_loss: 2.7944\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7774 - val_loss: 2.7941\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7772 - val_loss: 2.7939\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7770 - val_loss: 2.7937\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7768 - val_loss: 2.7935\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.7933\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7765 - val_loss: 2.7932\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7763 - val_loss: 2.7931\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7762 - val_loss: 2.7930\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7761 - val_loss: 2.7929\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7760 - val_loss: 2.7928\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7760 - val_loss: 2.7927\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7759 - val_loss: 2.7927\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7758 - val_loss: 2.7926\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7758 - val_loss: 2.7926\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7757 - val_loss: 2.7925\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7757 - val_loss: 2.7925\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7757 - val_loss: 2.7924\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7756 - val_loss: 2.7924\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7756 - val_loss: 2.7924\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7756 - val_loss: 2.7924\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7756 - val_loss: 2.7923\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7755 - val_loss: 2.7923\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7755 - val_loss: 2.7923\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7755 - val_loss: 2.7923\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7755 - val_loss: 2.7923\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7755 - val_loss: 2.7923\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7755 - val_loss: 2.7922\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7755 - val_loss: 2.7922\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7922\n","Validation Accuracy: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       273\n","           1       0.09      1.00      0.17        77\n","           2       0.00      0.00      0.00       170\n","           3       0.00      0.00      0.00       198\n","           4       0.00      0.00      0.00       124\n","\n","    accuracy                           0.09       842\n","   macro avg       0.02      0.20      0.03       842\n","weighted avg       0.01      0.09      0.02       842\n","\n","Accuracy: 0.09144893111638955\n","[[  0 273   0   0   0]\n"," [  0  77   0   0   0]\n"," [  0 170   0   0   0]\n"," [  0 198   0   0   0]\n"," [  0 124   0   0   0]]\n","Precision: 0.0084\n","Recall: 0.0914\n","F1 Score: 0.0153\n","INFO:tensorflow:Assets written to: ram://3acb15f3-c1d9-4cec-9578-e49a79892b7c/assets\n","model 9 saved\n","Average Validation Accuracy: 0.09776882697525803\n"]}]},{"cell_type":"code","source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/URL-HTML/NN_2/model_6.h5'\n","\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","def predict_prob(number):\n","  return [number[0],1-number[0]]\n","\n","y_prob = np.array(list(map(predict_prob, loaded_model.predict(x_test))))\n","y_prob \n","\n","# y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['nn2_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['nn2_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output['nn2_prediction_spam'] = [i[2] for i in y_pred_prob];\n","output['nn2_prediction_malware'] = [i[3] for i in y_pred_prob];\n","output['nn2_prediction_defacemen'] = [i[4] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":713},"id":"JPT9oIQ0wuZf","executionInfo":{"status":"ok","timestamp":1656569852606,"user_tz":-330,"elapsed":2111,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"a9eb1ea9-5fd3-4d45-9306-b60d3bad9293"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[3.91553873e-060 2.68015846e-220 1.00000000e+000 0.00000000e+000\n","  0.00000000e+000]\n"," [2.88464362e-006 3.83570678e-005 2.71159524e-023 9.99958758e-001\n","  7.63722366e-026]\n"," [5.90508965e-001 2.19733288e-001 1.59528637e-002 1.40523164e-002\n","  1.59752567e-001]\n"," ...\n"," [1.68863697e-002 1.03265965e-008 2.13086729e-003 1.38728674e-016\n","  9.80982753e-001]\n"," [1.00000000e+000 1.98653622e-037 3.73134969e-032 1.15221709e-078\n","  3.13849159e-038]\n"," [3.10639870e-005 9.01686443e-005 8.75004392e-003 5.05086029e-006\n","  9.91123673e-001]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  nn_prediction_non  \\\n","0          0        3.915539e-60         2.680158e-220       3.915539e-60   \n","1          3        2.884644e-06          3.835707e-05       2.884644e-06   \n","2          0        5.905090e-01          2.197333e-01       5.905090e-01   \n","3          1        2.825485e-02          4.110084e-01       2.825485e-02   \n","4          1        1.825027e-43          3.029391e-36       1.825027e-43   \n","...      ...                 ...                   ...                ...   \n","6891       1        6.344460e-06          9.982762e-01       6.344460e-06   \n","6892       3        9.905528e-03          1.295311e-02       9.905528e-03   \n","6893       2        1.688637e-02          1.032660e-08       1.688637e-02   \n","6894       0        1.000000e+00          1.986536e-37       1.000000e+00   \n","6895       4        3.106399e-05          9.016864e-05       3.106399e-05   \n","\n","      nn_prediction_phish  nn2_prediction_non  nn2_prediction_phish  \\\n","0           2.680158e-220        3.915539e-60         2.680158e-220   \n","1            3.835707e-05        2.884644e-06          3.835707e-05   \n","2            2.197333e-01        5.905090e-01          2.197333e-01   \n","3            4.110084e-01        2.825485e-02          4.110084e-01   \n","4            3.029391e-36        1.825027e-43          3.029391e-36   \n","...                   ...                 ...                   ...   \n","6891         9.982762e-01        6.344460e-06          9.982762e-01   \n","6892         1.295311e-02        9.905528e-03          1.295311e-02   \n","6893         1.032660e-08        1.688637e-02          1.032660e-08   \n","6894         1.986536e-37        1.000000e+00          1.986536e-37   \n","6895         9.016864e-05        3.106399e-05          9.016864e-05   \n","\n","      mlp_prediction_spam  mlp_prediction_malware  mlp_prediction_defacemen  \\\n","0            1.000000e+00            0.000000e+00              0.000000e+00   \n","1            2.711595e-23            9.999588e-01              7.637224e-26   \n","2            1.595286e-02            1.405232e-02              1.597526e-01   \n","3            2.974864e-02            6.680746e-03              5.243073e-01   \n","4            1.000000e+00           3.531859e-183             6.471977e-232   \n","...                   ...                     ...                       ...   \n","6891         5.259414e-05            1.664911e-03              1.978808e-10   \n","6892         6.272989e-03            9.691422e-01              1.726208e-03   \n","6893         2.130867e-03            1.387287e-16              9.809828e-01   \n","6894         3.731350e-32            1.152217e-78              3.138492e-38   \n","6895         8.750044e-03            5.050860e-06              9.911237e-01   \n","\n","      nn_prediction_spam  nn_prediction_malware  nn_prediction_defacemen  \\\n","0           1.000000e+00           0.000000e+00             0.000000e+00   \n","1           2.711595e-23           9.999588e-01             7.637224e-26   \n","2           1.595286e-02           1.405232e-02             1.597526e-01   \n","3           2.974864e-02           6.680746e-03             5.243073e-01   \n","4           1.000000e+00          3.531859e-183            6.471977e-232   \n","...                  ...                    ...                      ...   \n","6891        5.259414e-05           1.664911e-03             1.978808e-10   \n","6892        6.272989e-03           9.691422e-01             1.726208e-03   \n","6893        2.130867e-03           1.387287e-16             9.809828e-01   \n","6894        3.731350e-32           1.152217e-78             3.138492e-38   \n","6895        8.750044e-03           5.050860e-06             9.911237e-01   \n","\n","      nn2_prediction_spam  nn2_prediction_malware  nn2_prediction_defacemen  \n","0            1.000000e+00            0.000000e+00              0.000000e+00  \n","1            2.711595e-23            9.999588e-01              7.637224e-26  \n","2            1.595286e-02            1.405232e-02              1.597526e-01  \n","3            2.974864e-02            6.680746e-03              5.243073e-01  \n","4            1.000000e+00           3.531859e-183             6.471977e-232  \n","...                   ...                     ...                       ...  \n","6891         5.259414e-05            1.664911e-03              1.978808e-10  \n","6892         6.272989e-03            9.691422e-01              1.726208e-03  \n","6893         2.130867e-03            1.387287e-16              9.809828e-01  \n","6894         3.731350e-32            1.152217e-78              3.138492e-38  \n","6895         8.750044e-03            5.050860e-06              9.911237e-01  \n","\n","[6896 rows x 16 columns]"],"text/html":["\n","  <div id=\"df-bbc344a5-6bcf-42b0-9cb0-d7990fd25743\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","      <th>nn2_prediction_non</th>\n","      <th>nn2_prediction_phish</th>\n","      <th>mlp_prediction_spam</th>\n","      <th>mlp_prediction_malware</th>\n","      <th>mlp_prediction_defacemen</th>\n","      <th>nn_prediction_spam</th>\n","      <th>nn_prediction_malware</th>\n","      <th>nn_prediction_defacemen</th>\n","      <th>nn2_prediction_spam</th>\n","      <th>nn2_prediction_malware</th>\n","      <th>nn2_prediction_defacemen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>3.915539e-60</td>\n","      <td>2.680158e-220</td>\n","      <td>3.915539e-60</td>\n","      <td>2.680158e-220</td>\n","      <td>3.915539e-60</td>\n","      <td>2.680158e-220</td>\n","      <td>1.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>2.884644e-06</td>\n","      <td>3.835707e-05</td>\n","      <td>2.884644e-06</td>\n","      <td>3.835707e-05</td>\n","      <td>2.884644e-06</td>\n","      <td>3.835707e-05</td>\n","      <td>2.711595e-23</td>\n","      <td>9.999588e-01</td>\n","      <td>7.637224e-26</td>\n","      <td>2.711595e-23</td>\n","      <td>9.999588e-01</td>\n","      <td>7.637224e-26</td>\n","      <td>2.711595e-23</td>\n","      <td>9.999588e-01</td>\n","      <td>7.637224e-26</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>5.905090e-01</td>\n","      <td>2.197333e-01</td>\n","      <td>5.905090e-01</td>\n","      <td>2.197333e-01</td>\n","      <td>5.905090e-01</td>\n","      <td>2.197333e-01</td>\n","      <td>1.595286e-02</td>\n","      <td>1.405232e-02</td>\n","      <td>1.597526e-01</td>\n","      <td>1.595286e-02</td>\n","      <td>1.405232e-02</td>\n","      <td>1.597526e-01</td>\n","      <td>1.595286e-02</td>\n","      <td>1.405232e-02</td>\n","      <td>1.597526e-01</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>2.825485e-02</td>\n","      <td>4.110084e-01</td>\n","      <td>2.825485e-02</td>\n","      <td>4.110084e-01</td>\n","      <td>2.825485e-02</td>\n","      <td>4.110084e-01</td>\n","      <td>2.974864e-02</td>\n","      <td>6.680746e-03</td>\n","      <td>5.243073e-01</td>\n","      <td>2.974864e-02</td>\n","      <td>6.680746e-03</td>\n","      <td>5.243073e-01</td>\n","      <td>2.974864e-02</td>\n","      <td>6.680746e-03</td>\n","      <td>5.243073e-01</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1.825027e-43</td>\n","      <td>3.029391e-36</td>\n","      <td>1.825027e-43</td>\n","      <td>3.029391e-36</td>\n","      <td>1.825027e-43</td>\n","      <td>3.029391e-36</td>\n","      <td>1.000000e+00</td>\n","      <td>3.531859e-183</td>\n","      <td>6.471977e-232</td>\n","      <td>1.000000e+00</td>\n","      <td>3.531859e-183</td>\n","      <td>6.471977e-232</td>\n","      <td>1.000000e+00</td>\n","      <td>3.531859e-183</td>\n","      <td>6.471977e-232</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6891</th>\n","      <td>1</td>\n","      <td>6.344460e-06</td>\n","      <td>9.982762e-01</td>\n","      <td>6.344460e-06</td>\n","      <td>9.982762e-01</td>\n","      <td>6.344460e-06</td>\n","      <td>9.982762e-01</td>\n","      <td>5.259414e-05</td>\n","      <td>1.664911e-03</td>\n","      <td>1.978808e-10</td>\n","      <td>5.259414e-05</td>\n","      <td>1.664911e-03</td>\n","      <td>1.978808e-10</td>\n","      <td>5.259414e-05</td>\n","      <td>1.664911e-03</td>\n","      <td>1.978808e-10</td>\n","    </tr>\n","    <tr>\n","      <th>6892</th>\n","      <td>3</td>\n","      <td>9.905528e-03</td>\n","      <td>1.295311e-02</td>\n","      <td>9.905528e-03</td>\n","      <td>1.295311e-02</td>\n","      <td>9.905528e-03</td>\n","      <td>1.295311e-02</td>\n","      <td>6.272989e-03</td>\n","      <td>9.691422e-01</td>\n","      <td>1.726208e-03</td>\n","      <td>6.272989e-03</td>\n","      <td>9.691422e-01</td>\n","      <td>1.726208e-03</td>\n","      <td>6.272989e-03</td>\n","      <td>9.691422e-01</td>\n","      <td>1.726208e-03</td>\n","    </tr>\n","    <tr>\n","      <th>6893</th>\n","      <td>2</td>\n","      <td>1.688637e-02</td>\n","      <td>1.032660e-08</td>\n","      <td>1.688637e-02</td>\n","      <td>1.032660e-08</td>\n","      <td>1.688637e-02</td>\n","      <td>1.032660e-08</td>\n","      <td>2.130867e-03</td>\n","      <td>1.387287e-16</td>\n","      <td>9.809828e-01</td>\n","      <td>2.130867e-03</td>\n","      <td>1.387287e-16</td>\n","      <td>9.809828e-01</td>\n","      <td>2.130867e-03</td>\n","      <td>1.387287e-16</td>\n","      <td>9.809828e-01</td>\n","    </tr>\n","    <tr>\n","      <th>6894</th>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>1.986536e-37</td>\n","      <td>1.000000e+00</td>\n","      <td>1.986536e-37</td>\n","      <td>1.000000e+00</td>\n","      <td>1.986536e-37</td>\n","      <td>3.731350e-32</td>\n","      <td>1.152217e-78</td>\n","      <td>3.138492e-38</td>\n","      <td>3.731350e-32</td>\n","      <td>1.152217e-78</td>\n","      <td>3.138492e-38</td>\n","      <td>3.731350e-32</td>\n","      <td>1.152217e-78</td>\n","      <td>3.138492e-38</td>\n","    </tr>\n","    <tr>\n","      <th>6895</th>\n","      <td>4</td>\n","      <td>3.106399e-05</td>\n","      <td>9.016864e-05</td>\n","      <td>3.106399e-05</td>\n","      <td>9.016864e-05</td>\n","      <td>3.106399e-05</td>\n","      <td>9.016864e-05</td>\n","      <td>8.750044e-03</td>\n","      <td>5.050860e-06</td>\n","      <td>9.911237e-01</td>\n","      <td>8.750044e-03</td>\n","      <td>5.050860e-06</td>\n","      <td>9.911237e-01</td>\n","      <td>8.750044e-03</td>\n","      <td>5.050860e-06</td>\n","      <td>9.911237e-01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6896 rows × 16 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbc344a5-6bcf-42b0-9cb0-d7990fd25743')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bbc344a5-6bcf-42b0-9cb0-d7990fd25743 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bbc344a5-6bcf-42b0-9cb0-d7990fd25743');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["output.shape\n"],"metadata":{"id":"0lDqtfllUmwv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656569854689,"user_tz":-330,"elapsed":6,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"7d082b3e-1da0-43fe-a885-da2299ef4ee5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6896, 16)"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["# Storing the data in CSV file\n","output.to_csv('/content/drive/MyDrive/Phishing/UNB/Multi/Base_classifier_result(URL-HTML cross)(3).csv', index=False)"],"metadata":{"id":"ZsQkUbz6AiTx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"RN_-swX0JdhP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"W9DI0WYaJde9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"49lwyWNz0mSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"_9Vdw_Wx2NEo"},"execution_count":null,"outputs":[]}]}