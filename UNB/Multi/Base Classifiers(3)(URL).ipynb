{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Base Classifiers(3)(URL).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"PH13wfswmyDv"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Aiz0olfdKb4b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656572293589,"user_tz":-330,"elapsed":23238,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"cb69c712-cf44-4505-f6a5-8fa35573baa2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["urldata = pd.read_csv(\"/content/drive/MyDrive/Phishing/UNB/URL-HTML/preprocessed_url_features(multi).csv\")\n","urldata\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":485},"id":"Dw-EEymHAGNs","outputId":"ba5a7cd2-a2c6-46c1-8f65-cb107255e5cf","executionInfo":{"status":"ok","timestamp":1656572300596,"user_tz":-330,"elapsed":1507,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Unnamed: 0  Have IP  Have @  URL Length  URL Depth  Redirection  \\\n","0               0        0       0           1          1            0   \n","1               1        0       0           1          1            1   \n","2               2        0       0           1          1            0   \n","3               3        0       0           1          3            0   \n","4               4        0       0           1          3            0   \n","...           ...      ...     ...         ...        ...          ...   \n","15319       23429        0       0           1          1            0   \n","15320       23430        0       0           1          1            0   \n","15321       23431        0       0           1          1            0   \n","15322       23432        0       0           1          1            0   \n","15323       23433        0       0           1          1            0   \n","\n","       https Domain  TinyURL  Prefix/Suffix  Have client  ...  Num Embeds  \\\n","0                 0        0              0            0  ...           0   \n","1                 0        0              0            0  ...           0   \n","2                 1        0              0            0  ...           0   \n","3                 0        0              0            0  ...           0   \n","4                 0        0              0            0  ...           0   \n","...             ...      ...            ...          ...  ...         ...   \n","15319             0        0              0            0  ...           0   \n","15320             0        0              0            0  ...           0   \n","15321             0        0              0            0  ...           0   \n","15322             0        0              0            0  ...           0   \n","15323             0        0              0            0  ...           0   \n","\n","       Num Images  Num Links  Num Titles  Num Script  Special Characters  \\\n","0              49        691          42       13135                6400   \n","1               4         66           3        2034                 818   \n","2               1        100          27       32987               10451   \n","3               0          0           1           0                  52   \n","4             117        219          23        7944                3468   \n","...           ...        ...         ...         ...                 ...   \n","15319           0          0           1           0                   4   \n","15320           0          0           1           0                   4   \n","15321           0          0           1           0                   4   \n","15322           0          0           1           0                   4   \n","15323           0          0           1           0                   4   \n","\n","       Script To Special Chars Ratio  Script To body Ratio  \\\n","0                           2.052344              0.528869   \n","1                           2.486553              0.676197   \n","2                           3.156349              0.836681   \n","3                           0.000000              0.000000   \n","4                           2.290657              0.524460   \n","...                              ...                   ...   \n","15319                       0.000000              0.000000   \n","15320                       0.000000              0.000000   \n","15321                       0.000000              0.000000   \n","15322                       0.000000              0.000000   \n","15323                       0.000000              0.000000   \n","\n","       Body To Special Char Ratio  Label  \n","0                        0.257690      0  \n","1                        0.271941      0  \n","2                        0.265079      0  \n","3                        0.227074      0  \n","4                        0.228956      0  \n","...                           ...    ...  \n","15319                    0.121212      4  \n","15320                    0.121212      4  \n","15321                    0.121212      4  \n","15322                    0.121212      4  \n","15323                    0.121212      4  \n","\n","[15324 rows x 46 columns]"],"text/html":["\n","  <div id=\"df-5509b6a5-d060-42df-9d5f-0d5de0ce6e6a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>691</td>\n","      <td>42</td>\n","      <td>13135</td>\n","      <td>6400</td>\n","      <td>2.052344</td>\n","      <td>0.528869</td>\n","      <td>0.257690</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>66</td>\n","      <td>3</td>\n","      <td>2034</td>\n","      <td>818</td>\n","      <td>2.486553</td>\n","      <td>0.676197</td>\n","      <td>0.271941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>27</td>\n","      <td>32987</td>\n","      <td>10451</td>\n","      <td>3.156349</td>\n","      <td>0.836681</td>\n","      <td>0.265079</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.227074</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>117</td>\n","      <td>219</td>\n","      <td>23</td>\n","      <td>7944</td>\n","      <td>3468</td>\n","      <td>2.290657</td>\n","      <td>0.524460</td>\n","      <td>0.228956</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>15319</th>\n","      <td>23429</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.121212</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>15320</th>\n","      <td>23430</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.121212</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>15321</th>\n","      <td>23431</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.121212</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>15322</th>\n","      <td>23432</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.121212</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>15323</th>\n","      <td>23433</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.121212</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>15324 rows × 46 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5509b6a5-d060-42df-9d5f-0d5de0ce6e6a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5509b6a5-d060-42df-9d5f-0d5de0ce6e6a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5509b6a5-d060-42df-9d5f-0d5de0ce6e6a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["urldata.columns"],"metadata":{"id":"JQ4_qEulWybT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd84a7d9-23c4-4e96-c1e7-0ebd38668444","executionInfo":{"status":"ok","timestamp":1656572301019,"user_tz":-330,"elapsed":6,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Unnamed: 0', 'Have IP', 'Have @', 'URL Length', 'URL Depth',\n","       'Redirection', 'https Domain', 'TinyURL', 'Prefix/Suffix',\n","       'Have client', 'Have admin', 'Have login', 'Have server', '.php',\n","       '.html', '.info', '.txt', '.js', '.exe', 'Num of periods', 'Is encoded',\n","       'Num of encoded char', 'Num of parameters', 'Num of digits',\n","       'Num of spec char', 'iFrame', 'Mouse Over', 'Right Click',\n","       'Web Forwards', 'Number of page tokens', 'number of sentences',\n","       'number of html tags', 'number of whitespace', 'url Is Live',\n","       'HTML Length', 'Num Objects', 'Num Embeds', 'Num Images', 'Num Links',\n","       'Num Titles', 'Num Script', 'Special Characters',\n","       'Script To Special Chars Ratio', 'Script To body Ratio',\n","       'Body To Special Char Ratio', 'Label'],\n","      dtype='object')"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["urldata = urldata.drop(['Unnamed: 0', 'iFrame', 'Mouse Over', 'Right Click',\n","       'Web Forwards', 'Number of page tokens', 'number of sentences',\n","       'number of html tags', 'number of whitespace', 'url Is Live',\n","       'HTML Length', 'Num Objects', 'Num Embeds', 'Num Images', 'Num Links',\n","       'Num Titles', 'Num Script', 'Special Characters',\n","       'Script To Special Chars Ratio', 'Script To body Ratio',\n","       'Body To Special Char Ratio'], axis = 1).copy()\n","# urldata = urldata.drop(['Domain'], axis = 1).copy()\n","urldata.shape\n","urldata.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"qwye89TwRTOH","executionInfo":{"status":"ok","timestamp":1656572304455,"user_tz":-330,"elapsed":877,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"8423568d-71a6-43f0-ac86-2af44655b868"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Have IP  Have @  URL Length  URL Depth  Redirection  https Domain  TinyURL  \\\n","0        0       0           1          1            0             0        0   \n","1        0       0           1          1            1             0        0   \n","2        0       0           1          1            0             1        0   \n","3        0       0           1          3            0             0        0   \n","4        0       0           1          3            0             0        0   \n","\n","   Prefix/Suffix  Have client  Have admin  ...  .txt  .js  .exe  \\\n","0              0            0           0  ...     0    0     0   \n","1              0            0           0  ...     0    0     0   \n","2              0            0           0  ...     0    0     0   \n","3              0            0           0  ...     0    0     0   \n","4              0            0           0  ...     0    0     0   \n","\n","   Num of periods  Is encoded  Num of encoded char  Num of parameters  \\\n","0               1           0                    0                 10   \n","1               4           1                    2                  3   \n","2               1           1                    2                  2   \n","3               4           1                    5                  0   \n","4               2           0                    0                  1   \n","\n","   Num of digits  Num of spec char  Label  \n","0              0                25      0  \n","1             22                13      0  \n","2              2                 9      0  \n","3             19                18      0  \n","4             17                 7      0  \n","\n","[5 rows x 25 columns]"],"text/html":["\n","  <div id=\"df-8d5a1f2e-9bcb-4fd7-b336-ca2545c1bb94\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>Have admin</th>\n","      <th>...</th>\n","      <th>.txt</th>\n","      <th>.js</th>\n","      <th>.exe</th>\n","      <th>Num of periods</th>\n","      <th>Is encoded</th>\n","      <th>Num of encoded char</th>\n","      <th>Num of parameters</th>\n","      <th>Num of digits</th>\n","      <th>Num of spec char</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>25</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>22</td>\n","      <td>13</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>19</td>\n","      <td>18</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>17</td>\n","      <td>7</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 25 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d5a1f2e-9bcb-4fd7-b336-ca2545c1bb94')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8d5a1f2e-9bcb-4fd7-b336-ca2545c1bb94 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8d5a1f2e-9bcb-4fd7-b336-ca2545c1bb94');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["urldata.info()"],"metadata":{"id":"kKvKkmUNP5Cx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"03e0ed92-7fc9-4de0-c089-d933265784cf","executionInfo":{"status":"ok","timestamp":1656572304456,"user_tz":-330,"elapsed":18,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 15324 entries, 0 to 15323\n","Data columns (total 25 columns):\n"," #   Column               Non-Null Count  Dtype\n","---  ------               --------------  -----\n"," 0   Have IP              15324 non-null  int64\n"," 1   Have @               15324 non-null  int64\n"," 2   URL Length           15324 non-null  int64\n"," 3   URL Depth            15324 non-null  int64\n"," 4   Redirection          15324 non-null  int64\n"," 5   https Domain         15324 non-null  int64\n"," 6   TinyURL              15324 non-null  int64\n"," 7   Prefix/Suffix        15324 non-null  int64\n"," 8   Have client          15324 non-null  int64\n"," 9   Have admin           15324 non-null  int64\n"," 10  Have login           15324 non-null  int64\n"," 11  Have server          15324 non-null  int64\n"," 12  .php                 15324 non-null  int64\n"," 13  .html                15324 non-null  int64\n"," 14  .info                15324 non-null  int64\n"," 15  .txt                 15324 non-null  int64\n"," 16  .js                  15324 non-null  int64\n"," 17  .exe                 15324 non-null  int64\n"," 18  Num of periods       15324 non-null  int64\n"," 19  Is encoded           15324 non-null  int64\n"," 20  Num of encoded char  15324 non-null  int64\n"," 21  Num of parameters    15324 non-null  int64\n"," 22  Num of digits        15324 non-null  int64\n"," 23  Num of spec char     15324 non-null  int64\n"," 24  Label                15324 non-null  int64\n","dtypes: int64(25)\n","memory usage: 2.9 MB\n"]}]},{"cell_type":"code","source":["# Class Distribution of Labels\n","urldata.groupby('Label').size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvS3OQHTSHDt","executionInfo":{"status":"ok","timestamp":1656572304459,"user_tz":-330,"elapsed":16,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"d53ff950-9556-414d-94e0-e3c9c9de18f7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Label\n","0    4954\n","1    1573\n","2    3002\n","3    3543\n","4    2252\n","dtype: int64"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["\n","import numpy as np\n"],"metadata":{"id":"eLm1720QSaAv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["urldata.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"id":"WX-8Xbm3cfFf","outputId":"383e10b8-0f69-4a79-86ac-a71213a92262","executionInfo":{"status":"ok","timestamp":1656572313743,"user_tz":-330,"elapsed":31,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Have IP        Have @    URL Length     URL Depth   Redirection  \\\n","count  15324.0  15324.000000  15324.000000  15324.000000  15324.000000   \n","mean       0.0      0.003067      0.897938      3.190029      0.027212   \n","std        0.0      0.055298      0.302740      2.526227      0.162707   \n","min        0.0      0.000000      0.000000      0.000000      0.000000   \n","25%        0.0      0.000000      1.000000      1.000000      0.000000   \n","50%        0.0      0.000000      1.000000      2.000000      0.000000   \n","75%        0.0      0.000000      1.000000      4.000000      0.000000   \n","max        0.0      1.000000      1.000000     18.000000      1.000000   \n","\n","       https Domain       TinyURL  Prefix/Suffix   Have client    Have admin  \\\n","count  15324.000000  15324.000000   15324.000000  15324.000000  15324.000000   \n","mean       0.027930      0.034978       0.073871      0.001305      0.010702   \n","std        0.164778      0.183730       0.261569      0.036104      0.102900   \n","min        0.000000      0.000000       0.000000      0.000000      0.000000   \n","25%        0.000000      0.000000       0.000000      0.000000      0.000000   \n","50%        0.000000      0.000000       0.000000      0.000000      0.000000   \n","75%        0.000000      0.000000       0.000000      0.000000      0.000000   \n","max        1.000000      1.000000       1.000000      1.000000      1.000000   \n","\n","       ...          .txt           .js          .exe  Num of periods  \\\n","count  ...  15324.000000  15324.000000  15324.000000    15324.000000   \n","mean   ...      0.003132      0.026429      0.001305        2.598865   \n","std    ...      0.055881      0.160413      0.036104        1.816973   \n","min    ...      0.000000      0.000000      0.000000        1.000000   \n","25%    ...      0.000000      0.000000      0.000000        1.000000   \n","50%    ...      0.000000      0.000000      0.000000        2.000000   \n","75%    ...      0.000000      0.000000      0.000000        3.000000   \n","max    ...      1.000000      1.000000      1.000000       21.000000   \n","\n","         Is encoded  Num of encoded char  Num of parameters  Num of digits  \\\n","count  15324.000000         15324.000000       15324.000000   15324.000000   \n","mean       0.211564             5.016445           1.348147      15.870204   \n","std        0.408430            12.407880           2.519592      16.435665   \n","min        0.000000             0.000000           0.000000       0.000000   \n","25%        0.000000             0.000000           0.000000       4.000000   \n","50%        0.000000             0.000000           0.000000      11.000000   \n","75%        0.000000             0.000000           2.000000      25.000000   \n","max        1.000000           201.000000          19.000000     259.000000   \n","\n","       Num of spec char         Label  \n","count      15324.000000  15324.000000  \n","mean          10.220765      1.775907  \n","std           12.732849      1.471309  \n","min            0.000000      0.000000  \n","25%            1.000000      0.000000  \n","50%            7.000000      2.000000  \n","75%           13.000000      3.000000  \n","max          201.000000      4.000000  \n","\n","[8 rows x 25 columns]"],"text/html":["\n","  <div id=\"df-3970978e-eba1-4829-9630-72ea434fd2bb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>Have admin</th>\n","      <th>...</th>\n","      <th>.txt</th>\n","      <th>.js</th>\n","      <th>.exe</th>\n","      <th>Num of periods</th>\n","      <th>Is encoded</th>\n","      <th>Num of encoded char</th>\n","      <th>Num of parameters</th>\n","      <th>Num of digits</th>\n","      <th>Num of spec char</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>15324.0</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>...</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","      <td>15324.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.0</td>\n","      <td>0.003067</td>\n","      <td>0.897938</td>\n","      <td>3.190029</td>\n","      <td>0.027212</td>\n","      <td>0.027930</td>\n","      <td>0.034978</td>\n","      <td>0.073871</td>\n","      <td>0.001305</td>\n","      <td>0.010702</td>\n","      <td>...</td>\n","      <td>0.003132</td>\n","      <td>0.026429</td>\n","      <td>0.001305</td>\n","      <td>2.598865</td>\n","      <td>0.211564</td>\n","      <td>5.016445</td>\n","      <td>1.348147</td>\n","      <td>15.870204</td>\n","      <td>10.220765</td>\n","      <td>1.775907</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.0</td>\n","      <td>0.055298</td>\n","      <td>0.302740</td>\n","      <td>2.526227</td>\n","      <td>0.162707</td>\n","      <td>0.164778</td>\n","      <td>0.183730</td>\n","      <td>0.261569</td>\n","      <td>0.036104</td>\n","      <td>0.102900</td>\n","      <td>...</td>\n","      <td>0.055881</td>\n","      <td>0.160413</td>\n","      <td>0.036104</td>\n","      <td>1.816973</td>\n","      <td>0.408430</td>\n","      <td>12.407880</td>\n","      <td>2.519592</td>\n","      <td>16.435665</td>\n","      <td>12.732849</td>\n","      <td>1.471309</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>11.000000</td>\n","      <td>7.000000</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>4.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>25.000000</td>\n","      <td>13.000000</td>\n","      <td>3.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>18.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>21.000000</td>\n","      <td>1.000000</td>\n","      <td>201.000000</td>\n","      <td>19.000000</td>\n","      <td>259.000000</td>\n","      <td>201.000000</td>\n","      <td>4.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 25 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3970978e-eba1-4829-9630-72ea434fd2bb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3970978e-eba1-4829-9630-72ea434fd2bb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3970978e-eba1-4829-9630-72ea434fd2bb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["\n"],"metadata":{"id":"bUPfWi4TcfIA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#checking the data for null or missing values\n","urldata.isnull().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3PEbrTLcfXg","outputId":"a0b65e17-61ce-4803-c1cc-272f843fbaab","executionInfo":{"status":"ok","timestamp":1656572313750,"user_tz":-330,"elapsed":34,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Have IP                0\n","Have @                 0\n","URL Length             0\n","URL Depth              0\n","Redirection            0\n","https Domain           0\n","TinyURL                0\n","Prefix/Suffix          0\n","Have client            0\n","Have admin             0\n","Have login             0\n","Have server            0\n",".php                   0\n",".html                  0\n",".info                  0\n",".txt                   0\n",".js                    0\n",".exe                   0\n","Num of periods         0\n","Is encoded             0\n","Num of encoded char    0\n","Num of parameters      0\n","Num of digits          0\n","Num of spec char       0\n","Label                  0\n","dtype: int64"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# shuffling the rows in the dataset so that when splitting the train and test set are equally distributed\n","urldata = urldata.sample(frac=1).reset_index(drop=True)\n","urldata.head()"],"metadata":{"id":"n6YfGa82P5JZ","colab":{"base_uri":"https://localhost:8080/","height":297},"outputId":"6948f298-c6d3-4cd1-a12d-3ecb48b28c1c","executionInfo":{"status":"ok","timestamp":1656572313752,"user_tz":-330,"elapsed":32,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Have IP  Have @  URL Length  URL Depth  Redirection  https Domain  TinyURL  \\\n","0        0       0           1          1            0             0        0   \n","1        0       0           1          5            0             0        0   \n","2        0       0           1         10            0             0        0   \n","3        0       0           0          1            0             0        0   \n","4        0       0           1          1            0             0        0   \n","\n","   Prefix/Suffix  Have client  Have admin  ...  .txt  .js  .exe  \\\n","0              0            0           0  ...     0    0     0   \n","1              0            0           0  ...     0    0     0   \n","2              0            0           0  ...     0    0     0   \n","3              0            0           0  ...     0    0     0   \n","4              1            0           0  ...     0    0     0   \n","\n","   Num of periods  Is encoded  Num of encoded char  Num of parameters  \\\n","0               4           0                    0                  2   \n","1               1           0                    0                  0   \n","2               1           0                    0                  0   \n","3               3           0                    0                  1   \n","4               3           0                    0                  4   \n","\n","   Num of digits  Num of spec char  Label  \n","0              2                 4      4  \n","1              8                11      0  \n","2             18                 0      0  \n","3              2                 1      4  \n","4              6                 9      4  \n","\n","[5 rows x 25 columns]"],"text/html":["\n","  <div id=\"df-a8c26a53-9454-41c6-9beb-b902e93fa29a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>Have admin</th>\n","      <th>...</th>\n","      <th>.txt</th>\n","      <th>.js</th>\n","      <th>.exe</th>\n","      <th>Num of periods</th>\n","      <th>Is encoded</th>\n","      <th>Num of encoded char</th>\n","      <th>Num of parameters</th>\n","      <th>Num of digits</th>\n","      <th>Num of spec char</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>11</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>9</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 25 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8c26a53-9454-41c6-9beb-b902e93fa29a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a8c26a53-9454-41c6-9beb-b902e93fa29a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a8c26a53-9454-41c6-9beb-b902e93fa29a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# Sepratating & assigning features and target columns to X & y\n","y = urldata['Label'].values\n","x = np.array(urldata.drop('Label',axis=1))\n","\n"],"metadata":{"id":"Lasv_YzlP5L6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Splitting the dataset into train and test sets: 80-20 split\n","from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, \n","                                                    test_size = 0.45, random_state = 12)\n","print(x_train.shape, x_test.shape)\n","print(y_train.shape, y_test.shape)\n","\n"],"metadata":{"id":"in9C2ArWP5O0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"98f7e273-297e-4694-97eb-aec8242875e8","executionInfo":{"status":"ok","timestamp":1656572314335,"user_tz":-330,"elapsed":613,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(8428, 24) (6896, 24)\n","(8428,) (6896,)\n"]}]},{"cell_type":"code","source":["output = {}\n","output['labels'] = y_test"],"metadata":{"id":"jv6Y5m8ddMHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"fg4rdoEnUE0O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOV9VybfNIgE"},"source":["**MLP**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mr-AOgJ1JtXY"},"outputs":[],"source":["import keras\n","\n","from sklearn.neural_network import MLPClassifier\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","import pickle\n","\n","def model_mlp(x_train, x_val, y_train, y_val, opt, n):\n","  mlpclassifier = MLPClassifier(alpha=0.0001, hidden_layer_sizes=([100,100,100]))\n","  #compile model using mse as a measure of model performance\n","  mlpclassifier.fit(x_train, y_train)\n","\n","  y_pred = mlpclassifier.predict(x_val)\n","\n","  conf_matrix = confusion_matrix(y_val, y_pred)\n","  print(conf_matrix)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred, average='weighted'))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred, average='weighted'))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred, average='weighted'))\n","\n","  \n","  print(\"Validation Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/URL/MLP/model_'+str(n)+'.h5'\n","  pickle.dump(mlpclassifier, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","  return metrics.accuracy_score(y_val, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUCxdcapJtXZ","executionInfo":{"status":"ok","timestamp":1656572555781,"user_tz":-330,"elapsed":218885,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"c5f7ae70-4ee1-4394-80f2-cae681f72bab"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[253   1   1   3   2]\n"," [  2  72   2   1   1]\n"," [  0   0 166   0   2]\n"," [  2   2   1 181   0]\n"," [  3   0   7   1 140]]\n","Precision: 0.9635\n","Recall: 0.9632\n","F1 Score: 0.9631\n","Validation Accuracy: 0.963226571767497\n","model 0 saved\n","[[267   2   1   2   0]\n"," [  2  77   2   2   0]\n"," [  0   2 176   0   5]\n"," [  1   1   0 177   0]\n"," [  0   0  11   0 115]]\n","Precision: 0.9635\n","Recall: 0.9632\n","F1 Score: 0.9632\n","Validation Accuracy: 0.963226571767497\n","model 1 saved\n","[[244   2   1   0   0]\n"," [  5  74   2   5   1]\n"," [  2   2 162   2   2]\n"," [  4   2   1 218   0]\n"," [  3   2   4   0 105]]\n","Precision: 0.9525\n","Recall: 0.9526\n","F1 Score: 0.9522\n","Validation Accuracy: 0.9525504151838672\n","model 2 saved\n","[[270   0   0   4   0]\n"," [  7  69   1   8   2]\n"," [  1   0 164   0   3]\n"," [  1   0   1 202   0]\n"," [  1   0   1   0 108]]\n","Precision: 0.9655\n","Recall: 0.9644\n","F1 Score: 0.9635\n","Validation Accuracy: 0.9644128113879004\n","model 3 saved\n","[[259   0   1   4   1]\n"," [  3  76   2   1   1]\n"," [  3   3 156   2   2]\n"," [  7   1   0 184   1]\n"," [  3   1   7   0 125]]\n","Precision: 0.9492\n","Recall: 0.9490\n","F1 Score: 0.9489\n","Validation Accuracy: 0.9489916963226572\n","model 4 saved\n","[[289   1   1   3   0]\n"," [  5  89   0   1   2]\n"," [  2   0 144   2   3]\n"," [  2   1   0 189   0]\n"," [  1   0   4   1 103]]\n","Precision: 0.9657\n","Recall: 0.9656\n","F1 Score: 0.9655\n","Validation Accuracy: 0.9655990510083037\n","model 5 saved\n","[[267   5   1   1   0]\n"," [  3  64   3   2   1]\n"," [  2   4 154   0   8]\n"," [  5   1   1 198   0]\n"," [  0   0   4   0 119]]\n","Precision: 0.9517\n","Recall: 0.9514\n","F1 Score: 0.9514\n","Validation Accuracy: 0.9513641755634639\n","model 6 saved\n","[[284   2   3   1   0]\n"," [  1  78   2   0   2]\n"," [  1   1 145   0   4]\n"," [  4   1   2 180   0]\n"," [  1   0   5   0 126]]\n","Precision: 0.9649\n","Recall: 0.9644\n","F1 Score: 0.9645\n","Validation Accuracy: 0.9644128113879004\n","model 7 saved\n","[[274   6   1   6   0]\n"," [  4  76   1   1   1]\n"," [  0   5 155   1   6]\n"," [  4   0   2 180   0]\n"," [  2   0   4   1 112]]\n","Precision: 0.9470\n","Recall: 0.9466\n","F1 Score: 0.9467\n","Validation Accuracy: 0.9465558194774347\n","model 8 saved\n","[[261   1   2   4   2]\n"," [  3  70   4   2   1]\n"," [  4   2 163   0   9]\n"," [  5   0   0 196   0]\n"," [  0   0   1   0 112]]\n","Precision: 0.9532\n","Recall: 0.9525\n","F1 Score: 0.9523\n","Validation Accuracy: 0.9524940617577197\n","model 9 saved\n","Average Validation Accuracy: 0.9572833985624241\n"]}],"source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_mlp(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":649},"executionInfo":{"elapsed":635,"status":"ok","timestamp":1656572719733,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"6DA16IlPJtXZ","outputId":"d690b657-f52b-4ac0-a2c2-87ae18649483"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[2.27930408e-01 3.52669068e-07 3.17896223e-09 7.72068989e-01\n","  2.47127316e-07]\n"," [9.99849322e-01 4.83915474e-07 1.51218955e-09 1.50192352e-04\n","  2.28598272e-10]\n"," [1.28142616e-06 1.73256713e-08 3.98062294e-11 9.99998200e-01\n","  5.01489322e-07]\n"," ...\n"," [9.99685499e-01 1.59853046e-05 1.31639481e-12 2.98512764e-04\n","  3.36510890e-09]\n"," [1.66346146e-10 3.93031973e-02 9.60689680e-01 1.14207633e-11\n","  7.12230582e-06]\n"," [1.95998885e-04 9.99801785e-01 1.53610390e-11 2.21641900e-06\n","  3.52212170e-16]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  mlp_prediction_spam  \\\n","0          0        2.279304e-01          3.526691e-07         3.178962e-09   \n","1          0        9.998493e-01          4.839155e-07         1.512190e-09   \n","2          3        1.281426e-06          1.732567e-08         3.980623e-11   \n","3          3        1.273963e-03          6.203745e-08         6.837719e-12   \n","4          2        7.031173e-09          1.819293e-04         9.998181e-01   \n","...      ...                 ...                   ...                  ...   \n","6891       4        1.892153e-12          2.127109e-12         5.182954e-10   \n","6892       1        1.789397e-04          9.990517e-01         2.676060e-04   \n","6893       0        9.996855e-01          1.598530e-05         1.316395e-12   \n","6894       2        1.663461e-10          3.930320e-02         9.606897e-01   \n","6895       1        1.959989e-04          9.998018e-01         1.536104e-11   \n","\n","      mlp_prediction_malware  mlp_prediction_defacemen  \n","0               7.720690e-01              2.471273e-07  \n","1               1.501924e-04              2.285983e-10  \n","2               9.999982e-01              5.014893e-07  \n","3               9.987260e-01              1.322388e-11  \n","4               7.719379e-15              2.118226e-11  \n","...                      ...                       ...  \n","6891            1.837704e-16              1.000000e+00  \n","6892            5.004229e-04              1.291414e-06  \n","6893            2.985128e-04              3.365109e-09  \n","6894            1.142076e-11              7.122306e-06  \n","6895            2.216419e-06              3.522122e-16  \n","\n","[6896 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-136b9a7d-3819-4c34-97a2-5e996de52969\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>mlp_prediction_spam</th>\n","      <th>mlp_prediction_malware</th>\n","      <th>mlp_prediction_defacemen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2.279304e-01</td>\n","      <td>3.526691e-07</td>\n","      <td>3.178962e-09</td>\n","      <td>7.720690e-01</td>\n","      <td>2.471273e-07</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>9.998493e-01</td>\n","      <td>4.839155e-07</td>\n","      <td>1.512190e-09</td>\n","      <td>1.501924e-04</td>\n","      <td>2.285983e-10</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1.281426e-06</td>\n","      <td>1.732567e-08</td>\n","      <td>3.980623e-11</td>\n","      <td>9.999982e-01</td>\n","      <td>5.014893e-07</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1.273963e-03</td>\n","      <td>6.203745e-08</td>\n","      <td>6.837719e-12</td>\n","      <td>9.987260e-01</td>\n","      <td>1.322388e-11</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>7.031173e-09</td>\n","      <td>1.819293e-04</td>\n","      <td>9.998181e-01</td>\n","      <td>7.719379e-15</td>\n","      <td>2.118226e-11</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6891</th>\n","      <td>4</td>\n","      <td>1.892153e-12</td>\n","      <td>2.127109e-12</td>\n","      <td>5.182954e-10</td>\n","      <td>1.837704e-16</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>6892</th>\n","      <td>1</td>\n","      <td>1.789397e-04</td>\n","      <td>9.990517e-01</td>\n","      <td>2.676060e-04</td>\n","      <td>5.004229e-04</td>\n","      <td>1.291414e-06</td>\n","    </tr>\n","    <tr>\n","      <th>6893</th>\n","      <td>0</td>\n","      <td>9.996855e-01</td>\n","      <td>1.598530e-05</td>\n","      <td>1.316395e-12</td>\n","      <td>2.985128e-04</td>\n","      <td>3.365109e-09</td>\n","    </tr>\n","    <tr>\n","      <th>6894</th>\n","      <td>2</td>\n","      <td>1.663461e-10</td>\n","      <td>3.930320e-02</td>\n","      <td>9.606897e-01</td>\n","      <td>1.142076e-11</td>\n","      <td>7.122306e-06</td>\n","    </tr>\n","    <tr>\n","      <th>6895</th>\n","      <td>1</td>\n","      <td>1.959989e-04</td>\n","      <td>9.998018e-01</td>\n","      <td>1.536104e-11</td>\n","      <td>2.216419e-06</td>\n","      <td>3.522122e-16</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6896 rows × 6 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-136b9a7d-3819-4c34-97a2-5e996de52969')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-136b9a7d-3819-4c34-97a2-5e996de52969 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-136b9a7d-3819-4c34-97a2-5e996de52969');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}],"source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/URL/MLP/model_5.h5'\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['mlp_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['mlp_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output['mlp_prediction_spam'] = [i[2] for i in y_pred_prob];\n","output['mlp_prediction_malware'] = [i[3] for i in y_pred_prob];\n","output['mlp_prediction_defacemen'] = [i[4] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output\n"]},{"cell_type":"markdown","source":["**Neural Network**"],"metadata":{"id":"iLF4sz5NsSZ6"}},{"cell_type":"code","source":["\n","import keras\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","def model_aa(x_train, x_val, y_train, y_val, opt, n, early_stopping_monitor):\n","\n","  n_cols = x_train.shape[1]\n","  # print(\"check point\")\n","  #create model\n","  model = Sequential()\n","  model.add(Dense(30, activation='relu', input_shape=(n_cols,)))\n","  model.add(Dense(10, activation='relu'))\n","\n","  model.add(Dense(1, activation = 'sigmoid'))\n","  # softmax\n","  #compile model using mse as a measure of model performance\n","  model.compile(optimizer = opt, loss= 'binary_crossentropy', metrics=[\"accuracy\"])\n","\n","  history = model.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping_monitor])\n","\n","\n","  # plt.plot(history.history['loss'])\n","  # plt.plot(history.history['val_loss'])\n","  # plt.title('model loss')\n","  # plt.ylabel('Loss')\n","  # plt.xlabel('Epoch')\n","  # plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n","  # plt.show()\n","\n","\n","  print('Validation Accuracy: ')\n","  # Predicting the Test set results\n","  y_pred = model.predict(x_val)\n","  y_pred = (y_pred > 0.5)\n","\n","\n","  print(classification_report(y_val, y_pred))\n","\n","  # Model Accuracy, how often is the classifier correct?\n","  print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","\n","  # Creating the Confusion Matrix\n","  cm = confusion_matrix(y_val, y_pred)\n","  print(cm)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred, average='weighted'))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred, average='weighted'))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred, average='weighted'))\n","\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/URL/NN/model_'+str(n)+'.h5'\n","  pickle.dump(model, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","\n","  return metrics.accuracy_score(y_val, y_pred)\n","\n"],"metadata":{"id":"UfilmHKnL3LC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_aa(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n, early_stopping_monitor)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_OHdM1HNDio","executionInfo":{"status":"ok","timestamp":1656573524678,"user_tz":-330,"elapsed":803630,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"95914520-0397-4c39-f4a5-2d293d8781c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","238/238 [==============================] - 5s 5ms/step - loss: -4.4652 - accuracy: 0.1173 - val_loss: -19.0647 - val_accuracy: 0.0925\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -103.4408 - accuracy: 0.0997 - val_loss: -261.0423 - val_accuracy: 0.0925\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -578.5837 - accuracy: 0.0997 - val_loss: -1029.1730 - val_accuracy: 0.0925\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1682.0343 - accuracy: 0.0997 - val_loss: -2508.3130 - val_accuracy: 0.0925\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3543.9512 - accuracy: 0.0997 - val_loss: -4815.1465 - val_accuracy: 0.0925\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6271.7061 - accuracy: 0.0997 - val_loss: -8036.0908 - val_accuracy: 0.0925\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9966.2920 - accuracy: 0.0997 - val_loss: -12266.7979 - val_accuracy: 0.0925\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14660.4336 - accuracy: 0.0997 - val_loss: -17556.0664 - val_accuracy: 0.0925\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -20382.3809 - accuracy: 0.0997 - val_loss: -23827.1621 - val_accuracy: 0.0925\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -27182.6250 - accuracy: 0.0997 - val_loss: -31252.0898 - val_accuracy: 0.0925\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -35152.2383 - accuracy: 0.0997 - val_loss: -39941.2539 - val_accuracy: 0.0925\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -44374.9922 - accuracy: 0.0997 - val_loss: -49844.7461 - val_accuracy: 0.0925\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -54818.6914 - accuracy: 0.0997 - val_loss: -60962.4805 - val_accuracy: 0.0925\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -66418.9922 - accuracy: 0.0997 - val_loss: -73309.9297 - val_accuracy: 0.0925\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -79378.8672 - accuracy: 0.0997 - val_loss: -87013.4844 - val_accuracy: 0.0925\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -93713.0391 - accuracy: 0.0997 - val_loss: -102164.4688 - val_accuracy: 0.0925\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -109612.3828 - accuracy: 0.0997 - val_loss: -118713.6641 - val_accuracy: 0.0925\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -126500.3438 - accuracy: 0.0997 - val_loss: -136446.5938 - val_accuracy: 0.0925\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -144784.6094 - accuracy: 0.0997 - val_loss: -155700.9375 - val_accuracy: 0.0925\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -164689.3125 - accuracy: 0.0997 - val_loss: -176343.8594 - val_accuracy: 0.0925\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -185765.3125 - accuracy: 0.0997 - val_loss: -198530.2344 - val_accuracy: 0.0925\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -208554.0156 - accuracy: 0.0997 - val_loss: -222075.8281 - val_accuracy: 0.0925\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -232834.1406 - accuracy: 0.0997 - val_loss: -247379.0000 - val_accuracy: 0.0925\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -258585.3594 - accuracy: 0.0997 - val_loss: -274088.5938 - val_accuracy: 0.0925\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -285862.4688 - accuracy: 0.0997 - val_loss: -302458.8438 - val_accuracy: 0.0925\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -315039.8438 - accuracy: 0.0997 - val_loss: -332701.8125 - val_accuracy: 0.0925\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -346272.2500 - accuracy: 0.0997 - val_loss: -365007.4062 - val_accuracy: 0.0925\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -379072.6875 - accuracy: 0.0997 - val_loss: -398418.0625 - val_accuracy: 0.0925\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -412747.6875 - accuracy: 0.0997 - val_loss: -433468.9375 - val_accuracy: 0.0925\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -448250.3438 - accuracy: 0.0997 - val_loss: -469983.3125 - val_accuracy: 0.0925\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -485491.6250 - accuracy: 0.0997 - val_loss: -508728.6875 - val_accuracy: 0.0925\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -524884.8750 - accuracy: 0.0997 - val_loss: -549188.7500 - val_accuracy: 0.0925\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -565950.1250 - accuracy: 0.0997 - val_loss: -591606.5625 - val_accuracy: 0.0925\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -608948.3125 - accuracy: 0.0997 - val_loss: -635988.9375 - val_accuracy: 0.0925\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -654148.3750 - accuracy: 0.0997 - val_loss: -682394.2500 - val_accuracy: 0.0925\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -701467.0625 - accuracy: 0.0997 - val_loss: -730929.5625 - val_accuracy: 0.0925\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -750293.5000 - accuracy: 0.0997 - val_loss: -780989.0625 - val_accuracy: 0.0925\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -801857.4375 - accuracy: 0.0997 - val_loss: -833856.0000 - val_accuracy: 0.0925\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -854532.1875 - accuracy: 0.0997 - val_loss: -888024.8750 - val_accuracy: 0.0925\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -909813.1250 - accuracy: 0.0997 - val_loss: -944844.2500 - val_accuracy: 0.0925\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -966730.4375 - accuracy: 0.0997 - val_loss: -1003023.6875 - val_accuracy: 0.0925\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1025882.8750 - accuracy: 0.0997 - val_loss: -1063727.5000 - val_accuracy: 0.0925\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1088332.0000 - accuracy: 0.0997 - val_loss: -1127581.3750 - val_accuracy: 0.0925\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1151260.3750 - accuracy: 0.0997 - val_loss: -1192109.8750 - val_accuracy: 0.0925\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1216722.6250 - accuracy: 0.0997 - val_loss: -1259316.0000 - val_accuracy: 0.0925\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1284978.6250 - accuracy: 0.0997 - val_loss: -1328947.6250 - val_accuracy: 0.0925\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1355239.5000 - accuracy: 0.0997 - val_loss: -1401059.5000 - val_accuracy: 0.0925\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1427738.2500 - accuracy: 0.0997 - val_loss: -1474803.5000 - val_accuracy: 0.0925\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1504125.1250 - accuracy: 0.0997 - val_loss: -1553454.0000 - val_accuracy: 0.0925\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1581942.2500 - accuracy: 0.0997 - val_loss: -1632564.8750 - val_accuracy: 0.0925\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1663309.0000 - accuracy: 0.0997 - val_loss: -1715683.7500 - val_accuracy: 0.0925\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1744586.0000 - accuracy: 0.0997 - val_loss: -1798226.0000 - val_accuracy: 0.0925\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1824980.5000 - accuracy: 0.0997 - val_loss: -1880004.1250 - val_accuracy: 0.0925\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1909855.0000 - accuracy: 0.0997 - val_loss: -1966902.3750 - val_accuracy: 0.0925\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1997777.2500 - accuracy: 0.0997 - val_loss: -2057219.0000 - val_accuracy: 0.0925\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2089228.1250 - accuracy: 0.0997 - val_loss: -2150656.0000 - val_accuracy: 0.0925\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2183910.0000 - accuracy: 0.0997 - val_loss: -2247258.2500 - val_accuracy: 0.0925\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2281384.0000 - accuracy: 0.0997 - val_loss: -2347212.0000 - val_accuracy: 0.0925\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2380332.5000 - accuracy: 0.0997 - val_loss: -2447323.2500 - val_accuracy: 0.0925\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2482745.7500 - accuracy: 0.0997 - val_loss: -2552715.0000 - val_accuracy: 0.0925\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2589460.2500 - accuracy: 0.0997 - val_loss: -2660367.7500 - val_accuracy: 0.0925\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2696914.5000 - accuracy: 0.0997 - val_loss: -2770826.7500 - val_accuracy: 0.0925\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2808235.5000 - accuracy: 0.0997 - val_loss: -2884167.2500 - val_accuracy: 0.0925\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2921687.0000 - accuracy: 0.0997 - val_loss: -2999640.0000 - val_accuracy: 0.0925\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3038795.2500 - accuracy: 0.0997 - val_loss: -3119047.5000 - val_accuracy: 0.0925\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3159151.0000 - accuracy: 0.0997 - val_loss: -3242153.7500 - val_accuracy: 0.0925\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3281459.5000 - accuracy: 0.0997 - val_loss: -3366360.0000 - val_accuracy: 0.0925\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3401030.2500 - accuracy: 0.0997 - val_loss: -3487584.7500 - val_accuracy: 0.0925\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3525841.7500 - accuracy: 0.0997 - val_loss: -3614915.0000 - val_accuracy: 0.0925\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3654748.0000 - accuracy: 0.0997 - val_loss: -3746720.0000 - val_accuracy: 0.0925\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3789429.7500 - accuracy: 0.0997 - val_loss: -3883691.0000 - val_accuracy: 0.0925\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3926016.5000 - accuracy: 0.0997 - val_loss: -4022828.7500 - val_accuracy: 0.0925\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4064745.0000 - accuracy: 0.0997 - val_loss: -4163684.5000 - val_accuracy: 0.0925\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4206877.5000 - accuracy: 0.0997 - val_loss: -4308580.0000 - val_accuracy: 0.0925\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4352288.5000 - accuracy: 0.0997 - val_loss: -4457358.0000 - val_accuracy: 0.0925\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4502515.5000 - accuracy: 0.0997 - val_loss: -4610601.5000 - val_accuracy: 0.0925\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4655258.0000 - accuracy: 0.0997 - val_loss: -4765918.0000 - val_accuracy: 0.0925\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4812625.5000 - accuracy: 0.0997 - val_loss: -4926906.5000 - val_accuracy: 0.0925\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4974357.0000 - accuracy: 0.0997 - val_loss: -5091269.5000 - val_accuracy: 0.0925\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5139123.5000 - accuracy: 0.0997 - val_loss: -5258689.0000 - val_accuracy: 0.0925\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5306576.5000 - accuracy: 0.0997 - val_loss: -5429084.5000 - val_accuracy: 0.0925\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5477993.5000 - accuracy: 0.0997 - val_loss: -5603251.5000 - val_accuracy: 0.0925\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5653843.5000 - accuracy: 0.0997 - val_loss: -5782262.0000 - val_accuracy: 0.0925\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5830814.0000 - accuracy: 0.0997 - val_loss: -5962177.5000 - val_accuracy: 0.0925\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6011839.0000 - accuracy: 0.0997 - val_loss: -6145470.5000 - val_accuracy: 0.0925\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6196581.0000 - accuracy: 0.0997 - val_loss: -6334251.5000 - val_accuracy: 0.0925\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6384821.0000 - accuracy: 0.0997 - val_loss: -6524876.0000 - val_accuracy: 0.0925\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6578503.0000 - accuracy: 0.0997 - val_loss: -6721806.5000 - val_accuracy: 0.0925\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6774632.5000 - accuracy: 0.0997 - val_loss: -6921074.0000 - val_accuracy: 0.0925\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6976647.5000 - accuracy: 0.0997 - val_loss: -7126534.5000 - val_accuracy: 0.0925\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7180874.0000 - accuracy: 0.0997 - val_loss: -7334250.5000 - val_accuracy: 0.0925\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7387178.0000 - accuracy: 0.0997 - val_loss: -7545013.0000 - val_accuracy: 0.0925\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7601616.5000 - accuracy: 0.0997 - val_loss: -7760237.0000 - val_accuracy: 0.0925\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7814688.5000 - accuracy: 0.0997 - val_loss: -7976920.5000 - val_accuracy: 0.0925\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8032958.0000 - accuracy: 0.0997 - val_loss: -8200007.5000 - val_accuracy: 0.0925\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8255535.5000 - accuracy: 0.0997 - val_loss: -8424517.0000 - val_accuracy: 0.0925\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8484497.0000 - accuracy: 0.0997 - val_loss: -8657186.0000 - val_accuracy: 0.0925\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8716844.0000 - accuracy: 0.0997 - val_loss: -8893280.0000 - val_accuracy: 0.0925\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8952321.0000 - accuracy: 0.0997 - val_loss: -9133470.0000 - val_accuracy: 0.0925\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9194111.0000 - accuracy: 0.0997 - val_loss: -9378542.0000 - val_accuracy: 0.0925\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       260\n","           1       0.09      1.00      0.17        78\n","           2       0.00      0.00      0.00       168\n","           3       0.00      0.00      0.00       186\n","           4       0.00      0.00      0.00       151\n","\n","    accuracy                           0.09       843\n","   macro avg       0.02      0.20      0.03       843\n","weighted avg       0.01      0.09      0.02       843\n","\n","Accuracy: 0.09252669039145907\n","[[  0 260   0   0   0]\n"," [  0  78   0   0   0]\n"," [  0 168   0   0   0]\n"," [  0 186   0   0   0]\n"," [  0 151   0   0   0]]\n","Precision: 0.0086\n","Recall: 0.0925\n","F1 Score: 0.0157\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://41747de8-b420-4e63-a071-c57ebbda306b/assets\n","model 0 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: -193.0406 - accuracy: 0.0989 - val_loss: -574.7985 - val_accuracy: 0.0985\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1304.1869 - accuracy: 0.0990 - val_loss: -2075.7576 - val_accuracy: 0.0985\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3278.0110 - accuracy: 0.0990 - val_loss: -4355.7109 - val_accuracy: 0.0985\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6035.8945 - accuracy: 0.0990 - val_loss: -7361.6226 - val_accuracy: 0.0985\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9532.9248 - accuracy: 0.0990 - val_loss: -11070.1143 - val_accuracy: 0.0985\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13717.4229 - accuracy: 0.0990 - val_loss: -15339.2207 - val_accuracy: 0.0985\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -18494.3672 - accuracy: 0.0990 - val_loss: -20235.6875 - val_accuracy: 0.0985\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -23905.9805 - accuracy: 0.0990 - val_loss: -25779.7500 - val_accuracy: 0.0985\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -30019.9629 - accuracy: 0.0990 - val_loss: -31981.8555 - val_accuracy: 0.0985\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -36850.6016 - accuracy: 0.0990 - val_loss: -38901.2852 - val_accuracy: 0.0985\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -44451.1641 - accuracy: 0.0990 - val_loss: -46566.1172 - val_accuracy: 0.0985\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -52849.8047 - accuracy: 0.0990 - val_loss: -55016.0625 - val_accuracy: 0.0985\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -62102.0977 - accuracy: 0.0990 - val_loss: -64086.9180 - val_accuracy: 0.0985\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -71731.5625 - accuracy: 0.0990 - val_loss: -73657.9844 - val_accuracy: 0.0985\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -82065.7031 - accuracy: 0.0990 - val_loss: -84014.0156 - val_accuracy: 0.0985\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -93377.1953 - accuracy: 0.0990 - val_loss: -95308.0156 - val_accuracy: 0.0985\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -105587.5938 - accuracy: 0.0990 - val_loss: -107391.7266 - val_accuracy: 0.0985\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -118738.8672 - accuracy: 0.0990 - val_loss: -120504.7969 - val_accuracy: 0.0985\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -132706.6406 - accuracy: 0.0990 - val_loss: -134285.4062 - val_accuracy: 0.0985\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -147823.9531 - accuracy: 0.0990 - val_loss: -149170.6406 - val_accuracy: 0.0985\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -163427.8906 - accuracy: 0.0990 - val_loss: -164538.7500 - val_accuracy: 0.0985\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -180104.0781 - accuracy: 0.0990 - val_loss: -181077.6719 - val_accuracy: 0.0985\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -197738.6406 - accuracy: 0.0990 - val_loss: -198456.8281 - val_accuracy: 0.0985\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -216703.7344 - accuracy: 0.0990 - val_loss: -216851.9062 - val_accuracy: 0.0985\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -235824.4844 - accuracy: 0.0990 - val_loss: -235638.8125 - val_accuracy: 0.0985\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -256013.3438 - accuracy: 0.0990 - val_loss: -255487.0312 - val_accuracy: 0.0985\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -277465.1250 - accuracy: 0.0990 - val_loss: -276748.6875 - val_accuracy: 0.0985\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -299896.2188 - accuracy: 0.0990 - val_loss: -298767.7188 - val_accuracy: 0.0985\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -323453.9375 - accuracy: 0.0990 - val_loss: -321805.8438 - val_accuracy: 0.0985\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -348189.1875 - accuracy: 0.0990 - val_loss: -346300.0000 - val_accuracy: 0.0985\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -374253.7812 - accuracy: 0.0990 - val_loss: -371546.7188 - val_accuracy: 0.0985\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -401700.6250 - accuracy: 0.0990 - val_loss: -398603.8438 - val_accuracy: 0.0985\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -429967.1250 - accuracy: 0.0990 - val_loss: -426282.2812 - val_accuracy: 0.0985\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -459437.3438 - accuracy: 0.0990 - val_loss: -454852.7188 - val_accuracy: 0.0985\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -489917.7500 - accuracy: 0.0990 - val_loss: -484957.7188 - val_accuracy: 0.0985\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -521965.1562 - accuracy: 0.0990 - val_loss: -516224.5312 - val_accuracy: 0.0985\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -554931.8750 - accuracy: 0.0990 - val_loss: -548347.4375 - val_accuracy: 0.0985\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -589156.9375 - accuracy: 0.0990 - val_loss: -581619.1250 - val_accuracy: 0.0985\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -624889.6875 - accuracy: 0.0990 - val_loss: -616501.5000 - val_accuracy: 0.0985\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -661725.1875 - accuracy: 0.0990 - val_loss: -652685.3125 - val_accuracy: 0.0985\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -699995.3125 - accuracy: 0.0990 - val_loss: -689801.4375 - val_accuracy: 0.0985\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -740099.0625 - accuracy: 0.0990 - val_loss: -728722.6250 - val_accuracy: 0.0985\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -780924.0625 - accuracy: 0.0990 - val_loss: -768623.2500 - val_accuracy: 0.0985\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -822721.6250 - accuracy: 0.0990 - val_loss: -809081.3750 - val_accuracy: 0.0985\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -865949.0625 - accuracy: 0.0990 - val_loss: -851736.1875 - val_accuracy: 0.0985\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -910831.8750 - accuracy: 0.0990 - val_loss: -895274.0000 - val_accuracy: 0.0985\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -956996.9375 - accuracy: 0.0990 - val_loss: -940205.9375 - val_accuracy: 0.0985\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1004865.5625 - accuracy: 0.0990 - val_loss: -987069.9375 - val_accuracy: 0.0985\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1054214.5000 - accuracy: 0.0990 - val_loss: -1034900.5625 - val_accuracy: 0.0985\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1105401.7500 - accuracy: 0.0990 - val_loss: -1084649.5000 - val_accuracy: 0.0985\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1158334.5000 - accuracy: 0.0990 - val_loss: -1136407.2500 - val_accuracy: 0.0985\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1212438.0000 - accuracy: 0.0990 - val_loss: -1188926.5000 - val_accuracy: 0.0985\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1268194.8750 - accuracy: 0.0990 - val_loss: -1242962.6250 - val_accuracy: 0.0985\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1325624.8750 - accuracy: 0.0990 - val_loss: -1298767.1250 - val_accuracy: 0.0985\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1383271.6250 - accuracy: 0.0990 - val_loss: -1354619.8750 - val_accuracy: 0.0985\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1443258.7500 - accuracy: 0.0990 - val_loss: -1412921.8750 - val_accuracy: 0.0985\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1505392.7500 - accuracy: 0.0990 - val_loss: -1473274.3750 - val_accuracy: 0.0985\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1568775.7500 - accuracy: 0.0990 - val_loss: -1535058.0000 - val_accuracy: 0.0985\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1634875.6250 - accuracy: 0.0990 - val_loss: -1598827.3750 - val_accuracy: 0.0985\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1699576.3750 - accuracy: 0.0990 - val_loss: -1661295.2500 - val_accuracy: 0.0985\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1767005.3750 - accuracy: 0.0990 - val_loss: -1726905.2500 - val_accuracy: 0.0985\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1836699.0000 - accuracy: 0.0990 - val_loss: -1794615.1250 - val_accuracy: 0.0985\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1908747.7500 - accuracy: 0.0990 - val_loss: -1864658.2500 - val_accuracy: 0.0985\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1981625.2500 - accuracy: 0.0990 - val_loss: -1935195.0000 - val_accuracy: 0.0985\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2056577.2500 - accuracy: 0.0990 - val_loss: -2007986.3750 - val_accuracy: 0.0985\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2133799.7500 - accuracy: 0.0990 - val_loss: -2082838.3750 - val_accuracy: 0.0985\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2212458.2500 - accuracy: 0.0990 - val_loss: -2159355.5000 - val_accuracy: 0.0985\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2293724.0000 - accuracy: 0.0990 - val_loss: -2238515.7500 - val_accuracy: 0.0985\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2377248.0000 - accuracy: 0.0990 - val_loss: -2319660.2500 - val_accuracy: 0.0985\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2462874.2500 - accuracy: 0.0990 - val_loss: -2402222.7500 - val_accuracy: 0.0985\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2550710.5000 - accuracy: 0.0990 - val_loss: -2486294.2500 - val_accuracy: 0.0985\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2637616.0000 - accuracy: 0.0990 - val_loss: -2570889.2500 - val_accuracy: 0.0985\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2727099.0000 - accuracy: 0.0990 - val_loss: -2657704.5000 - val_accuracy: 0.0985\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2818518.0000 - accuracy: 0.0990 - val_loss: -2746806.7500 - val_accuracy: 0.0985\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2913897.2500 - accuracy: 0.0990 - val_loss: -2838686.0000 - val_accuracy: 0.0985\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3010243.7500 - accuracy: 0.0990 - val_loss: -2931299.0000 - val_accuracy: 0.0985\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3107140.0000 - accuracy: 0.0990 - val_loss: -3025155.2500 - val_accuracy: 0.0985\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3204707.7500 - accuracy: 0.0990 - val_loss: -3119368.7500 - val_accuracy: 0.0985\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3304439.5000 - accuracy: 0.0990 - val_loss: -3216301.0000 - val_accuracy: 0.0985\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3407753.7500 - accuracy: 0.0990 - val_loss: -3316957.0000 - val_accuracy: 0.0985\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3514509.7500 - accuracy: 0.0990 - val_loss: -3419322.2500 - val_accuracy: 0.0985\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3620900.5000 - accuracy: 0.0990 - val_loss: -3521958.0000 - val_accuracy: 0.0985\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3731500.5000 - accuracy: 0.0990 - val_loss: -3629082.7500 - val_accuracy: 0.0985\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3842980.2500 - accuracy: 0.0990 - val_loss: -3737540.7500 - val_accuracy: 0.0985\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3956903.5000 - accuracy: 0.0990 - val_loss: -3847803.0000 - val_accuracy: 0.0985\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4071851.0000 - accuracy: 0.0990 - val_loss: -3959071.0000 - val_accuracy: 0.0985\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4189116.7500 - accuracy: 0.0990 - val_loss: -4072484.7500 - val_accuracy: 0.0985\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4308827.5000 - accuracy: 0.0990 - val_loss: -4188523.7500 - val_accuracy: 0.0985\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4430696.5000 - accuracy: 0.0990 - val_loss: -4305938.5000 - val_accuracy: 0.0985\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4556090.0000 - accuracy: 0.0990 - val_loss: -4428202.5000 - val_accuracy: 0.0985\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4683776.5000 - accuracy: 0.0990 - val_loss: -4551488.0000 - val_accuracy: 0.0985\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4814103.0000 - accuracy: 0.0990 - val_loss: -4677561.0000 - val_accuracy: 0.0985\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4946770.5000 - accuracy: 0.0990 - val_loss: -4805520.5000 - val_accuracy: 0.0985\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5081868.5000 - accuracy: 0.0990 - val_loss: -4936663.5000 - val_accuracy: 0.0985\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5218613.0000 - accuracy: 0.0990 - val_loss: -5068135.5000 - val_accuracy: 0.0985\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5357776.5000 - accuracy: 0.0990 - val_loss: -5203390.5000 - val_accuracy: 0.0985\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5500443.0000 - accuracy: 0.0990 - val_loss: -5341322.0000 - val_accuracy: 0.0985\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5643584.5000 - accuracy: 0.0990 - val_loss: -5478375.5000 - val_accuracy: 0.0985\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5787692.5000 - accuracy: 0.0990 - val_loss: -5617773.5000 - val_accuracy: 0.0985\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5934745.0000 - accuracy: 0.0990 - val_loss: -5760110.5000 - val_accuracy: 0.0985\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       272\n","           1       0.10      1.00      0.18        83\n","           2       0.00      0.00      0.00       183\n","           3       0.00      0.00      0.00       179\n","           4       0.00      0.00      0.00       126\n","\n","    accuracy                           0.10       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.10      0.02       843\n","\n","Accuracy: 0.09845788849347568\n","[[  0 272   0   0   0]\n"," [  0  83   0   0   0]\n"," [  0 183   0   0   0]\n"," [  0 179   0   0   0]\n"," [  0 126   0   0   0]]\n","Precision: 0.0097\n","Recall: 0.0985\n","F1 Score: 0.0177\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://34f8973a-9393-492b-a966-1b20a4a27f09/assets\n","model 1 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: -240.4154 - accuracy: 0.0990 - val_loss: -893.6364 - val_accuracy: 0.1032\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1771.9454 - accuracy: 0.0985 - val_loss: -3603.7334 - val_accuracy: 0.1032\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4753.8169 - accuracy: 0.0985 - val_loss: -7933.2681 - val_accuracy: 0.1032\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8997.1807 - accuracy: 0.0985 - val_loss: -13699.4473 - val_accuracy: 0.1032\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14415.7588 - accuracy: 0.0985 - val_loss: -20607.0938 - val_accuracy: 0.1032\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -20745.5703 - accuracy: 0.0985 - val_loss: -28777.9590 - val_accuracy: 0.1032\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -28199.3535 - accuracy: 0.0985 - val_loss: -38220.4648 - val_accuracy: 0.1032\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -36766.0078 - accuracy: 0.0985 - val_loss: -49052.6250 - val_accuracy: 0.1032\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -46513.5586 - accuracy: 0.0985 - val_loss: -61271.9375 - val_accuracy: 0.1032\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -57490.7852 - accuracy: 0.0985 - val_loss: -74949.3438 - val_accuracy: 0.1032\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -69612.0078 - accuracy: 0.0985 - val_loss: -89983.0000 - val_accuracy: 0.1032\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -82870.2578 - accuracy: 0.0985 - val_loss: -106377.7109 - val_accuracy: 0.1032\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -97448.2812 - accuracy: 0.0985 - val_loss: -124253.8203 - val_accuracy: 0.1032\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -113279.1562 - accuracy: 0.0985 - val_loss: -143707.7344 - val_accuracy: 0.1032\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -130271.2266 - accuracy: 0.0985 - val_loss: -164551.3438 - val_accuracy: 0.1032\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -148525.7656 - accuracy: 0.0985 - val_loss: -187147.2344 - val_accuracy: 0.1032\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -168381.3125 - accuracy: 0.0985 - val_loss: -211424.1875 - val_accuracy: 0.1032\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -189805.8750 - accuracy: 0.0985 - val_loss: -237503.7188 - val_accuracy: 0.1032\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -212285.4375 - accuracy: 0.0985 - val_loss: -264794.5625 - val_accuracy: 0.1032\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -236156.5000 - accuracy: 0.0985 - val_loss: -293929.2500 - val_accuracy: 0.1032\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -261820.7969 - accuracy: 0.0985 - val_loss: -325252.4688 - val_accuracy: 0.1032\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -288800.3438 - accuracy: 0.0985 - val_loss: -357755.6250 - val_accuracy: 0.1032\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -317010.1562 - accuracy: 0.0985 - val_loss: -392323.5625 - val_accuracy: 0.1032\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -347263.2188 - accuracy: 0.0985 - val_loss: -428765.1250 - val_accuracy: 0.1032\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -379172.0312 - accuracy: 0.0985 - val_loss: -467600.5625 - val_accuracy: 0.1032\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -412382.5000 - accuracy: 0.0985 - val_loss: -508087.7188 - val_accuracy: 0.1032\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -447636.1562 - accuracy: 0.0985 - val_loss: -550666.1875 - val_accuracy: 0.1032\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -485004.8438 - accuracy: 0.0985 - val_loss: -595440.8125 - val_accuracy: 0.1032\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -522968.4375 - accuracy: 0.0985 - val_loss: -641282.6875 - val_accuracy: 0.1032\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -562887.1875 - accuracy: 0.0985 - val_loss: -689814.3750 - val_accuracy: 0.1032\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -604736.1875 - accuracy: 0.0985 - val_loss: -740238.0625 - val_accuracy: 0.1032\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -649256.3125 - accuracy: 0.0985 - val_loss: -793755.3125 - val_accuracy: 0.1032\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -695157.1875 - accuracy: 0.0985 - val_loss: -848743.5625 - val_accuracy: 0.1032\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -741716.9375 - accuracy: 0.0985 - val_loss: -904816.4375 - val_accuracy: 0.1032\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -790419.9375 - accuracy: 0.0985 - val_loss: -963895.2500 - val_accuracy: 0.1032\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -841362.9375 - accuracy: 0.0985 - val_loss: -1025298.8750 - val_accuracy: 0.1032\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -894735.6250 - accuracy: 0.0985 - val_loss: -1089736.2500 - val_accuracy: 0.1032\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -950486.0000 - accuracy: 0.0985 - val_loss: -1156451.8750 - val_accuracy: 0.1032\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1007397.3750 - accuracy: 0.0985 - val_loss: -1225315.2500 - val_accuracy: 0.1032\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1066349.1250 - accuracy: 0.0985 - val_loss: -1295786.3750 - val_accuracy: 0.1032\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1127648.7500 - accuracy: 0.0985 - val_loss: -1370085.8750 - val_accuracy: 0.1032\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1191972.3750 - accuracy: 0.0985 - val_loss: -1446646.3750 - val_accuracy: 0.1032\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1257129.5000 - accuracy: 0.0985 - val_loss: -1524862.1250 - val_accuracy: 0.1032\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1324336.7500 - accuracy: 0.0985 - val_loss: -1606001.0000 - val_accuracy: 0.1032\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1394495.2500 - accuracy: 0.0985 - val_loss: -1690414.6250 - val_accuracy: 0.1032\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1466396.5000 - accuracy: 0.0985 - val_loss: -1776490.5000 - val_accuracy: 0.1032\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1540763.7500 - accuracy: 0.0985 - val_loss: -1865393.3750 - val_accuracy: 0.1032\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1617337.8750 - accuracy: 0.0985 - val_loss: -1957805.0000 - val_accuracy: 0.1032\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1696658.2500 - accuracy: 0.0985 - val_loss: -2053119.5000 - val_accuracy: 0.1032\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1778152.8750 - accuracy: 0.0985 - val_loss: -2150593.0000 - val_accuracy: 0.1032\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1863125.6250 - accuracy: 0.0985 - val_loss: -2251794.0000 - val_accuracy: 0.1032\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1949385.6250 - accuracy: 0.0985 - val_loss: -2355752.7500 - val_accuracy: 0.1032\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2037660.2500 - accuracy: 0.0985 - val_loss: -2460634.7500 - val_accuracy: 0.1032\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2129051.0000 - accuracy: 0.0985 - val_loss: -2570979.2500 - val_accuracy: 0.1032\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2222957.2500 - accuracy: 0.0985 - val_loss: -2683161.5000 - val_accuracy: 0.1032\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2320888.7500 - accuracy: 0.0985 - val_loss: -2800072.0000 - val_accuracy: 0.1032\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2419327.7500 - accuracy: 0.0985 - val_loss: -2918254.2500 - val_accuracy: 0.1032\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2521986.2500 - accuracy: 0.0985 - val_loss: -3040828.2500 - val_accuracy: 0.1032\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2626172.7500 - accuracy: 0.0985 - val_loss: -3166238.2500 - val_accuracy: 0.1032\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2732539.0000 - accuracy: 0.0985 - val_loss: -3292810.5000 - val_accuracy: 0.1032\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2841636.7500 - accuracy: 0.0985 - val_loss: -3423646.5000 - val_accuracy: 0.1032\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2953569.7500 - accuracy: 0.0985 - val_loss: -3557281.2500 - val_accuracy: 0.1032\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3068420.5000 - accuracy: 0.0985 - val_loss: -3695554.7500 - val_accuracy: 0.1032\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3187599.0000 - accuracy: 0.0985 - val_loss: -3837324.5000 - val_accuracy: 0.1032\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3308194.7500 - accuracy: 0.0985 - val_loss: -3981077.7500 - val_accuracy: 0.1032\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3432614.5000 - accuracy: 0.0985 - val_loss: -4130771.7500 - val_accuracy: 0.1032\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3559436.2500 - accuracy: 0.0985 - val_loss: -4281852.5000 - val_accuracy: 0.1032\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3689227.7500 - accuracy: 0.0985 - val_loss: -4437575.0000 - val_accuracy: 0.1032\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3822581.7500 - accuracy: 0.0985 - val_loss: -4595674.5000 - val_accuracy: 0.1032\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3959031.2500 - accuracy: 0.0985 - val_loss: -4758592.5000 - val_accuracy: 0.1032\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4097611.2500 - accuracy: 0.0985 - val_loss: -4924654.5000 - val_accuracy: 0.1032\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4240490.0000 - accuracy: 0.0985 - val_loss: -5095167.5000 - val_accuracy: 0.1032\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4386437.0000 - accuracy: 0.0985 - val_loss: -5269187.5000 - val_accuracy: 0.1032\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4534191.0000 - accuracy: 0.0985 - val_loss: -5446316.5000 - val_accuracy: 0.1032\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4686166.0000 - accuracy: 0.0985 - val_loss: -5626515.5000 - val_accuracy: 0.1032\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4841270.5000 - accuracy: 0.0985 - val_loss: -5813384.0000 - val_accuracy: 0.1032\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5001700.5000 - accuracy: 0.0985 - val_loss: -6003271.0000 - val_accuracy: 0.1032\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5152497.0000 - accuracy: 0.0985 - val_loss: -6179385.5000 - val_accuracy: 0.1032\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5311755.0000 - accuracy: 0.0985 - val_loss: -6369433.5000 - val_accuracy: 0.1032\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5471309.0000 - accuracy: 0.0985 - val_loss: -6560849.5000 - val_accuracy: 0.1032\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5635129.0000 - accuracy: 0.0985 - val_loss: -6757152.0000 - val_accuracy: 0.1032\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5804010.5000 - accuracy: 0.0985 - val_loss: -6959293.0000 - val_accuracy: 0.1032\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5977763.0000 - accuracy: 0.0985 - val_loss: -7166985.0000 - val_accuracy: 0.1032\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6156130.0000 - accuracy: 0.0985 - val_loss: -7379349.0000 - val_accuracy: 0.1032\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6339377.5000 - accuracy: 0.0985 - val_loss: -7599087.0000 - val_accuracy: 0.1032\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6526707.5000 - accuracy: 0.0985 - val_loss: -7821440.0000 - val_accuracy: 0.1032\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6715679.5000 - accuracy: 0.0985 - val_loss: -8047056.0000 - val_accuracy: 0.1032\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6910929.5000 - accuracy: 0.0985 - val_loss: -8279685.0000 - val_accuracy: 0.1032\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7107649.5000 - accuracy: 0.0985 - val_loss: -8515154.0000 - val_accuracy: 0.1032\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7307176.5000 - accuracy: 0.0985 - val_loss: -8751722.0000 - val_accuracy: 0.1032\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7510528.0000 - accuracy: 0.0985 - val_loss: -8996410.0000 - val_accuracy: 0.1032\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7720682.0000 - accuracy: 0.0985 - val_loss: -9244345.0000 - val_accuracy: 0.1032\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7933171.0000 - accuracy: 0.0985 - val_loss: -9497429.0000 - val_accuracy: 0.1032\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8149527.0000 - accuracy: 0.0985 - val_loss: -9758165.0000 - val_accuracy: 0.1032\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8371459.0000 - accuracy: 0.0985 - val_loss: -10022495.0000 - val_accuracy: 0.1032\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8595184.0000 - accuracy: 0.0985 - val_loss: -10287059.0000 - val_accuracy: 0.1032\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8821932.0000 - accuracy: 0.0985 - val_loss: -10558138.0000 - val_accuracy: 0.1032\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9052235.0000 - accuracy: 0.0985 - val_loss: -10830716.0000 - val_accuracy: 0.1032\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9287176.0000 - accuracy: 0.0985 - val_loss: -11111518.0000 - val_accuracy: 0.1032\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9527544.0000 - accuracy: 0.0985 - val_loss: -11398410.0000 - val_accuracy: 0.1032\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       247\n","           1       0.10      1.00      0.19        87\n","           2       0.00      0.00      0.00       170\n","           3       0.00      0.00      0.00       225\n","           4       0.00      0.00      0.00       114\n","\n","    accuracy                           0.10       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.10      0.02       843\n","\n","Accuracy: 0.10320284697508897\n","[[  0 247   0   0   0]\n"," [  0  87   0   0   0]\n"," [  0 170   0   0   0]\n"," [  0 225   0   0   0]\n"," [  0 114   0   0   0]]\n","Precision: 0.0107\n","Recall: 0.1032\n","F1 Score: 0.0193\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://d0c865f7-e4be-466f-aa3d-e2e6a3b689d0/assets\n","model 2 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 4ms/step - loss: -295.3080 - accuracy: 0.1051 - val_loss: -904.8782 - val_accuracy: 0.1032\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2113.3872 - accuracy: 0.0985 - val_loss: -3457.2847 - val_accuracy: 0.1032\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5404.1270 - accuracy: 0.0985 - val_loss: -7252.2617 - val_accuracy: 0.1032\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9900.4893 - accuracy: 0.0985 - val_loss: -12186.4082 - val_accuracy: 0.1032\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -15465.3291 - accuracy: 0.0985 - val_loss: -18136.6289 - val_accuracy: 0.1032\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -22056.6738 - accuracy: 0.0985 - val_loss: -25014.9844 - val_accuracy: 0.1032\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -29639.0137 - accuracy: 0.0985 - val_loss: -32902.7070 - val_accuracy: 0.1032\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -38374.8086 - accuracy: 0.0985 - val_loss: -41904.7344 - val_accuracy: 0.1032\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -48121.6133 - accuracy: 0.0985 - val_loss: -51959.8828 - val_accuracy: 0.1032\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -59106.2305 - accuracy: 0.0985 - val_loss: -63120.4570 - val_accuracy: 0.1032\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -70998.4922 - accuracy: 0.0985 - val_loss: -75276.2031 - val_accuracy: 0.1032\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -84003.5156 - accuracy: 0.0985 - val_loss: -88483.4062 - val_accuracy: 0.1032\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -98200.5625 - accuracy: 0.0985 - val_loss: -102893.0469 - val_accuracy: 0.1032\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -113525.9766 - accuracy: 0.0985 - val_loss: -118444.6953 - val_accuracy: 0.1032\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -130091.5312 - accuracy: 0.0985 - val_loss: -135183.7812 - val_accuracy: 0.1032\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -148141.8281 - accuracy: 0.0985 - val_loss: -153357.8125 - val_accuracy: 0.1032\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -167496.5938 - accuracy: 0.0985 - val_loss: -172891.3281 - val_accuracy: 0.1032\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -188097.9062 - accuracy: 0.0985 - val_loss: -193674.8594 - val_accuracy: 0.1032\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -210254.4062 - accuracy: 0.0985 - val_loss: -215969.9375 - val_accuracy: 0.1032\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -233990.1250 - accuracy: 0.0985 - val_loss: -239413.5156 - val_accuracy: 0.1032\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -257747.7031 - accuracy: 0.0985 - val_loss: -263160.8125 - val_accuracy: 0.1032\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -283701.1250 - accuracy: 0.0985 - val_loss: -288850.0938 - val_accuracy: 0.1032\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -310337.9688 - accuracy: 0.0985 - val_loss: -315630.0938 - val_accuracy: 0.1032\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -338863.5000 - accuracy: 0.0985 - val_loss: -344180.1875 - val_accuracy: 0.1032\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -369484.0312 - accuracy: 0.0985 - val_loss: -374678.0312 - val_accuracy: 0.1032\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -401006.8438 - accuracy: 0.0985 - val_loss: -406280.6250 - val_accuracy: 0.1032\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -434328.0000 - accuracy: 0.0985 - val_loss: -439688.3438 - val_accuracy: 0.1032\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -469235.4062 - accuracy: 0.0985 - val_loss: -474284.3438 - val_accuracy: 0.1032\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -505839.8125 - accuracy: 0.0985 - val_loss: -510872.4375 - val_accuracy: 0.1032\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -544290.5000 - accuracy: 0.0985 - val_loss: -549281.0000 - val_accuracy: 0.1032\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -585248.9375 - accuracy: 0.0985 - val_loss: -589625.6250 - val_accuracy: 0.1032\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -627333.8750 - accuracy: 0.0985 - val_loss: -631526.1250 - val_accuracy: 0.1032\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -671064.2500 - accuracy: 0.0985 - val_loss: -675207.5000 - val_accuracy: 0.1032\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -716728.6875 - accuracy: 0.0985 - val_loss: -720657.0000 - val_accuracy: 0.1032\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -765040.2500 - accuracy: 0.0985 - val_loss: -768173.5000 - val_accuracy: 0.1032\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -813813.5000 - accuracy: 0.0985 - val_loss: -816640.3750 - val_accuracy: 0.1032\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -864680.4375 - accuracy: 0.0985 - val_loss: -867220.5000 - val_accuracy: 0.1032\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -918090.1250 - accuracy: 0.0985 - val_loss: -920229.3750 - val_accuracy: 0.1032\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -973649.2500 - accuracy: 0.0985 - val_loss: -975344.4375 - val_accuracy: 0.1032\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1030724.6250 - accuracy: 0.0985 - val_loss: -1031651.2500 - val_accuracy: 0.1032\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1089873.2500 - accuracy: 0.0985 - val_loss: -1089896.8750 - val_accuracy: 0.1032\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1151267.5000 - accuracy: 0.0985 - val_loss: -1151174.5000 - val_accuracy: 0.1032\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1215007.8750 - accuracy: 0.0985 - val_loss: -1214197.6250 - val_accuracy: 0.1032\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1280883.0000 - accuracy: 0.0985 - val_loss: -1279169.1250 - val_accuracy: 0.1032\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1348257.1250 - accuracy: 0.0985 - val_loss: -1345585.7500 - val_accuracy: 0.1032\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1418856.2500 - accuracy: 0.0985 - val_loss: -1415345.7500 - val_accuracy: 0.1032\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1490696.7500 - accuracy: 0.0985 - val_loss: -1486789.7500 - val_accuracy: 0.1032\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1565207.5000 - accuracy: 0.0985 - val_loss: -1560233.2500 - val_accuracy: 0.1032\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1641055.0000 - accuracy: 0.0985 - val_loss: -1635040.1250 - val_accuracy: 0.1032\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1720922.8750 - accuracy: 0.0985 - val_loss: -1713727.3750 - val_accuracy: 0.1032\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1801204.3750 - accuracy: 0.0985 - val_loss: -1792963.3750 - val_accuracy: 0.1032\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1884027.1250 - accuracy: 0.0985 - val_loss: -1875097.8750 - val_accuracy: 0.1032\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1969832.8750 - accuracy: 0.0985 - val_loss: -1959273.6250 - val_accuracy: 0.1032\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2058104.3750 - accuracy: 0.0985 - val_loss: -2047293.6250 - val_accuracy: 0.1032\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2148881.0000 - accuracy: 0.0985 - val_loss: -2136845.2500 - val_accuracy: 0.1032\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2243753.5000 - accuracy: 0.0985 - val_loss: -2229927.0000 - val_accuracy: 0.1032\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2337238.5000 - accuracy: 0.0985 - val_loss: -2321772.0000 - val_accuracy: 0.1032\n","Epoch 58/100\n","238/238 [==============================] - 1s 4ms/step - loss: -2433971.0000 - accuracy: 0.0985 - val_loss: -2417795.2500 - val_accuracy: 0.1032\n","Epoch 59/100\n","238/238 [==============================] - 1s 4ms/step - loss: -2534238.2500 - accuracy: 0.0985 - val_loss: -2516474.5000 - val_accuracy: 0.1032\n","Epoch 60/100\n","238/238 [==============================] - 1s 4ms/step - loss: -2636440.2500 - accuracy: 0.0985 - val_loss: -2616968.2500 - val_accuracy: 0.1032\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2741718.5000 - accuracy: 0.0985 - val_loss: -2720712.0000 - val_accuracy: 0.1032\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2848877.5000 - accuracy: 0.0985 - val_loss: -2827186.2500 - val_accuracy: 0.1032\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2959596.5000 - accuracy: 0.0985 - val_loss: -2936099.0000 - val_accuracy: 0.1032\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3073251.7500 - accuracy: 0.0985 - val_loss: -3046868.5000 - val_accuracy: 0.1032\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3188466.0000 - accuracy: 0.0985 - val_loss: -3161563.0000 - val_accuracy: 0.1032\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3306798.5000 - accuracy: 0.0985 - val_loss: -3276885.2500 - val_accuracy: 0.1032\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3427984.5000 - accuracy: 0.0985 - val_loss: -3396896.5000 - val_accuracy: 0.1032\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3552132.2500 - accuracy: 0.0985 - val_loss: -3519233.2500 - val_accuracy: 0.1032\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3678969.2500 - accuracy: 0.0985 - val_loss: -3644460.2500 - val_accuracy: 0.1032\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3809695.5000 - accuracy: 0.0985 - val_loss: -3773320.2500 - val_accuracy: 0.1032\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3944909.2500 - accuracy: 0.0985 - val_loss: -3905545.0000 - val_accuracy: 0.1032\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4080446.2500 - accuracy: 0.0985 - val_loss: -4037957.2500 - val_accuracy: 0.1032\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4219509.5000 - accuracy: 0.0985 - val_loss: -4175027.5000 - val_accuracy: 0.1032\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4360530.5000 - accuracy: 0.0985 - val_loss: -4314722.0000 - val_accuracy: 0.1032\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4507339.0000 - accuracy: 0.0985 - val_loss: -4458893.0000 - val_accuracy: 0.1032\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4653675.5000 - accuracy: 0.0985 - val_loss: -4602575.0000 - val_accuracy: 0.1032\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4803925.0000 - accuracy: 0.0985 - val_loss: -4750582.5000 - val_accuracy: 0.1032\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4956898.5000 - accuracy: 0.0985 - val_loss: -4900595.0000 - val_accuracy: 0.1032\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5113490.0000 - accuracy: 0.0985 - val_loss: -5054940.0000 - val_accuracy: 0.1032\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5274570.0000 - accuracy: 0.0985 - val_loss: -5213535.5000 - val_accuracy: 0.1032\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5438595.0000 - accuracy: 0.0985 - val_loss: -5375933.0000 - val_accuracy: 0.1032\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5605731.5000 - accuracy: 0.0985 - val_loss: -5539265.0000 - val_accuracy: 0.1032\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5776070.5000 - accuracy: 0.0985 - val_loss: -5706732.0000 - val_accuracy: 0.1032\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5950777.5000 - accuracy: 0.0985 - val_loss: -5879211.0000 - val_accuracy: 0.1032\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6128421.0000 - accuracy: 0.0985 - val_loss: -6053769.0000 - val_accuracy: 0.1032\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6311229.5000 - accuracy: 0.0985 - val_loss: -6232423.5000 - val_accuracy: 0.1032\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6494535.0000 - accuracy: 0.0985 - val_loss: -6413278.5000 - val_accuracy: 0.1032\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6681378.0000 - accuracy: 0.0985 - val_loss: -6597047.0000 - val_accuracy: 0.1032\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6875159.5000 - accuracy: 0.0985 - val_loss: -6785849.0000 - val_accuracy: 0.1032\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7067214.5000 - accuracy: 0.0985 - val_loss: -6975138.0000 - val_accuracy: 0.1032\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7263010.0000 - accuracy: 0.0985 - val_loss: -7167434.5000 - val_accuracy: 0.1032\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7461743.0000 - accuracy: 0.0985 - val_loss: -7362043.0000 - val_accuracy: 0.1032\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7664466.5000 - accuracy: 0.0985 - val_loss: -7560499.5000 - val_accuracy: 0.1032\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7871276.5000 - accuracy: 0.0985 - val_loss: -7765450.0000 - val_accuracy: 0.1032\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8083967.5000 - accuracy: 0.0985 - val_loss: -7973194.5000 - val_accuracy: 0.1032\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8301835.5000 - accuracy: 0.0985 - val_loss: -8187262.0000 - val_accuracy: 0.1032\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8521562.0000 - accuracy: 0.0985 - val_loss: -8401749.0000 - val_accuracy: 0.1032\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8742841.0000 - accuracy: 0.0985 - val_loss: -8618833.0000 - val_accuracy: 0.1032\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8964413.0000 - accuracy: 0.0985 - val_loss: -8837675.0000 - val_accuracy: 0.1032\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9193480.0000 - accuracy: 0.0985 - val_loss: -9060057.0000 - val_accuracy: 0.1032\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       274\n","           1       0.10      1.00      0.19        87\n","           2       0.00      0.00      0.00       168\n","           3       0.00      0.00      0.00       204\n","           4       0.00      0.00      0.00       110\n","\n","    accuracy                           0.10       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.10      0.02       843\n","\n","Accuracy: 0.10320284697508897\n","[[  0 274   0   0   0]\n"," [  0  87   0   0   0]\n"," [  0 168   0   0   0]\n"," [  0 204   0   0   0]\n"," [  0 110   0   0   0]]\n","Precision: 0.0107\n","Recall: 0.1032\n","F1 Score: 0.0193\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://6a11525c-41e8-4859-bf27-680941ed98aa/assets\n","model 3 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 4ms/step - loss: -122.2747 - accuracy: 0.1156 - val_loss: -468.2352 - val_accuracy: 0.0985\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1242.9702 - accuracy: 0.0990 - val_loss: -2280.7512 - val_accuracy: 0.0985\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3479.5615 - accuracy: 0.0990 - val_loss: -5038.5791 - val_accuracy: 0.0985\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6667.1250 - accuracy: 0.0990 - val_loss: -8778.6104 - val_accuracy: 0.0985\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10807.2627 - accuracy: 0.0990 - val_loss: -13446.4746 - val_accuracy: 0.0985\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -15810.6084 - accuracy: 0.0990 - val_loss: -18981.9160 - val_accuracy: 0.0985\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -21692.8809 - accuracy: 0.0990 - val_loss: -25395.4902 - val_accuracy: 0.0985\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -28487.1367 - accuracy: 0.0990 - val_loss: -32778.0859 - val_accuracy: 0.0985\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -36083.6094 - accuracy: 0.0990 - val_loss: -40970.5625 - val_accuracy: 0.0985\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -44656.8398 - accuracy: 0.0990 - val_loss: -50251.5156 - val_accuracy: 0.0985\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -54277.3945 - accuracy: 0.0990 - val_loss: -60414.8203 - val_accuracy: 0.0985\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -64497.6914 - accuracy: 0.0990 - val_loss: -71243.4062 - val_accuracy: 0.0985\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -75858.9141 - accuracy: 0.0990 - val_loss: -83392.0703 - val_accuracy: 0.0985\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -88227.7266 - accuracy: 0.0990 - val_loss: -96451.9688 - val_accuracy: 0.0985\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -101559.0078 - accuracy: 0.0990 - val_loss: -110617.1406 - val_accuracy: 0.0985\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -115880.0547 - accuracy: 0.0990 - val_loss: -125692.6328 - val_accuracy: 0.0985\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -131397.5625 - accuracy: 0.0990 - val_loss: -142064.3125 - val_accuracy: 0.0985\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -147875.3125 - accuracy: 0.0990 - val_loss: -159341.1719 - val_accuracy: 0.0985\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -165468.0000 - accuracy: 0.0990 - val_loss: -177772.9062 - val_accuracy: 0.0985\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -182838.1719 - accuracy: 0.0990 - val_loss: -195370.2656 - val_accuracy: 0.0985\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -200663.3281 - accuracy: 0.0990 - val_loss: -213958.1094 - val_accuracy: 0.0985\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -220217.4844 - accuracy: 0.0990 - val_loss: -234600.7188 - val_accuracy: 0.0985\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -240850.7812 - accuracy: 0.0990 - val_loss: -256349.1094 - val_accuracy: 0.0985\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -263093.0938 - accuracy: 0.0990 - val_loss: -279857.5938 - val_accuracy: 0.0985\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -286724.8750 - accuracy: 0.0990 - val_loss: -304674.0625 - val_accuracy: 0.0985\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -312198.8750 - accuracy: 0.0990 - val_loss: -331091.7500 - val_accuracy: 0.0985\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -338278.4688 - accuracy: 0.0990 - val_loss: -358324.1250 - val_accuracy: 0.0985\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -366014.3125 - accuracy: 0.0990 - val_loss: -387135.3125 - val_accuracy: 0.0985\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -395087.5625 - accuracy: 0.0990 - val_loss: -417814.1562 - val_accuracy: 0.0985\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -425965.5000 - accuracy: 0.0990 - val_loss: -449679.3125 - val_accuracy: 0.0985\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -457961.9688 - accuracy: 0.0990 - val_loss: -483249.1875 - val_accuracy: 0.0985\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -491499.1875 - accuracy: 0.0990 - val_loss: -517999.2500 - val_accuracy: 0.0985\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -526786.7500 - accuracy: 0.0990 - val_loss: -554741.5000 - val_accuracy: 0.0985\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -563324.1875 - accuracy: 0.0990 - val_loss: -592606.3125 - val_accuracy: 0.0985\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -601473.2500 - accuracy: 0.0990 - val_loss: -632308.6250 - val_accuracy: 0.0985\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -641498.0625 - accuracy: 0.0990 - val_loss: -673751.7500 - val_accuracy: 0.0985\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -682373.3125 - accuracy: 0.0990 - val_loss: -716143.2500 - val_accuracy: 0.0985\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -725486.2500 - accuracy: 0.0990 - val_loss: -760391.5625 - val_accuracy: 0.0985\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -768840.8125 - accuracy: 0.0990 - val_loss: -805653.4375 - val_accuracy: 0.0985\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -814107.7500 - accuracy: 0.0990 - val_loss: -852493.4375 - val_accuracy: 0.0985\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -861203.9375 - accuracy: 0.0990 - val_loss: -901433.3125 - val_accuracy: 0.0985\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -910536.5000 - accuracy: 0.0990 - val_loss: -952121.6875 - val_accuracy: 0.0985\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -960659.2500 - accuracy: 0.0990 - val_loss: -1004244.8750 - val_accuracy: 0.0985\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1012697.3750 - accuracy: 0.0990 - val_loss: -1058035.7500 - val_accuracy: 0.0985\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1066576.2500 - accuracy: 0.0990 - val_loss: -1113775.7500 - val_accuracy: 0.0985\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1122535.2500 - accuracy: 0.0990 - val_loss: -1171994.3750 - val_accuracy: 0.0985\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1180434.3750 - accuracy: 0.0990 - val_loss: -1231911.7500 - val_accuracy: 0.0985\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1239766.3750 - accuracy: 0.0990 - val_loss: -1292981.5000 - val_accuracy: 0.0985\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1301375.2500 - accuracy: 0.0990 - val_loss: -1356553.6250 - val_accuracy: 0.0985\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1364161.5000 - accuracy: 0.0990 - val_loss: -1421480.3750 - val_accuracy: 0.0985\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1428971.0000 - accuracy: 0.0990 - val_loss: -1488274.5000 - val_accuracy: 0.0985\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1496497.2500 - accuracy: 0.0990 - val_loss: -1558223.2500 - val_accuracy: 0.0985\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1566000.7500 - accuracy: 0.0990 - val_loss: -1630078.6250 - val_accuracy: 0.0985\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1638404.1250 - accuracy: 0.0990 - val_loss: -1704210.2500 - val_accuracy: 0.0985\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1710798.5000 - accuracy: 0.0990 - val_loss: -1779370.5000 - val_accuracy: 0.0985\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1786000.5000 - accuracy: 0.0990 - val_loss: -1857429.3750 - val_accuracy: 0.0985\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1864144.6250 - accuracy: 0.0990 - val_loss: -1937036.8750 - val_accuracy: 0.0985\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1942684.2500 - accuracy: 0.0990 - val_loss: -2018473.8750 - val_accuracy: 0.0985\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2023310.2500 - accuracy: 0.0990 - val_loss: -2101149.5000 - val_accuracy: 0.0985\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2106160.7500 - accuracy: 0.0990 - val_loss: -2186785.0000 - val_accuracy: 0.0985\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2191475.0000 - accuracy: 0.0990 - val_loss: -2274682.7500 - val_accuracy: 0.0985\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2278563.7500 - accuracy: 0.0990 - val_loss: -2364588.7500 - val_accuracy: 0.0985\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2369488.5000 - accuracy: 0.0990 - val_loss: -2458142.7500 - val_accuracy: 0.0985\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2461930.2500 - accuracy: 0.0990 - val_loss: -2552906.0000 - val_accuracy: 0.0985\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2555605.2500 - accuracy: 0.0990 - val_loss: -2648660.7500 - val_accuracy: 0.0985\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2649847.5000 - accuracy: 0.0990 - val_loss: -2745887.0000 - val_accuracy: 0.0985\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2748146.0000 - accuracy: 0.0990 - val_loss: -2846906.2500 - val_accuracy: 0.0985\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2847082.5000 - accuracy: 0.0990 - val_loss: -2949563.2500 - val_accuracy: 0.0985\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2949009.0000 - accuracy: 0.0990 - val_loss: -3054425.5000 - val_accuracy: 0.0985\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3052901.2500 - accuracy: 0.0990 - val_loss: -3161458.5000 - val_accuracy: 0.0985\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3158511.5000 - accuracy: 0.0990 - val_loss: -3270118.7500 - val_accuracy: 0.0985\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3268854.5000 - accuracy: 0.0990 - val_loss: -3383630.0000 - val_accuracy: 0.0985\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3379257.5000 - accuracy: 0.0990 - val_loss: -3496329.0000 - val_accuracy: 0.0985\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3492339.7500 - accuracy: 0.0990 - val_loss: -3613306.7500 - val_accuracy: 0.0985\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3610159.7500 - accuracy: 0.0990 - val_loss: -3733502.2500 - val_accuracy: 0.0985\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3728236.0000 - accuracy: 0.0990 - val_loss: -3855756.5000 - val_accuracy: 0.0985\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3850416.2500 - accuracy: 0.0990 - val_loss: -3978315.5000 - val_accuracy: 0.0985\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3967844.2500 - accuracy: 0.0990 - val_loss: -4099735.0000 - val_accuracy: 0.0985\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4089780.5000 - accuracy: 0.0990 - val_loss: -4225532.5000 - val_accuracy: 0.0985\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4214531.5000 - accuracy: 0.0990 - val_loss: -4354312.0000 - val_accuracy: 0.0985\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4344182.0000 - accuracy: 0.0990 - val_loss: -4486854.5000 - val_accuracy: 0.0985\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4473717.5000 - accuracy: 0.0990 - val_loss: -4620760.0000 - val_accuracy: 0.0985\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4609492.0000 - accuracy: 0.0990 - val_loss: -4760608.0000 - val_accuracy: 0.0985\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4745372.5000 - accuracy: 0.0990 - val_loss: -4899269.5000 - val_accuracy: 0.0985\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4884201.5000 - accuracy: 0.0990 - val_loss: -5043006.5000 - val_accuracy: 0.0985\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5026498.0000 - accuracy: 0.0990 - val_loss: -5190240.0000 - val_accuracy: 0.0985\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5173045.5000 - accuracy: 0.0990 - val_loss: -5340389.5000 - val_accuracy: 0.0985\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5323575.5000 - accuracy: 0.0990 - val_loss: -5495118.0000 - val_accuracy: 0.0985\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5478330.5000 - accuracy: 0.0990 - val_loss: -5652714.5000 - val_accuracy: 0.0985\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5631368.0000 - accuracy: 0.0990 - val_loss: -5810686.0000 - val_accuracy: 0.0985\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5787766.5000 - accuracy: 0.0990 - val_loss: -5972115.5000 - val_accuracy: 0.0985\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5947302.5000 - accuracy: 0.0990 - val_loss: -6135930.5000 - val_accuracy: 0.0985\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6111555.0000 - accuracy: 0.0990 - val_loss: -6304608.5000 - val_accuracy: 0.0985\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6278684.0000 - accuracy: 0.0990 - val_loss: -6477300.0000 - val_accuracy: 0.0985\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6449193.0000 - accuracy: 0.0990 - val_loss: -6653088.5000 - val_accuracy: 0.0985\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6625832.0000 - accuracy: 0.0990 - val_loss: -6831955.0000 - val_accuracy: 0.0985\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6800876.0000 - accuracy: 0.0990 - val_loss: -7011666.5000 - val_accuracy: 0.0985\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6979648.5000 - accuracy: 0.0990 - val_loss: -7196996.5000 - val_accuracy: 0.0985\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7162337.5000 - accuracy: 0.0990 - val_loss: -7383866.0000 - val_accuracy: 0.0985\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7347929.0000 - accuracy: 0.0990 - val_loss: -7574311.0000 - val_accuracy: 0.0985\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       265\n","           1       0.10      1.00      0.18        83\n","           2       0.00      0.00      0.00       166\n","           3       0.00      0.00      0.00       193\n","           4       0.00      0.00      0.00       136\n","\n","    accuracy                           0.10       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.10      0.02       843\n","\n","Accuracy: 0.09845788849347568\n","[[  0 265   0   0   0]\n"," [  0  83   0   0   0]\n"," [  0 166   0   0   0]\n"," [  0 193   0   0   0]\n"," [  0 136   0   0   0]]\n","Precision: 0.0097\n","Recall: 0.0985\n","F1 Score: 0.0177\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://75fb7e7d-c767-4d60-bf3d-f706ebc3a01f/assets\n","model 4 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: -273.5657 - accuracy: 0.0972 - val_loss: -751.1539 - val_accuracy: 0.1151\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1824.7648 - accuracy: 0.0972 - val_loss: -2727.2483 - val_accuracy: 0.1151\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4557.8281 - accuracy: 0.0972 - val_loss: -5672.0054 - val_accuracy: 0.1151\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8294.6152 - accuracy: 0.0972 - val_loss: -9503.1318 - val_accuracy: 0.1151\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13020.1230 - accuracy: 0.0972 - val_loss: -14215.6699 - val_accuracy: 0.1151\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -18626.0000 - accuracy: 0.0972 - val_loss: -19680.3359 - val_accuracy: 0.1151\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -25228.2754 - accuracy: 0.0972 - val_loss: -26008.4707 - val_accuracy: 0.1151\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -32518.0898 - accuracy: 0.0972 - val_loss: -33028.0156 - val_accuracy: 0.1151\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -40809.8594 - accuracy: 0.0972 - val_loss: -41038.9219 - val_accuracy: 0.1151\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -50083.9531 - accuracy: 0.0972 - val_loss: -49798.9922 - val_accuracy: 0.1151\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -60431.3906 - accuracy: 0.0972 - val_loss: -59680.0508 - val_accuracy: 0.1151\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -71750.3047 - accuracy: 0.0972 - val_loss: -70304.4766 - val_accuracy: 0.1151\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -83970.1797 - accuracy: 0.0972 - val_loss: -81852.8281 - val_accuracy: 0.1151\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -97383.0547 - accuracy: 0.0972 - val_loss: -94407.3438 - val_accuracy: 0.1151\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -111793.4141 - accuracy: 0.0972 - val_loss: -108039.4688 - val_accuracy: 0.1151\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -127459.9219 - accuracy: 0.0972 - val_loss: -122672.6484 - val_accuracy: 0.1151\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -144204.8906 - accuracy: 0.0972 - val_loss: -138374.7656 - val_accuracy: 0.1151\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -161791.2188 - accuracy: 0.0972 - val_loss: -154833.8281 - val_accuracy: 0.1151\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -180765.4062 - accuracy: 0.0972 - val_loss: -172520.9531 - val_accuracy: 0.1151\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -201105.9219 - accuracy: 0.0972 - val_loss: -191556.7500 - val_accuracy: 0.1151\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -222646.2031 - accuracy: 0.0972 - val_loss: -211664.2812 - val_accuracy: 0.1151\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -245519.4062 - accuracy: 0.0972 - val_loss: -232902.7344 - val_accuracy: 0.1151\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -269762.5000 - accuracy: 0.0972 - val_loss: -255343.5781 - val_accuracy: 0.1151\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -295059.7812 - accuracy: 0.0972 - val_loss: -278875.9062 - val_accuracy: 0.1151\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -321771.3125 - accuracy: 0.0972 - val_loss: -303767.7500 - val_accuracy: 0.1151\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -349938.4375 - accuracy: 0.0972 - val_loss: -329938.5625 - val_accuracy: 0.1151\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -379620.7188 - accuracy: 0.0972 - val_loss: -357346.4375 - val_accuracy: 0.1151\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -410880.3438 - accuracy: 0.0972 - val_loss: -386208.6562 - val_accuracy: 0.1151\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -442763.5625 - accuracy: 0.0972 - val_loss: -415752.8125 - val_accuracy: 0.1151\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -476842.2500 - accuracy: 0.0972 - val_loss: -447272.5000 - val_accuracy: 0.1151\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -511545.0000 - accuracy: 0.0972 - val_loss: -479205.8750 - val_accuracy: 0.1151\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -547912.3125 - accuracy: 0.0972 - val_loss: -512802.0000 - val_accuracy: 0.1151\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -583325.8125 - accuracy: 0.0972 - val_loss: -544636.9375 - val_accuracy: 0.1151\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -620964.8750 - accuracy: 0.0972 - val_loss: -579721.8750 - val_accuracy: 0.1151\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -660488.1250 - accuracy: 0.0972 - val_loss: -616377.7500 - val_accuracy: 0.1151\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -702120.5000 - accuracy: 0.0972 - val_loss: -655036.5000 - val_accuracy: 0.1151\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -745470.3750 - accuracy: 0.0972 - val_loss: -695059.4375 - val_accuracy: 0.1151\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -790760.0625 - accuracy: 0.0972 - val_loss: -736805.0625 - val_accuracy: 0.1151\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -838293.0625 - accuracy: 0.0972 - val_loss: -780657.4375 - val_accuracy: 0.1151\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -887920.4375 - accuracy: 0.0972 - val_loss: -826677.3125 - val_accuracy: 0.1151\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -938838.5625 - accuracy: 0.0972 - val_loss: -873369.3750 - val_accuracy: 0.1151\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -991812.9375 - accuracy: 0.0972 - val_loss: -922418.2500 - val_accuracy: 0.1151\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1046560.4375 - accuracy: 0.0972 - val_loss: -972953.7500 - val_accuracy: 0.1151\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1103378.7500 - accuracy: 0.0972 - val_loss: -1025116.3750 - val_accuracy: 0.1151\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1162941.5000 - accuracy: 0.0972 - val_loss: -1079630.7500 - val_accuracy: 0.1151\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1223469.1250 - accuracy: 0.0972 - val_loss: -1135366.1250 - val_accuracy: 0.1151\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1285667.6250 - accuracy: 0.0972 - val_loss: -1192502.3750 - val_accuracy: 0.1151\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1349715.2500 - accuracy: 0.0972 - val_loss: -1251682.8750 - val_accuracy: 0.1151\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1415658.3750 - accuracy: 0.0972 - val_loss: -1311780.8750 - val_accuracy: 0.1151\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1483866.6250 - accuracy: 0.0972 - val_loss: -1374542.6250 - val_accuracy: 0.1151\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1554064.1250 - accuracy: 0.0972 - val_loss: -1439263.3750 - val_accuracy: 0.1151\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1627125.7500 - accuracy: 0.0972 - val_loss: -1506276.5000 - val_accuracy: 0.1151\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1702507.3750 - accuracy: 0.0972 - val_loss: -1575720.8750 - val_accuracy: 0.1151\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1779018.3750 - accuracy: 0.0972 - val_loss: -1645446.6250 - val_accuracy: 0.1151\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1858404.6250 - accuracy: 0.0972 - val_loss: -1718661.0000 - val_accuracy: 0.1151\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1939689.5000 - accuracy: 0.0972 - val_loss: -1793687.6250 - val_accuracy: 0.1151\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2023047.5000 - accuracy: 0.0972 - val_loss: -1869958.1250 - val_accuracy: 0.1151\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2109105.7500 - accuracy: 0.0972 - val_loss: -1948680.6250 - val_accuracy: 0.1151\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2197896.0000 - accuracy: 0.0972 - val_loss: -2030078.0000 - val_accuracy: 0.1151\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2288144.5000 - accuracy: 0.0972 - val_loss: -2113252.7500 - val_accuracy: 0.1151\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2380577.0000 - accuracy: 0.0972 - val_loss: -2197584.5000 - val_accuracy: 0.1151\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2475070.7500 - accuracy: 0.0972 - val_loss: -2284321.0000 - val_accuracy: 0.1151\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2572492.7500 - accuracy: 0.0972 - val_loss: -2373904.0000 - val_accuracy: 0.1151\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2673614.2500 - accuracy: 0.0972 - val_loss: -2466001.7500 - val_accuracy: 0.1151\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2774786.2500 - accuracy: 0.0972 - val_loss: -2559331.2500 - val_accuracy: 0.1151\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2877989.7500 - accuracy: 0.0972 - val_loss: -2652832.2500 - val_accuracy: 0.1151\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2983976.0000 - accuracy: 0.0972 - val_loss: -2750360.7500 - val_accuracy: 0.1151\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3092348.0000 - accuracy: 0.0972 - val_loss: -2849524.5000 - val_accuracy: 0.1151\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3204130.0000 - accuracy: 0.0972 - val_loss: -2951961.5000 - val_accuracy: 0.1151\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3316934.2500 - accuracy: 0.0972 - val_loss: -3055418.5000 - val_accuracy: 0.1151\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3433809.7500 - accuracy: 0.0972 - val_loss: -3162385.5000 - val_accuracy: 0.1151\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3552681.7500 - accuracy: 0.0972 - val_loss: -3270802.2500 - val_accuracy: 0.1151\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3674553.5000 - accuracy: 0.0972 - val_loss: -3382683.5000 - val_accuracy: 0.1151\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3798244.5000 - accuracy: 0.0972 - val_loss: -3495387.2500 - val_accuracy: 0.1151\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3926168.0000 - accuracy: 0.0972 - val_loss: -3612976.2500 - val_accuracy: 0.1151\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4055091.7500 - accuracy: 0.0972 - val_loss: -3730370.2500 - val_accuracy: 0.1151\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4186638.0000 - accuracy: 0.0972 - val_loss: -3851238.7500 - val_accuracy: 0.1151\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4323039.5000 - accuracy: 0.0972 - val_loss: -3975480.7500 - val_accuracy: 0.1151\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4459801.5000 - accuracy: 0.0972 - val_loss: -4101213.2500 - val_accuracy: 0.1151\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4600260.5000 - accuracy: 0.0972 - val_loss: -4228569.5000 - val_accuracy: 0.1151\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4742226.0000 - accuracy: 0.0972 - val_loss: -4357504.0000 - val_accuracy: 0.1151\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4883881.0000 - accuracy: 0.0972 - val_loss: -4488326.0000 - val_accuracy: 0.1151\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5029162.0000 - accuracy: 0.0972 - val_loss: -4621005.5000 - val_accuracy: 0.1151\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5178466.0000 - accuracy: 0.0972 - val_loss: -4757537.5000 - val_accuracy: 0.1151\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5333352.0000 - accuracy: 0.0972 - val_loss: -4898809.5000 - val_accuracy: 0.1151\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5487370.5000 - accuracy: 0.0972 - val_loss: -5039477.0000 - val_accuracy: 0.1151\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5646954.0000 - accuracy: 0.0972 - val_loss: -5185394.0000 - val_accuracy: 0.1151\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5807642.0000 - accuracy: 0.0972 - val_loss: -5332492.0000 - val_accuracy: 0.1151\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5973050.0000 - accuracy: 0.0972 - val_loss: -5482004.0000 - val_accuracy: 0.1151\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6137655.5000 - accuracy: 0.0972 - val_loss: -5633190.0000 - val_accuracy: 0.1151\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6305564.5000 - accuracy: 0.0972 - val_loss: -5787351.0000 - val_accuracy: 0.1151\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6478904.0000 - accuracy: 0.0972 - val_loss: -5946076.0000 - val_accuracy: 0.1151\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6653943.5000 - accuracy: 0.0972 - val_loss: -6104789.0000 - val_accuracy: 0.1151\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6832163.5000 - accuracy: 0.0972 - val_loss: -6268874.0000 - val_accuracy: 0.1151\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7015488.0000 - accuracy: 0.0972 - val_loss: -6436923.5000 - val_accuracy: 0.1151\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7201673.0000 - accuracy: 0.0972 - val_loss: -6605997.5000 - val_accuracy: 0.1151\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7392437.5000 - accuracy: 0.0972 - val_loss: -6780842.0000 - val_accuracy: 0.1151\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7586710.5000 - accuracy: 0.0972 - val_loss: -6957179.5000 - val_accuracy: 0.1151\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7783632.5000 - accuracy: 0.0972 - val_loss: -7137983.5000 - val_accuracy: 0.1151\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7985394.5000 - accuracy: 0.0972 - val_loss: -7320901.0000 - val_accuracy: 0.1151\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       294\n","           1       0.12      1.00      0.21        97\n","           2       0.00      0.00      0.00       151\n","           3       0.00      0.00      0.00       192\n","           4       0.00      0.00      0.00       109\n","\n","    accuracy                           0.12       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.12      0.02       843\n","\n","Accuracy: 0.11506524317912219\n","[[  0 294   0   0   0]\n"," [  0  97   0   0   0]\n"," [  0 151   0   0   0]\n"," [  0 192   0   0   0]\n"," [  0 109   0   0   0]]\n","Precision: 0.0132\n","Recall: 0.1151\n","F1 Score: 0.0237\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://543b56fd-095e-48dc-9d9d-78575c743d69/assets\n","model 5 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: -435.0992 - accuracy: 0.1001 - val_loss: -1438.9122 - val_accuracy: 0.0866\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3213.3572 - accuracy: 0.1003 - val_loss: -5836.2773 - val_accuracy: 0.0866\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8372.2773 - accuracy: 0.1003 - val_loss: -12424.5742 - val_accuracy: 0.0866\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -15512.1836 - accuracy: 0.1003 - val_loss: -21005.7988 - val_accuracy: 0.0866\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -24433.1055 - accuracy: 0.1003 - val_loss: -31468.7656 - val_accuracy: 0.0866\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -35148.0469 - accuracy: 0.1003 - val_loss: -43794.9180 - val_accuracy: 0.0866\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -47431.5781 - accuracy: 0.1003 - val_loss: -57640.1836 - val_accuracy: 0.0866\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -61322.0898 - accuracy: 0.1003 - val_loss: -73489.9297 - val_accuracy: 0.0866\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -76983.5391 - accuracy: 0.1003 - val_loss: -91227.1562 - val_accuracy: 0.0866\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -94660.8672 - accuracy: 0.1003 - val_loss: -111109.4531 - val_accuracy: 0.0866\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -114153.5234 - accuracy: 0.1003 - val_loss: -132782.5938 - val_accuracy: 0.0866\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -135815.7344 - accuracy: 0.1003 - val_loss: -156797.4219 - val_accuracy: 0.0866\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -158828.3438 - accuracy: 0.1003 - val_loss: -182380.8125 - val_accuracy: 0.0866\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -183806.9688 - accuracy: 0.1003 - val_loss: -210101.7188 - val_accuracy: 0.0866\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -211056.8750 - accuracy: 0.1003 - val_loss: -240588.1094 - val_accuracy: 0.0866\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -240679.6250 - accuracy: 0.1003 - val_loss: -273349.1250 - val_accuracy: 0.0866\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -271992.4375 - accuracy: 0.1003 - val_loss: -307587.9062 - val_accuracy: 0.0866\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -305516.4062 - accuracy: 0.1003 - val_loss: -344833.5312 - val_accuracy: 0.0866\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -341745.5625 - accuracy: 0.1003 - val_loss: -384478.6562 - val_accuracy: 0.0866\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -379890.7812 - accuracy: 0.1003 - val_loss: -426306.2812 - val_accuracy: 0.0866\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -420732.1250 - accuracy: 0.1003 - val_loss: -471376.3125 - val_accuracy: 0.0866\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -463710.4062 - accuracy: 0.1003 - val_loss: -518344.8438 - val_accuracy: 0.0866\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -509139.5312 - accuracy: 0.1003 - val_loss: -567782.3750 - val_accuracy: 0.0866\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -557324.5625 - accuracy: 0.1003 - val_loss: -620859.4375 - val_accuracy: 0.0866\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -608620.5000 - accuracy: 0.1003 - val_loss: -677322.9375 - val_accuracy: 0.0866\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -663210.6250 - accuracy: 0.1003 - val_loss: -736297.5000 - val_accuracy: 0.0866\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -718733.5625 - accuracy: 0.1003 - val_loss: -797427.0625 - val_accuracy: 0.0866\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -777389.1875 - accuracy: 0.1003 - val_loss: -861182.8125 - val_accuracy: 0.0866\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -839003.4375 - accuracy: 0.1003 - val_loss: -928389.4375 - val_accuracy: 0.0866\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -903339.1250 - accuracy: 0.1003 - val_loss: -998867.1250 - val_accuracy: 0.0866\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -970548.9375 - accuracy: 0.1003 - val_loss: -1071713.5000 - val_accuracy: 0.0866\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1040822.6875 - accuracy: 0.1003 - val_loss: -1148281.0000 - val_accuracy: 0.0866\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1114014.7500 - accuracy: 0.1003 - val_loss: -1228054.5000 - val_accuracy: 0.0866\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1191358.0000 - accuracy: 0.1003 - val_loss: -1311706.3750 - val_accuracy: 0.0866\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1271707.7500 - accuracy: 0.1003 - val_loss: -1398585.0000 - val_accuracy: 0.0866\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1353740.7500 - accuracy: 0.1003 - val_loss: -1487803.6250 - val_accuracy: 0.0866\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1438975.7500 - accuracy: 0.1003 - val_loss: -1580018.3750 - val_accuracy: 0.0866\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1526453.2500 - accuracy: 0.1003 - val_loss: -1675038.8750 - val_accuracy: 0.0866\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1617383.3750 - accuracy: 0.1003 - val_loss: -1773676.7500 - val_accuracy: 0.0866\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1712427.8750 - accuracy: 0.1003 - val_loss: -1877263.5000 - val_accuracy: 0.0866\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1810228.3750 - accuracy: 0.1003 - val_loss: -1983644.8750 - val_accuracy: 0.0866\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1912023.3750 - accuracy: 0.1003 - val_loss: -2094428.0000 - val_accuracy: 0.0866\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2018033.7500 - accuracy: 0.1003 - val_loss: -2208645.7500 - val_accuracy: 0.0866\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2128021.2500 - accuracy: 0.1003 - val_loss: -2328278.0000 - val_accuracy: 0.0866\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2242087.0000 - accuracy: 0.1003 - val_loss: -2451297.2500 - val_accuracy: 0.0866\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2360479.7500 - accuracy: 0.1003 - val_loss: -2579549.5000 - val_accuracy: 0.0866\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2480705.5000 - accuracy: 0.1003 - val_loss: -2709366.2500 - val_accuracy: 0.0866\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2603008.5000 - accuracy: 0.1003 - val_loss: -2841365.0000 - val_accuracy: 0.0866\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2731437.5000 - accuracy: 0.1003 - val_loss: -2979540.0000 - val_accuracy: 0.0866\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2862071.0000 - accuracy: 0.1003 - val_loss: -3120656.0000 - val_accuracy: 0.0866\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2995436.0000 - accuracy: 0.1003 - val_loss: -3265518.5000 - val_accuracy: 0.0866\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3133741.2500 - accuracy: 0.1003 - val_loss: -3414789.2500 - val_accuracy: 0.0866\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3275471.5000 - accuracy: 0.1003 - val_loss: -3568821.0000 - val_accuracy: 0.0866\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3421674.7500 - accuracy: 0.1003 - val_loss: -3727045.0000 - val_accuracy: 0.0866\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3573550.2500 - accuracy: 0.1003 - val_loss: -3890622.5000 - val_accuracy: 0.0866\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3730762.5000 - accuracy: 0.1003 - val_loss: -4059868.2500 - val_accuracy: 0.0866\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3889137.0000 - accuracy: 0.1003 - val_loss: -4231087.0000 - val_accuracy: 0.0866\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4051570.0000 - accuracy: 0.1003 - val_loss: -4406538.0000 - val_accuracy: 0.0866\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4218064.5000 - accuracy: 0.1003 - val_loss: -4587564.5000 - val_accuracy: 0.0866\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4392168.5000 - accuracy: 0.1003 - val_loss: -4772915.0000 - val_accuracy: 0.0866\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4569141.0000 - accuracy: 0.1003 - val_loss: -4963815.5000 - val_accuracy: 0.0866\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4746816.5000 - accuracy: 0.1003 - val_loss: -5156036.0000 - val_accuracy: 0.0866\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4929704.0000 - accuracy: 0.1003 - val_loss: -5353910.0000 - val_accuracy: 0.0866\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5120238.5000 - accuracy: 0.1003 - val_loss: -5559810.0000 - val_accuracy: 0.0866\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5316485.0000 - accuracy: 0.1003 - val_loss: -5770469.0000 - val_accuracy: 0.0866\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5513063.5000 - accuracy: 0.1003 - val_loss: -5982366.5000 - val_accuracy: 0.0866\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5716460.0000 - accuracy: 0.1003 - val_loss: -6200359.5000 - val_accuracy: 0.0866\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5925253.5000 - accuracy: 0.1003 - val_loss: -6425695.5000 - val_accuracy: 0.0866\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6132632.5000 - accuracy: 0.1003 - val_loss: -6649771.0000 - val_accuracy: 0.0866\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6346228.5000 - accuracy: 0.1003 - val_loss: -6880963.0000 - val_accuracy: 0.0866\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6567880.0000 - accuracy: 0.1003 - val_loss: -7118652.5000 - val_accuracy: 0.0866\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6793781.5000 - accuracy: 0.1003 - val_loss: -7362480.5000 - val_accuracy: 0.0866\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7024580.5000 - accuracy: 0.1003 - val_loss: -7613840.0000 - val_accuracy: 0.0866\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7265060.0000 - accuracy: 0.1003 - val_loss: -7869558.5000 - val_accuracy: 0.0866\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7506046.5000 - accuracy: 0.1003 - val_loss: -8131048.5000 - val_accuracy: 0.0866\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7755890.0000 - accuracy: 0.1003 - val_loss: -8397444.0000 - val_accuracy: 0.0866\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8007074.5000 - accuracy: 0.1003 - val_loss: -8668815.0000 - val_accuracy: 0.0866\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8264384.5000 - accuracy: 0.1003 - val_loss: -8945824.0000 - val_accuracy: 0.0866\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8525610.0000 - accuracy: 0.1003 - val_loss: -9228405.0000 - val_accuracy: 0.0866\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8796377.0000 - accuracy: 0.1003 - val_loss: -9517700.0000 - val_accuracy: 0.0866\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9065599.0000 - accuracy: 0.1003 - val_loss: -9808556.0000 - val_accuracy: 0.0866\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9344222.0000 - accuracy: 0.1003 - val_loss: -10107724.0000 - val_accuracy: 0.0866\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9627500.0000 - accuracy: 0.1003 - val_loss: -10411205.0000 - val_accuracy: 0.0866\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9917531.0000 - accuracy: 0.1003 - val_loss: -10727045.0000 - val_accuracy: 0.0866\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10211034.0000 - accuracy: 0.1003 - val_loss: -11040649.0000 - val_accuracy: 0.0866\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10510360.0000 - accuracy: 0.1003 - val_loss: -11364002.0000 - val_accuracy: 0.0866\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10817940.0000 - accuracy: 0.1003 - val_loss: -11695847.0000 - val_accuracy: 0.0866\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11129381.0000 - accuracy: 0.1003 - val_loss: -12028782.0000 - val_accuracy: 0.0866\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11450090.0000 - accuracy: 0.1003 - val_loss: -12375661.0000 - val_accuracy: 0.0866\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11774996.0000 - accuracy: 0.1003 - val_loss: -12722634.0000 - val_accuracy: 0.0866\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12104199.0000 - accuracy: 0.1003 - val_loss: -13078131.0000 - val_accuracy: 0.0866\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12441814.0000 - accuracy: 0.1003 - val_loss: -13440004.0000 - val_accuracy: 0.0866\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12783883.0000 - accuracy: 0.1003 - val_loss: -13808416.0000 - val_accuracy: 0.0866\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13134844.0000 - accuracy: 0.1003 - val_loss: -14186882.0000 - val_accuracy: 0.0866\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13488437.0000 - accuracy: 0.1003 - val_loss: -14566076.0000 - val_accuracy: 0.0866\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13850902.0000 - accuracy: 0.1003 - val_loss: -14955621.0000 - val_accuracy: 0.0866\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14215389.0000 - accuracy: 0.1003 - val_loss: -15347628.0000 - val_accuracy: 0.0866\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14593688.0000 - accuracy: 0.1003 - val_loss: -15752582.0000 - val_accuracy: 0.0866\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -14971144.0000 - accuracy: 0.1003 - val_loss: -16156060.0000 - val_accuracy: 0.0866\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -15354882.0000 - accuracy: 0.1003 - val_loss: -16570619.0000 - val_accuracy: 0.0866\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       274\n","           1       0.09      1.00      0.16        73\n","           2       0.00      0.00      0.00       168\n","           3       0.00      0.00      0.00       205\n","           4       0.00      0.00      0.00       123\n","\n","    accuracy                           0.09       843\n","   macro avg       0.02      0.20      0.03       843\n","weighted avg       0.01      0.09      0.01       843\n","\n","Accuracy: 0.08659549228944247\n","[[  0 274   0   0   0]\n"," [  0  73   0   0   0]\n"," [  0 168   0   0   0]\n"," [  0 205   0   0   0]\n"," [  0 123   0   0   0]]\n","Precision: 0.0075\n","Recall: 0.0866\n","F1 Score: 0.0138\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://c70e480d-357c-4fa3-b76e-531fe0b8deec/assets\n","model 6 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 4ms/step - loss: -184.4959 - accuracy: 0.0982 - val_loss: -502.5780 - val_accuracy: 0.0985\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1227.5472 - accuracy: 0.0990 - val_loss: -1935.6318 - val_accuracy: 0.0985\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3211.8396 - accuracy: 0.0990 - val_loss: -4110.6211 - val_accuracy: 0.0985\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5890.2285 - accuracy: 0.0990 - val_loss: -6908.7090 - val_accuracy: 0.0985\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9265.1836 - accuracy: 0.0990 - val_loss: -10276.5684 - val_accuracy: 0.0985\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13209.9736 - accuracy: 0.0990 - val_loss: -14228.7559 - val_accuracy: 0.0985\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -17830.9648 - accuracy: 0.0990 - val_loss: -18762.8203 - val_accuracy: 0.0985\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -22721.7734 - accuracy: 0.0990 - val_loss: -23451.7910 - val_accuracy: 0.0985\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -28273.2051 - accuracy: 0.0990 - val_loss: -28914.0371 - val_accuracy: 0.0985\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -34534.4531 - accuracy: 0.0990 - val_loss: -35007.8984 - val_accuracy: 0.0985\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -41462.1602 - accuracy: 0.0990 - val_loss: -41775.4688 - val_accuracy: 0.0985\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -49257.7109 - accuracy: 0.0990 - val_loss: -49321.2422 - val_accuracy: 0.0985\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -57853.0859 - accuracy: 0.0990 - val_loss: -57601.1055 - val_accuracy: 0.0985\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -67235.6719 - accuracy: 0.0990 - val_loss: -66635.2188 - val_accuracy: 0.0985\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -77433.3594 - accuracy: 0.0990 - val_loss: -76388.4609 - val_accuracy: 0.0985\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -88316.9219 - accuracy: 0.0990 - val_loss: -86831.5312 - val_accuracy: 0.0985\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -100080.6484 - accuracy: 0.0990 - val_loss: -98033.5312 - val_accuracy: 0.0985\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -112615.7656 - accuracy: 0.0990 - val_loss: -110085.4062 - val_accuracy: 0.0985\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -126251.2344 - accuracy: 0.0990 - val_loss: -122974.2031 - val_accuracy: 0.0985\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -140528.7969 - accuracy: 0.0990 - val_loss: -136576.2969 - val_accuracy: 0.0985\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -155683.4844 - accuracy: 0.0990 - val_loss: -151022.8125 - val_accuracy: 0.0985\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -171900.4844 - accuracy: 0.0990 - val_loss: -166363.5469 - val_accuracy: 0.0985\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -188848.5156 - accuracy: 0.0990 - val_loss: -182353.9375 - val_accuracy: 0.0985\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -206356.1094 - accuracy: 0.0990 - val_loss: -198914.2969 - val_accuracy: 0.0985\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -225106.0000 - accuracy: 0.0990 - val_loss: -216775.0000 - val_accuracy: 0.0985\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -244474.5312 - accuracy: 0.0990 - val_loss: -235145.8125 - val_accuracy: 0.0985\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -265240.0625 - accuracy: 0.0990 - val_loss: -254786.0469 - val_accuracy: 0.0985\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -287054.4688 - accuracy: 0.0990 - val_loss: -275430.2500 - val_accuracy: 0.0985\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -309778.8125 - accuracy: 0.0990 - val_loss: -296891.0312 - val_accuracy: 0.0985\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -333730.4062 - accuracy: 0.0990 - val_loss: -319538.0312 - val_accuracy: 0.0985\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -359038.4375 - accuracy: 0.0990 - val_loss: -343448.0000 - val_accuracy: 0.0985\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -385141.5312 - accuracy: 0.0990 - val_loss: -368091.3438 - val_accuracy: 0.0985\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -412610.3750 - accuracy: 0.0990 - val_loss: -393778.0938 - val_accuracy: 0.0985\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -440599.9062 - accuracy: 0.0990 - val_loss: -420183.5000 - val_accuracy: 0.0985\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -469465.3750 - accuracy: 0.0990 - val_loss: -447250.5938 - val_accuracy: 0.0985\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -500211.7188 - accuracy: 0.0990 - val_loss: -476242.1875 - val_accuracy: 0.0985\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -531400.9375 - accuracy: 0.0990 - val_loss: -505414.7500 - val_accuracy: 0.0985\n","Epoch 38/100\n","238/238 [==============================] - 1s 5ms/step - loss: -563835.3125 - accuracy: 0.0990 - val_loss: -535934.3125 - val_accuracy: 0.0985\n","Epoch 39/100\n","238/238 [==============================] - 1s 5ms/step - loss: -597856.4375 - accuracy: 0.0990 - val_loss: -568193.8125 - val_accuracy: 0.0985\n","Epoch 40/100\n","238/238 [==============================] - 1s 4ms/step - loss: -633331.8750 - accuracy: 0.0990 - val_loss: -601435.5000 - val_accuracy: 0.0985\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -670348.3750 - accuracy: 0.0990 - val_loss: -636154.3750 - val_accuracy: 0.0985\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -708040.2500 - accuracy: 0.0990 - val_loss: -671270.5000 - val_accuracy: 0.0985\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -747015.6250 - accuracy: 0.0990 - val_loss: -708153.3750 - val_accuracy: 0.0985\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -787410.5625 - accuracy: 0.0990 - val_loss: -746137.4375 - val_accuracy: 0.0985\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -829047.0000 - accuracy: 0.0990 - val_loss: -785115.8750 - val_accuracy: 0.0985\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -872120.8750 - accuracy: 0.0990 - val_loss: -825299.5625 - val_accuracy: 0.0985\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -916638.5625 - accuracy: 0.0990 - val_loss: -867290.6250 - val_accuracy: 0.0985\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -962374.6250 - accuracy: 0.0990 - val_loss: -910337.5000 - val_accuracy: 0.0985\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1009435.4375 - accuracy: 0.0990 - val_loss: -954518.2500 - val_accuracy: 0.0985\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1058200.3750 - accuracy: 0.0990 - val_loss: -1000277.1250 - val_accuracy: 0.0985\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1108900.8750 - accuracy: 0.0990 - val_loss: -1047520.7500 - val_accuracy: 0.0985\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1160614.2500 - accuracy: 0.0990 - val_loss: -1095953.3750 - val_accuracy: 0.0985\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1214339.1250 - accuracy: 0.0990 - val_loss: -1146522.6250 - val_accuracy: 0.0985\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1269482.1250 - accuracy: 0.0990 - val_loss: -1197891.2500 - val_accuracy: 0.0985\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1325707.2500 - accuracy: 0.0990 - val_loss: -1250967.5000 - val_accuracy: 0.0985\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1383645.1250 - accuracy: 0.0990 - val_loss: -1304864.5000 - val_accuracy: 0.0985\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1443540.7500 - accuracy: 0.0990 - val_loss: -1360939.3750 - val_accuracy: 0.0985\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1504586.1250 - accuracy: 0.0990 - val_loss: -1417900.5000 - val_accuracy: 0.0985\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1567769.2500 - accuracy: 0.0990 - val_loss: -1477480.5000 - val_accuracy: 0.0985\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1632732.7500 - accuracy: 0.0990 - val_loss: -1537958.0000 - val_accuracy: 0.0985\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1699864.1250 - accuracy: 0.0990 - val_loss: -1600477.2500 - val_accuracy: 0.0985\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1766934.5000 - accuracy: 0.0990 - val_loss: -1663169.5000 - val_accuracy: 0.0985\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1836730.5000 - accuracy: 0.0990 - val_loss: -1728369.6250 - val_accuracy: 0.0985\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1907001.7500 - accuracy: 0.0990 - val_loss: -1793899.7500 - val_accuracy: 0.0985\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1979328.8750 - accuracy: 0.0990 - val_loss: -1861662.5000 - val_accuracy: 0.0985\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2054193.2500 - accuracy: 0.0990 - val_loss: -1931557.0000 - val_accuracy: 0.0985\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2130005.5000 - accuracy: 0.0990 - val_loss: -2001571.2500 - val_accuracy: 0.0985\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2206531.7500 - accuracy: 0.0990 - val_loss: -2073706.8750 - val_accuracy: 0.0985\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2285340.7500 - accuracy: 0.0990 - val_loss: -2146997.2500 - val_accuracy: 0.0985\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2362414.5000 - accuracy: 0.0990 - val_loss: -2218171.7500 - val_accuracy: 0.0985\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2443975.5000 - accuracy: 0.0990 - val_loss: -2294138.5000 - val_accuracy: 0.0985\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2525903.7500 - accuracy: 0.0990 - val_loss: -2371500.2500 - val_accuracy: 0.0985\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2611219.0000 - accuracy: 0.0990 - val_loss: -2451249.5000 - val_accuracy: 0.0985\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2698350.7500 - accuracy: 0.0990 - val_loss: -2532506.0000 - val_accuracy: 0.0985\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2786784.0000 - accuracy: 0.0990 - val_loss: -2615388.5000 - val_accuracy: 0.0985\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2879235.0000 - accuracy: 0.0990 - val_loss: -2701255.2500 - val_accuracy: 0.0985\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2972637.2500 - accuracy: 0.0990 - val_loss: -2787341.0000 - val_accuracy: 0.0985\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3066080.5000 - accuracy: 0.0990 - val_loss: -2875371.7500 - val_accuracy: 0.0985\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3161629.0000 - accuracy: 0.0990 - val_loss: -2964157.0000 - val_accuracy: 0.0985\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3260017.2500 - accuracy: 0.0990 - val_loss: -3056357.2500 - val_accuracy: 0.0985\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3360560.2500 - accuracy: 0.0990 - val_loss: -3150422.0000 - val_accuracy: 0.0985\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3464771.7500 - accuracy: 0.0990 - val_loss: -3246860.2500 - val_accuracy: 0.0985\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3568158.2500 - accuracy: 0.0990 - val_loss: -3343497.7500 - val_accuracy: 0.0985\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3674762.0000 - accuracy: 0.0990 - val_loss: -3443099.0000 - val_accuracy: 0.0985\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3783462.2500 - accuracy: 0.0990 - val_loss: -3544994.2500 - val_accuracy: 0.0985\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3894512.0000 - accuracy: 0.0990 - val_loss: -3648409.7500 - val_accuracy: 0.0985\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4007628.7500 - accuracy: 0.0990 - val_loss: -3754123.5000 - val_accuracy: 0.0985\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4123037.7500 - accuracy: 0.0990 - val_loss: -3861112.2500 - val_accuracy: 0.0985\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4240412.5000 - accuracy: 0.0990 - val_loss: -3971271.7500 - val_accuracy: 0.0985\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4359903.0000 - accuracy: 0.0990 - val_loss: -4082037.2500 - val_accuracy: 0.0985\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4482440.5000 - accuracy: 0.0990 - val_loss: -4196726.5000 - val_accuracy: 0.0985\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4606789.5000 - accuracy: 0.0990 - val_loss: -4312722.0000 - val_accuracy: 0.0985\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4733648.0000 - accuracy: 0.0990 - val_loss: -4430599.5000 - val_accuracy: 0.0985\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4863336.5000 - accuracy: 0.0990 - val_loss: -4550894.0000 - val_accuracy: 0.0985\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4996286.0000 - accuracy: 0.0990 - val_loss: -4674743.0000 - val_accuracy: 0.0985\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5129615.5000 - accuracy: 0.0990 - val_loss: -4799118.5000 - val_accuracy: 0.0985\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5265691.0000 - accuracy: 0.0990 - val_loss: -4926282.0000 - val_accuracy: 0.0985\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5404386.0000 - accuracy: 0.0990 - val_loss: -5055743.5000 - val_accuracy: 0.0985\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5546889.0000 - accuracy: 0.0990 - val_loss: -5187629.0000 - val_accuracy: 0.0985\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5689129.0000 - accuracy: 0.0990 - val_loss: -5321108.0000 - val_accuracy: 0.0985\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       290\n","           1       0.10      1.00      0.18        83\n","           2       0.00      0.00      0.00       151\n","           3       0.00      0.00      0.00       187\n","           4       0.00      0.00      0.00       132\n","\n","    accuracy                           0.10       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.10      0.02       843\n","\n","Accuracy: 0.09845788849347568\n","[[  0 290   0   0   0]\n"," [  0  83   0   0   0]\n"," [  0 151   0   0   0]\n"," [  0 187   0   0   0]\n"," [  0 132   0   0   0]]\n","Precision: 0.0097\n","Recall: 0.0985\n","F1 Score: 0.0177\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://c98f52de-0fd0-4278-9cd5-0df64a380a6d/assets\n","model 7 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: -344.9666 - accuracy: 0.0999 - val_loss: -959.4754 - val_accuracy: 0.0986\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2323.0769 - accuracy: 0.0990 - val_loss: -3601.6157 - val_accuracy: 0.0986\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6024.0283 - accuracy: 0.0990 - val_loss: -7703.2466 - val_accuracy: 0.0986\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11213.2861 - accuracy: 0.0990 - val_loss: -13082.5459 - val_accuracy: 0.0986\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -17753.9844 - accuracy: 0.0990 - val_loss: -19746.4199 - val_accuracy: 0.0986\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -25702.9941 - accuracy: 0.0990 - val_loss: -27681.8047 - val_accuracy: 0.0986\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -35136.8125 - accuracy: 0.0990 - val_loss: -36928.3750 - val_accuracy: 0.0986\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -45841.6719 - accuracy: 0.0990 - val_loss: -47352.3672 - val_accuracy: 0.0986\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -57976.3945 - accuracy: 0.0990 - val_loss: -59227.7812 - val_accuracy: 0.0986\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -71670.4766 - accuracy: 0.0990 - val_loss: -72298.9062 - val_accuracy: 0.0986\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -86605.7891 - accuracy: 0.0990 - val_loss: -86738.5078 - val_accuracy: 0.0986\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -103100.2656 - accuracy: 0.0990 - val_loss: -102519.2031 - val_accuracy: 0.0986\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -121205.1172 - accuracy: 0.0990 - val_loss: -119918.3594 - val_accuracy: 0.0986\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -140795.5469 - accuracy: 0.0990 - val_loss: -138575.7969 - val_accuracy: 0.0986\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -162184.7188 - accuracy: 0.0990 - val_loss: -158984.5938 - val_accuracy: 0.0986\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -185359.5781 - accuracy: 0.0990 - val_loss: -181040.2656 - val_accuracy: 0.0986\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -209928.7188 - accuracy: 0.0990 - val_loss: -204345.1562 - val_accuracy: 0.0986\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -236417.4062 - accuracy: 0.0990 - val_loss: -229452.1406 - val_accuracy: 0.0986\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -264301.1250 - accuracy: 0.0990 - val_loss: -255727.0312 - val_accuracy: 0.0986\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -294433.7500 - accuracy: 0.0990 - val_loss: -284014.7500 - val_accuracy: 0.0986\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -325085.9688 - accuracy: 0.0990 - val_loss: -312873.2812 - val_accuracy: 0.0986\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -358063.4062 - accuracy: 0.0990 - val_loss: -343932.8750 - val_accuracy: 0.0986\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -392868.3750 - accuracy: 0.0990 - val_loss: -376802.6562 - val_accuracy: 0.0986\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -429629.4375 - accuracy: 0.0990 - val_loss: -411434.7188 - val_accuracy: 0.0986\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -468593.2500 - accuracy: 0.0990 - val_loss: -447947.2500 - val_accuracy: 0.0986\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -509639.3750 - accuracy: 0.0990 - val_loss: -486588.1250 - val_accuracy: 0.0986\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -552916.3750 - accuracy: 0.0990 - val_loss: -527142.9375 - val_accuracy: 0.0986\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -597890.1250 - accuracy: 0.0990 - val_loss: -569686.3750 - val_accuracy: 0.0986\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -645630.1250 - accuracy: 0.0990 - val_loss: -614220.0625 - val_accuracy: 0.0986\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -694374.5000 - accuracy: 0.0990 - val_loss: -659890.5625 - val_accuracy: 0.0986\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -745896.4375 - accuracy: 0.0990 - val_loss: -708059.5000 - val_accuracy: 0.0986\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -799836.0000 - accuracy: 0.0990 - val_loss: -758704.1875 - val_accuracy: 0.0986\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -855790.6250 - accuracy: 0.0990 - val_loss: -810902.7500 - val_accuracy: 0.0986\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -914249.8125 - accuracy: 0.0990 - val_loss: -865967.1250 - val_accuracy: 0.0986\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -974939.5000 - accuracy: 0.0990 - val_loss: -922400.3750 - val_accuracy: 0.0986\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1038242.5625 - accuracy: 0.0990 - val_loss: -981833.0625 - val_accuracy: 0.0986\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1104006.2500 - accuracy: 0.0990 - val_loss: -1042953.7500 - val_accuracy: 0.0986\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1172775.6250 - accuracy: 0.0990 - val_loss: -1106871.7500 - val_accuracy: 0.0986\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1243794.6250 - accuracy: 0.0990 - val_loss: -1173471.1250 - val_accuracy: 0.0986\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1317734.0000 - accuracy: 0.0990 - val_loss: -1242053.6250 - val_accuracy: 0.0986\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1393780.0000 - accuracy: 0.0990 - val_loss: -1313495.0000 - val_accuracy: 0.0986\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1471443.8750 - accuracy: 0.0990 - val_loss: -1385524.0000 - val_accuracy: 0.0986\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1552996.3750 - accuracy: 0.0990 - val_loss: -1461759.2500 - val_accuracy: 0.0986\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1636665.6250 - accuracy: 0.0990 - val_loss: -1540105.0000 - val_accuracy: 0.0986\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1723397.1250 - accuracy: 0.0990 - val_loss: -1620317.0000 - val_accuracy: 0.0986\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1813588.5000 - accuracy: 0.0990 - val_loss: -1704568.8750 - val_accuracy: 0.0986\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1905835.6250 - accuracy: 0.0990 - val_loss: -1790223.0000 - val_accuracy: 0.0986\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2001854.2500 - accuracy: 0.0990 - val_loss: -1879765.6250 - val_accuracy: 0.0986\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2099829.7500 - accuracy: 0.0990 - val_loss: -1970399.8750 - val_accuracy: 0.0986\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2201237.7500 - accuracy: 0.0990 - val_loss: -2065248.2500 - val_accuracy: 0.0986\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2306187.7500 - accuracy: 0.0990 - val_loss: -2162362.5000 - val_accuracy: 0.0986\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2413365.7500 - accuracy: 0.0990 - val_loss: -2262491.2500 - val_accuracy: 0.0986\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2524747.0000 - accuracy: 0.0990 - val_loss: -2365526.2500 - val_accuracy: 0.0986\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2638631.0000 - accuracy: 0.0990 - val_loss: -2471794.0000 - val_accuracy: 0.0986\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2755916.2500 - accuracy: 0.0990 - val_loss: -2580519.5000 - val_accuracy: 0.0986\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2875801.5000 - accuracy: 0.0990 - val_loss: -2691865.2500 - val_accuracy: 0.0986\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2999214.5000 - accuracy: 0.0990 - val_loss: -2806298.5000 - val_accuracy: 0.0986\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3125468.2500 - accuracy: 0.0990 - val_loss: -2923836.2500 - val_accuracy: 0.0986\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3255414.7500 - accuracy: 0.0990 - val_loss: -3044901.5000 - val_accuracy: 0.0986\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3390677.7500 - accuracy: 0.0990 - val_loss: -3169723.0000 - val_accuracy: 0.0986\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3527053.5000 - accuracy: 0.0990 - val_loss: -3295202.5000 - val_accuracy: 0.0986\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3665593.5000 - accuracy: 0.0990 - val_loss: -3425063.2500 - val_accuracy: 0.0986\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3809105.2500 - accuracy: 0.0990 - val_loss: -3556882.0000 - val_accuracy: 0.0986\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3952457.7500 - accuracy: 0.0990 - val_loss: -3689759.5000 - val_accuracy: 0.0986\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4100438.7500 - accuracy: 0.0990 - val_loss: -3827516.0000 - val_accuracy: 0.0986\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4251397.0000 - accuracy: 0.0990 - val_loss: -3967814.7500 - val_accuracy: 0.0986\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4406345.0000 - accuracy: 0.0990 - val_loss: -4112049.2500 - val_accuracy: 0.0986\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4568238.5000 - accuracy: 0.0990 - val_loss: -4261515.0000 - val_accuracy: 0.0986\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4731803.5000 - accuracy: 0.0990 - val_loss: -4412959.5000 - val_accuracy: 0.0986\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4898382.0000 - accuracy: 0.0990 - val_loss: -4567478.5000 - val_accuracy: 0.0986\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5068826.0000 - accuracy: 0.0990 - val_loss: -4725527.0000 - val_accuracy: 0.0986\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5245006.0000 - accuracy: 0.0990 - val_loss: -4889145.5000 - val_accuracy: 0.0986\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5426522.5000 - accuracy: 0.0990 - val_loss: -5055921.5000 - val_accuracy: 0.0986\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5607743.0000 - accuracy: 0.0990 - val_loss: -5224625.0000 - val_accuracy: 0.0986\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5793682.5000 - accuracy: 0.0990 - val_loss: -5396596.0000 - val_accuracy: 0.0986\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5981985.0000 - accuracy: 0.0990 - val_loss: -5571115.0000 - val_accuracy: 0.0986\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6175052.5000 - accuracy: 0.0990 - val_loss: -5751027.0000 - val_accuracy: 0.0986\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6373526.5000 - accuracy: 0.0990 - val_loss: -5933305.5000 - val_accuracy: 0.0986\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6577190.0000 - accuracy: 0.0990 - val_loss: -6122500.5000 - val_accuracy: 0.0986\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6784984.0000 - accuracy: 0.0990 - val_loss: -6315500.0000 - val_accuracy: 0.0986\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6997332.5000 - accuracy: 0.0990 - val_loss: -6511051.5000 - val_accuracy: 0.0986\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7211570.0000 - accuracy: 0.0990 - val_loss: -6709711.5000 - val_accuracy: 0.0986\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7431673.5000 - accuracy: 0.0990 - val_loss: -6914101.5000 - val_accuracy: 0.0986\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7655193.0000 - accuracy: 0.0990 - val_loss: -7120587.5000 - val_accuracy: 0.0986\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7882928.0000 - accuracy: 0.0990 - val_loss: -7331564.0000 - val_accuracy: 0.0986\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8116333.5000 - accuracy: 0.0990 - val_loss: -7547737.0000 - val_accuracy: 0.0986\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8354057.5000 - accuracy: 0.0990 - val_loss: -7767411.5000 - val_accuracy: 0.0986\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8596886.0000 - accuracy: 0.0990 - val_loss: -7991829.5000 - val_accuracy: 0.0986\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8844097.0000 - accuracy: 0.0990 - val_loss: -8219561.0000 - val_accuracy: 0.0986\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9096056.0000 - accuracy: 0.0990 - val_loss: -8452560.0000 - val_accuracy: 0.0986\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9347587.0000 - accuracy: 0.0990 - val_loss: -8684856.0000 - val_accuracy: 0.0986\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9605572.0000 - accuracy: 0.0990 - val_loss: -8924127.0000 - val_accuracy: 0.0986\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9869304.0000 - accuracy: 0.0990 - val_loss: -9167670.0000 - val_accuracy: 0.0986\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10136055.0000 - accuracy: 0.0990 - val_loss: -9415215.0000 - val_accuracy: 0.0986\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10411139.0000 - accuracy: 0.0990 - val_loss: -9668538.0000 - val_accuracy: 0.0986\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10690969.0000 - accuracy: 0.0990 - val_loss: -9927223.0000 - val_accuracy: 0.0986\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10972996.0000 - accuracy: 0.0990 - val_loss: -10189371.0000 - val_accuracy: 0.0986\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11260353.0000 - accuracy: 0.0990 - val_loss: -10453487.0000 - val_accuracy: 0.0986\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11550728.0000 - accuracy: 0.0990 - val_loss: -10722278.0000 - val_accuracy: 0.0986\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11848335.0000 - accuracy: 0.0990 - val_loss: -10998150.0000 - val_accuracy: 0.0986\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       287\n","           1       0.10      1.00      0.18        83\n","           2       0.00      0.00      0.00       167\n","           3       0.00      0.00      0.00       186\n","           4       0.00      0.00      0.00       119\n","\n","    accuracy                           0.10       842\n","   macro avg       0.02      0.20      0.04       842\n","weighted avg       0.01      0.10      0.02       842\n","\n","Accuracy: 0.09857482185273159\n","[[  0 287   0   0   0]\n"," [  0  83   0   0   0]\n"," [  0 167   0   0   0]\n"," [  0 186   0   0   0]\n"," [  0 119   0   0   0]]\n","Precision: 0.0097\n","Recall: 0.0986\n","F1 Score: 0.0177\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://d470ffcc-06ac-4e85-9336-fb046a167176/assets\n","model 8 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: -367.0874 - accuracy: 0.1010 - val_loss: -1254.5363 - val_accuracy: 0.0950\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2785.1350 - accuracy: 0.0994 - val_loss: -5098.6694 - val_accuracy: 0.0950\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7371.7246 - accuracy: 0.0994 - val_loss: -10942.3633 - val_accuracy: 0.0950\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13743.2969 - accuracy: 0.0994 - val_loss: -18590.5312 - val_accuracy: 0.0950\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: -21728.8906 - accuracy: 0.0994 - val_loss: -27944.7070 - val_accuracy: 0.0950\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: -31296.1641 - accuracy: 0.0994 - val_loss: -38996.9727 - val_accuracy: 0.0950\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: -42452.1328 - accuracy: 0.0994 - val_loss: -51708.4805 - val_accuracy: 0.0950\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: -55190.1133 - accuracy: 0.0994 - val_loss: -66064.5625 - val_accuracy: 0.0950\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: -69605.4062 - accuracy: 0.0994 - val_loss: -82312.5859 - val_accuracy: 0.0950\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: -85692.2266 - accuracy: 0.0994 - val_loss: -100373.3125 - val_accuracy: 0.0950\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: -103337.0625 - accuracy: 0.0994 - val_loss: -120012.6094 - val_accuracy: 0.0950\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: -122888.5156 - accuracy: 0.0994 - val_loss: -141705.6719 - val_accuracy: 0.0950\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: -144043.1094 - accuracy: 0.0994 - val_loss: -165090.4531 - val_accuracy: 0.0950\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: -166525.1406 - accuracy: 0.0994 - val_loss: -189773.0781 - val_accuracy: 0.0950\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: -191276.6562 - accuracy: 0.0994 - val_loss: -217018.4375 - val_accuracy: 0.0950\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: -217522.6875 - accuracy: 0.0994 - val_loss: -245969.8594 - val_accuracy: 0.0950\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: -245663.5156 - accuracy: 0.0994 - val_loss: -276998.3438 - val_accuracy: 0.0950\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: -275863.0000 - accuracy: 0.0994 - val_loss: -310167.2812 - val_accuracy: 0.0950\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: -308412.5312 - accuracy: 0.0994 - val_loss: -346197.9688 - val_accuracy: 0.0950\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: -343184.9062 - accuracy: 0.0994 - val_loss: -384199.3438 - val_accuracy: 0.0950\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: -380430.6562 - accuracy: 0.0994 - val_loss: -424911.1562 - val_accuracy: 0.0950\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: -419527.5000 - accuracy: 0.0994 - val_loss: -467850.4375 - val_accuracy: 0.0950\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: -461123.5938 - accuracy: 0.0994 - val_loss: -512920.3750 - val_accuracy: 0.0950\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: -504248.0312 - accuracy: 0.0994 - val_loss: -560024.1875 - val_accuracy: 0.0950\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: -550383.8750 - accuracy: 0.0994 - val_loss: -610423.0000 - val_accuracy: 0.0950\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: -598770.6875 - accuracy: 0.0994 - val_loss: -662805.1875 - val_accuracy: 0.0950\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: -649148.5625 - accuracy: 0.0994 - val_loss: -717795.2500 - val_accuracy: 0.0950\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: -701008.1250 - accuracy: 0.0994 - val_loss: -773978.4375 - val_accuracy: 0.0950\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: -755824.7500 - accuracy: 0.0994 - val_loss: -833661.8125 - val_accuracy: 0.0950\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: -813197.3750 - accuracy: 0.0994 - val_loss: -895785.8750 - val_accuracy: 0.0950\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: -873080.8125 - accuracy: 0.0994 - val_loss: -961653.6875 - val_accuracy: 0.0950\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: -936308.5000 - accuracy: 0.0994 - val_loss: -1029646.1250 - val_accuracy: 0.0950\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1002333.3125 - accuracy: 0.0994 - val_loss: -1100902.7500 - val_accuracy: 0.0950\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1069876.1250 - accuracy: 0.0994 - val_loss: -1174531.6250 - val_accuracy: 0.0950\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1140820.8750 - accuracy: 0.0994 - val_loss: -1251470.0000 - val_accuracy: 0.0950\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1215542.5000 - accuracy: 0.0994 - val_loss: -1332643.3750 - val_accuracy: 0.0950\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1291971.7500 - accuracy: 0.0994 - val_loss: -1415739.0000 - val_accuracy: 0.0950\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1372236.3750 - accuracy: 0.0994 - val_loss: -1502088.8750 - val_accuracy: 0.0950\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1452891.0000 - accuracy: 0.0994 - val_loss: -1589298.8750 - val_accuracy: 0.0950\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1537766.8750 - accuracy: 0.0994 - val_loss: -1681078.2500 - val_accuracy: 0.0950\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1626021.8750 - accuracy: 0.0994 - val_loss: -1776938.8750 - val_accuracy: 0.0950\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1718292.7500 - accuracy: 0.0994 - val_loss: -1876347.1250 - val_accuracy: 0.0950\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1813405.3750 - accuracy: 0.0994 - val_loss: -1978945.1250 - val_accuracy: 0.0950\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: -1911892.6250 - accuracy: 0.0994 - val_loss: -2085497.5000 - val_accuracy: 0.0950\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2013046.3750 - accuracy: 0.0994 - val_loss: -2194247.2500 - val_accuracy: 0.0950\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2116380.5000 - accuracy: 0.0994 - val_loss: -2305944.0000 - val_accuracy: 0.0950\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2223255.0000 - accuracy: 0.0994 - val_loss: -2421335.5000 - val_accuracy: 0.0950\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2334421.5000 - accuracy: 0.0994 - val_loss: -2541389.2500 - val_accuracy: 0.0950\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2448515.5000 - accuracy: 0.0994 - val_loss: -2664489.7500 - val_accuracy: 0.0950\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2567315.7500 - accuracy: 0.0994 - val_loss: -2792524.5000 - val_accuracy: 0.0950\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2689176.0000 - accuracy: 0.0994 - val_loss: -2924305.7500 - val_accuracy: 0.0950\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2815275.2500 - accuracy: 0.0994 - val_loss: -3060206.0000 - val_accuracy: 0.0950\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: -2944548.5000 - accuracy: 0.0994 - val_loss: -3199335.2500 - val_accuracy: 0.0950\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3077971.5000 - accuracy: 0.0994 - val_loss: -3343572.0000 - val_accuracy: 0.0950\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3214231.0000 - accuracy: 0.0994 - val_loss: -3489915.5000 - val_accuracy: 0.0950\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3354384.0000 - accuracy: 0.0994 - val_loss: -3641936.5000 - val_accuracy: 0.0950\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3498366.7500 - accuracy: 0.0994 - val_loss: -3795928.5000 - val_accuracy: 0.0950\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3645476.0000 - accuracy: 0.0994 - val_loss: -3954585.2500 - val_accuracy: 0.0950\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3796738.7500 - accuracy: 0.0994 - val_loss: -4117575.7500 - val_accuracy: 0.0950\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: -3952883.2500 - accuracy: 0.0994 - val_loss: -4286089.0000 - val_accuracy: 0.0950\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4112225.7500 - accuracy: 0.0994 - val_loss: -4456417.0000 - val_accuracy: 0.0950\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4275098.0000 - accuracy: 0.0994 - val_loss: -4631576.5000 - val_accuracy: 0.0950\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4441585.5000 - accuracy: 0.0994 - val_loss: -4811272.0000 - val_accuracy: 0.0950\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4613062.5000 - accuracy: 0.0994 - val_loss: -4996685.0000 - val_accuracy: 0.0950\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4789023.5000 - accuracy: 0.0994 - val_loss: -5183560.0000 - val_accuracy: 0.0950\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: -4969182.5000 - accuracy: 0.0994 - val_loss: -5378197.5000 - val_accuracy: 0.0950\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5152159.5000 - accuracy: 0.0994 - val_loss: -5575261.0000 - val_accuracy: 0.0950\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5340455.5000 - accuracy: 0.0994 - val_loss: -5776988.0000 - val_accuracy: 0.0950\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5534608.0000 - accuracy: 0.0994 - val_loss: -5986188.0000 - val_accuracy: 0.0950\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5731013.5000 - accuracy: 0.0994 - val_loss: -6197537.0000 - val_accuracy: 0.0950\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: -5931057.0000 - accuracy: 0.0994 - val_loss: -6412372.0000 - val_accuracy: 0.0950\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6134837.5000 - accuracy: 0.0994 - val_loss: -6630337.0000 - val_accuracy: 0.0950\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6345333.5000 - accuracy: 0.0994 - val_loss: -6858066.0000 - val_accuracy: 0.0950\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6560386.0000 - accuracy: 0.0994 - val_loss: -7087648.0000 - val_accuracy: 0.0950\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: -6780949.5000 - accuracy: 0.0994 - val_loss: -7323488.5000 - val_accuracy: 0.0950\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7003018.0000 - accuracy: 0.0994 - val_loss: -7562405.0000 - val_accuracy: 0.0950\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7230821.5000 - accuracy: 0.0994 - val_loss: -7806705.5000 - val_accuracy: 0.0950\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7461400.0000 - accuracy: 0.0994 - val_loss: -8056046.5000 - val_accuracy: 0.0950\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7700168.5000 - accuracy: 0.0994 - val_loss: -8310486.5000 - val_accuracy: 0.0950\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: -7940879.0000 - accuracy: 0.0994 - val_loss: -8569433.0000 - val_accuracy: 0.0950\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8187097.5000 - accuracy: 0.0994 - val_loss: -8833351.0000 - val_accuracy: 0.0950\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8438428.0000 - accuracy: 0.0994 - val_loss: -9103901.0000 - val_accuracy: 0.0950\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8692400.0000 - accuracy: 0.0994 - val_loss: -9377239.0000 - val_accuracy: 0.0950\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: -8952825.0000 - accuracy: 0.0994 - val_loss: -9654938.0000 - val_accuracy: 0.0950\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9209725.0000 - accuracy: 0.0994 - val_loss: -9929519.0000 - val_accuracy: 0.0950\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9476483.0000 - accuracy: 0.0994 - val_loss: -10215540.0000 - val_accuracy: 0.0950\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: -9750336.0000 - accuracy: 0.0994 - val_loss: -10510902.0000 - val_accuracy: 0.0950\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10030834.0000 - accuracy: 0.0994 - val_loss: -10810389.0000 - val_accuracy: 0.0950\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10317958.0000 - accuracy: 0.0994 - val_loss: -11116805.0000 - val_accuracy: 0.0950\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10605371.0000 - accuracy: 0.0994 - val_loss: -11428103.0000 - val_accuracy: 0.0950\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: -10897981.0000 - accuracy: 0.0994 - val_loss: -11742820.0000 - val_accuracy: 0.0950\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11197453.0000 - accuracy: 0.0994 - val_loss: -12063025.0000 - val_accuracy: 0.0950\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11503554.0000 - accuracy: 0.0994 - val_loss: -12389062.0000 - val_accuracy: 0.0950\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: -11813082.0000 - accuracy: 0.0994 - val_loss: -12721362.0000 - val_accuracy: 0.0950\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12128950.0000 - accuracy: 0.0994 - val_loss: -13061129.0000 - val_accuracy: 0.0950\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12452398.0000 - accuracy: 0.0994 - val_loss: -13408620.0000 - val_accuracy: 0.0950\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: -12782693.0000 - accuracy: 0.0994 - val_loss: -13762702.0000 - val_accuracy: 0.0950\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13120452.0000 - accuracy: 0.0994 - val_loss: -14123310.0000 - val_accuracy: 0.0950\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13457241.0000 - accuracy: 0.0994 - val_loss: -14486543.0000 - val_accuracy: 0.0950\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: -13804816.0000 - accuracy: 0.0994 - val_loss: -14859262.0000 - val_accuracy: 0.0950\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       270\n","           1       0.10      1.00      0.17        80\n","           2       0.00      0.00      0.00       178\n","           3       0.00      0.00      0.00       201\n","           4       0.00      0.00      0.00       113\n","\n","    accuracy                           0.10       842\n","   macro avg       0.02      0.20      0.03       842\n","weighted avg       0.01      0.10      0.02       842\n","\n","Accuracy: 0.09501187648456057\n","[[  0 270   0   0   0]\n"," [  0  80   0   0   0]\n"," [  0 178   0   0   0]\n"," [  0 201   0   0   0]\n"," [  0 113   0   0   0]]\n","Precision: 0.0090\n","Recall: 0.0950\n","F1 Score: 0.0165\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://7c2c57f4-d52c-467a-9091-f60f2365db5c/assets\n","model 9 saved\n","Average Validation Accuracy: 0.09895534836279209\n"]}]},{"cell_type":"code","source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/URL/NN/model_5.h5'\n","\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","def predict_prob(number):\n","  return [number[0],1-number[0]]\n","\n","y_prob = np.array(list(map(predict_prob, loaded_model.predict(x_test))))\n","y_prob \n","\n","# y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['nn_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['nn_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output['nn_prediction_spam'] = [i[2] for i in y_pred_prob];\n","output['nn_prediction_malware'] = [i[3] for i in y_pred_prob];\n","output['nn_prediction_defacemen'] = [i[4] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":693},"id":"dolEygpVsl_4","executionInfo":{"status":"ok","timestamp":1656573664338,"user_tz":-330,"elapsed":1538,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"62803abe-9501-4275-f8fc-0a79b5deb496"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[2.27930408e-01 3.52669068e-07 3.17896223e-09 7.72068989e-01\n","  2.47127316e-07]\n"," [9.99849322e-01 4.83915474e-07 1.51218955e-09 1.50192352e-04\n","  2.28598272e-10]\n"," [1.28142616e-06 1.73256713e-08 3.98062294e-11 9.99998200e-01\n","  5.01489322e-07]\n"," ...\n"," [9.99685499e-01 1.59853046e-05 1.31639481e-12 2.98512764e-04\n","  3.36510890e-09]\n"," [1.66346146e-10 3.93031973e-02 9.60689680e-01 1.14207633e-11\n","  7.12230582e-06]\n"," [1.95998885e-04 9.99801785e-01 1.53610390e-11 2.21641900e-06\n","  3.52212170e-16]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  mlp_prediction_spam  \\\n","0          0        2.279304e-01          3.526691e-07         3.178962e-09   \n","1          0        9.998493e-01          4.839155e-07         1.512190e-09   \n","2          3        1.281426e-06          1.732567e-08         3.980623e-11   \n","3          3        1.273963e-03          6.203745e-08         6.837719e-12   \n","4          2        7.031173e-09          1.819293e-04         9.998181e-01   \n","...      ...                 ...                   ...                  ...   \n","6891       4        1.892153e-12          2.127109e-12         5.182954e-10   \n","6892       1        1.789397e-04          9.990517e-01         2.676060e-04   \n","6893       0        9.996855e-01          1.598530e-05         1.316395e-12   \n","6894       2        1.663461e-10          3.930320e-02         9.606897e-01   \n","6895       1        1.959989e-04          9.998018e-01         1.536104e-11   \n","\n","      mlp_prediction_malware  mlp_prediction_defacemen  nn_prediction_non  \\\n","0               7.720690e-01              2.471273e-07       2.279304e-01   \n","1               1.501924e-04              2.285983e-10       9.998493e-01   \n","2               9.999982e-01              5.014893e-07       1.281426e-06   \n","3               9.987260e-01              1.322388e-11       1.273963e-03   \n","4               7.719379e-15              2.118226e-11       7.031173e-09   \n","...                      ...                       ...                ...   \n","6891            1.837704e-16              1.000000e+00       1.892153e-12   \n","6892            5.004229e-04              1.291414e-06       1.789397e-04   \n","6893            2.985128e-04              3.365109e-09       9.996855e-01   \n","6894            1.142076e-11              7.122306e-06       1.663461e-10   \n","6895            2.216419e-06              3.522122e-16       1.959989e-04   \n","\n","      nn_prediction_phish  nn_prediction_spam  nn_prediction_malware  \\\n","0            3.526691e-07        3.178962e-09           7.720690e-01   \n","1            4.839155e-07        1.512190e-09           1.501924e-04   \n","2            1.732567e-08        3.980623e-11           9.999982e-01   \n","3            6.203745e-08        6.837719e-12           9.987260e-01   \n","4            1.819293e-04        9.998181e-01           7.719379e-15   \n","...                   ...                 ...                    ...   \n","6891         2.127109e-12        5.182954e-10           1.837704e-16   \n","6892         9.990517e-01        2.676060e-04           5.004229e-04   \n","6893         1.598530e-05        1.316395e-12           2.985128e-04   \n","6894         3.930320e-02        9.606897e-01           1.142076e-11   \n","6895         9.998018e-01        1.536104e-11           2.216419e-06   \n","\n","      nn_prediction_defacemen  \n","0                2.471273e-07  \n","1                2.285983e-10  \n","2                5.014893e-07  \n","3                1.322388e-11  \n","4                2.118226e-11  \n","...                       ...  \n","6891             1.000000e+00  \n","6892             1.291414e-06  \n","6893             3.365109e-09  \n","6894             7.122306e-06  \n","6895             3.522122e-16  \n","\n","[6896 rows x 11 columns]"],"text/html":["\n","  <div id=\"df-6af6c65c-e174-4e2b-ab98-fddcf526a7b6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>mlp_prediction_spam</th>\n","      <th>mlp_prediction_malware</th>\n","      <th>mlp_prediction_defacemen</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","      <th>nn_prediction_spam</th>\n","      <th>nn_prediction_malware</th>\n","      <th>nn_prediction_defacemen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2.279304e-01</td>\n","      <td>3.526691e-07</td>\n","      <td>3.178962e-09</td>\n","      <td>7.720690e-01</td>\n","      <td>2.471273e-07</td>\n","      <td>2.279304e-01</td>\n","      <td>3.526691e-07</td>\n","      <td>3.178962e-09</td>\n","      <td>7.720690e-01</td>\n","      <td>2.471273e-07</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>9.998493e-01</td>\n","      <td>4.839155e-07</td>\n","      <td>1.512190e-09</td>\n","      <td>1.501924e-04</td>\n","      <td>2.285983e-10</td>\n","      <td>9.998493e-01</td>\n","      <td>4.839155e-07</td>\n","      <td>1.512190e-09</td>\n","      <td>1.501924e-04</td>\n","      <td>2.285983e-10</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1.281426e-06</td>\n","      <td>1.732567e-08</td>\n","      <td>3.980623e-11</td>\n","      <td>9.999982e-01</td>\n","      <td>5.014893e-07</td>\n","      <td>1.281426e-06</td>\n","      <td>1.732567e-08</td>\n","      <td>3.980623e-11</td>\n","      <td>9.999982e-01</td>\n","      <td>5.014893e-07</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1.273963e-03</td>\n","      <td>6.203745e-08</td>\n","      <td>6.837719e-12</td>\n","      <td>9.987260e-01</td>\n","      <td>1.322388e-11</td>\n","      <td>1.273963e-03</td>\n","      <td>6.203745e-08</td>\n","      <td>6.837719e-12</td>\n","      <td>9.987260e-01</td>\n","      <td>1.322388e-11</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>7.031173e-09</td>\n","      <td>1.819293e-04</td>\n","      <td>9.998181e-01</td>\n","      <td>7.719379e-15</td>\n","      <td>2.118226e-11</td>\n","      <td>7.031173e-09</td>\n","      <td>1.819293e-04</td>\n","      <td>9.998181e-01</td>\n","      <td>7.719379e-15</td>\n","      <td>2.118226e-11</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6891</th>\n","      <td>4</td>\n","      <td>1.892153e-12</td>\n","      <td>2.127109e-12</td>\n","      <td>5.182954e-10</td>\n","      <td>1.837704e-16</td>\n","      <td>1.000000e+00</td>\n","      <td>1.892153e-12</td>\n","      <td>2.127109e-12</td>\n","      <td>5.182954e-10</td>\n","      <td>1.837704e-16</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>6892</th>\n","      <td>1</td>\n","      <td>1.789397e-04</td>\n","      <td>9.990517e-01</td>\n","      <td>2.676060e-04</td>\n","      <td>5.004229e-04</td>\n","      <td>1.291414e-06</td>\n","      <td>1.789397e-04</td>\n","      <td>9.990517e-01</td>\n","      <td>2.676060e-04</td>\n","      <td>5.004229e-04</td>\n","      <td>1.291414e-06</td>\n","    </tr>\n","    <tr>\n","      <th>6893</th>\n","      <td>0</td>\n","      <td>9.996855e-01</td>\n","      <td>1.598530e-05</td>\n","      <td>1.316395e-12</td>\n","      <td>2.985128e-04</td>\n","      <td>3.365109e-09</td>\n","      <td>9.996855e-01</td>\n","      <td>1.598530e-05</td>\n","      <td>1.316395e-12</td>\n","      <td>2.985128e-04</td>\n","      <td>3.365109e-09</td>\n","    </tr>\n","    <tr>\n","      <th>6894</th>\n","      <td>2</td>\n","      <td>1.663461e-10</td>\n","      <td>3.930320e-02</td>\n","      <td>9.606897e-01</td>\n","      <td>1.142076e-11</td>\n","      <td>7.122306e-06</td>\n","      <td>1.663461e-10</td>\n","      <td>3.930320e-02</td>\n","      <td>9.606897e-01</td>\n","      <td>1.142076e-11</td>\n","      <td>7.122306e-06</td>\n","    </tr>\n","    <tr>\n","      <th>6895</th>\n","      <td>1</td>\n","      <td>1.959989e-04</td>\n","      <td>9.998018e-01</td>\n","      <td>1.536104e-11</td>\n","      <td>2.216419e-06</td>\n","      <td>3.522122e-16</td>\n","      <td>1.959989e-04</td>\n","      <td>9.998018e-01</td>\n","      <td>1.536104e-11</td>\n","      <td>2.216419e-06</td>\n","      <td>3.522122e-16</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6896 rows × 11 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6af6c65c-e174-4e2b-ab98-fddcf526a7b6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6af6c65c-e174-4e2b-ab98-fddcf526a7b6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6af6c65c-e174-4e2b-ab98-fddcf526a7b6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["**Neural Network 2**"],"metadata":{"id":"fMdqVtYLwwy4"}},{"cell_type":"code","source":["\n","import keras\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","def model_a(x_train, x_val, y_train, y_val, opt, n, early_stopping_monitor):\n","\n","  n_cols = x_train.shape[1]\n","\n","  #create model\n","  model_2 = Sequential()\n","  model_2.add(Dense(30, activation='sigmoid', input_shape=(n_cols,)))\n","  model_2.add(Dense(25, activation='sigmoid'))\n","  model_2.add(Dense(20, activation='sigmoid'))\n","  model_2.add(Dense(15, activation='sigmoid'))\n","  model_2.add(Dense(10, activation='sigmoid'))\n","  model_2.add(Dense(1, activation = 'sigmoid'))\n","\n","  #compile model using mse as a measure of model performance\n","  model_2.compile(optimizer='adam', loss='mean_squared_error')\n","\n","\n","\n","  history = model_2.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping_monitor])\n","\n","\n","  # plt.plot(history.history['loss'])\n","  # plt.plot(history.history['val_loss'])\n","  # plt.title('model loss')\n","  # plt.ylabel('Loss')\n","  # plt.xlabel('Epoch')\n","  # plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n","  # plt.show()\n","\n","\n","  print('Validation Accuracy: ')\n","  # Predicting the Test set results\n","  y_pred = model_2.predict(x_val)\n","  y_pred = (y_pred > 0.5)\n","\n","\n","  print(classification_report(y_val, y_pred))\n","\n","  # Model Accuracy, how often is the classifier correct?\n","  print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","\n","  # Creating the Confusion Matrix\n","  cm = confusion_matrix(y_val, y_pred)\n","  print(cm)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred, average='weighted'))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred, average='weighted'))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred, average='weighted'))\n","\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/URL/NN_2/model_'+str(n)+'.h5'\n","  pickle.dump(model_2, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","\n","  return metrics.accuracy_score(y_val, y_pred)\n","\n"],"metadata":{"id":"L8ZhB8W9tVQS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_a(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n, early_stopping_monitor)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osCV0Uo5wqac","executionInfo":{"status":"ok","timestamp":1656574387198,"user_tz":-330,"elapsed":639134,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"d8d22016-cd5b-4b0e-bf34-ded303b5a5e7"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","238/238 [==============================] - 3s 8ms/step - loss: 3.1990 - val_loss: 3.2511\n","Epoch 2/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.8989 - val_loss: 3.1250\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8265 - val_loss: 3.0755\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7953 - val_loss: 3.0511\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7788 - val_loss: 3.0369\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7685 - val_loss: 3.0275\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7615 - val_loss: 3.0208\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7565 - val_loss: 3.0163\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7532 - val_loss: 3.0131\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7508 - val_loss: 3.0108\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7491 - val_loss: 3.0091\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7477 - val_loss: 3.0077\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7466 - val_loss: 3.0066\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7458 - val_loss: 3.0058\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7451 - val_loss: 3.0051\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7445 - val_loss: 3.0045\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7441 - val_loss: 3.0041\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7437 - val_loss: 3.0038\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7435 - val_loss: 3.0035\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7433 - val_loss: 3.0033\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7432 - val_loss: 3.0032\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7431 - val_loss: 3.0031\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7430 - val_loss: 3.0030\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7429 - val_loss: 3.0029\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7428 - val_loss: 3.0028\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7428 - val_loss: 3.0028\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7427 - val_loss: 3.0027\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7427 - val_loss: 3.0027\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7426 - val_loss: 3.0026\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7426 - val_loss: 3.0026\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7426 - val_loss: 3.0026\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7426 - val_loss: 3.0025\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7425 - val_loss: 3.0025\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7425 - val_loss: 3.0025\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7425 - val_loss: 3.0025\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7425 - val_loss: 3.0025\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7425 - val_loss: 3.0025\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7425 - val_loss: 3.0024\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7424 - val_loss: 3.0024\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       260\n","           1       0.09      1.00      0.17        78\n","           2       0.00      0.00      0.00       168\n","           3       0.00      0.00      0.00       186\n","           4       0.00      0.00      0.00       151\n","\n","    accuracy                           0.09       843\n","   macro avg       0.02      0.20      0.03       843\n","weighted avg       0.01      0.09      0.02       843\n","\n","Accuracy: 0.09252669039145907\n","[[  0 260   0   0   0]\n"," [  0  78   0   0   0]\n"," [  0 168   0   0   0]\n"," [  0 186   0   0   0]\n"," [  0 151   0   0   0]]\n","Precision: 0.0086\n","Recall: 0.0925\n","F1 Score: 0.0157\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://bfd804e1-f176-4874-97dd-3adba7b54f09/assets\n","model 0 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.7188 - val_loss: 3.1676\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.0523 - val_loss: 2.9123\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.9084 - val_loss: 2.8355\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8544 - val_loss: 2.7993\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8270 - val_loss: 2.7788\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8101 - val_loss: 2.7654\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7993 - val_loss: 2.7572\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7925 - val_loss: 2.7518\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7880 - val_loss: 2.7481\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7848 - val_loss: 2.7454\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7824 - val_loss: 2.7434\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7806 - val_loss: 2.7419\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7793 - val_loss: 2.7407\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7781 - val_loss: 2.7397\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7772 - val_loss: 2.7389\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7765 - val_loss: 2.7382\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7759 - val_loss: 2.7377\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7754 - val_loss: 2.7372\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7750 - val_loss: 2.7368\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7746 - val_loss: 2.7365\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7743 - val_loss: 2.7362\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7740 - val_loss: 2.7360\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7738 - val_loss: 2.7357\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7736 - val_loss: 2.7355\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7734 - val_loss: 2.7354\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7732 - val_loss: 2.7352\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7731 - val_loss: 2.7351\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7729 - val_loss: 2.7350\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7728 - val_loss: 2.7349\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7727 - val_loss: 2.7348\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7727 - val_loss: 2.7347\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7726 - val_loss: 2.7347\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7725 - val_loss: 2.7346\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7725 - val_loss: 2.7346\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7725 - val_loss: 2.7345\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7724 - val_loss: 2.7345\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7724 - val_loss: 2.7345\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7724 - val_loss: 2.7345\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7723 - val_loss: 2.7344\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7723 - val_loss: 2.7344\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7723 - val_loss: 2.7344\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7723 - val_loss: 2.7344\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7723 - val_loss: 2.7344\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7723 - val_loss: 2.7344\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7723 - val_loss: 2.7344\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7723 - val_loss: 2.7343\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7722 - val_loss: 2.7343\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       272\n","           1       0.10      1.00      0.18        83\n","           2       0.00      0.00      0.00       183\n","           3       0.00      0.00      0.00       179\n","           4       0.00      0.00      0.00       126\n","\n","    accuracy                           0.10       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.10      0.02       843\n","\n","Accuracy: 0.09845788849347568\n","[[  0 272   0   0   0]\n"," [  0  83   0   0   0]\n"," [  0 183   0   0   0]\n"," [  0 179   0   0   0]\n"," [  0 126   0   0   0]]\n","Precision: 0.0097\n","Recall: 0.0985\n","F1 Score: 0.0177\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://75a4cebc-b347-46c2-80b9-e74140d6ee51/assets\n","model 1 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.5570 - val_loss: 3.1001\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.9640 - val_loss: 2.9288\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8736 - val_loss: 2.8709\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8360 - val_loss: 2.8418\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8156 - val_loss: 2.8247\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8030 - val_loss: 2.8136\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7947 - val_loss: 2.8061\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7890 - val_loss: 2.8008\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7848 - val_loss: 2.7968\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7816 - val_loss: 2.7937\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7791 - val_loss: 2.7914\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7772 - val_loss: 2.7895\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7756 - val_loss: 2.7879\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7743 - val_loss: 2.7867\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7733 - val_loss: 2.7856\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7725 - val_loss: 2.7848\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7717 - val_loss: 2.7840\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7711 - val_loss: 2.7834\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7706 - val_loss: 2.7829\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7702 - val_loss: 2.7825\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7698 - val_loss: 2.7821\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7695 - val_loss: 2.7817\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7692 - val_loss: 2.7815\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7690 - val_loss: 2.7812\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7687 - val_loss: 2.7810\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7686 - val_loss: 2.7808\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7684 - val_loss: 2.7806\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7682 - val_loss: 2.7805\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7681 - val_loss: 2.7803\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7680 - val_loss: 2.7802\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7679 - val_loss: 2.7801\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7678 - val_loss: 2.7800\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7678 - val_loss: 2.7800\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7677 - val_loss: 2.7799\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7676 - val_loss: 2.7798\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7676 - val_loss: 2.7798\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7675 - val_loss: 2.7797\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7675 - val_loss: 2.7797\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7675 - val_loss: 2.7797\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7674 - val_loss: 2.7796\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7674 - val_loss: 2.7796\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7674 - val_loss: 2.7796\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7673 - val_loss: 2.7795\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7673 - val_loss: 2.7795\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7673 - val_loss: 2.7795\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7673 - val_loss: 2.7795\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7673 - val_loss: 2.7795\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7673 - val_loss: 2.7795\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7673 - val_loss: 2.7794\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7672 - val_loss: 2.7794\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       247\n","           1       0.10      1.00      0.19        87\n","           2       0.00      0.00      0.00       170\n","           3       0.00      0.00      0.00       225\n","           4       0.00      0.00      0.00       114\n","\n","    accuracy                           0.10       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.10      0.02       843\n","\n","Accuracy: 0.10320284697508897\n","[[  0 247   0   0   0]\n"," [  0  87   0   0   0]\n"," [  0 170   0   0   0]\n"," [  0 225   0   0   0]\n"," [  0 114   0   0   0]]\n","Precision: 0.0107\n","Recall: 0.1032\n","F1 Score: 0.0193\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://2f20d77c-c34d-4f39-a64a-150a2e6139e3/assets\n","model 2 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.1134 - val_loss: 2.7589\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8412 - val_loss: 2.7056\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8108 - val_loss: 2.6896\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7993 - val_loss: 2.6821\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7934 - val_loss: 2.6779\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7899 - val_loss: 2.6752\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7875 - val_loss: 2.6733\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7859 - val_loss: 2.6719\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7847 - val_loss: 2.6710\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7838 - val_loss: 2.6702\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7831 - val_loss: 2.6696\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7825 - val_loss: 2.6692\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7821 - val_loss: 2.6688\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7817 - val_loss: 2.6685\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7815 - val_loss: 2.6682\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7812 - val_loss: 2.6680\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7810 - val_loss: 2.6678\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7808 - val_loss: 2.6677\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7807 - val_loss: 2.6676\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7806 - val_loss: 2.6674\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7805 - val_loss: 2.6673\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7804 - val_loss: 2.6673\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7803 - val_loss: 2.6672\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7802 - val_loss: 2.6671\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7801 - val_loss: 2.6671\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7801 - val_loss: 2.6670\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7800 - val_loss: 2.6670\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7800 - val_loss: 2.6669\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7800 - val_loss: 2.6669\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7799 - val_loss: 2.6669\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7799 - val_loss: 2.6669\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7799 - val_loss: 2.6668\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7799 - val_loss: 2.6668\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7798 - val_loss: 2.6668\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7798 - val_loss: 2.6668\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7798 - val_loss: 2.6668\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7798 - val_loss: 2.6668\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7798 - val_loss: 2.6667\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7798 - val_loss: 2.6667\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7798 - val_loss: 2.6667\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7798 - val_loss: 2.6667\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7798 - val_loss: 2.6667\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 52/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 53/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.6667\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       274\n","           1       0.10      1.00      0.19        87\n","           2       0.00      0.00      0.00       168\n","           3       0.00      0.00      0.00       204\n","           4       0.00      0.00      0.00       110\n","\n","    accuracy                           0.10       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.10      0.02       843\n","\n","Accuracy: 0.10320284697508897\n","[[  0 274   0   0   0]\n"," [  0  87   0   0   0]\n"," [  0 168   0   0   0]\n"," [  0 204   0   0   0]\n"," [  0 110   0   0   0]]\n","Precision: 0.0107\n","Recall: 0.1032\n","F1 Score: 0.0193\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://ef4f4ea7-52a2-424f-a0f4-e8e6bfb01240/assets\n","model 3 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.3387 - val_loss: 3.0786\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8815 - val_loss: 2.9705\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8230 - val_loss: 2.9350\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7997 - val_loss: 2.9176\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7872 - val_loss: 2.9074\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7793 - val_loss: 2.9006\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7741 - val_loss: 2.8960\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7704 - val_loss: 2.8926\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7676 - val_loss: 2.8901\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7656 - val_loss: 2.8882\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8867\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8855\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7617 - val_loss: 2.8845\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7609 - val_loss: 2.8838\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7602 - val_loss: 2.8831\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7597 - val_loss: 2.8825\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7592 - val_loss: 2.8821\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7588 - val_loss: 2.8817\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7584 - val_loss: 2.8813\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7581 - val_loss: 2.8810\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7579 - val_loss: 2.8808\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7577 - val_loss: 2.8806\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7575 - val_loss: 2.8804\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7573 - val_loss: 2.8802\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7572 - val_loss: 2.8801\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7570 - val_loss: 2.8799\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7569 - val_loss: 2.8798\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7568 - val_loss: 2.8797\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7567 - val_loss: 2.8797\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7567 - val_loss: 2.8796\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7566 - val_loss: 2.8795\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7565 - val_loss: 2.8795\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7565 - val_loss: 2.8794\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7564 - val_loss: 2.8794\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7564 - val_loss: 2.8793\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7564 - val_loss: 2.8793\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7563 - val_loss: 2.8793\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7563 - val_loss: 2.8792\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7563 - val_loss: 2.8792\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7563 - val_loss: 2.8792\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7563 - val_loss: 2.8792\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7562 - val_loss: 2.8791\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7562 - val_loss: 2.8791\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7562 - val_loss: 2.8791\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7562 - val_loss: 2.8791\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7562 - val_loss: 2.8791\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7562 - val_loss: 2.8791\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7562 - val_loss: 2.8791\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7562 - val_loss: 2.8791\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7562 - val_loss: 2.8791\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8791\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7561 - val_loss: 2.8790\n","Validation Accuracy: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       265\n","           1       0.10      1.00      0.18        83\n","           2       0.00      0.00      0.00       166\n","           3       0.00      0.00      0.00       193\n","           4       0.00      0.00      0.00       136\n","\n","    accuracy                           0.10       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.10      0.02       843\n","\n","Accuracy: 0.09845788849347568\n","[[  0 265   0   0   0]\n"," [  0  83   0   0   0]\n"," [  0 166   0   0   0]\n"," [  0 193   0   0   0]\n"," [  0 136   0   0   0]]\n","Precision: 0.0097\n","Recall: 0.0985\n","F1 Score: 0.0177\n","INFO:tensorflow:Assets written to: ram://3504ccca-50aa-4767-86cc-b84cfd53ac0d/assets\n","model 4 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.5949 - val_loss: 2.9093\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.0101 - val_loss: 2.7221\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8908 - val_loss: 2.6702\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8511 - val_loss: 2.6473\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8311 - val_loss: 2.6345\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8192 - val_loss: 2.6265\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8114 - val_loss: 2.6210\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8059 - val_loss: 2.6169\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8010 - val_loss: 2.6127\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7969 - val_loss: 2.6100\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7944 - val_loss: 2.6083\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7928 - val_loss: 2.6072\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7916 - val_loss: 2.6063\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7908 - val_loss: 2.6057\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7901 - val_loss: 2.6052\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7896 - val_loss: 2.6048\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7892 - val_loss: 2.6045\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7888 - val_loss: 2.6042\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7886 - val_loss: 2.6040\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7883 - val_loss: 2.6038\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7881 - val_loss: 2.6037\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7880 - val_loss: 2.6035\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7878 - val_loss: 2.6034\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7877 - val_loss: 2.6033\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7876 - val_loss: 2.6032\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7875 - val_loss: 2.6032\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7874 - val_loss: 2.6031\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7873 - val_loss: 2.6030\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7873 - val_loss: 2.6030\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7872 - val_loss: 2.6029\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7872 - val_loss: 2.6029\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7871 - val_loss: 2.6029\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7871 - val_loss: 2.6028\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7871 - val_loss: 2.6028\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6028\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6028\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6028\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6027\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7870 - val_loss: 2.6027\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6027\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6027\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6027\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6027\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6027\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6027\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6027\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6027\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6026\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6026\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6026\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7869 - val_loss: 2.6026\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.6026\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       294\n","           1       0.12      1.00      0.21        97\n","           2       0.00      0.00      0.00       151\n","           3       0.00      0.00      0.00       192\n","           4       0.00      0.00      0.00       109\n","\n","    accuracy                           0.12       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.12      0.02       843\n","\n","Accuracy: 0.11506524317912219\n","[[  0 294   0   0   0]\n"," [  0  97   0   0   0]\n"," [  0 151   0   0   0]\n"," [  0 192   0   0   0]\n"," [  0 109   0   0   0]]\n","Precision: 0.0132\n","Recall: 0.1151\n","F1 Score: 0.0237\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://2134db9e-a098-4e55-8b38-e0eb16e8ed6d/assets\n","model 5 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.5667 - val_loss: 3.1184\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.9484 - val_loss: 2.9307\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8516 - val_loss: 2.8785\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8177 - val_loss: 2.8552\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8006 - val_loss: 2.8422\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7906 - val_loss: 2.8340\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7841 - val_loss: 2.8286\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7797 - val_loss: 2.8248\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7765 - val_loss: 2.8220\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7741 - val_loss: 2.8199\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7723 - val_loss: 2.8182\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7709 - val_loss: 2.8169\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7698 - val_loss: 2.8159\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7689 - val_loss: 2.8151\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7681 - val_loss: 2.8144\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7675 - val_loss: 2.8138\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7670 - val_loss: 2.8133\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7666 - val_loss: 2.8129\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7662 - val_loss: 2.8125\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7659 - val_loss: 2.8122\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7656 - val_loss: 2.8120\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7654 - val_loss: 2.8118\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7652 - val_loss: 2.8116\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7650 - val_loss: 2.8114\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7648 - val_loss: 2.8113\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7647 - val_loss: 2.8111\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7646 - val_loss: 2.8110\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7645 - val_loss: 2.8109\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7644 - val_loss: 2.8108\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7643 - val_loss: 2.8108\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7643 - val_loss: 2.8107\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7642 - val_loss: 2.8106\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7642 - val_loss: 2.8106\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7641 - val_loss: 2.8105\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7641 - val_loss: 2.8105\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8105\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8104\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8104\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7639 - val_loss: 2.8104\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7639 - val_loss: 2.8104\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7639 - val_loss: 2.8104\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7639 - val_loss: 2.8103\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7639 - val_loss: 2.8103\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7639 - val_loss: 2.8103\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8103\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8103\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8103\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8103\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8103\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8103\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8102\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8102\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8102\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8102\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8102\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8102\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8102\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8102\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8102\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8102\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8102\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8102\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8102\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 95/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 96/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 97/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 98/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 99/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Epoch 100/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8102\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       274\n","           1       0.09      1.00      0.16        73\n","           2       0.00      0.00      0.00       168\n","           3       0.00      0.00      0.00       205\n","           4       0.00      0.00      0.00       123\n","\n","    accuracy                           0.09       843\n","   macro avg       0.02      0.20      0.03       843\n","weighted avg       0.01      0.09      0.01       843\n","\n","Accuracy: 0.08659549228944247\n","[[  0 274   0   0   0]\n"," [  0  73   0   0   0]\n"," [  0 168   0   0   0]\n"," [  0 205   0   0   0]\n"," [  0 123   0   0   0]]\n","Precision: 0.0075\n","Recall: 0.0866\n","F1 Score: 0.0138\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://7a984d82-14cc-4125-a032-797f9b8c9aa7/assets\n","model 6 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.1987 - val_loss: 2.9732\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8689 - val_loss: 2.8884\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8177 - val_loss: 2.8605\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7976 - val_loss: 2.8471\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7871 - val_loss: 2.8396\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7807 - val_loss: 2.8347\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7765 - val_loss: 2.8314\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7736 - val_loss: 2.8290\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7715 - val_loss: 2.8273\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7699 - val_loss: 2.8260\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7687 - val_loss: 2.8249\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7677 - val_loss: 2.8241\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7669 - val_loss: 2.8234\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7663 - val_loss: 2.8229\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7658 - val_loss: 2.8224\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7653 - val_loss: 2.8220\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7650 - val_loss: 2.8217\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7647 - val_loss: 2.8215\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7644 - val_loss: 2.8212\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7642 - val_loss: 2.8210\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7640 - val_loss: 2.8209\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7638 - val_loss: 2.8207\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7637 - val_loss: 2.8206\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7636 - val_loss: 2.8205\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7635 - val_loss: 2.8204\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7634 - val_loss: 2.8203\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7633 - val_loss: 2.8202\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7632 - val_loss: 2.8202\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7632 - val_loss: 2.8201\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7631 - val_loss: 2.8201\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7631 - val_loss: 2.8200\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7630 - val_loss: 2.8200\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7630 - val_loss: 2.8200\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7629 - val_loss: 2.8199\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7629 - val_loss: 2.8199\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7629 - val_loss: 2.8199\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7629 - val_loss: 2.8199\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7628 - val_loss: 2.8198\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7628 - val_loss: 2.8198\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7628 - val_loss: 2.8198\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7628 - val_loss: 2.8198\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7628 - val_loss: 2.8198\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7628 - val_loss: 2.8198\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7628 - val_loss: 2.8198\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7628 - val_loss: 2.8198\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7628 - val_loss: 2.8197\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 87/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 88/100\n","238/238 [==============================] - 1s 4ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7627 - val_loss: 2.8197\n","Validation Accuracy: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       290\n","           1       0.10      1.00      0.18        83\n","           2       0.00      0.00      0.00       151\n","           3       0.00      0.00      0.00       187\n","           4       0.00      0.00      0.00       132\n","\n","    accuracy                           0.10       843\n","   macro avg       0.02      0.20      0.04       843\n","weighted avg       0.01      0.10      0.02       843\n","\n","Accuracy: 0.09845788849347568\n","[[  0 290   0   0   0]\n"," [  0  83   0   0   0]\n"," [  0 151   0   0   0]\n"," [  0 187   0   0   0]\n"," [  0 132   0   0   0]]\n","Precision: 0.0097\n","Recall: 0.0985\n","F1 Score: 0.0177\n","INFO:tensorflow:Assets written to: ram://d26c5225-555c-4b8d-922c-d1250308768d/assets\n","model 7 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.2215 - val_loss: 2.8027\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8482 - val_loss: 2.7378\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8125 - val_loss: 2.7208\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8001 - val_loss: 2.7129\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7934 - val_loss: 2.7081\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7893 - val_loss: 2.7051\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7866 - val_loss: 2.7030\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7846 - val_loss: 2.7014\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7831 - val_loss: 2.7003\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7820 - val_loss: 2.6993\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7811 - val_loss: 2.6986\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7804 - val_loss: 2.6980\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7798 - val_loss: 2.6976\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7794 - val_loss: 2.6972\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7790 - val_loss: 2.6968\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7786 - val_loss: 2.6966\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7784 - val_loss: 2.6963\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7781 - val_loss: 2.6961\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7779 - val_loss: 2.6960\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7778 - val_loss: 2.6958\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7776 - val_loss: 2.6957\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7775 - val_loss: 2.6956\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7774 - val_loss: 2.6955\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7773 - val_loss: 2.6954\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7772 - val_loss: 2.6953\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7771 - val_loss: 2.6953\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7771 - val_loss: 2.6952\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7770 - val_loss: 2.6952\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7769 - val_loss: 2.6951\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7769 - val_loss: 2.6951\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7769 - val_loss: 2.6950\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7768 - val_loss: 2.6950\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7768 - val_loss: 2.6950\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7768 - val_loss: 2.6950\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7767 - val_loss: 2.6949\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7767 - val_loss: 2.6949\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7767 - val_loss: 2.6949\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7767 - val_loss: 2.6949\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7767 - val_loss: 2.6949\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7767 - val_loss: 2.6949\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7767 - val_loss: 2.6949\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       287\n","           1       0.10      1.00      0.18        83\n","           2       0.00      0.00      0.00       167\n","           3       0.00      0.00      0.00       186\n","           4       0.00      0.00      0.00       119\n","\n","    accuracy                           0.10       842\n","   macro avg       0.02      0.20      0.04       842\n","weighted avg       0.01      0.10      0.02       842\n","\n","Accuracy: 0.09857482185273159\n","[[  0 287   0   0   0]\n"," [  0  83   0   0   0]\n"," [  0 167   0   0   0]\n"," [  0 186   0   0   0]\n"," [  0 119   0   0   0]]\n","Precision: 0.0097\n","Recall: 0.0986\n","F1 Score: 0.0177\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://98923242-3a9e-4ded-9ea4-6d1d8179b949/assets\n","model 8 saved\n","Epoch 1/100\n","238/238 [==============================] - 1s 3ms/step - loss: 3.4647 - val_loss: 2.9024\n","Epoch 2/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.9100 - val_loss: 2.7840\n","Epoch 3/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8468 - val_loss: 2.7496\n","Epoch 4/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8225 - val_loss: 2.7327\n","Epoch 5/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8094 - val_loss: 2.7227\n","Epoch 6/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.8012 - val_loss: 2.7161\n","Epoch 7/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7958 - val_loss: 2.7116\n","Epoch 8/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7918 - val_loss: 2.7083\n","Epoch 9/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7890 - val_loss: 2.7059\n","Epoch 10/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7868 - val_loss: 2.7040\n","Epoch 11/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7851 - val_loss: 2.7025\n","Epoch 12/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7837 - val_loss: 2.7013\n","Epoch 13/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7826 - val_loss: 2.7003\n","Epoch 14/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7818 - val_loss: 2.6995\n","Epoch 15/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7810 - val_loss: 2.6989\n","Epoch 16/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7804 - val_loss: 2.6983\n","Epoch 17/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7799 - val_loss: 2.6978\n","Epoch 18/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7794 - val_loss: 2.6974\n","Epoch 19/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7791 - val_loss: 2.6971\n","Epoch 20/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7788 - val_loss: 2.6968\n","Epoch 21/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7785 - val_loss: 2.6966\n","Epoch 22/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7782 - val_loss: 2.6963\n","Epoch 23/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7780 - val_loss: 2.6961\n","Epoch 24/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7779 - val_loss: 2.6960\n","Epoch 25/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7777 - val_loss: 2.6958\n","Epoch 26/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7776 - val_loss: 2.6957\n","Epoch 27/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7775 - val_loss: 2.6956\n","Epoch 28/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7773 - val_loss: 2.6955\n","Epoch 29/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7773 - val_loss: 2.6954\n","Epoch 30/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7772 - val_loss: 2.6953\n","Epoch 31/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7771 - val_loss: 2.6953\n","Epoch 32/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7770 - val_loss: 2.6952\n","Epoch 33/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7770 - val_loss: 2.6952\n","Epoch 34/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7769 - val_loss: 2.6951\n","Epoch 35/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7769 - val_loss: 2.6951\n","Epoch 36/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7769 - val_loss: 2.6951\n","Epoch 37/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7768 - val_loss: 2.6950\n","Epoch 38/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7768 - val_loss: 2.6950\n","Epoch 39/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7768 - val_loss: 2.6950\n","Epoch 40/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7767 - val_loss: 2.6949\n","Epoch 41/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7767 - val_loss: 2.6949\n","Epoch 42/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7767 - val_loss: 2.6949\n","Epoch 43/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7767 - val_loss: 2.6949\n","Epoch 44/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7767 - val_loss: 2.6949\n","Epoch 45/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7767 - val_loss: 2.6949\n","Epoch 46/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7767 - val_loss: 2.6949\n","Epoch 47/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6949\n","Epoch 48/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 49/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 50/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 51/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 52/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 53/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 54/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 55/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 56/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 57/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 58/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 59/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 60/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 61/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 62/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 63/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 64/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 65/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 66/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 67/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 68/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 69/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 70/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 71/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 72/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 73/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 74/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 75/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 76/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 77/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 78/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 79/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 80/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 81/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 82/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 83/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 84/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 85/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 86/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 87/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 88/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 89/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 90/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 91/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 92/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 93/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Epoch 94/100\n","238/238 [==============================] - 1s 3ms/step - loss: 2.7766 - val_loss: 2.6948\n","Validation Accuracy: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       270\n","           1       0.10      1.00      0.17        80\n","           2       0.00      0.00      0.00       178\n","           3       0.00      0.00      0.00       201\n","           4       0.00      0.00      0.00       113\n","\n","    accuracy                           0.10       842\n","   macro avg       0.02      0.20      0.03       842\n","weighted avg       0.01      0.10      0.02       842\n","\n","Accuracy: 0.09501187648456057\n","[[  0 270   0   0   0]\n"," [  0  80   0   0   0]\n"," [  0 178   0   0   0]\n"," [  0 201   0   0   0]\n"," [  0 113   0   0   0]]\n","Precision: 0.0090\n","Recall: 0.0950\n","F1 Score: 0.0165\n","INFO:tensorflow:Assets written to: ram://57d64eac-f327-4272-883e-2edacb900043/assets\n","model 9 saved\n","Average Validation Accuracy: 0.09895534836279209\n"]}]},{"cell_type":"code","source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/UNB/Multi/Models/URL/NN_2/model_5.h5'\n","\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","def predict_prob(number):\n","  return [number[0],1-number[0]]\n","\n","y_prob = np.array(list(map(predict_prob, loaded_model.predict(x_test))))\n","y_prob \n","\n","# y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['nn2_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['nn2_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output['nn2_prediction_spam'] = [i[2] for i in y_pred_prob];\n","output['nn2_prediction_malware'] = [i[3] for i in y_pred_prob];\n","output['nn2_prediction_defacemen'] = [i[4] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":713},"id":"JPT9oIQ0wuZf","executionInfo":{"status":"ok","timestamp":1656574450990,"user_tz":-330,"elapsed":2117,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"169a2e6e-13b7-454c-947f-0e9c088727c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[2.27930408e-01 3.52669068e-07 3.17896223e-09 7.72068989e-01\n","  2.47127316e-07]\n"," [9.99849322e-01 4.83915474e-07 1.51218955e-09 1.50192352e-04\n","  2.28598272e-10]\n"," [1.28142616e-06 1.73256713e-08 3.98062294e-11 9.99998200e-01\n","  5.01489322e-07]\n"," ...\n"," [9.99685499e-01 1.59853046e-05 1.31639481e-12 2.98512764e-04\n","  3.36510890e-09]\n"," [1.66346146e-10 3.93031973e-02 9.60689680e-01 1.14207633e-11\n","  7.12230582e-06]\n"," [1.95998885e-04 9.99801785e-01 1.53610390e-11 2.21641900e-06\n","  3.52212170e-16]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  mlp_prediction_spam  \\\n","0          0        2.279304e-01          3.526691e-07         3.178962e-09   \n","1          0        9.998493e-01          4.839155e-07         1.512190e-09   \n","2          3        1.281426e-06          1.732567e-08         3.980623e-11   \n","3          3        1.273963e-03          6.203745e-08         6.837719e-12   \n","4          2        7.031173e-09          1.819293e-04         9.998181e-01   \n","...      ...                 ...                   ...                  ...   \n","6891       4        1.892153e-12          2.127109e-12         5.182954e-10   \n","6892       1        1.789397e-04          9.990517e-01         2.676060e-04   \n","6893       0        9.996855e-01          1.598530e-05         1.316395e-12   \n","6894       2        1.663461e-10          3.930320e-02         9.606897e-01   \n","6895       1        1.959989e-04          9.998018e-01         1.536104e-11   \n","\n","      mlp_prediction_malware  mlp_prediction_defacemen  nn_prediction_non  \\\n","0               7.720690e-01              2.471273e-07       2.279304e-01   \n","1               1.501924e-04              2.285983e-10       9.998493e-01   \n","2               9.999982e-01              5.014893e-07       1.281426e-06   \n","3               9.987260e-01              1.322388e-11       1.273963e-03   \n","4               7.719379e-15              2.118226e-11       7.031173e-09   \n","...                      ...                       ...                ...   \n","6891            1.837704e-16              1.000000e+00       1.892153e-12   \n","6892            5.004229e-04              1.291414e-06       1.789397e-04   \n","6893            2.985128e-04              3.365109e-09       9.996855e-01   \n","6894            1.142076e-11              7.122306e-06       1.663461e-10   \n","6895            2.216419e-06              3.522122e-16       1.959989e-04   \n","\n","      nn_prediction_phish  nn_prediction_spam  nn_prediction_malware  \\\n","0            3.526691e-07        3.178962e-09           7.720690e-01   \n","1            4.839155e-07        1.512190e-09           1.501924e-04   \n","2            1.732567e-08        3.980623e-11           9.999982e-01   \n","3            6.203745e-08        6.837719e-12           9.987260e-01   \n","4            1.819293e-04        9.998181e-01           7.719379e-15   \n","...                   ...                 ...                    ...   \n","6891         2.127109e-12        5.182954e-10           1.837704e-16   \n","6892         9.990517e-01        2.676060e-04           5.004229e-04   \n","6893         1.598530e-05        1.316395e-12           2.985128e-04   \n","6894         3.930320e-02        9.606897e-01           1.142076e-11   \n","6895         9.998018e-01        1.536104e-11           2.216419e-06   \n","\n","      nn_prediction_defacemen  nn2_prediction_non  nn2_prediction_phish  \\\n","0                2.471273e-07        2.279304e-01          3.526691e-07   \n","1                2.285983e-10        9.998493e-01          4.839155e-07   \n","2                5.014893e-07        1.281426e-06          1.732567e-08   \n","3                1.322388e-11        1.273963e-03          6.203745e-08   \n","4                2.118226e-11        7.031173e-09          1.819293e-04   \n","...                       ...                 ...                   ...   \n","6891             1.000000e+00        1.892153e-12          2.127109e-12   \n","6892             1.291414e-06        1.789397e-04          9.990517e-01   \n","6893             3.365109e-09        9.996855e-01          1.598530e-05   \n","6894             7.122306e-06        1.663461e-10          3.930320e-02   \n","6895             3.522122e-16        1.959989e-04          9.998018e-01   \n","\n","      nn2_prediction_spam  nn2_prediction_malware  nn2_prediction_defacemen  \n","0            3.178962e-09            7.720690e-01              2.471273e-07  \n","1            1.512190e-09            1.501924e-04              2.285983e-10  \n","2            3.980623e-11            9.999982e-01              5.014893e-07  \n","3            6.837719e-12            9.987260e-01              1.322388e-11  \n","4            9.998181e-01            7.719379e-15              2.118226e-11  \n","...                   ...                     ...                       ...  \n","6891         5.182954e-10            1.837704e-16              1.000000e+00  \n","6892         2.676060e-04            5.004229e-04              1.291414e-06  \n","6893         1.316395e-12            2.985128e-04              3.365109e-09  \n","6894         9.606897e-01            1.142076e-11              7.122306e-06  \n","6895         1.536104e-11            2.216419e-06              3.522122e-16  \n","\n","[6896 rows x 16 columns]"],"text/html":["\n","  <div id=\"df-807f8ea0-27d8-402e-8e93-91d5a3c24bac\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>mlp_prediction_spam</th>\n","      <th>mlp_prediction_malware</th>\n","      <th>mlp_prediction_defacemen</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","      <th>nn_prediction_spam</th>\n","      <th>nn_prediction_malware</th>\n","      <th>nn_prediction_defacemen</th>\n","      <th>nn2_prediction_non</th>\n","      <th>nn2_prediction_phish</th>\n","      <th>nn2_prediction_spam</th>\n","      <th>nn2_prediction_malware</th>\n","      <th>nn2_prediction_defacemen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2.279304e-01</td>\n","      <td>3.526691e-07</td>\n","      <td>3.178962e-09</td>\n","      <td>7.720690e-01</td>\n","      <td>2.471273e-07</td>\n","      <td>2.279304e-01</td>\n","      <td>3.526691e-07</td>\n","      <td>3.178962e-09</td>\n","      <td>7.720690e-01</td>\n","      <td>2.471273e-07</td>\n","      <td>2.279304e-01</td>\n","      <td>3.526691e-07</td>\n","      <td>3.178962e-09</td>\n","      <td>7.720690e-01</td>\n","      <td>2.471273e-07</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>9.998493e-01</td>\n","      <td>4.839155e-07</td>\n","      <td>1.512190e-09</td>\n","      <td>1.501924e-04</td>\n","      <td>2.285983e-10</td>\n","      <td>9.998493e-01</td>\n","      <td>4.839155e-07</td>\n","      <td>1.512190e-09</td>\n","      <td>1.501924e-04</td>\n","      <td>2.285983e-10</td>\n","      <td>9.998493e-01</td>\n","      <td>4.839155e-07</td>\n","      <td>1.512190e-09</td>\n","      <td>1.501924e-04</td>\n","      <td>2.285983e-10</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1.281426e-06</td>\n","      <td>1.732567e-08</td>\n","      <td>3.980623e-11</td>\n","      <td>9.999982e-01</td>\n","      <td>5.014893e-07</td>\n","      <td>1.281426e-06</td>\n","      <td>1.732567e-08</td>\n","      <td>3.980623e-11</td>\n","      <td>9.999982e-01</td>\n","      <td>5.014893e-07</td>\n","      <td>1.281426e-06</td>\n","      <td>1.732567e-08</td>\n","      <td>3.980623e-11</td>\n","      <td>9.999982e-01</td>\n","      <td>5.014893e-07</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1.273963e-03</td>\n","      <td>6.203745e-08</td>\n","      <td>6.837719e-12</td>\n","      <td>9.987260e-01</td>\n","      <td>1.322388e-11</td>\n","      <td>1.273963e-03</td>\n","      <td>6.203745e-08</td>\n","      <td>6.837719e-12</td>\n","      <td>9.987260e-01</td>\n","      <td>1.322388e-11</td>\n","      <td>1.273963e-03</td>\n","      <td>6.203745e-08</td>\n","      <td>6.837719e-12</td>\n","      <td>9.987260e-01</td>\n","      <td>1.322388e-11</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>7.031173e-09</td>\n","      <td>1.819293e-04</td>\n","      <td>9.998181e-01</td>\n","      <td>7.719379e-15</td>\n","      <td>2.118226e-11</td>\n","      <td>7.031173e-09</td>\n","      <td>1.819293e-04</td>\n","      <td>9.998181e-01</td>\n","      <td>7.719379e-15</td>\n","      <td>2.118226e-11</td>\n","      <td>7.031173e-09</td>\n","      <td>1.819293e-04</td>\n","      <td>9.998181e-01</td>\n","      <td>7.719379e-15</td>\n","      <td>2.118226e-11</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6891</th>\n","      <td>4</td>\n","      <td>1.892153e-12</td>\n","      <td>2.127109e-12</td>\n","      <td>5.182954e-10</td>\n","      <td>1.837704e-16</td>\n","      <td>1.000000e+00</td>\n","      <td>1.892153e-12</td>\n","      <td>2.127109e-12</td>\n","      <td>5.182954e-10</td>\n","      <td>1.837704e-16</td>\n","      <td>1.000000e+00</td>\n","      <td>1.892153e-12</td>\n","      <td>2.127109e-12</td>\n","      <td>5.182954e-10</td>\n","      <td>1.837704e-16</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>6892</th>\n","      <td>1</td>\n","      <td>1.789397e-04</td>\n","      <td>9.990517e-01</td>\n","      <td>2.676060e-04</td>\n","      <td>5.004229e-04</td>\n","      <td>1.291414e-06</td>\n","      <td>1.789397e-04</td>\n","      <td>9.990517e-01</td>\n","      <td>2.676060e-04</td>\n","      <td>5.004229e-04</td>\n","      <td>1.291414e-06</td>\n","      <td>1.789397e-04</td>\n","      <td>9.990517e-01</td>\n","      <td>2.676060e-04</td>\n","      <td>5.004229e-04</td>\n","      <td>1.291414e-06</td>\n","    </tr>\n","    <tr>\n","      <th>6893</th>\n","      <td>0</td>\n","      <td>9.996855e-01</td>\n","      <td>1.598530e-05</td>\n","      <td>1.316395e-12</td>\n","      <td>2.985128e-04</td>\n","      <td>3.365109e-09</td>\n","      <td>9.996855e-01</td>\n","      <td>1.598530e-05</td>\n","      <td>1.316395e-12</td>\n","      <td>2.985128e-04</td>\n","      <td>3.365109e-09</td>\n","      <td>9.996855e-01</td>\n","      <td>1.598530e-05</td>\n","      <td>1.316395e-12</td>\n","      <td>2.985128e-04</td>\n","      <td>3.365109e-09</td>\n","    </tr>\n","    <tr>\n","      <th>6894</th>\n","      <td>2</td>\n","      <td>1.663461e-10</td>\n","      <td>3.930320e-02</td>\n","      <td>9.606897e-01</td>\n","      <td>1.142076e-11</td>\n","      <td>7.122306e-06</td>\n","      <td>1.663461e-10</td>\n","      <td>3.930320e-02</td>\n","      <td>9.606897e-01</td>\n","      <td>1.142076e-11</td>\n","      <td>7.122306e-06</td>\n","      <td>1.663461e-10</td>\n","      <td>3.930320e-02</td>\n","      <td>9.606897e-01</td>\n","      <td>1.142076e-11</td>\n","      <td>7.122306e-06</td>\n","    </tr>\n","    <tr>\n","      <th>6895</th>\n","      <td>1</td>\n","      <td>1.959989e-04</td>\n","      <td>9.998018e-01</td>\n","      <td>1.536104e-11</td>\n","      <td>2.216419e-06</td>\n","      <td>3.522122e-16</td>\n","      <td>1.959989e-04</td>\n","      <td>9.998018e-01</td>\n","      <td>1.536104e-11</td>\n","      <td>2.216419e-06</td>\n","      <td>3.522122e-16</td>\n","      <td>1.959989e-04</td>\n","      <td>9.998018e-01</td>\n","      <td>1.536104e-11</td>\n","      <td>2.216419e-06</td>\n","      <td>3.522122e-16</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6896 rows × 16 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-807f8ea0-27d8-402e-8e93-91d5a3c24bac')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-807f8ea0-27d8-402e-8e93-91d5a3c24bac button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-807f8ea0-27d8-402e-8e93-91d5a3c24bac');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":[""],"metadata":{"id":"l2h6ZoAhFWTB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output.shape\n"],"metadata":{"id":"Yq4uCy0RFTFc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Storing the data in CSV file\n","output.to_csv('/content/drive/MyDrive/Phishing/UNB/Multi/Base_classifier_result(URL cross)(3).csv', index=False)"],"metadata":{"id":"ZsQkUbz6AiTx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"RN_-swX0JdhP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"W9DI0WYaJde9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"49lwyWNz0mSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"_9Vdw_Wx2NEo"},"execution_count":null,"outputs":[]}]}