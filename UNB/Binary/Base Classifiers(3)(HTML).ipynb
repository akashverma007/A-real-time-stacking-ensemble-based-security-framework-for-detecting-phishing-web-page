{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Base Classifiers(3)(HTML).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"PH13wfswmyDv"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Aiz0olfdKb4b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656486164949,"user_tz":-330,"elapsed":29570,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"393e9d9a-4886-4ae6-a2ce-48ddeab1f7d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["urldata = pd.read_csv(\"/content/drive/MyDrive/Phishing/UNB/URL-HTML/preprocessed_url_features(binary).csv\")\n","urldata\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":557},"id":"Dw-EEymHAGNs","outputId":"301c01fd-f147-426c-f62c-b8fdf5ddbb32","executionInfo":{"status":"ok","timestamp":1656486168360,"user_tz":-330,"elapsed":3423,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Unnamed: 0  Have IP  Have @  URL Length  URL Depth  Redirection  \\\n","0              0        0       0           1          1            0   \n","1              1        0       0           1          1            1   \n","2              2        0       0           1          1            0   \n","3              3        0       0           1          3            0   \n","4              4        0       0           1          3            0   \n","...          ...      ...     ...         ...        ...          ...   \n","6522        9992        0       0           1          5            0   \n","6523        9994        0       0           1          3            0   \n","6524        9995        0       0           1          6            0   \n","6525        9996        0       0           1          5            0   \n","6526        9997        0       0           1          4            0   \n","\n","      https Domain  TinyURL  Prefix/Suffix  Have client  ...  Num Embeds  \\\n","0                0        0              0            0  ...           0   \n","1                0        0              0            0  ...           0   \n","2                1        0              0            0  ...           0   \n","3                0        0              0            0  ...           0   \n","4                0        0              0            0  ...           0   \n","...            ...      ...            ...          ...  ...         ...   \n","6522             0        0              0            0  ...           0   \n","6523             0        0              0            0  ...           0   \n","6524             0        0              0            0  ...           0   \n","6525             0        0              0            0  ...           0   \n","6526             0        0              0            0  ...           0   \n","\n","      Num Images  Num Links  Num Titles  Num Script  Special Characters  \\\n","0             49        691          42       13135                6400   \n","1              4         66           3        2034                 818   \n","2              1        100          27       32987               10451   \n","3              0          0           1           0                  52   \n","4            117        219          23        7944                3468   \n","...          ...        ...         ...         ...                 ...   \n","6522           0          0           1           0                  34   \n","6523           0          0           1           0                  14   \n","6524           0          0           1           0                 249   \n","6525           0          0           1           0                   6   \n","6526           0          0           1           0                 630   \n","\n","      Script To Special Chars Ratio  Script To body Ratio  \\\n","0                          2.052344              0.528869   \n","1                          2.486553              0.676197   \n","2                          3.156349              0.836681   \n","3                          0.000000              0.000000   \n","4                          2.290657              0.524460   \n","...                             ...                   ...   \n","6522                       0.000000              0.000000   \n","6523                       0.000000              0.000000   \n","6524                       0.000000              0.000000   \n","6525                       0.000000              0.000000   \n","6526                       0.000000              0.000000   \n","\n","      Body To Special Char Ratio  Label  \n","0                       0.257690      0  \n","1                       0.271941      0  \n","2                       0.265079      0  \n","3                       0.227074      0  \n","4                       0.228956      0  \n","...                          ...    ...  \n","6522                    0.185792      1  \n","6523                    0.197183      1  \n","6524                    0.315990      1  \n","6525                    0.139535      1  \n","6526                    0.310192      1  \n","\n","[6527 rows x 46 columns]"],"text/html":["\n","  <div id=\"df-11f05a63-77ad-4340-bf7f-dcef1a471ea4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>691</td>\n","      <td>42</td>\n","      <td>13135</td>\n","      <td>6400</td>\n","      <td>2.052344</td>\n","      <td>0.528869</td>\n","      <td>0.257690</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>66</td>\n","      <td>3</td>\n","      <td>2034</td>\n","      <td>818</td>\n","      <td>2.486553</td>\n","      <td>0.676197</td>\n","      <td>0.271941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>27</td>\n","      <td>32987</td>\n","      <td>10451</td>\n","      <td>3.156349</td>\n","      <td>0.836681</td>\n","      <td>0.265079</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.227074</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>117</td>\n","      <td>219</td>\n","      <td>23</td>\n","      <td>7944</td>\n","      <td>3468</td>\n","      <td>2.290657</td>\n","      <td>0.524460</td>\n","      <td>0.228956</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6522</th>\n","      <td>9992</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>34</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.185792</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6523</th>\n","      <td>9994</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.197183</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6524</th>\n","      <td>9995</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>249</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.315990</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6525</th>\n","      <td>9996</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.139535</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6526</th>\n","      <td>9997</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>630</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.310192</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6527 rows × 46 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11f05a63-77ad-4340-bf7f-dcef1a471ea4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-11f05a63-77ad-4340-bf7f-dcef1a471ea4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-11f05a63-77ad-4340-bf7f-dcef1a471ea4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["urldata.columns"],"metadata":{"id":"JQ4_qEulWybT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bb135f76-1ea7-4afd-8d2a-3d31c809fe34","executionInfo":{"status":"ok","timestamp":1656486228283,"user_tz":-330,"elapsed":832,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Unnamed: 0', 'Have IP', 'Have @', 'URL Length', 'URL Depth',\n","       'Redirection', 'https Domain', 'TinyURL', 'Prefix/Suffix',\n","       'Have client', 'Have admin', 'Have login', 'Have server', '.php',\n","       '.html', '.info', '.txt', '.js', '.exe', 'Num of periods', 'Is encoded',\n","       'Num of encoded char', 'Num of parameters', 'Num of digits',\n","       'Num of spec char', 'iFrame', 'Mouse Over', 'Right Click',\n","       'Web Forwards', 'Number of page tokens', 'number of sentences',\n","       'number of html tags', 'number of whitespace', 'url Is Live',\n","       'HTML Length', 'Num Objects', 'Num Embeds', 'Num Images', 'Num Links',\n","       'Num Titles', 'Num Script', 'Special Characters',\n","       'Script To Special Chars Ratio', 'Script To body Ratio',\n","       'Body To Special Char Ratio', 'Label'],\n","      dtype='object')"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["urldata = urldata.drop(['Unnamed: 0', 'Have IP', 'Have @', 'URL Length', 'URL Depth',\n","       'Redirection', 'https Domain', 'TinyURL', 'Prefix/Suffix',\n","       'Have client', 'Have admin', 'Have login', 'Have server', '.php',\n","       '.html', '.info', '.txt', '.js', '.exe', 'Num of periods', 'Is encoded',\n","       'Num of encoded char', 'Num of parameters', 'Num of digits',\n","       'Num of spec char'], axis = 1).copy()\n","# urldata = urldata.drop(['Domain'], axis = 1).copy()\n","urldata.shape\n","urldata.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"id":"qwye89TwRTOH","executionInfo":{"status":"ok","timestamp":1656486229254,"user_tz":-330,"elapsed":15,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"a4e0dd2e-ed60-4ed7-fb7b-40de9dc70ce3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   iFrame  Mouse Over  Right Click  Web Forwards  Number of page tokens  \\\n","0       1           0            0             1                  21444   \n","1       1           0            0             1                   1075   \n","2       1           0            0             1                   4531   \n","3       1           0            0             1                     32   \n","4       1           0            0             1                   4880   \n","\n","   number of sentences  number of html tags  number of whitespace  \\\n","0                 1853                 3247                     0   \n","1                  136                  236                     0   \n","2                 2634                  486                     0   \n","3                    9                    8                     0   \n","4                  981                 1412                     0   \n","\n","   url Is Live  HTML Length  ...  Num Embeds  Num Images  Num Links  \\\n","0            1        24836  ...           0          49        691   \n","1            1         3008  ...           0           4         66   \n","2            1        39426  ...           0           1        100   \n","3            0          229  ...           0           0          0   \n","4            1        15147  ...           0         117        219   \n","\n","   Num Titles  Num Script  Special Characters  Script To Special Chars Ratio  \\\n","0          42       13135                6400                       2.052344   \n","1           3        2034                 818                       2.486553   \n","2          27       32987               10451                       3.156349   \n","3           1           0                  52                       0.000000   \n","4          23        7944                3468                       2.290657   \n","\n","   Script To body Ratio  Body To Special Char Ratio  Label  \n","0              0.528869                    0.257690      0  \n","1              0.676197                    0.271941      0  \n","2              0.836681                    0.265079      0  \n","3              0.000000                    0.227074      0  \n","4              0.524460                    0.228956      0  \n","\n","[5 rows x 21 columns]"],"text/html":["\n","  <div id=\"df-4fd9c2a2-df7d-4dc4-bf18-902fd6f4fee6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>iFrame</th>\n","      <th>Mouse Over</th>\n","      <th>Right Click</th>\n","      <th>Web Forwards</th>\n","      <th>Number of page tokens</th>\n","      <th>number of sentences</th>\n","      <th>number of html tags</th>\n","      <th>number of whitespace</th>\n","      <th>url Is Live</th>\n","      <th>HTML Length</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>21444</td>\n","      <td>1853</td>\n","      <td>3247</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>24836</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>691</td>\n","      <td>42</td>\n","      <td>13135</td>\n","      <td>6400</td>\n","      <td>2.052344</td>\n","      <td>0.528869</td>\n","      <td>0.257690</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1075</td>\n","      <td>136</td>\n","      <td>236</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3008</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>66</td>\n","      <td>3</td>\n","      <td>2034</td>\n","      <td>818</td>\n","      <td>2.486553</td>\n","      <td>0.676197</td>\n","      <td>0.271941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4531</td>\n","      <td>2634</td>\n","      <td>486</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>39426</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>27</td>\n","      <td>32987</td>\n","      <td>10451</td>\n","      <td>3.156349</td>\n","      <td>0.836681</td>\n","      <td>0.265079</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>32</td>\n","      <td>9</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>229</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.227074</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4880</td>\n","      <td>981</td>\n","      <td>1412</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>15147</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>117</td>\n","      <td>219</td>\n","      <td>23</td>\n","      <td>7944</td>\n","      <td>3468</td>\n","      <td>2.290657</td>\n","      <td>0.524460</td>\n","      <td>0.228956</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fd9c2a2-df7d-4dc4-bf18-902fd6f4fee6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4fd9c2a2-df7d-4dc4-bf18-902fd6f4fee6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4fd9c2a2-df7d-4dc4-bf18-902fd6f4fee6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["urldata.info()"],"metadata":{"id":"kKvKkmUNP5Cx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ccc84aa2-7524-4f76-aef3-44b9783ebd65","executionInfo":{"status":"ok","timestamp":1656486229255,"user_tz":-330,"elapsed":13,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 6527 entries, 0 to 6526\n","Data columns (total 21 columns):\n"," #   Column                         Non-Null Count  Dtype  \n","---  ------                         --------------  -----  \n"," 0   iFrame                         6527 non-null   int64  \n"," 1   Mouse Over                     6527 non-null   int64  \n"," 2   Right Click                    6527 non-null   int64  \n"," 3   Web Forwards                   6527 non-null   int64  \n"," 4   Number of page tokens          6527 non-null   int64  \n"," 5   number of sentences            6527 non-null   int64  \n"," 6   number of html tags            6527 non-null   int64  \n"," 7   number of whitespace           6527 non-null   int64  \n"," 8   url Is Live                    6527 non-null   int64  \n"," 9   HTML Length                    6527 non-null   int64  \n"," 10  Num Objects                    6527 non-null   int64  \n"," 11  Num Embeds                     6527 non-null   int64  \n"," 12  Num Images                     6527 non-null   int64  \n"," 13  Num Links                      6527 non-null   int64  \n"," 14  Num Titles                     6527 non-null   int64  \n"," 15  Num Script                     6527 non-null   int64  \n"," 16  Special Characters             6527 non-null   int64  \n"," 17  Script To Special Chars Ratio  6527 non-null   float64\n"," 18  Script To body Ratio           6527 non-null   float64\n"," 19  Body To Special Char Ratio     6527 non-null   float64\n"," 20  Label                          6527 non-null   int64  \n","dtypes: float64(3), int64(18)\n","memory usage: 1.0 MB\n"]}]},{"cell_type":"code","source":["# Class Distribution of Labels\n","urldata.groupby('Label').size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvS3OQHTSHDt","executionInfo":{"status":"ok","timestamp":1656486230005,"user_tz":-330,"elapsed":13,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"de9c48fa-85be-4f17-a216-64d7780ec7ae"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Label\n","0    4954\n","1    1573\n","dtype: int64"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Analysis of Postives and Negatives in the Dataset\n","pos,neg = urldata['Label'].value_counts()\n","total = neg + pos\n","print ('Total of Samples: %s'% total)\n","print('Non-Phishing: {} ({:.2f}% of total)'.format(pos, 100 * pos / total))\n","print('Phishing: {} ({:.2f}% of total)'.format(neg, 100 * neg / total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kHCjZCSBSKi3","executionInfo":{"status":"ok","timestamp":1656486230005,"user_tz":-330,"elapsed":10,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"51ee7eae-ab00-4d99-be12-8e941c643ad3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total of Samples: 6527\n","Non-Phishing: 4954 (75.90% of total)\n","Phishing: 1573 (24.10% of total)\n"]}]},{"cell_type":"code","source":["\n","import numpy as np\n"],"metadata":{"id":"eLm1720QSaAv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["urldata.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":446},"id":"WX-8Xbm3cfFf","outputId":"676d88dd-edfb-495f-ee32-c20d9c670765","executionInfo":{"status":"ok","timestamp":1656486236852,"user_tz":-330,"elapsed":679,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            iFrame   Mouse Over  Right Click  Web Forwards  \\\n","count  6527.000000  6527.000000       6527.0   6527.000000   \n","mean      0.999387     0.000306          0.0      0.937490   \n","std       0.024750     0.017504          0.0      0.242097   \n","min       0.000000     0.000000          0.0      0.000000   \n","25%       1.000000     0.000000          0.0      1.000000   \n","50%       1.000000     0.000000          0.0      1.000000   \n","75%       1.000000     0.000000          0.0      1.000000   \n","max       1.000000     1.000000          0.0      1.000000   \n","\n","       Number of page tokens  number of sentences  number of html tags  \\\n","count            6527.000000          6527.000000          6527.000000   \n","mean             3606.327256          1812.912364           433.003830   \n","std              5828.320950          3543.768665           733.633379   \n","min                 1.000000             1.000000             1.000000   \n","25%               103.000000            20.000000            16.000000   \n","50%              1719.000000           666.000000           159.000000   \n","75%              5131.500000          1683.000000           525.000000   \n","max             74678.000000         43777.000000          8760.000000   \n","\n","       number of whitespace  url Is Live   HTML Length  ...   Num Embeds  \\\n","count                6527.0  6527.000000  6.527000e+03  ...  6527.000000   \n","mean                    0.0     0.422399  4.792708e+04  ...     0.000613   \n","std                     0.0     0.505630  1.162579e+05  ...     0.024750   \n","min                     0.0    -1.000000  0.000000e+00  ...     0.000000   \n","25%                     0.0     0.000000  6.630000e+02  ...     0.000000   \n","50%                     0.0     0.000000  1.811000e+04  ...     0.000000   \n","75%                     0.0     1.000000  3.479350e+04  ...     0.000000   \n","max                     0.0     1.000000  2.107635e+06  ...     1.000000   \n","\n","        Num Images    Num Links   Num Titles    Num Script  \\\n","count  6527.000000  6527.000000  6527.000000  6.527000e+03   \n","mean     13.078290    71.623717     8.910679  2.911380e+04   \n","std      37.301509   117.479116    34.106562  9.681226e+04   \n","min       0.000000     0.000000     0.000000  0.000000e+00   \n","25%       0.000000     0.000000     1.000000  4.400000e+01   \n","50%       3.000000    28.000000     1.000000  6.953000e+03   \n","75%       8.000000    91.000000     5.000000  1.672850e+04   \n","max     526.000000  1159.000000  1042.000000  2.076633e+06   \n","\n","       Special Characters  Script To Special Chars Ratio  \\\n","count         6527.000000                    6527.000000   \n","mean         11168.757009                       4.175212   \n","std          24456.427671                      22.109670   \n","min              0.000000                       0.000000   \n","25%            143.000000                       0.043897   \n","50%           4102.000000                       1.916015   \n","75%           9126.000000                       2.764967   \n","max         359290.000000                     381.227732   \n","\n","       Script To body Ratio  Body To Special Char Ratio        Label  \n","count           6527.000000                 6527.000000  6527.000000  \n","mean               0.456171                    0.227569     0.240999  \n","std                0.349764                    0.077076     0.427722  \n","min                0.000000                    0.000000     0.000000  \n","25%                0.016658                    0.197183     0.000000  \n","50%                0.488331                    0.248328     0.000000  \n","75%                0.739913                    0.262355     0.000000  \n","max                1.005038                    0.605483     1.000000  \n","\n","[8 rows x 21 columns]"],"text/html":["\n","  <div id=\"df-cc787d5d-e667-489b-86bc-531aded2e3ba\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>iFrame</th>\n","      <th>Mouse Over</th>\n","      <th>Right Click</th>\n","      <th>Web Forwards</th>\n","      <th>Number of page tokens</th>\n","      <th>number of sentences</th>\n","      <th>number of html tags</th>\n","      <th>number of whitespace</th>\n","      <th>url Is Live</th>\n","      <th>HTML Length</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.0</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.0</td>\n","      <td>6527.000000</td>\n","      <td>6.527000e+03</td>\n","      <td>...</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6.527000e+03</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.999387</td>\n","      <td>0.000306</td>\n","      <td>0.0</td>\n","      <td>0.937490</td>\n","      <td>3606.327256</td>\n","      <td>1812.912364</td>\n","      <td>433.003830</td>\n","      <td>0.0</td>\n","      <td>0.422399</td>\n","      <td>4.792708e+04</td>\n","      <td>...</td>\n","      <td>0.000613</td>\n","      <td>13.078290</td>\n","      <td>71.623717</td>\n","      <td>8.910679</td>\n","      <td>2.911380e+04</td>\n","      <td>11168.757009</td>\n","      <td>4.175212</td>\n","      <td>0.456171</td>\n","      <td>0.227569</td>\n","      <td>0.240999</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.024750</td>\n","      <td>0.017504</td>\n","      <td>0.0</td>\n","      <td>0.242097</td>\n","      <td>5828.320950</td>\n","      <td>3543.768665</td>\n","      <td>733.633379</td>\n","      <td>0.0</td>\n","      <td>0.505630</td>\n","      <td>1.162579e+05</td>\n","      <td>...</td>\n","      <td>0.024750</td>\n","      <td>37.301509</td>\n","      <td>117.479116</td>\n","      <td>34.106562</td>\n","      <td>9.681226e+04</td>\n","      <td>24456.427671</td>\n","      <td>22.109670</td>\n","      <td>0.349764</td>\n","      <td>0.077076</td>\n","      <td>0.427722</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.0</td>\n","      <td>-1.000000</td>\n","      <td>0.000000e+00</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>103.000000</td>\n","      <td>20.000000</td>\n","      <td>16.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>6.630000e+02</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>4.400000e+01</td>\n","      <td>143.000000</td>\n","      <td>0.043897</td>\n","      <td>0.016658</td>\n","      <td>0.197183</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>1719.000000</td>\n","      <td>666.000000</td>\n","      <td>159.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.811000e+04</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>28.000000</td>\n","      <td>1.000000</td>\n","      <td>6.953000e+03</td>\n","      <td>4102.000000</td>\n","      <td>1.916015</td>\n","      <td>0.488331</td>\n","      <td>0.248328</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>5131.500000</td>\n","      <td>1683.000000</td>\n","      <td>525.000000</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>3.479350e+04</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>8.000000</td>\n","      <td>91.000000</td>\n","      <td>5.000000</td>\n","      <td>1.672850e+04</td>\n","      <td>9126.000000</td>\n","      <td>2.764967</td>\n","      <td>0.739913</td>\n","      <td>0.262355</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>74678.000000</td>\n","      <td>43777.000000</td>\n","      <td>8760.000000</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>2.107635e+06</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>526.000000</td>\n","      <td>1159.000000</td>\n","      <td>1042.000000</td>\n","      <td>2.076633e+06</td>\n","      <td>359290.000000</td>\n","      <td>381.227732</td>\n","      <td>1.005038</td>\n","      <td>0.605483</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 21 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc787d5d-e667-489b-86bc-531aded2e3ba')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cc787d5d-e667-489b-86bc-531aded2e3ba button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cc787d5d-e667-489b-86bc-531aded2e3ba');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":[""],"metadata":{"id":"bUPfWi4TcfIA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#checking the data for null or missing values\n","urldata.isnull().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3PEbrTLcfXg","outputId":"a175dfe5-2d9e-4941-c0e2-8d78dd233681","executionInfo":{"status":"ok","timestamp":1656486236859,"user_tz":-330,"elapsed":22,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["iFrame                           0\n","Mouse Over                       0\n","Right Click                      0\n","Web Forwards                     0\n","Number of page tokens            0\n","number of sentences              0\n","number of html tags              0\n","number of whitespace             0\n","url Is Live                      0\n","HTML Length                      0\n","Num Objects                      0\n","Num Embeds                       0\n","Num Images                       0\n","Num Links                        0\n","Num Titles                       0\n","Num Script                       0\n","Special Characters               0\n","Script To Special Chars Ratio    0\n","Script To body Ratio             0\n","Body To Special Char Ratio       0\n","Label                            0\n","dtype: int64"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# shuffling the rows in the dataset so that when splitting the train and test set are equally distributed\n","urldata = urldata.sample(frac=1).reset_index(drop=True)\n","urldata.head()"],"metadata":{"id":"n6YfGa82P5JZ","colab":{"base_uri":"https://localhost:8080/","height":369},"outputId":"27453544-622b-42c7-99ba-32e3c01930b3","executionInfo":{"status":"ok","timestamp":1656486237524,"user_tz":-330,"elapsed":19,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   iFrame  Mouse Over  Right Click  Web Forwards  Number of page tokens  \\\n","0       1           0            0             1                     23   \n","1       1           0            0             1                  10657   \n","2       1           0            0             0                   2103   \n","3       1           0            0             1                   3833   \n","4       1           0            0             1                   1695   \n","\n","   number of sentences  number of html tags  number of whitespace  \\\n","0                    3                    6                     0   \n","1                 2872                 1106                     0   \n","2                  287                  457                     0   \n","3                10053                  758                     0   \n","4                 1679                  162                     0   \n","\n","   url Is Live  HTML Length  ...  Num Embeds  Num Images  Num Links  \\\n","0            0           71  ...           0           0          0   \n","1            1        39924  ...           0          44        203   \n","2            1         6635  ...           0           1        115   \n","3            0        43843  ...           0          11        192   \n","4            0        32749  ...           0           4         28   \n","\n","   Num Titles  Num Script  Special Characters  Script To Special Chars Ratio  \\\n","0           1           0                  14                       0.000000   \n","1          55       16612               10908                       1.522919   \n","2          10        2522                1587                       1.589162   \n","3          20       13480                9816                       1.373268   \n","4           1       15924                8341                       1.909124   \n","\n","   Script To body Ratio  Body To Special Char Ratio  Label  \n","0              0.000000                    0.197183      0  \n","1              0.416091                    0.273219      0  \n","2              0.380106                    0.239186      0  \n","3              0.307461                    0.223890      0  \n","4              0.486244                    0.254695      0  \n","\n","[5 rows x 21 columns]"],"text/html":["\n","  <div id=\"df-bbfad1f5-b0ac-4254-a516-67ba08c85733\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>iFrame</th>\n","      <th>Mouse Over</th>\n","      <th>Right Click</th>\n","      <th>Web Forwards</th>\n","      <th>Number of page tokens</th>\n","      <th>number of sentences</th>\n","      <th>number of html tags</th>\n","      <th>number of whitespace</th>\n","      <th>url Is Live</th>\n","      <th>HTML Length</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>23</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>71</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.197183</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10657</td>\n","      <td>2872</td>\n","      <td>1106</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>39924</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>44</td>\n","      <td>203</td>\n","      <td>55</td>\n","      <td>16612</td>\n","      <td>10908</td>\n","      <td>1.522919</td>\n","      <td>0.416091</td>\n","      <td>0.273219</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2103</td>\n","      <td>287</td>\n","      <td>457</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6635</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>115</td>\n","      <td>10</td>\n","      <td>2522</td>\n","      <td>1587</td>\n","      <td>1.589162</td>\n","      <td>0.380106</td>\n","      <td>0.239186</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3833</td>\n","      <td>10053</td>\n","      <td>758</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>43843</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>192</td>\n","      <td>20</td>\n","      <td>13480</td>\n","      <td>9816</td>\n","      <td>1.373268</td>\n","      <td>0.307461</td>\n","      <td>0.223890</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1695</td>\n","      <td>1679</td>\n","      <td>162</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>32749</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>28</td>\n","      <td>1</td>\n","      <td>15924</td>\n","      <td>8341</td>\n","      <td>1.909124</td>\n","      <td>0.486244</td>\n","      <td>0.254695</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbfad1f5-b0ac-4254-a516-67ba08c85733')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bbfad1f5-b0ac-4254-a516-67ba08c85733 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bbfad1f5-b0ac-4254-a516-67ba08c85733');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["import numpy as np\n","# Sepratating & assigning features and target columns to X & y\n","y = urldata['Label'].values\n","x = np.array(urldata.drop('Label',axis=1))\n","\n"],"metadata":{"id":"Lasv_YzlP5L6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Splitting the dataset into train and test sets: 80-20 split\n","from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, \n","                                                    test_size = 0.45, random_state = 12)\n","print(x_train.shape, x_test.shape)\n","print(y_train.shape, y_test.shape)\n","\n"],"metadata":{"id":"in9C2ArWP5O0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"57c37bd0-a494-4118-ab38-c56ea84b6b46","executionInfo":{"status":"ok","timestamp":1656486238824,"user_tz":-330,"elapsed":6,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(3589, 20) (2938, 20)\n","(3589,) (2938,)\n"]}]},{"cell_type":"code","source":["output = {}\n","output['labels'] = y_test"],"metadata":{"id":"jv6Y5m8ddMHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"fg4rdoEnUE0O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOV9VybfNIgE"},"source":["**MLP**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mr-AOgJ1JtXY"},"outputs":[],"source":["import keras\n","\n","from sklearn.neural_network import MLPClassifier\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","import pickle\n","\n","def model_mlp(x_train, x_val, y_train, y_val, opt, n):\n","  mlpclassifier = MLPClassifier(alpha=0.0001, hidden_layer_sizes=([100,100,100]))\n","  #compile model using mse as a measure of model performance\n","  mlpclassifier.fit(x_train, y_train)\n","\n","  y_pred = mlpclassifier.predict(x_val)\n","\n","  conf_matrix = confusion_matrix(y_val, y_pred)\n","  print(conf_matrix)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred))\n","\n","  \n","  print(\"Validation Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/UNB/Binary/Models/HTML/MLP/model_'+str(n)+'.h5'\n","  pickle.dump(mlpclassifier, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","  return metrics.accuracy_score(y_val, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUCxdcapJtXZ","executionInfo":{"status":"ok","timestamp":1656486276938,"user_tz":-330,"elapsed":34684,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"19daed40-7c63-46dd-dbab-8ad62a99ba3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[247  25]\n"," [ 43  44]]\n","Precision: 0.6377\n","Recall: 0.5057\n","F1 Score: 0.5641\n","Validation Accuracy: 0.8105849582172702\n","model 0 saved\n","[[251  37]\n"," [ 31  40]]\n","Precision: 0.5195\n","Recall: 0.5634\n","F1 Score: 0.5405\n","Validation Accuracy: 0.8105849582172702\n","model 1 saved\n","[[236  41]\n"," [ 30  52]]\n","Precision: 0.5591\n","Recall: 0.6341\n","F1 Score: 0.5943\n","Validation Accuracy: 0.8022284122562674\n","model 2 saved\n","[[249  37]\n"," [ 24  49]]\n","Precision: 0.5698\n","Recall: 0.6712\n","F1 Score: 0.6164\n","Validation Accuracy: 0.83008356545961\n","model 3 saved\n","[[227  49]\n"," [ 32  51]]\n","Precision: 0.5100\n","Recall: 0.6145\n","F1 Score: 0.5574\n","Validation Accuracy: 0.7743732590529248\n","model 4 saved\n","[[234  34]\n"," [ 28  63]]\n","Precision: 0.6495\n","Recall: 0.6923\n","F1 Score: 0.6702\n","Validation Accuracy: 0.8272980501392758\n","model 5 saved\n","[[ 90 172]\n"," [  9  88]]\n","Precision: 0.3385\n","Recall: 0.9072\n","F1 Score: 0.4930\n","Validation Accuracy: 0.4958217270194986\n","model 6 saved\n","[[214  52]\n"," [ 17  76]]\n","Precision: 0.5938\n","Recall: 0.8172\n","F1 Score: 0.6878\n","Validation Accuracy: 0.807799442896936\n","model 7 saved\n","[[182  91]\n"," [ 26  60]]\n","Precision: 0.3974\n","Recall: 0.6977\n","F1 Score: 0.5063\n","Validation Accuracy: 0.6740947075208914\n","model 8 saved\n","[[225  41]\n"," [ 44  48]]\n","Precision: 0.5393\n","Recall: 0.5217\n","F1 Score: 0.5304\n","Validation Accuracy: 0.7625698324022346\n","model 9 saved\n","Average Validation Accuracy: 0.7595438913182178\n"]}],"source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_mlp(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545},"executionInfo":{"elapsed":596,"status":"ok","timestamp":1656486348844,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"6DA16IlPJtXZ","outputId":"7174a896-8bec-4be4-f7b1-d88fe1453af9"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.00000000e+000 4.63278408e-021]\n"," [1.00000000e+000 1.83409020e-139]\n"," [2.77758362e-001 7.22241638e-001]\n"," ...\n"," [1.21342538e-001 8.78657462e-001]\n"," [9.99999994e-001 5.69171352e-009]\n"," [1.00000000e+000 2.72645734e-139]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish\n","0          0            1.000000          4.632784e-21\n","1          0            1.000000         1.834090e-139\n","2          0            0.277758          7.222416e-01\n","3          1            0.303680          6.963204e-01\n","4          0            1.000000          2.524615e-08\n","...      ...                 ...                   ...\n","2933       1            0.000000          1.000000e+00\n","2934       0            0.168642          8.313583e-01\n","2935       1            0.121343          8.786575e-01\n","2936       1            1.000000          5.691714e-09\n","2937       0            1.000000         2.726457e-139\n","\n","[2938 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-6595e7ee-c90c-4f08-8bd0-ab74d0997858\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>4.632784e-21</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>1.834090e-139</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0.277758</td>\n","      <td>7.222416e-01</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0.303680</td>\n","      <td>6.963204e-01</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>2.524615e-08</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2933</th>\n","      <td>1</td>\n","      <td>0.000000</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>2934</th>\n","      <td>0</td>\n","      <td>0.168642</td>\n","      <td>8.313583e-01</td>\n","    </tr>\n","    <tr>\n","      <th>2935</th>\n","      <td>1</td>\n","      <td>0.121343</td>\n","      <td>8.786575e-01</td>\n","    </tr>\n","    <tr>\n","      <th>2936</th>\n","      <td>1</td>\n","      <td>1.000000</td>\n","      <td>5.691714e-09</td>\n","    </tr>\n","    <tr>\n","      <th>2937</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>2.726457e-139</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2938 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6595e7ee-c90c-4f08-8bd0-ab74d0997858')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6595e7ee-c90c-4f08-8bd0-ab74d0997858 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6595e7ee-c90c-4f08-8bd0-ab74d0997858');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}],"source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/UNB/Binary/Models/HTML/MLP/model_3.h5'\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['mlp_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['mlp_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output\n"]},{"cell_type":"markdown","source":["**Neural Network**"],"metadata":{"id":"iLF4sz5NsSZ6"}},{"cell_type":"code","source":["\n","import keras\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","def model_aa(x_train, x_val, y_train, y_val, opt, n, early_stopping_monitor):\n","\n","  n_cols = x_train.shape[1]\n","  # print(\"check point\")\n","  #create model\n","  model = Sequential()\n","  model.add(Dense(30, activation='relu', input_shape=(n_cols,)))\n","  model.add(Dense(10, activation='relu'))\n","\n","  model.add(Dense(1, activation = 'sigmoid'))\n","  # softmax\n","  #compile model using mse as a measure of model performance\n","  model.compile(optimizer = opt, loss= 'binary_crossentropy', metrics=[\"accuracy\"])\n","\n","  history = model.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping_monitor])\n","\n","\n","  # plt.plot(history.history['loss'])\n","  # plt.plot(history.history['val_loss'])\n","  # plt.title('model loss')\n","  # plt.ylabel('Loss')\n","  # plt.xlabel('Epoch')\n","  # plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n","  # plt.show()\n","\n","\n","  print('Validation Accuracy: ')\n","  # Predicting the Test set results\n","  y_pred = model.predict(x_val)\n","  y_pred = (y_pred > 0.5)\n","\n","\n","  print(classification_report(y_val, y_pred))\n","\n","  # Model Accuracy, how often is the classifier correct?\n","  print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","\n","  # Creating the Confusion Matrix\n","  cm = confusion_matrix(y_val, y_pred)\n","  print(cm)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred))\n","\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/UNB/Binary/Models/HTML/NN/model_'+str(n)+'.h5'\n","  pickle.dump(model, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","\n","  return metrics.accuracy_score(y_val, y_pred)\n","\n"],"metadata":{"id":"UfilmHKnL3LC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_aa(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n, early_stopping_monitor)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_OHdM1HNDio","executionInfo":{"status":"ok","timestamp":1656486585073,"user_tz":-330,"elapsed":233178,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"cfb3d2b9-6e46-4918-8f01-c87b77feda0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","101/101 [==============================] - 4s 5ms/step - loss: 616.2397 - accuracy: 0.7585 - val_loss: 149.0274 - val_accuracy: 0.7632\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 201.4700 - accuracy: 0.7520 - val_loss: 33.6687 - val_accuracy: 0.7437\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 54.0784 - accuracy: 0.7368 - val_loss: 7.8167 - val_accuracy: 0.7159\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 18.0066 - accuracy: 0.7616 - val_loss: 7.5425 - val_accuracy: 0.7883\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 17.6382 - accuracy: 0.7765 - val_loss: 14.0622 - val_accuracy: 0.7409\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 18.4021 - accuracy: 0.7836 - val_loss: 3.7066 - val_accuracy: 0.7688\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 23.6051 - accuracy: 0.7582 - val_loss: 9.2740 - val_accuracy: 0.7883\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 19.5298 - accuracy: 0.7690 - val_loss: 6.8997 - val_accuracy: 0.7994\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 15.3107 - accuracy: 0.7824 - val_loss: 7.4613 - val_accuracy: 0.7939\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 17.7838 - accuracy: 0.7882 - val_loss: 5.0635 - val_accuracy: 0.8050\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 17.9359 - accuracy: 0.7777 - val_loss: 7.9401 - val_accuracy: 0.7939\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.9076 - accuracy: 0.7780 - val_loss: 21.0371 - val_accuracy: 0.7493\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 23.6106 - accuracy: 0.7666 - val_loss: 4.7001 - val_accuracy: 0.8134\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.0753 - accuracy: 0.7864 - val_loss: 5.0455 - val_accuracy: 0.8106\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.6112 - accuracy: 0.7687 - val_loss: 3.6068 - val_accuracy: 0.8078\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.8824 - accuracy: 0.7802 - val_loss: 4.5980 - val_accuracy: 0.8245\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 25.4935 - accuracy: 0.7672 - val_loss: 16.6352 - val_accuracy: 0.7855\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 15.1148 - accuracy: 0.7724 - val_loss: 17.9470 - val_accuracy: 0.7827\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 24.8013 - accuracy: 0.7780 - val_loss: 4.6225 - val_accuracy: 0.7577\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 17.3844 - accuracy: 0.7728 - val_loss: 4.5136 - val_accuracy: 0.8078\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 11.4498 - accuracy: 0.7793 - val_loss: 3.2000 - val_accuracy: 0.7967\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 11.0432 - accuracy: 0.7793 - val_loss: 13.5428 - val_accuracy: 0.7883\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 16.7433 - accuracy: 0.7805 - val_loss: 5.8638 - val_accuracy: 0.7855\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 15.2929 - accuracy: 0.7765 - val_loss: 7.9690 - val_accuracy: 0.7799\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.3363 - accuracy: 0.7799 - val_loss: 7.2157 - val_accuracy: 0.7604\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 7.3710 - accuracy: 0.7923 - val_loss: 3.4182 - val_accuracy: 0.8189\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 10.0618 - accuracy: 0.7920 - val_loss: 4.8186 - val_accuracy: 0.8078\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.5353 - accuracy: 0.7811 - val_loss: 9.4922 - val_accuracy: 0.7911\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.2793 - accuracy: 0.7836 - val_loss: 6.3500 - val_accuracy: 0.8189\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.9926 - accuracy: 0.7904 - val_loss: 10.4091 - val_accuracy: 0.7298\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 10.0169 - accuracy: 0.7820 - val_loss: 3.7189 - val_accuracy: 0.8189\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.88      0.88       272\n","           1       0.62      0.63      0.63        87\n","\n","    accuracy                           0.82       359\n","   macro avg       0.75      0.76      0.75       359\n","weighted avg       0.82      0.82      0.82       359\n","\n","Accuracy: 0.8189415041782729\n","[[239  33]\n"," [ 32  55]]\n","Precision: 0.6250\n","Recall: 0.6322\n","F1 Score: 0.6286\n","INFO:tensorflow:Assets written to: ram://72646540-2206-4809-ab86-65035c179981/assets\n","model 0 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 10.6907 - accuracy: 0.7139 - val_loss: 0.8022 - val_accuracy: 0.3733\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.7608 - accuracy: 0.3551 - val_loss: 0.6471 - val_accuracy: 0.3231\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.6935 - val_loss: 0.6287 - val_accuracy: 0.8022\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.7573 - val_loss: 0.6028 - val_accuracy: 0.8022\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.7573 - val_loss: 0.5865 - val_accuracy: 0.8022\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.7573 - val_loss: 0.5745 - val_accuracy: 0.8022\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.7573 - val_loss: 0.5720 - val_accuracy: 0.8022\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.7573 - val_loss: 0.5642 - val_accuracy: 0.8022\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7573 - val_loss: 0.5562 - val_accuracy: 0.8022\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.7573 - val_loss: 0.5480 - val_accuracy: 0.8022\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.7573 - val_loss: 0.5434 - val_accuracy: 0.8022\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.7573 - val_loss: 0.5358 - val_accuracy: 0.8022\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7573 - val_loss: 0.5308 - val_accuracy: 0.8022\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7573 - val_loss: 0.5265 - val_accuracy: 0.8022\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7573 - val_loss: 0.5244 - val_accuracy: 0.8022\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7573 - val_loss: 0.5205 - val_accuracy: 0.8022\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7573 - val_loss: 0.5172 - val_accuracy: 0.8022\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7573 - val_loss: 0.5158 - val_accuracy: 0.8022\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.7573 - val_loss: 0.5124 - val_accuracy: 0.8022\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.7573 - val_loss: 0.5102 - val_accuracy: 0.8022\n","Epoch 21/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.7573 - val_loss: 0.5093 - val_accuracy: 0.8022\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7573 - val_loss: 0.5066 - val_accuracy: 0.8022\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7573 - val_loss: 0.5048 - val_accuracy: 0.8022\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7573 - val_loss: 0.5041 - val_accuracy: 0.8022\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7573 - val_loss: 0.5023 - val_accuracy: 0.8022\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.7573 - val_loss: 0.5007 - val_accuracy: 0.8022\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7573 - val_loss: 0.5000 - val_accuracy: 0.8022\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7573 - val_loss: 0.4995 - val_accuracy: 0.8022\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7573 - val_loss: 0.4977 - val_accuracy: 0.8022\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7573 - val_loss: 0.4978 - val_accuracy: 0.8022\n","Epoch 31/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5409 - accuracy: 0.7573 - val_loss: 0.4980 - val_accuracy: 0.8022\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7573 - val_loss: 0.5054 - val_accuracy: 0.8022\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7573 - val_loss: 0.5055 - val_accuracy: 0.8022\n","Epoch 34/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.7573 - val_loss: 0.5061 - val_accuracy: 0.8022\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7573 - val_loss: 0.4941 - val_accuracy: 0.8022\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7573 - val_loss: 0.4943 - val_accuracy: 0.8022\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7573 - val_loss: 0.4929 - val_accuracy: 0.8022\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7573 - val_loss: 0.4931 - val_accuracy: 0.8022\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.7573 - val_loss: 0.4987 - val_accuracy: 0.8022\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7573 - val_loss: 0.4922 - val_accuracy: 0.8022\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7573 - val_loss: 0.4913 - val_accuracy: 0.8022\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7573 - val_loss: 0.4914 - val_accuracy: 0.8022\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7573 - val_loss: 0.4910 - val_accuracy: 0.8022\n","Epoch 44/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7573 - val_loss: 0.4922 - val_accuracy: 0.8022\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7573 - val_loss: 0.4904 - val_accuracy: 0.8022\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7573 - val_loss: 0.4901 - val_accuracy: 0.8022\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7573 - val_loss: 0.4952 - val_accuracy: 0.8022\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7573 - val_loss: 0.4924 - val_accuracy: 0.8022\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7573 - val_loss: 0.4901 - val_accuracy: 0.8022\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7573 - val_loss: 0.5019 - val_accuracy: 0.8022\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7573 - val_loss: 0.4901 - val_accuracy: 0.8022\n","Epoch 52/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7573 - val_loss: 0.4900 - val_accuracy: 0.8022\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7573 - val_loss: 0.5048 - val_accuracy: 0.8022\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7573 - val_loss: 0.5033 - val_accuracy: 0.8022\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7573 - val_loss: 0.4901 - val_accuracy: 0.8022\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.7573 - val_loss: 0.4888 - val_accuracy: 0.8022\n","Epoch 57/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7573 - val_loss: 0.4871 - val_accuracy: 0.8022\n","Epoch 58/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7573 - val_loss: 0.5047 - val_accuracy: 0.8022\n","Epoch 59/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7573 - val_loss: 0.4905 - val_accuracy: 0.8022\n","Epoch 60/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7573 - val_loss: 0.4920 - val_accuracy: 0.8022\n","Epoch 61/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7573 - val_loss: 0.4885 - val_accuracy: 0.8022\n","Epoch 62/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7573 - val_loss: 0.4927 - val_accuracy: 0.8022\n","Epoch 63/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7573 - val_loss: 0.4908 - val_accuracy: 0.8022\n","Epoch 64/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7573 - val_loss: 0.4896 - val_accuracy: 0.8022\n","Epoch 65/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7573 - val_loss: 0.4915 - val_accuracy: 0.8022\n","Epoch 66/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7573 - val_loss: 0.4898 - val_accuracy: 0.8022\n","Epoch 67/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.7573 - val_loss: 0.4902 - val_accuracy: 0.8022\n","Validation Accuracy: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.80      1.00      0.89       288\n","           1       0.00      0.00      0.00        71\n","\n","    accuracy                           0.80       359\n","   macro avg       0.40      0.50      0.45       359\n","weighted avg       0.64      0.80      0.71       359\n","\n","Accuracy: 0.8022284122562674\n","[[288   0]\n"," [ 71   0]]\n","Precision: 0.0000\n","Recall: 0.0000\n","F1 Score: 0.0000\n","INFO:tensorflow:Assets written to: ram://e9375a1c-7d38-4c04-9081-718655436fee/assets\n","model 1 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 93.4164 - accuracy: 0.7663 - val_loss: 44.2719 - val_accuracy: 0.7939\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 32.9086 - accuracy: 0.7576 - val_loss: 65.7437 - val_accuracy: 0.7883\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 23.1807 - accuracy: 0.7876 - val_loss: 25.7321 - val_accuracy: 0.7103\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 17.7270 - accuracy: 0.7904 - val_loss: 25.3885 - val_accuracy: 0.7270\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.3353 - accuracy: 0.7960 - val_loss: 18.4167 - val_accuracy: 0.7994\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.4645 - accuracy: 0.8019 - val_loss: 22.9448 - val_accuracy: 0.7632\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 11.9228 - accuracy: 0.8019 - val_loss: 29.9632 - val_accuracy: 0.7688\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 16.2476 - accuracy: 0.7913 - val_loss: 19.2596 - val_accuracy: 0.7939\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.7217 - accuracy: 0.7950 - val_loss: 18.6170 - val_accuracy: 0.8022\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 15.4898 - accuracy: 0.7907 - val_loss: 18.0897 - val_accuracy: 0.8162\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 10.5461 - accuracy: 0.8031 - val_loss: 24.8890 - val_accuracy: 0.8050\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 9.7760 - accuracy: 0.7981 - val_loss: 8.3445 - val_accuracy: 0.8134\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.2750 - accuracy: 0.7950 - val_loss: 8.7227 - val_accuracy: 0.8078\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 7.1112 - accuracy: 0.7913 - val_loss: 19.6240 - val_accuracy: 0.8162\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 9.3275 - accuracy: 0.7975 - val_loss: 12.6369 - val_accuracy: 0.7994\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.8831 - accuracy: 0.8034 - val_loss: 4.8969 - val_accuracy: 0.8106\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 7.1335 - accuracy: 0.7913 - val_loss: 4.8823 - val_accuracy: 0.7660\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 7.7845 - accuracy: 0.7985 - val_loss: 7.4136 - val_accuracy: 0.8273\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 10.1349 - accuracy: 0.7994 - val_loss: 5.8624 - val_accuracy: 0.7298\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 10.9799 - accuracy: 0.7941 - val_loss: 20.5282 - val_accuracy: 0.7911\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 9.2479 - accuracy: 0.7895 - val_loss: 4.3271 - val_accuracy: 0.7549\n","Epoch 22/100\n","101/101 [==============================] - 0s 4ms/step - loss: 5.2541 - accuracy: 0.7957 - val_loss: 5.4578 - val_accuracy: 0.8189\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.2493 - accuracy: 0.7941 - val_loss: 4.4793 - val_accuracy: 0.7632\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.7677 - accuracy: 0.7960 - val_loss: 33.9735 - val_accuracy: 0.7967\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.8124 - accuracy: 0.7950 - val_loss: 7.8517 - val_accuracy: 0.8134\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.5263 - accuracy: 0.7932 - val_loss: 15.6726 - val_accuracy: 0.7939\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.0120 - accuracy: 0.7997 - val_loss: 38.7079 - val_accuracy: 0.5487\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.8670 - accuracy: 0.7960 - val_loss: 8.6990 - val_accuracy: 0.8189\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.7842 - accuracy: 0.7885 - val_loss: 9.1097 - val_accuracy: 0.7883\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.1974 - accuracy: 0.7944 - val_loss: 25.3798 - val_accuracy: 0.8162\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 16.5597 - accuracy: 0.7941 - val_loss: 58.5180 - val_accuracy: 0.8106\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.94      0.88       277\n","           1       0.65      0.38      0.48        82\n","\n","    accuracy                           0.81       359\n","   macro avg       0.74      0.66      0.68       359\n","weighted avg       0.79      0.81      0.79       359\n","\n","Accuracy: 0.8105849582172702\n","[[260  17]\n"," [ 51  31]]\n","Precision: 0.6458\n","Recall: 0.3780\n","F1 Score: 0.4769\n","INFO:tensorflow:Assets written to: ram://e5ee8959-3d1c-442a-afff-23b92a0e0ec4/assets\n","model 2 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 41.4403 - accuracy: 0.7390 - val_loss: 11.0295 - val_accuracy: 0.7604\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 30.8291 - accuracy: 0.7576 - val_loss: 8.2379 - val_accuracy: 0.7577\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 21.7075 - accuracy: 0.7678 - val_loss: 7.0751 - val_accuracy: 0.8106\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.6192 - accuracy: 0.7808 - val_loss: 11.5112 - val_accuracy: 0.8134\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 16.1597 - accuracy: 0.7814 - val_loss: 24.0287 - val_accuracy: 0.6184\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.1610 - accuracy: 0.7802 - val_loss: 5.6881 - val_accuracy: 0.7827\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.0810 - accuracy: 0.7743 - val_loss: 11.5920 - val_accuracy: 0.7994\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.5572 - accuracy: 0.7885 - val_loss: 3.9644 - val_accuracy: 0.8078\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 10.2067 - accuracy: 0.7978 - val_loss: 4.7600 - val_accuracy: 0.7994\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 11.1367 - accuracy: 0.7923 - val_loss: 8.5573 - val_accuracy: 0.8050\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 19.6403 - accuracy: 0.7932 - val_loss: 4.7254 - val_accuracy: 0.8078\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.2697 - accuracy: 0.7793 - val_loss: 11.7085 - val_accuracy: 0.8162\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 10.4888 - accuracy: 0.7944 - val_loss: 6.3910 - val_accuracy: 0.7911\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.2568 - accuracy: 0.8037 - val_loss: 6.2675 - val_accuracy: 0.7939\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 16.5614 - accuracy: 0.7805 - val_loss: 8.6138 - val_accuracy: 0.8022\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 11.9607 - accuracy: 0.7830 - val_loss: 3.8569 - val_accuracy: 0.8134\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.5531 - accuracy: 0.7808 - val_loss: 4.8185 - val_accuracy: 0.7855\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 7.6970 - accuracy: 0.7969 - val_loss: 9.0461 - val_accuracy: 0.7437\n","Epoch 19/100\n","101/101 [==============================] - 0s 4ms/step - loss: 7.3380 - accuracy: 0.7839 - val_loss: 21.1658 - val_accuracy: 0.6323\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 10.1278 - accuracy: 0.7960 - val_loss: 4.0697 - val_accuracy: 0.7660\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.1307 - accuracy: 0.7929 - val_loss: 9.4540 - val_accuracy: 0.8022\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 9.7935 - accuracy: 0.7935 - val_loss: 4.5168 - val_accuracy: 0.8078\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.0221 - accuracy: 0.8043 - val_loss: 8.9483 - val_accuracy: 0.8050\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 7.8153 - accuracy: 0.7972 - val_loss: 3.6261 - val_accuracy: 0.7967\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.9447 - accuracy: 0.7969 - val_loss: 4.5085 - val_accuracy: 0.7883\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.9323 - accuracy: 0.7864 - val_loss: 4.3300 - val_accuracy: 0.8022\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.7589 - accuracy: 0.7972 - val_loss: 6.5142 - val_accuracy: 0.7967\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.4621 - accuracy: 0.7848 - val_loss: 4.3709 - val_accuracy: 0.7493\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.7716 - accuracy: 0.7941 - val_loss: 7.2528 - val_accuracy: 0.7827\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.3809 - accuracy: 0.7882 - val_loss: 3.6671 - val_accuracy: 0.7744\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.4680 - accuracy: 0.7978 - val_loss: 4.2929 - val_accuracy: 0.7939\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.8815 - accuracy: 0.7957 - val_loss: 4.1887 - val_accuracy: 0.7939\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.2776 - accuracy: 0.8149 - val_loss: 3.8392 - val_accuracy: 0.7772\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.6847 - accuracy: 0.8053 - val_loss: 3.4022 - val_accuracy: 0.7772\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.3146 - accuracy: 0.8080 - val_loss: 3.7396 - val_accuracy: 0.7827\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.3031 - accuracy: 0.7981 - val_loss: 3.6052 - val_accuracy: 0.7967\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.6191 - accuracy: 0.7997 - val_loss: 5.8340 - val_accuracy: 0.7855\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.5914 - accuracy: 0.8077 - val_loss: 2.6655 - val_accuracy: 0.7911\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.2728 - accuracy: 0.8056 - val_loss: 3.1531 - val_accuracy: 0.7939\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.4644 - accuracy: 0.7907 - val_loss: 3.3321 - val_accuracy: 0.7994\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.5011 - accuracy: 0.8189 - val_loss: 4.8211 - val_accuracy: 0.7967\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.3847 - accuracy: 0.7944 - val_loss: 7.7769 - val_accuracy: 0.7827\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.0414 - accuracy: 0.7981 - val_loss: 11.2946 - val_accuracy: 0.6462\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.7652 - accuracy: 0.8019 - val_loss: 4.9186 - val_accuracy: 0.7911\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 7.1395 - accuracy: 0.7963 - val_loss: 3.9738 - val_accuracy: 0.7939\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.8248 - accuracy: 0.8046 - val_loss: 4.5689 - val_accuracy: 0.7883\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.0502 - accuracy: 0.7941 - val_loss: 4.3340 - val_accuracy: 0.7660\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.9949 - accuracy: 0.8028 - val_loss: 5.2576 - val_accuracy: 0.7827\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.85      0.86       286\n","           1       0.47      0.51      0.49        73\n","\n","    accuracy                           0.78       359\n","   macro avg       0.67      0.68      0.67       359\n","weighted avg       0.79      0.78      0.79       359\n","\n","Accuracy: 0.7827298050139275\n","[[244  42]\n"," [ 36  37]]\n","Precision: 0.4684\n","Recall: 0.5068\n","F1 Score: 0.4868\n","INFO:tensorflow:Assets written to: ram://3863b5ae-d51e-4f35-810c-f8663ecf5800/assets\n","model 3 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 89.3104 - accuracy: 0.7508 - val_loss: 111.6105 - val_accuracy: 0.8078\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 44.2547 - accuracy: 0.7687 - val_loss: 45.4904 - val_accuracy: 0.7883\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 21.2163 - accuracy: 0.7796 - val_loss: 24.6432 - val_accuracy: 0.7354\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.6849 - accuracy: 0.7858 - val_loss: 46.6852 - val_accuracy: 0.7827\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.7987 - accuracy: 0.7802 - val_loss: 55.7302 - val_accuracy: 0.7855\n","Epoch 6/100\n","101/101 [==============================] - 0s 4ms/step - loss: 16.6905 - accuracy: 0.7889 - val_loss: 65.4788 - val_accuracy: 0.8134\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 17.4679 - accuracy: 0.7796 - val_loss: 82.2047 - val_accuracy: 0.8162\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 29.6540 - accuracy: 0.7755 - val_loss: 68.0043 - val_accuracy: 0.7744\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 17.1698 - accuracy: 0.7892 - val_loss: 45.8011 - val_accuracy: 0.7855\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 11.4459 - accuracy: 0.7885 - val_loss: 32.9567 - val_accuracy: 0.7187\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 10.4690 - accuracy: 0.7876 - val_loss: 9.7664 - val_accuracy: 0.7772\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.6853 - accuracy: 0.7895 - val_loss: 9.5157 - val_accuracy: 0.7883\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.1866 - accuracy: 0.7827 - val_loss: 17.0147 - val_accuracy: 0.8106\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 17.7075 - accuracy: 0.7923 - val_loss: 81.5934 - val_accuracy: 0.8022\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 22.8614 - accuracy: 0.7873 - val_loss: 23.1937 - val_accuracy: 0.7409\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.0815 - accuracy: 0.7889 - val_loss: 29.9384 - val_accuracy: 0.7911\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.8878 - accuracy: 0.7941 - val_loss: 51.4365 - val_accuracy: 0.7883\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.8657 - accuracy: 0.8025 - val_loss: 48.3186 - val_accuracy: 0.7994\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 11.9842 - accuracy: 0.7923 - val_loss: 74.4788 - val_accuracy: 0.8189\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 16.7057 - accuracy: 0.7867 - val_loss: 22.4100 - val_accuracy: 0.7939\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 10.4094 - accuracy: 0.8006 - val_loss: 15.5620 - val_accuracy: 0.7799\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.1865 - accuracy: 0.8053 - val_loss: 21.2623 - val_accuracy: 0.7827\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.82      0.85       276\n","           1       0.52      0.67      0.59        83\n","\n","    accuracy                           0.78       359\n","   macro avg       0.71      0.74      0.72       359\n","weighted avg       0.81      0.78      0.79       359\n","\n","Accuracy: 0.7827298050139275\n","[[225  51]\n"," [ 27  56]]\n","Precision: 0.5234\n","Recall: 0.6747\n","F1 Score: 0.5895\n","INFO:tensorflow:Assets written to: ram://8c949ccb-c753-461d-821c-d5d2339b5604/assets\n","model 4 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 253.0546 - accuracy: 0.7542 - val_loss: 62.9263 - val_accuracy: 0.7660\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 43.8191 - accuracy: 0.7650 - val_loss: 39.3734 - val_accuracy: 0.5599\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 21.7586 - accuracy: 0.7433 - val_loss: 15.5901 - val_accuracy: 0.8050\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 18.1337 - accuracy: 0.7709 - val_loss: 11.9137 - val_accuracy: 0.7549\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.1456 - accuracy: 0.7774 - val_loss: 10.0921 - val_accuracy: 0.7994\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.8395 - accuracy: 0.7752 - val_loss: 15.2560 - val_accuracy: 0.6741\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.3366 - accuracy: 0.7898 - val_loss: 7.8603 - val_accuracy: 0.7939\n","Epoch 8/100\n","101/101 [==============================] - 0s 4ms/step - loss: 7.9003 - accuracy: 0.7848 - val_loss: 10.7714 - val_accuracy: 0.6936\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 9.0540 - accuracy: 0.7947 - val_loss: 7.7487 - val_accuracy: 0.8217\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 7.7914 - accuracy: 0.7845 - val_loss: 13.0743 - val_accuracy: 0.7994\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 9.3277 - accuracy: 0.7854 - val_loss: 7.4606 - val_accuracy: 0.7772\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.8760 - accuracy: 0.7910 - val_loss: 10.0552 - val_accuracy: 0.7716\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.7593 - accuracy: 0.7913 - val_loss: 7.6341 - val_accuracy: 0.8022\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.4377 - accuracy: 0.8012 - val_loss: 8.3037 - val_accuracy: 0.8162\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.5169 - accuracy: 0.8006 - val_loss: 9.4245 - val_accuracy: 0.8106\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.0050 - accuracy: 0.8115 - val_loss: 22.2233 - val_accuracy: 0.8050\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.6082 - accuracy: 0.7960 - val_loss: 7.3096 - val_accuracy: 0.8329\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.8011 - accuracy: 0.8186 - val_loss: 10.9598 - val_accuracy: 0.8217\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.7233 - accuracy: 0.8186 - val_loss: 8.2335 - val_accuracy: 0.8329\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.2643 - accuracy: 0.8155 - val_loss: 6.1039 - val_accuracy: 0.8189\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.3433 - accuracy: 0.8102 - val_loss: 6.3460 - val_accuracy: 0.8301\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.5877 - accuracy: 0.8170 - val_loss: 5.2019 - val_accuracy: 0.8134\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.0277 - accuracy: 0.8068 - val_loss: 10.0938 - val_accuracy: 0.8245\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.9772 - accuracy: 0.8186 - val_loss: 4.8550 - val_accuracy: 0.8134\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.8605 - accuracy: 0.8074 - val_loss: 5.3399 - val_accuracy: 0.7883\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.9759 - accuracy: 0.8146 - val_loss: 5.5148 - val_accuracy: 0.8217\n","Epoch 27/100\n","101/101 [==============================] - 0s 4ms/step - loss: 4.1929 - accuracy: 0.8142 - val_loss: 5.0515 - val_accuracy: 0.7632\n","Epoch 28/100\n","101/101 [==============================] - 1s 6ms/step - loss: 4.9798 - accuracy: 0.8074 - val_loss: 5.6026 - val_accuracy: 0.7577\n","Epoch 29/100\n","101/101 [==============================] - 1s 5ms/step - loss: 4.3076 - accuracy: 0.8028 - val_loss: 8.7801 - val_accuracy: 0.8134\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 7.4623 - accuracy: 0.8022 - val_loss: 4.3086 - val_accuracy: 0.8022\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.8540 - accuracy: 0.8046 - val_loss: 8.9534 - val_accuracy: 0.8078\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.4727 - accuracy: 0.8077 - val_loss: 8.9047 - val_accuracy: 0.8134\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.4679 - accuracy: 0.8108 - val_loss: 5.4567 - val_accuracy: 0.8134\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.9309 - accuracy: 0.8012 - val_loss: 4.8475 - val_accuracy: 0.8050\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.0730 - accuracy: 0.8068 - val_loss: 3.9542 - val_accuracy: 0.7994\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.6073 - accuracy: 0.7963 - val_loss: 7.7431 - val_accuracy: 0.7159\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.2928 - accuracy: 0.8118 - val_loss: 3.9580 - val_accuracy: 0.7549\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.3951 - accuracy: 0.8053 - val_loss: 4.5736 - val_accuracy: 0.7994\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.2592 - accuracy: 0.8015 - val_loss: 7.7542 - val_accuracy: 0.8050\n","Epoch 40/100\n","101/101 [==============================] - 0s 4ms/step - loss: 4.7831 - accuracy: 0.7988 - val_loss: 9.2097 - val_accuracy: 0.8022\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.3512 - accuracy: 0.8022 - val_loss: 3.4783 - val_accuracy: 0.7604\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.5789 - accuracy: 0.7994 - val_loss: 4.0420 - val_accuracy: 0.8050\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 7.2731 - accuracy: 0.8077 - val_loss: 8.0898 - val_accuracy: 0.8162\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.3794 - accuracy: 0.7879 - val_loss: 3.5606 - val_accuracy: 0.7521\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.7092 - accuracy: 0.8099 - val_loss: 6.2327 - val_accuracy: 0.8050\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.5346 - accuracy: 0.8028 - val_loss: 4.2369 - val_accuracy: 0.8134\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.6169 - accuracy: 0.8130 - val_loss: 3.4393 - val_accuracy: 0.7799\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.3582 - accuracy: 0.8043 - val_loss: 4.6911 - val_accuracy: 0.6908\n","Epoch 49/100\n","101/101 [==============================] - 0s 4ms/step - loss: 4.0216 - accuracy: 0.8006 - val_loss: 3.1832 - val_accuracy: 0.8134\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.8418 - accuracy: 0.7994 - val_loss: 4.2481 - val_accuracy: 0.7911\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.7624 - accuracy: 0.8053 - val_loss: 3.6131 - val_accuracy: 0.7660\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.2573 - accuracy: 0.8102 - val_loss: 5.1760 - val_accuracy: 0.8189\n","Epoch 53/100\n","101/101 [==============================] - 0s 4ms/step - loss: 3.2154 - accuracy: 0.8146 - val_loss: 4.4045 - val_accuracy: 0.8189\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.8344 - accuracy: 0.8127 - val_loss: 4.0026 - val_accuracy: 0.7604\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.0861 - accuracy: 0.8071 - val_loss: 3.7265 - val_accuracy: 0.7855\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.0064 - accuracy: 0.8096 - val_loss: 3.4211 - val_accuracy: 0.8329\n","Epoch 57/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.2840 - accuracy: 0.8266 - val_loss: 7.8781 - val_accuracy: 0.8273\n","Epoch 58/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.2561 - accuracy: 0.8170 - val_loss: 3.1146 - val_accuracy: 0.8245\n","Epoch 59/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.6278 - accuracy: 0.8127 - val_loss: 3.8799 - val_accuracy: 0.8524\n","Epoch 60/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.6912 - accuracy: 0.8149 - val_loss: 3.1376 - val_accuracy: 0.8245\n","Epoch 61/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.6987 - accuracy: 0.8269 - val_loss: 3.1536 - val_accuracy: 0.8357\n","Epoch 62/100\n","101/101 [==============================] - 0s 3ms/step - loss: 1.8215 - accuracy: 0.8121 - val_loss: 6.6015 - val_accuracy: 0.8384\n","Epoch 63/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.5756 - accuracy: 0.8279 - val_loss: 2.7455 - val_accuracy: 0.7967\n","Epoch 64/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.3703 - accuracy: 0.8257 - val_loss: 5.9715 - val_accuracy: 0.5543\n","Epoch 65/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.9231 - accuracy: 0.8214 - val_loss: 2.9321 - val_accuracy: 0.8189\n","Epoch 66/100\n","101/101 [==============================] - 0s 3ms/step - loss: 1.5773 - accuracy: 0.8164 - val_loss: 3.4410 - val_accuracy: 0.8245\n","Epoch 67/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.6740 - accuracy: 0.8207 - val_loss: 2.7198 - val_accuracy: 0.8189\n","Epoch 68/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.9122 - accuracy: 0.8080 - val_loss: 6.5187 - val_accuracy: 0.8329\n","Epoch 69/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.3764 - accuracy: 0.8161 - val_loss: 6.3517 - val_accuracy: 0.8329\n","Epoch 70/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.6829 - accuracy: 0.8238 - val_loss: 3.8425 - val_accuracy: 0.8384\n","Epoch 71/100\n","101/101 [==============================] - 0s 4ms/step - loss: 2.2444 - accuracy: 0.8149 - val_loss: 5.3946 - val_accuracy: 0.8384\n","Epoch 72/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.9549 - accuracy: 0.8251 - val_loss: 5.1161 - val_accuracy: 0.8357\n","Epoch 73/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.5680 - accuracy: 0.8065 - val_loss: 5.8247 - val_accuracy: 0.7521\n","Epoch 74/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.7370 - accuracy: 0.8195 - val_loss: 2.4075 - val_accuracy: 0.8106\n","Epoch 75/100\n","101/101 [==============================] - 0s 3ms/step - loss: 1.7022 - accuracy: 0.8235 - val_loss: 2.6951 - val_accuracy: 0.8412\n","Epoch 76/100\n","101/101 [==============================] - 0s 4ms/step - loss: 3.4238 - accuracy: 0.8294 - val_loss: 4.2510 - val_accuracy: 0.8189\n","Epoch 77/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.6934 - accuracy: 0.8059 - val_loss: 4.0706 - val_accuracy: 0.8357\n","Epoch 78/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.9654 - accuracy: 0.8220 - val_loss: 4.4727 - val_accuracy: 0.8245\n","Epoch 79/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.0369 - accuracy: 0.8136 - val_loss: 3.5328 - val_accuracy: 0.8050\n","Epoch 80/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.7068 - accuracy: 0.8077 - val_loss: 4.3538 - val_accuracy: 0.8301\n","Epoch 81/100\n","101/101 [==============================] - 0s 3ms/step - loss: 1.8373 - accuracy: 0.8276 - val_loss: 2.2332 - val_accuracy: 0.8022\n","Epoch 82/100\n","101/101 [==============================] - 0s 4ms/step - loss: 2.8944 - accuracy: 0.8189 - val_loss: 3.9826 - val_accuracy: 0.8412\n","Epoch 83/100\n","101/101 [==============================] - 0s 3ms/step - loss: 1.7585 - accuracy: 0.8263 - val_loss: 2.8436 - val_accuracy: 0.7382\n","Epoch 84/100\n","101/101 [==============================] - 0s 3ms/step - loss: 1.4728 - accuracy: 0.8279 - val_loss: 2.4707 - val_accuracy: 0.8217\n","Epoch 85/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.2990 - accuracy: 0.8217 - val_loss: 2.3537 - val_accuracy: 0.7744\n","Epoch 86/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.0771 - accuracy: 0.8241 - val_loss: 1.7389 - val_accuracy: 0.7911\n","Epoch 87/100\n","101/101 [==============================] - 0s 3ms/step - loss: 1.8789 - accuracy: 0.8297 - val_loss: 2.1257 - val_accuracy: 0.8022\n","Epoch 88/100\n","101/101 [==============================] - 0s 3ms/step - loss: 1.5052 - accuracy: 0.8238 - val_loss: 2.6036 - val_accuracy: 0.8134\n","Epoch 89/100\n","101/101 [==============================] - 0s 3ms/step - loss: 1.7460 - accuracy: 0.8248 - val_loss: 2.6473 - val_accuracy: 0.7465\n","Epoch 90/100\n","101/101 [==============================] - 0s 3ms/step - loss: 1.9300 - accuracy: 0.8186 - val_loss: 1.8465 - val_accuracy: 0.7994\n","Epoch 91/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.2639 - accuracy: 0.8124 - val_loss: 1.9774 - val_accuracy: 0.7994\n","Epoch 92/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.2040 - accuracy: 0.8232 - val_loss: 2.4368 - val_accuracy: 0.8189\n","Epoch 93/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.2999 - accuracy: 0.7975 - val_loss: 3.9945 - val_accuracy: 0.8329\n","Epoch 94/100\n","101/101 [==============================] - 0s 3ms/step - loss: 1.7351 - accuracy: 0.8260 - val_loss: 1.7672 - val_accuracy: 0.8162\n","Epoch 95/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.9937 - accuracy: 0.8220 - val_loss: 3.4653 - val_accuracy: 0.8357\n","Epoch 96/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.1561 - accuracy: 0.8297 - val_loss: 1.9412 - val_accuracy: 0.7911\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.88      0.86       268\n","           1       0.60      0.52      0.56        91\n","\n","    accuracy                           0.79       359\n","   macro avg       0.72      0.70      0.71       359\n","weighted avg       0.78      0.79      0.79       359\n","\n","Accuracy: 0.7910863509749304\n","[[237  31]\n"," [ 44  47]]\n","Precision: 0.6026\n","Recall: 0.5165\n","F1 Score: 0.5562\n","INFO:tensorflow:Assets written to: ram://150f24a2-179f-4ab7-9597-758e4eefe48e/assets\n","model 5 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 5ms/step - loss: 519.9402 - accuracy: 0.7458 - val_loss: 119.8568 - val_accuracy: 0.7604\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 101.7258 - accuracy: 0.7641 - val_loss: 50.2163 - val_accuracy: 0.7772\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 48.8803 - accuracy: 0.7666 - val_loss: 33.0016 - val_accuracy: 0.7465\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 47.1027 - accuracy: 0.7728 - val_loss: 21.4535 - val_accuracy: 0.8162\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 43.7267 - accuracy: 0.7743 - val_loss: 25.2430 - val_accuracy: 0.7660\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 32.7169 - accuracy: 0.7771 - val_loss: 12.3131 - val_accuracy: 0.8217\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 25.9067 - accuracy: 0.7898 - val_loss: 9.0931 - val_accuracy: 0.8134\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 28.9878 - accuracy: 0.7777 - val_loss: 27.1894 - val_accuracy: 0.7493\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 17.9381 - accuracy: 0.7805 - val_loss: 19.7031 - val_accuracy: 0.7577\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 18.2907 - accuracy: 0.7802 - val_loss: 37.8679 - val_accuracy: 0.7772\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 15.3626 - accuracy: 0.7901 - val_loss: 31.2302 - val_accuracy: 0.7632\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 28.4839 - accuracy: 0.7858 - val_loss: 6.3115 - val_accuracy: 0.8050\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.5091 - accuracy: 0.7923 - val_loss: 49.3928 - val_accuracy: 0.6964\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 28.7290 - accuracy: 0.7842 - val_loss: 10.2818 - val_accuracy: 0.7883\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.8550 - accuracy: 0.7985 - val_loss: 21.8120 - val_accuracy: 0.7716\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 16.0455 - accuracy: 0.8028 - val_loss: 6.8813 - val_accuracy: 0.7994\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.8473 - accuracy: 0.8003 - val_loss: 21.1341 - val_accuracy: 0.6407\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 16.5544 - accuracy: 0.7985 - val_loss: 5.8222 - val_accuracy: 0.8050\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 20.1890 - accuracy: 0.8053 - val_loss: 12.8912 - val_accuracy: 0.7716\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 18.7932 - accuracy: 0.7969 - val_loss: 8.5178 - val_accuracy: 0.7549\n","Epoch 21/100\n","101/101 [==============================] - 0s 4ms/step - loss: 13.1611 - accuracy: 0.8096 - val_loss: 11.0287 - val_accuracy: 0.7827\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.1058 - accuracy: 0.8068 - val_loss: 5.4663 - val_accuracy: 0.7939\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 9.0672 - accuracy: 0.8108 - val_loss: 3.2564 - val_accuracy: 0.8301\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 15.2855 - accuracy: 0.7957 - val_loss: 11.8127 - val_accuracy: 0.7827\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.3863 - accuracy: 0.8068 - val_loss: 6.6114 - val_accuracy: 0.7883\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 19.1868 - accuracy: 0.7957 - val_loss: 8.8352 - val_accuracy: 0.7883\n","Epoch 27/100\n","101/101 [==============================] - 0s 4ms/step - loss: 11.2901 - accuracy: 0.8074 - val_loss: 8.8119 - val_accuracy: 0.7716\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 18.5137 - accuracy: 0.8046 - val_loss: 5.6907 - val_accuracy: 0.8301\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 11.5054 - accuracy: 0.8022 - val_loss: 6.2857 - val_accuracy: 0.7994\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.9260 - accuracy: 0.7957 - val_loss: 6.2463 - val_accuracy: 0.7827\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 10.0787 - accuracy: 0.8056 - val_loss: 3.5510 - val_accuracy: 0.8440\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.9820 - accuracy: 0.8056 - val_loss: 2.8259 - val_accuracy: 0.8635\n","Epoch 33/100\n","101/101 [==============================] - 0s 4ms/step - loss: 15.4683 - accuracy: 0.8155 - val_loss: 8.8746 - val_accuracy: 0.7911\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.1937 - accuracy: 0.8077 - val_loss: 3.2331 - val_accuracy: 0.8607\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.0457 - accuracy: 0.8053 - val_loss: 16.9457 - val_accuracy: 0.7883\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 17.6223 - accuracy: 0.8065 - val_loss: 12.8002 - val_accuracy: 0.8162\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 21.3631 - accuracy: 0.7944 - val_loss: 5.5908 - val_accuracy: 0.8412\n","Epoch 38/100\n","101/101 [==============================] - 0s 4ms/step - loss: 14.0328 - accuracy: 0.8025 - val_loss: 2.7219 - val_accuracy: 0.8440\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.8221 - accuracy: 0.8183 - val_loss: 4.6984 - val_accuracy: 0.7967\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 11.5223 - accuracy: 0.8080 - val_loss: 10.2013 - val_accuracy: 0.8050\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.7225 - accuracy: 0.8087 - val_loss: 20.8772 - val_accuracy: 0.7772\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 18.4551 - accuracy: 0.7966 - val_loss: 3.8043 - val_accuracy: 0.8384\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.6232 - accuracy: 0.8000 - val_loss: 7.5080 - val_accuracy: 0.8301\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 21.1147 - accuracy: 0.7904 - val_loss: 8.6712 - val_accuracy: 0.8357\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 15.3347 - accuracy: 0.8161 - val_loss: 4.0326 - val_accuracy: 0.8440\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 11.2853 - accuracy: 0.8207 - val_loss: 3.9202 - val_accuracy: 0.8635\n","Epoch 47/100\n","101/101 [==============================] - 0s 4ms/step - loss: 6.2664 - accuracy: 0.8170 - val_loss: 6.3687 - val_accuracy: 0.7744\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.1327 - accuracy: 0.8025 - val_loss: 9.1982 - val_accuracy: 0.7994\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.96      0.87       262\n","           1       0.77      0.37      0.50        97\n","\n","    accuracy                           0.80       359\n","   macro avg       0.79      0.66      0.69       359\n","weighted avg       0.79      0.80      0.77       359\n","\n","Accuracy: 0.7994428969359332\n","[[251  11]\n"," [ 61  36]]\n","Precision: 0.7660\n","Recall: 0.3711\n","F1 Score: 0.5000\n","INFO:tensorflow:Assets written to: ram://eb11ccba-5611-4899-b721-2ff8450d3830/assets\n","model 6 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 489.5209 - accuracy: 0.7520 - val_loss: 81.5015 - val_accuracy: 0.7994\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 75.7105 - accuracy: 0.7851 - val_loss: 29.1380 - val_accuracy: 0.7604\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 45.5543 - accuracy: 0.7672 - val_loss: 33.9317 - val_accuracy: 0.7660\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 41.8255 - accuracy: 0.7703 - val_loss: 15.7858 - val_accuracy: 0.8078\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 33.0153 - accuracy: 0.7715 - val_loss: 19.9623 - val_accuracy: 0.8217\n","Epoch 6/100\n","101/101 [==============================] - 0s 4ms/step - loss: 18.1753 - accuracy: 0.7882 - val_loss: 23.0140 - val_accuracy: 0.7911\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 22.8199 - accuracy: 0.7759 - val_loss: 13.2701 - val_accuracy: 0.8245\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 20.5018 - accuracy: 0.7898 - val_loss: 15.0240 - val_accuracy: 0.7939\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 22.8399 - accuracy: 0.7814 - val_loss: 15.1145 - val_accuracy: 0.8273\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 15.5043 - accuracy: 0.7923 - val_loss: 17.0322 - val_accuracy: 0.7632\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 18.6778 - accuracy: 0.7870 - val_loss: 16.5795 - val_accuracy: 0.7772\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 26.2067 - accuracy: 0.7824 - val_loss: 14.7229 - val_accuracy: 0.8245\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.6923 - accuracy: 0.7876 - val_loss: 10.6303 - val_accuracy: 0.8022\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 21.3298 - accuracy: 0.7898 - val_loss: 12.4943 - val_accuracy: 0.8162\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 10.9066 - accuracy: 0.7916 - val_loss: 9.4779 - val_accuracy: 0.8273\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.5324 - accuracy: 0.7963 - val_loss: 13.0226 - val_accuracy: 0.8189\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.2059 - accuracy: 0.8015 - val_loss: 9.5247 - val_accuracy: 0.8412\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.2622 - accuracy: 0.7972 - val_loss: 15.2507 - val_accuracy: 0.8245\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 19.6338 - accuracy: 0.7904 - val_loss: 13.0954 - val_accuracy: 0.8217\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 22.8896 - accuracy: 0.7950 - val_loss: 8.3543 - val_accuracy: 0.8357\n","Epoch 21/100\n","101/101 [==============================] - 0s 4ms/step - loss: 9.8128 - accuracy: 0.7988 - val_loss: 7.9963 - val_accuracy: 0.8106\n","Epoch 22/100\n","101/101 [==============================] - 0s 4ms/step - loss: 10.5044 - accuracy: 0.8040 - val_loss: 11.8044 - val_accuracy: 0.8273\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.4418 - accuracy: 0.8037 - val_loss: 11.5183 - val_accuracy: 0.8273\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.2116 - accuracy: 0.7988 - val_loss: 12.7477 - val_accuracy: 0.8022\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 17.8758 - accuracy: 0.7957 - val_loss: 13.5275 - val_accuracy: 0.8162\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 16.8047 - accuracy: 0.7941 - val_loss: 7.4252 - val_accuracy: 0.8189\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 9.8934 - accuracy: 0.7947 - val_loss: 20.0121 - val_accuracy: 0.7967\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.6682 - accuracy: 0.7941 - val_loss: 7.6307 - val_accuracy: 0.8245\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 9.4660 - accuracy: 0.8031 - val_loss: 8.1279 - val_accuracy: 0.8357\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 11.7751 - accuracy: 0.8046 - val_loss: 6.9023 - val_accuracy: 0.8134\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.5928 - accuracy: 0.8009 - val_loss: 9.3483 - val_accuracy: 0.8134\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 10.7396 - accuracy: 0.7960 - val_loss: 9.2603 - val_accuracy: 0.8301\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 9.6679 - accuracy: 0.7960 - val_loss: 20.3359 - val_accuracy: 0.8273\n","Epoch 34/100\n","101/101 [==============================] - 0s 4ms/step - loss: 8.7702 - accuracy: 0.8068 - val_loss: 6.4928 - val_accuracy: 0.7744\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 10.4864 - accuracy: 0.7950 - val_loss: 6.9198 - val_accuracy: 0.7967\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 7.8613 - accuracy: 0.8062 - val_loss: 8.9772 - val_accuracy: 0.8384\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.2718 - accuracy: 0.8015 - val_loss: 19.4430 - val_accuracy: 0.7967\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 11.3975 - accuracy: 0.7885 - val_loss: 5.5493 - val_accuracy: 0.8273\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 18.5072 - accuracy: 0.7966 - val_loss: 9.3636 - val_accuracy: 0.8329\n","Epoch 40/100\n","101/101 [==============================] - 0s 4ms/step - loss: 20.5113 - accuracy: 0.7929 - val_loss: 6.0996 - val_accuracy: 0.8273\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.3953 - accuracy: 0.7944 - val_loss: 11.4679 - val_accuracy: 0.7744\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.5814 - accuracy: 0.7954 - val_loss: 15.2686 - val_accuracy: 0.7911\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.3540 - accuracy: 0.7950 - val_loss: 8.2887 - val_accuracy: 0.8162\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.6337 - accuracy: 0.7988 - val_loss: 6.5494 - val_accuracy: 0.8162\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 13.9750 - accuracy: 0.7985 - val_loss: 18.6796 - val_accuracy: 0.8022\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 17.6611 - accuracy: 0.7966 - val_loss: 10.8099 - val_accuracy: 0.7911\n","Epoch 47/100\n","101/101 [==============================] - 0s 4ms/step - loss: 9.3441 - accuracy: 0.7966 - val_loss: 5.3028 - val_accuracy: 0.8245\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.6146 - accuracy: 0.8000 - val_loss: 39.4437 - val_accuracy: 0.5655\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 16.8120 - accuracy: 0.7864 - val_loss: 10.7823 - val_accuracy: 0.8134\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 11.6407 - accuracy: 0.7938 - val_loss: 10.2595 - val_accuracy: 0.8162\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 7.9365 - accuracy: 0.8003 - val_loss: 11.7613 - val_accuracy: 0.7799\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 17.5898 - accuracy: 0.7935 - val_loss: 5.4056 - val_accuracy: 0.8189\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.1292 - accuracy: 0.8062 - val_loss: 6.9398 - val_accuracy: 0.8134\n","Epoch 54/100\n","101/101 [==============================] - 0s 4ms/step - loss: 13.6340 - accuracy: 0.7960 - val_loss: 13.2468 - val_accuracy: 0.8134\n","Epoch 55/100\n","101/101 [==============================] - 0s 4ms/step - loss: 11.0961 - accuracy: 0.7972 - val_loss: 14.9166 - val_accuracy: 0.7967\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 14.8602 - accuracy: 0.8025 - val_loss: 4.8197 - val_accuracy: 0.8357\n","Epoch 57/100\n","101/101 [==============================] - 0s 4ms/step - loss: 7.9609 - accuracy: 0.8074 - val_loss: 15.9758 - val_accuracy: 0.7994\n","Epoch 58/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.8135 - accuracy: 0.8028 - val_loss: 22.1112 - val_accuracy: 0.7911\n","Epoch 59/100\n","101/101 [==============================] - 0s 4ms/step - loss: 18.0948 - accuracy: 0.7988 - val_loss: 6.6622 - val_accuracy: 0.8217\n","Epoch 60/100\n","101/101 [==============================] - 0s 4ms/step - loss: 9.1017 - accuracy: 0.7935 - val_loss: 9.5006 - val_accuracy: 0.7744\n","Epoch 61/100\n","101/101 [==============================] - 0s 3ms/step - loss: 15.8811 - accuracy: 0.7923 - val_loss: 7.4450 - val_accuracy: 0.8162\n","Epoch 62/100\n","101/101 [==============================] - 0s 4ms/step - loss: 9.6144 - accuracy: 0.7941 - val_loss: 10.3090 - val_accuracy: 0.8050\n","Epoch 63/100\n","101/101 [==============================] - 0s 3ms/step - loss: 19.7963 - accuracy: 0.7864 - val_loss: 15.3220 - val_accuracy: 0.8329\n","Epoch 64/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.5551 - accuracy: 0.7954 - val_loss: 20.0247 - val_accuracy: 0.7911\n","Epoch 65/100\n","101/101 [==============================] - 0s 3ms/step - loss: 9.5923 - accuracy: 0.8012 - val_loss: 5.0652 - val_accuracy: 0.8245\n","Epoch 66/100\n","101/101 [==============================] - 0s 3ms/step - loss: 7.9678 - accuracy: 0.7947 - val_loss: 7.0491 - val_accuracy: 0.7716\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.95      0.73      0.83       266\n","           1       0.54      0.88      0.67        93\n","\n","    accuracy                           0.77       359\n","   macro avg       0.74      0.81      0.75       359\n","weighted avg       0.84      0.77      0.78       359\n","\n","Accuracy: 0.7715877437325905\n","[[195  71]\n"," [ 11  82]]\n","Precision: 0.5359\n","Recall: 0.8817\n","F1 Score: 0.6667\n","INFO:tensorflow:Assets written to: ram://ccfcdbb0-90b8-42ce-9427-a2228a7c5461/assets\n","model 7 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 549.2447 - accuracy: 0.7189 - val_loss: 33.0541 - val_accuracy: 0.7437\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 54.0951 - accuracy: 0.7319 - val_loss: 30.9976 - val_accuracy: 0.7047\n","Epoch 3/100\n","101/101 [==============================] - 0s 4ms/step - loss: 35.5163 - accuracy: 0.7613 - val_loss: 21.6772 - val_accuracy: 0.7744\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 32.1556 - accuracy: 0.7752 - val_loss: 9.7472 - val_accuracy: 0.7716\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 25.9347 - accuracy: 0.7672 - val_loss: 16.6016 - val_accuracy: 0.7382\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 20.8244 - accuracy: 0.7805 - val_loss: 11.0210 - val_accuracy: 0.7883\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 28.4738 - accuracy: 0.7681 - val_loss: 17.5783 - val_accuracy: 0.8022\n","Epoch 8/100\n","101/101 [==============================] - 0s 4ms/step - loss: 23.6611 - accuracy: 0.7808 - val_loss: 7.0166 - val_accuracy: 0.7744\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 10.9108 - accuracy: 0.7780 - val_loss: 8.1104 - val_accuracy: 0.7827\n","Epoch 10/100\n","101/101 [==============================] - 0s 4ms/step - loss: 14.8270 - accuracy: 0.7780 - val_loss: 5.5976 - val_accuracy: 0.7911\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 16.0408 - accuracy: 0.7762 - val_loss: 12.2506 - val_accuracy: 0.7883\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 15.0639 - accuracy: 0.7771 - val_loss: 17.4763 - val_accuracy: 0.7326\n","Epoch 13/100\n","101/101 [==============================] - 0s 4ms/step - loss: 13.6438 - accuracy: 0.7712 - val_loss: 5.1067 - val_accuracy: 0.7354\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 20.2918 - accuracy: 0.7768 - val_loss: 7.9414 - val_accuracy: 0.7911\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 17.9865 - accuracy: 0.7737 - val_loss: 3.6320 - val_accuracy: 0.7549\n","Epoch 16/100\n","101/101 [==============================] - 0s 4ms/step - loss: 13.4354 - accuracy: 0.7799 - val_loss: 45.1529 - val_accuracy: 0.4206\n","Epoch 17/100\n","101/101 [==============================] - 0s 4ms/step - loss: 15.5268 - accuracy: 0.7768 - val_loss: 5.8701 - val_accuracy: 0.7549\n","Epoch 18/100\n","101/101 [==============================] - 0s 4ms/step - loss: 15.2351 - accuracy: 0.7628 - val_loss: 6.7232 - val_accuracy: 0.7772\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 11.3987 - accuracy: 0.7765 - val_loss: 6.6756 - val_accuracy: 0.7772\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.4865 - accuracy: 0.7706 - val_loss: 16.7035 - val_accuracy: 0.7772\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 16.8080 - accuracy: 0.7780 - val_loss: 6.0738 - val_accuracy: 0.7799\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.3237 - accuracy: 0.7799 - val_loss: 6.7010 - val_accuracy: 0.7799\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 26.0741 - accuracy: 0.7684 - val_loss: 14.9936 - val_accuracy: 0.6852\n","Epoch 24/100\n","101/101 [==============================] - 0s 4ms/step - loss: 14.5940 - accuracy: 0.7755 - val_loss: 5.4401 - val_accuracy: 0.7799\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.2503 - accuracy: 0.7820 - val_loss: 5.1396 - val_accuracy: 0.7911\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.84      0.86       273\n","           1       0.56      0.63      0.59        86\n","\n","    accuracy                           0.79       359\n","   macro avg       0.72      0.74      0.72       359\n","weighted avg       0.80      0.79      0.80       359\n","\n","Accuracy: 0.7910863509749304\n","[[230  43]\n"," [ 32  54]]\n","Precision: 0.5567\n","Recall: 0.6279\n","F1 Score: 0.5902\n","INFO:tensorflow:Assets written to: ram://0d585064-360e-4ff1-9c3e-8ff9e6812558/assets\n","model 8 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 5ms/step - loss: 93.1699 - accuracy: 0.7586 - val_loss: 128.0048 - val_accuracy: 0.7542\n","Epoch 2/100\n","101/101 [==============================] - 0s 4ms/step - loss: 32.0861 - accuracy: 0.7660 - val_loss: 66.1129 - val_accuracy: 0.7570\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 26.4100 - accuracy: 0.7799 - val_loss: 46.7992 - val_accuracy: 0.7570\n","Epoch 4/100\n","101/101 [==============================] - 0s 4ms/step - loss: 21.7861 - accuracy: 0.7827 - val_loss: 62.4936 - val_accuracy: 0.7542\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 20.3761 - accuracy: 0.7874 - val_loss: 77.2584 - val_accuracy: 0.7570\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 16.4028 - accuracy: 0.7877 - val_loss: 17.7447 - val_accuracy: 0.7737\n","Epoch 7/100\n","101/101 [==============================] - 0s 4ms/step - loss: 12.0362 - accuracy: 0.7883 - val_loss: 23.2417 - val_accuracy: 0.7877\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 9.4587 - accuracy: 0.7951 - val_loss: 11.1129 - val_accuracy: 0.7765\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 9.9287 - accuracy: 0.7911 - val_loss: 29.4249 - val_accuracy: 0.7877\n","Epoch 10/100\n","101/101 [==============================] - 0s 4ms/step - loss: 10.7238 - accuracy: 0.7886 - val_loss: 8.0426 - val_accuracy: 0.6788\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 9.4485 - accuracy: 0.7734 - val_loss: 41.4700 - val_accuracy: 0.7514\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.3760 - accuracy: 0.7840 - val_loss: 14.8932 - val_accuracy: 0.7542\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 10.1524 - accuracy: 0.7818 - val_loss: 20.9729 - val_accuracy: 0.7737\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 7.4179 - accuracy: 0.7809 - val_loss: 11.0056 - val_accuracy: 0.7737\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.7586 - accuracy: 0.7787 - val_loss: 11.6956 - val_accuracy: 0.7458\n","Epoch 16/100\n","101/101 [==============================] - 0s 4ms/step - loss: 8.8658 - accuracy: 0.7775 - val_loss: 18.3988 - val_accuracy: 0.7849\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.8587 - accuracy: 0.7905 - val_loss: 13.4290 - val_accuracy: 0.7626\n","Epoch 18/100\n","101/101 [==============================] - 0s 4ms/step - loss: 5.0259 - accuracy: 0.7837 - val_loss: 13.8266 - val_accuracy: 0.6620\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 12.5439 - accuracy: 0.7762 - val_loss: 46.4684 - val_accuracy: 0.4637\n","Epoch 20/100\n","101/101 [==============================] - 0s 4ms/step - loss: 7.6461 - accuracy: 0.7806 - val_loss: 6.0585 - val_accuracy: 0.7235\n","Epoch 21/100\n","101/101 [==============================] - 0s 4ms/step - loss: 9.3524 - accuracy: 0.7673 - val_loss: 14.1368 - val_accuracy: 0.7542\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 11.7953 - accuracy: 0.7728 - val_loss: 29.1348 - val_accuracy: 0.7682\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.0996 - accuracy: 0.7707 - val_loss: 23.3443 - val_accuracy: 0.7793\n","Epoch 24/100\n","101/101 [==============================] - 0s 4ms/step - loss: 7.7485 - accuracy: 0.7747 - val_loss: 15.1862 - val_accuracy: 0.7486\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.0318 - accuracy: 0.7929 - val_loss: 11.2101 - val_accuracy: 0.7654\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.8290 - accuracy: 0.7858 - val_loss: 5.2988 - val_accuracy: 0.7179\n","Epoch 27/100\n","101/101 [==============================] - 0s 4ms/step - loss: 6.2007 - accuracy: 0.7744 - val_loss: 9.6309 - val_accuracy: 0.7626\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.3104 - accuracy: 0.7768 - val_loss: 4.7921 - val_accuracy: 0.7486\n","Epoch 29/100\n","101/101 [==============================] - 0s 4ms/step - loss: 10.7621 - accuracy: 0.7889 - val_loss: 8.0490 - val_accuracy: 0.6704\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.3399 - accuracy: 0.7889 - val_loss: 14.1285 - val_accuracy: 0.7626\n","Epoch 31/100\n","101/101 [==============================] - 0s 4ms/step - loss: 8.0447 - accuracy: 0.7861 - val_loss: 18.6587 - val_accuracy: 0.7709\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 6.4742 - accuracy: 0.7803 - val_loss: 4.0002 - val_accuracy: 0.6872\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 8.8564 - accuracy: 0.7911 - val_loss: 9.0769 - val_accuracy: 0.7626\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.8014 - accuracy: 0.7762 - val_loss: 7.6005 - val_accuracy: 0.7346\n","Epoch 35/100\n","101/101 [==============================] - 0s 4ms/step - loss: 11.1480 - accuracy: 0.7821 - val_loss: 5.7821 - val_accuracy: 0.6397\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.9531 - accuracy: 0.7818 - val_loss: 5.4118 - val_accuracy: 0.7598\n","Epoch 37/100\n","101/101 [==============================] - 0s 4ms/step - loss: 3.4862 - accuracy: 0.7827 - val_loss: 15.5684 - val_accuracy: 0.7682\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 4.1432 - accuracy: 0.7837 - val_loss: 3.1807 - val_accuracy: 0.6453\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.7137 - accuracy: 0.7868 - val_loss: 4.7269 - val_accuracy: 0.7291\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 7.6095 - accuracy: 0.7787 - val_loss: 14.7631 - val_accuracy: 0.7430\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.4952 - accuracy: 0.7803 - val_loss: 4.0398 - val_accuracy: 0.7207\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 2.6551 - accuracy: 0.7772 - val_loss: 3.8409 - val_accuracy: 0.7598\n","Epoch 43/100\n","101/101 [==============================] - 0s 4ms/step - loss: 4.5797 - accuracy: 0.7889 - val_loss: 4.8497 - val_accuracy: 0.5475\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 7.7958 - accuracy: 0.8019 - val_loss: 5.3235 - val_accuracy: 0.7737\n","Epoch 45/100\n","101/101 [==============================] - 0s 4ms/step - loss: 2.8018 - accuracy: 0.7855 - val_loss: 13.0826 - val_accuracy: 0.7598\n","Epoch 46/100\n","101/101 [==============================] - 0s 4ms/step - loss: 7.4203 - accuracy: 0.7809 - val_loss: 10.5797 - val_accuracy: 0.7263\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 3.2508 - accuracy: 0.8035 - val_loss: 9.4322 - val_accuracy: 0.7877\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 5.2355 - accuracy: 0.8028 - val_loss: 11.9873 - val_accuracy: 0.7821\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.80      0.84       266\n","           1       0.56      0.74      0.64        92\n","\n","    accuracy                           0.78       358\n","   macro avg       0.73      0.77      0.74       358\n","weighted avg       0.81      0.78      0.79       358\n","\n","Accuracy: 0.7821229050279329\n","[[212  54]\n"," [ 24  68]]\n","Precision: 0.5574\n","Recall: 0.7391\n","F1 Score: 0.6355\n","INFO:tensorflow:Assets written to: ram://eaac0feb-1f6d-47ed-b04a-ca7502207a12/assets\n","model 9 saved\n","Average Validation Accuracy: 0.7932540732325982\n"]}]},{"cell_type":"code","source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/UNB/Binary/Models/HTML/NN/model_0.h5'\n","\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","def predict_prob(number):\n","  return [number[0],1-number[0]]\n","\n","y_prob = np.array(list(map(predict_prob, loaded_model.predict(x_test))))\n","y_prob \n","\n","# y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['nn_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['nn_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545},"id":"dolEygpVsl_4","executionInfo":{"status":"ok","timestamp":1656486680541,"user_tz":-330,"elapsed":21,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"f2b11d77-878f-4663-c34c-e6edef0355da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.00000000e+000 4.63278408e-021]\n"," [1.00000000e+000 1.83409020e-139]\n"," [2.77758362e-001 7.22241638e-001]\n"," ...\n"," [1.21342538e-001 8.78657462e-001]\n"," [9.99999994e-001 5.69171352e-009]\n"," [1.00000000e+000 2.72645734e-139]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  nn_prediction_non  \\\n","0          0            1.000000          4.632784e-21           1.000000   \n","1          0            1.000000         1.834090e-139           1.000000   \n","2          0            0.277758          7.222416e-01           0.277758   \n","3          1            0.303680          6.963204e-01           0.303680   \n","4          0            1.000000          2.524615e-08           1.000000   \n","...      ...                 ...                   ...                ...   \n","2933       1            0.000000          1.000000e+00           0.000000   \n","2934       0            0.168642          8.313583e-01           0.168642   \n","2935       1            0.121343          8.786575e-01           0.121343   \n","2936       1            1.000000          5.691714e-09           1.000000   \n","2937       0            1.000000         2.726457e-139           1.000000   \n","\n","      nn_prediction_phish  \n","0            4.632784e-21  \n","1           1.834090e-139  \n","2            7.222416e-01  \n","3            6.963204e-01  \n","4            2.524615e-08  \n","...                   ...  \n","2933         1.000000e+00  \n","2934         8.313583e-01  \n","2935         8.786575e-01  \n","2936         5.691714e-09  \n","2937        2.726457e-139  \n","\n","[2938 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-5bf99c44-aa6e-4d87-8ecb-6b2cb6a9e097\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>4.632784e-21</td>\n","      <td>1.000000</td>\n","      <td>4.632784e-21</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>1.834090e-139</td>\n","      <td>1.000000</td>\n","      <td>1.834090e-139</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0.277758</td>\n","      <td>7.222416e-01</td>\n","      <td>0.277758</td>\n","      <td>7.222416e-01</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0.303680</td>\n","      <td>6.963204e-01</td>\n","      <td>0.303680</td>\n","      <td>6.963204e-01</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>2.524615e-08</td>\n","      <td>1.000000</td>\n","      <td>2.524615e-08</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2933</th>\n","      <td>1</td>\n","      <td>0.000000</td>\n","      <td>1.000000e+00</td>\n","      <td>0.000000</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>2934</th>\n","      <td>0</td>\n","      <td>0.168642</td>\n","      <td>8.313583e-01</td>\n","      <td>0.168642</td>\n","      <td>8.313583e-01</td>\n","    </tr>\n","    <tr>\n","      <th>2935</th>\n","      <td>1</td>\n","      <td>0.121343</td>\n","      <td>8.786575e-01</td>\n","      <td>0.121343</td>\n","      <td>8.786575e-01</td>\n","    </tr>\n","    <tr>\n","      <th>2936</th>\n","      <td>1</td>\n","      <td>1.000000</td>\n","      <td>5.691714e-09</td>\n","      <td>1.000000</td>\n","      <td>5.691714e-09</td>\n","    </tr>\n","    <tr>\n","      <th>2937</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>2.726457e-139</td>\n","      <td>1.000000</td>\n","      <td>2.726457e-139</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2938 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bf99c44-aa6e-4d87-8ecb-6b2cb6a9e097')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5bf99c44-aa6e-4d87-8ecb-6b2cb6a9e097 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5bf99c44-aa6e-4d87-8ecb-6b2cb6a9e097');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["**Neural Network 2**"],"metadata":{"id":"fMdqVtYLwwy4"}},{"cell_type":"code","source":["\n","import keras\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","def model_a(x_train, x_val, y_train, y_val, opt, n, early_stopping_monitor):\n","\n","  n_cols = x_train.shape[1]\n","\n","  #create model\n","  model_2 = Sequential()\n","  model_2.add(Dense(30, activation='sigmoid', input_shape=(n_cols,)))\n","  model_2.add(Dense(25, activation='sigmoid'))\n","  model_2.add(Dense(20, activation='sigmoid'))\n","  model_2.add(Dense(15, activation='sigmoid'))\n","  model_2.add(Dense(10, activation='sigmoid'))\n","  model_2.add(Dense(1, activation = 'sigmoid'))\n","\n","  #compile model using mse as a measure of model performance\n","  model_2.compile(optimizer='adam', loss='mean_squared_error')\n","\n","\n","\n","  history = model_2.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping_monitor])\n","\n","\n","  # plt.plot(history.history['loss'])\n","  # plt.plot(history.history['val_loss'])\n","  # plt.title('model loss')\n","  # plt.ylabel('Loss')\n","  # plt.xlabel('Epoch')\n","  # plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n","  # plt.show()\n","\n","\n","  print('Validation Accuracy: ')\n","  # Predicting the Test set results\n","  y_pred = model_2.predict(x_val)\n","  y_pred = (y_pred > 0.5)\n","\n","\n","  print(classification_report(y_val, y_pred))\n","\n","  # Model Accuracy, how often is the classifier correct?\n","  print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","\n","  # Creating the Confusion Matrix\n","  cm = confusion_matrix(y_val, y_pred)\n","  print(cm)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred))\n","\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/UNB/Binary/Models/HTML/NN_2/model_'+str(n)+'.h5'\n","  pickle.dump(model_2, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","\n","  return metrics.accuracy_score(y_val, y_pred)\n","\n"],"metadata":{"id":"L8ZhB8W9tVQS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_a(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n, early_stopping_monitor)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osCV0Uo5wqac","executionInfo":{"status":"ok","timestamp":1656486875758,"user_tz":-330,"elapsed":193354,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"61ee97fc-0845-4049-9b47-3738b527001d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.2033 - val_loss: 0.1847\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1811 - val_loss: 0.1828\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1795 - val_loss: 0.1807\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1751 - val_loss: 0.1723\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1613 - val_loss: 0.1564\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1486 - val_loss: 0.1486\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1432 - val_loss: 0.1431\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1416 - val_loss: 0.1415\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1400 - val_loss: 0.1418\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1384 - val_loss: 0.1400\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1380 - val_loss: 0.1397\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1392 - val_loss: 0.1419\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1373 - val_loss: 0.1371\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1376 - val_loss: 0.1374\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1387 - val_loss: 0.1399\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1383 - val_loss: 0.1421\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1388 - val_loss: 0.1417\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1388 - val_loss: 0.1380\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1376 - val_loss: 0.1381\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1380 - val_loss: 0.1376\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1371 - val_loss: 0.1398\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1380 - val_loss: 0.1372\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1370 - val_loss: 0.1358\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1344 - val_loss: 0.1325\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1354 - val_loss: 0.1334\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1335 - val_loss: 0.1306\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1305 - val_loss: 0.1346\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1276 - val_loss: 0.1230\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1231 - val_loss: 0.1163\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1228 - val_loss: 0.1185\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1214 - val_loss: 0.1128\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1214 - val_loss: 0.1195\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1227 - val_loss: 0.1290\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1218 - val_loss: 0.1225\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1204 - val_loss: 0.1162\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1168 - val_loss: 0.1155\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1160 - val_loss: 0.1114\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1148 - val_loss: 0.1145\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1147 - val_loss: 0.1165\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1141 - val_loss: 0.1132\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1133 - val_loss: 0.1122\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1140 - val_loss: 0.1101\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1136 - val_loss: 0.1093\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1120 - val_loss: 0.1116\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1114 - val_loss: 0.1096\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1116 - val_loss: 0.1080\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1118 - val_loss: 0.1102\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1125 - val_loss: 0.1084\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1107 - val_loss: 0.1082\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1097 - val_loss: 0.1099\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1105 - val_loss: 0.1144\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1126 - val_loss: 0.1107\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1106 - val_loss: 0.1108\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1096 - val_loss: 0.1079\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1082 - val_loss: 0.1120\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1092 - val_loss: 0.1065\n","Epoch 57/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1100 - val_loss: 0.1054\n","Epoch 58/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1100 - val_loss: 0.1073\n","Epoch 59/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1104 - val_loss: 0.1133\n","Epoch 60/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1105 - val_loss: 0.1082\n","Epoch 61/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1098 - val_loss: 0.1082\n","Epoch 62/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1102 - val_loss: 0.1071\n","Epoch 63/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1101 - val_loss: 0.1056\n","Epoch 64/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1099 - val_loss: 0.1046\n","Epoch 65/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1090 - val_loss: 0.1078\n","Epoch 66/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1104 - val_loss: 0.1057\n","Epoch 67/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1090 - val_loss: 0.1069\n","Epoch 68/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1086 - val_loss: 0.1039\n","Epoch 69/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1084 - val_loss: 0.1081\n","Epoch 70/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1081 - val_loss: 0.1073\n","Epoch 71/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1090 - val_loss: 0.1073\n","Epoch 72/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1077 - val_loss: 0.1032\n","Epoch 73/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1067 - val_loss: 0.1056\n","Epoch 74/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1079 - val_loss: 0.1039\n","Epoch 75/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1168 - val_loss: 0.1110\n","Epoch 76/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1091 - val_loss: 0.1067\n","Epoch 77/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1078 - val_loss: 0.1058\n","Epoch 78/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1071 - val_loss: 0.1069\n","Epoch 79/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1073 - val_loss: 0.1163\n","Epoch 80/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1067 - val_loss: 0.1081\n","Epoch 81/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1087 - val_loss: 0.1079\n","Epoch 82/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1084 - val_loss: 0.1057\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.97      0.92       272\n","           1       0.87      0.55      0.68        87\n","\n","    accuracy                           0.87       359\n","   macro avg       0.87      0.76      0.80       359\n","weighted avg       0.87      0.87      0.86       359\n","\n","Accuracy: 0.871866295264624\n","[[265   7]\n"," [ 39  48]]\n","Precision: 0.8727\n","Recall: 0.5517\n","F1 Score: 0.6761\n","INFO:tensorflow:Assets written to: ram://7ca47d2f-6e2c-43ce-bead-988bc42dec0b/assets\n","model 0 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.1838 - val_loss: 0.1605\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1823 - val_loss: 0.1581\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1730 - val_loss: 0.1492\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1557 - val_loss: 0.1418\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1471 - val_loss: 0.1364\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1463 - val_loss: 0.1375\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1425 - val_loss: 0.1368\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1400 - val_loss: 0.1307\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1396 - val_loss: 0.1289\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1389 - val_loss: 0.1267\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1348 - val_loss: 0.1270\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1343 - val_loss: 0.1310\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1315 - val_loss: 0.1268\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1267 - val_loss: 0.1234\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1235 - val_loss: 0.1172\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1230 - val_loss: 0.1163\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1219 - val_loss: 0.1182\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1191 - val_loss: 0.1162\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1208 - val_loss: 0.1137\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1185 - val_loss: 0.1107\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.1093\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1171 - val_loss: 0.1146\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1158 - val_loss: 0.1188\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1201 - val_loss: 0.1126\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1238 - val_loss: 0.1129\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1197 - val_loss: 0.1093\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1201 - val_loss: 0.1179\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1258 - val_loss: 0.1121\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1266 - val_loss: 0.1290\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1215 - val_loss: 0.1135\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1140 - val_loss: 0.1128\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1124 - val_loss: 0.1108\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1144 - val_loss: 0.1163\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1224 - val_loss: 0.1171\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1166 - val_loss: 0.1086\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1166 - val_loss: 0.1106\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1144 - val_loss: 0.1106\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1173 - val_loss: 0.1088\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1140 - val_loss: 0.1099\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1124 - val_loss: 0.1115\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1126 - val_loss: 0.1116\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1122 - val_loss: 0.1117\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1110 - val_loss: 0.1154\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.1098\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1202 - val_loss: 0.1085\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1212 - val_loss: 0.1173\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1172 - val_loss: 0.1175\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.1308\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1259 - val_loss: 0.1144\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1198 - val_loss: 0.1144\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1172 - val_loss: 0.1198\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1138 - val_loss: 0.1105\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1135 - val_loss: 0.1150\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1126 - val_loss: 0.1084\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1139 - val_loss: 0.1117\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1123 - val_loss: 0.1173\n","Epoch 57/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1102 - val_loss: 0.1140\n","Epoch 58/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1124 - val_loss: 0.1202\n","Epoch 59/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1135 - val_loss: 0.1150\n","Epoch 60/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1148 - val_loss: 0.1223\n","Epoch 61/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1136 - val_loss: 0.1099\n","Epoch 62/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1116 - val_loss: 0.1147\n","Epoch 63/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1098 - val_loss: 0.1118\n","Epoch 64/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1095 - val_loss: 0.1141\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.96      0.92       288\n","           1       0.73      0.46      0.57        71\n","\n","    accuracy                           0.86       359\n","   macro avg       0.81      0.71      0.74       359\n","weighted avg       0.85      0.86      0.85       359\n","\n","Accuracy: 0.8607242339832869\n","[[276  12]\n"," [ 38  33]]\n","Precision: 0.7333\n","Recall: 0.4648\n","F1 Score: 0.5690\n","INFO:tensorflow:Assets written to: ram://8e3b2ffa-210d-437b-b85a-fa2d8901cdd0/assets\n","model 1 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.1826 - val_loss: 0.1768\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1817 - val_loss: 0.1754\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1792 - val_loss: 0.1680\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1672 - val_loss: 0.1515\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1548 - val_loss: 0.1405\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1465 - val_loss: 0.1371\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1443 - val_loss: 0.1393\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1434 - val_loss: 0.1414\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1425 - val_loss: 0.1390\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1420 - val_loss: 0.1351\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1408 - val_loss: 0.1361\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1387 - val_loss: 0.1361\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1376 - val_loss: 0.1330\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1394 - val_loss: 0.1322\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1404 - val_loss: 0.1311\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1408 - val_loss: 0.1287\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1364 - val_loss: 0.1332\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1363 - val_loss: 0.1345\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1326 - val_loss: 0.1306\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1317 - val_loss: 0.1363\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1298 - val_loss: 0.1289\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1256 - val_loss: 0.1299\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1237 - val_loss: 0.1294\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1248 - val_loss: 0.1296\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1232 - val_loss: 0.1287\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1189 - val_loss: 0.1257\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1187 - val_loss: 0.1324\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1202 - val_loss: 0.1333\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1185 - val_loss: 0.1343\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1205 - val_loss: 0.1326\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1172 - val_loss: 0.1304\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1149 - val_loss: 0.1371\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1155 - val_loss: 0.1352\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1158 - val_loss: 0.1328\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1145 - val_loss: 0.1269\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1115 - val_loss: 0.1273\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.94      0.90       277\n","           1       0.72      0.50      0.59        82\n","\n","    accuracy                           0.84       359\n","   macro avg       0.79      0.72      0.75       359\n","weighted avg       0.83      0.84      0.83       359\n","\n","Accuracy: 0.841225626740947\n","[[261  16]\n"," [ 41  41]]\n","Precision: 0.7193\n","Recall: 0.5000\n","F1 Score: 0.5899\n","INFO:tensorflow:Assets written to: ram://1151a5c2-4a09-437e-8289-fe97bc37c416/assets\n","model 2 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.1853 - val_loss: 0.1628\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1814 - val_loss: 0.1592\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1728 - val_loss: 0.1484\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1582 - val_loss: 0.1379\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1490 - val_loss: 0.1312\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1446 - val_loss: 0.1298\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1420 - val_loss: 0.1295\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1406 - val_loss: 0.1300\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1398 - val_loss: 0.1275\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1387 - val_loss: 0.1277\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1385 - val_loss: 0.1266\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1379 - val_loss: 0.1277\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1375 - val_loss: 0.1278\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1367 - val_loss: 0.1272\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1353 - val_loss: 0.1259\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1338 - val_loss: 0.1240\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1282 - val_loss: 0.1201\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1254 - val_loss: 0.1199\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1245 - val_loss: 0.1195\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1225 - val_loss: 0.1199\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1231 - val_loss: 0.1204\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1255 - val_loss: 0.1176\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1222 - val_loss: 0.1147\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1264 - val_loss: 0.1188\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1261 - val_loss: 0.1156\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1297 - val_loss: 0.1180\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1294 - val_loss: 0.1168\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1281 - val_loss: 0.1190\n","Epoch 29/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1282 - val_loss: 0.1149\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1262 - val_loss: 0.1128\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1272 - val_loss: 0.1122\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1296 - val_loss: 0.1133\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1237 - val_loss: 0.1162\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1219 - val_loss: 0.1188\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1239 - val_loss: 0.1124\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1249 - val_loss: 0.1078\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1232 - val_loss: 0.1103\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1210 - val_loss: 0.1080\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1206 - val_loss: 0.1084\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1228 - val_loss: 0.1072\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1212 - val_loss: 0.1136\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1215 - val_loss: 0.1192\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1215 - val_loss: 0.1114\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1163 - val_loss: 0.1070\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1182 - val_loss: 0.1050\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1171 - val_loss: 0.1060\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1181 - val_loss: 0.1082\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1189 - val_loss: 0.1065\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1185 - val_loss: 0.1071\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1209 - val_loss: 0.1117\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1204 - val_loss: 0.1091\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1187 - val_loss: 0.1069\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1212 - val_loss: 0.1103\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1228 - val_loss: 0.1153\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1211 - val_loss: 0.1120\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.97      0.92       286\n","           1       0.80      0.48      0.60        73\n","\n","    accuracy                           0.87       359\n","   macro avg       0.84      0.72      0.76       359\n","weighted avg       0.86      0.87      0.86       359\n","\n","Accuracy: 0.8690807799442897\n","[[277   9]\n"," [ 38  35]]\n","Precision: 0.7955\n","Recall: 0.4795\n","F1 Score: 0.5983\n","INFO:tensorflow:Assets written to: ram://6444d750-8fc3-421c-a66c-97273bc0da27/assets\n","model 3 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.1821 - val_loss: 0.1775\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1800 - val_loss: 0.1738\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1702 - val_loss: 0.1616\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1545 - val_loss: 0.1557\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1487 - val_loss: 0.1549\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1502 - val_loss: 0.1516\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1474 - val_loss: 0.1530\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1439 - val_loss: 0.1488\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1438 - val_loss: 0.1444\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1437 - val_loss: 0.1465\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1426 - val_loss: 0.1424\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1381 - val_loss: 0.1402\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1389 - val_loss: 0.1390\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1422 - val_loss: 0.1404\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1395 - val_loss: 0.1343\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1350 - val_loss: 0.1279\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1321 - val_loss: 0.1271\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1310 - val_loss: 0.1278\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1271 - val_loss: 0.1198\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1249 - val_loss: 0.1255\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1290 - val_loss: 0.1243\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1290 - val_loss: 0.1262\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1285 - val_loss: 0.1219\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1291 - val_loss: 0.1277\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1288 - val_loss: 0.1246\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1279 - val_loss: 0.1232\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1275 - val_loss: 0.1279\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1266 - val_loss: 0.1241\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1264 - val_loss: 0.1263\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.92      0.89       276\n","           1       0.68      0.53      0.59        83\n","\n","    accuracy                           0.83       359\n","   macro avg       0.77      0.73      0.74       359\n","weighted avg       0.82      0.83      0.83       359\n","\n","Accuracy: 0.8328690807799443\n","[[255  21]\n"," [ 39  44]]\n","Precision: 0.6769\n","Recall: 0.5301\n","F1 Score: 0.5946\n","INFO:tensorflow:Assets written to: ram://8101f485-384c-4e17-9f3f-aab5c20160ed/assets\n","model 4 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.1863 - val_loss: 0.1893\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1799 - val_loss: 0.1876\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1763 - val_loss: 0.1803\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1620 - val_loss: 0.1597\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1481 - val_loss: 0.1496\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1439 - val_loss: 0.1487\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1420 - val_loss: 0.1493\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1416 - val_loss: 0.1452\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1391 - val_loss: 0.1423\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1371 - val_loss: 0.1414\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1388 - val_loss: 0.1383\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1364 - val_loss: 0.1384\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1350 - val_loss: 0.1348\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1334 - val_loss: 0.1355\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1305 - val_loss: 0.1315\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1292 - val_loss: 0.1342\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1287 - val_loss: 0.1291\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1287 - val_loss: 0.1296\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1233 - val_loss: 0.1242\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1226 - val_loss: 0.1203\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1183 - val_loss: 0.1133\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.1134\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.1131\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1220 - val_loss: 0.1184\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1230 - val_loss: 0.1161\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1169 - val_loss: 0.1121\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1151 - val_loss: 0.1095\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1144 - val_loss: 0.1102\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1142 - val_loss: 0.1095\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1131 - val_loss: 0.1101\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1156 - val_loss: 0.1106\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1166 - val_loss: 0.1114\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1165 - val_loss: 0.1128\n","Epoch 34/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1165 - val_loss: 0.1135\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1169 - val_loss: 0.1135\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1139 - val_loss: 0.1122\n","Epoch 37/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1122 - val_loss: 0.1095\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.93      0.91       268\n","           1       0.77      0.67      0.72        91\n","\n","    accuracy                           0.87       359\n","   macro avg       0.83      0.80      0.82       359\n","weighted avg       0.86      0.87      0.86       359\n","\n","Accuracy: 0.8662952646239555\n","[[250  18]\n"," [ 30  61]]\n","Precision: 0.7722\n","Recall: 0.6703\n","F1 Score: 0.7176\n","INFO:tensorflow:Assets written to: ram://d7549cae-d556-419a-b824-770a663c4a5c/assets\n","model 5 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.1801 - val_loss: 0.1983\n","Epoch 2/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1785 - val_loss: 0.1946\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1733 - val_loss: 0.1804\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1580 - val_loss: 0.1567\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1467 - val_loss: 0.1481\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1436 - val_loss: 0.1450\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1440 - val_loss: 0.1485\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1437 - val_loss: 0.1430\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1431 - val_loss: 0.1451\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1435 - val_loss: 0.1418\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1391 - val_loss: 0.1383\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1383 - val_loss: 0.1387\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1379 - val_loss: 0.1347\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1379 - val_loss: 0.1363\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1380 - val_loss: 0.1374\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1366 - val_loss: 0.1394\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1347 - val_loss: 0.1419\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1305 - val_loss: 0.1313\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1277 - val_loss: 0.1314\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1261 - val_loss: 0.1271\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1245 - val_loss: 0.1246\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1237 - val_loss: 0.1220\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1225 - val_loss: 0.1226\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1220 - val_loss: 0.1227\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1195 - val_loss: 0.1289\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1283 - val_loss: 0.1327\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1233 - val_loss: 0.1212\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1231 - val_loss: 0.1354\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1294 - val_loss: 0.1263\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1262 - val_loss: 0.1338\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1262 - val_loss: 0.1344\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1236 - val_loss: 0.1269\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1215 - val_loss: 0.1173\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1190 - val_loss: 0.1200\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1186 - val_loss: 0.1204\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1191 - val_loss: 0.1223\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1169 - val_loss: 0.1179\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.1168\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1147 - val_loss: 0.1186\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1123 - val_loss: 0.1225\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1097 - val_loss: 0.1195\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1120 - val_loss: 0.1166\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1071 - val_loss: 0.1182\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1109 - val_loss: 0.1146\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1114 - val_loss: 0.1218\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1109 - val_loss: 0.1129\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1140 - val_loss: 0.1181\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1167 - val_loss: 0.1199\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1229 - val_loss: 0.1152\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1116 - val_loss: 0.1048\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1069 - val_loss: 0.1170\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1183 - val_loss: 0.1151\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1103 - val_loss: 0.1149\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1104 - val_loss: 0.1150\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1106 - val_loss: 0.1174\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1091 - val_loss: 0.1152\n","Epoch 57/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1086 - val_loss: 0.1130\n","Epoch 58/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1075 - val_loss: 0.1131\n","Epoch 59/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1090 - val_loss: 0.1152\n","Epoch 60/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1085 - val_loss: 0.1123\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.94      0.89       262\n","           1       0.77      0.58      0.66        97\n","\n","    accuracy                           0.84       359\n","   macro avg       0.81      0.76      0.78       359\n","weighted avg       0.83      0.84      0.83       359\n","\n","Accuracy: 0.8384401114206128\n","[[245  17]\n"," [ 41  56]]\n","Precision: 0.7671\n","Recall: 0.5773\n","F1 Score: 0.6588\n","INFO:tensorflow:Assets written to: ram://78252b55-e3c0-45cb-9bc8-713ed04ab71b/assets\n","model 6 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.2210 - val_loss: 0.1932\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1809 - val_loss: 0.1916\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1795 - val_loss: 0.1906\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1771 - val_loss: 0.1843\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1694 - val_loss: 0.1702\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1566 - val_loss: 0.1545\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1466 - val_loss: 0.1457\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1441 - val_loss: 0.1448\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1423 - val_loss: 0.1415\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1416 - val_loss: 0.1408\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1408 - val_loss: 0.1394\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1400 - val_loss: 0.1362\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1403 - val_loss: 0.1391\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1395 - val_loss: 0.1358\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1397 - val_loss: 0.1354\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1375 - val_loss: 0.1371\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1419 - val_loss: 0.1388\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1412 - val_loss: 0.1374\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1403 - val_loss: 0.1370\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1398 - val_loss: 0.1357\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1384 - val_loss: 0.1365\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1370 - val_loss: 0.1364\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1367 - val_loss: 0.1340\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1333 - val_loss: 0.1310\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1287 - val_loss: 0.1252\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1245 - val_loss: 0.1232\n","Epoch 27/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1231 - val_loss: 0.1196\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1224 - val_loss: 0.1302\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1227 - val_loss: 0.1152\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1200 - val_loss: 0.1129\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.1200\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1225 - val_loss: 0.1132\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1186 - val_loss: 0.1156\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1170 - val_loss: 0.1099\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1153 - val_loss: 0.1094\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1138 - val_loss: 0.1078\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1111 - val_loss: 0.1078\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1113 - val_loss: 0.1029\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1119 - val_loss: 0.1050\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1142 - val_loss: 0.1035\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1118 - val_loss: 0.1025\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1134 - val_loss: 0.1058\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1153 - val_loss: 0.1091\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1160 - val_loss: 0.1087\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1114 - val_loss: 0.1069\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1131 - val_loss: 0.1092\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1181 - val_loss: 0.1127\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1156 - val_loss: 0.1085\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1117 - val_loss: 0.1082\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1109 - val_loss: 0.1063\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1106 - val_loss: 0.1090\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.98      0.92       266\n","           1       0.93      0.55      0.69        93\n","\n","    accuracy                           0.87       359\n","   macro avg       0.89      0.77      0.80       359\n","weighted avg       0.88      0.87      0.86       359\n","\n","Accuracy: 0.871866295264624\n","[[262   4]\n"," [ 42  51]]\n","Precision: 0.9273\n","Recall: 0.5484\n","F1 Score: 0.6892\n","INFO:tensorflow:Assets written to: ram://8232636f-d5fd-4639-ac49-69c56f5c47d7/assets\n","model 7 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.2308 - val_loss: 0.1895\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1838 - val_loss: 0.1823\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1811 - val_loss: 0.1814\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1796 - val_loss: 0.1792\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1759 - val_loss: 0.1746\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1679 - val_loss: 0.1628\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1549 - val_loss: 0.1540\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1471 - val_loss: 0.1518\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1454 - val_loss: 0.1501\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1470 - val_loss: 0.1546\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1450 - val_loss: 0.1557\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1458 - val_loss: 0.1503\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1401 - val_loss: 0.1404\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1333 - val_loss: 0.1378\n","Epoch 15/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1312 - val_loss: 0.1376\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1274 - val_loss: 0.1327\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1262 - val_loss: 0.1358\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1255 - val_loss: 0.1338\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1228 - val_loss: 0.1272\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1238 - val_loss: 0.1279\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1268 - val_loss: 0.1213\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1265 - val_loss: 0.1404\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1266 - val_loss: 0.1311\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1230 - val_loss: 0.1217\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1195 - val_loss: 0.1197\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1223 - val_loss: 0.1301\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1239 - val_loss: 0.1295\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1220 - val_loss: 0.1227\n","Epoch 29/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1241 - val_loss: 0.1328\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1205 - val_loss: 0.1229\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1206 - val_loss: 0.1274\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1219 - val_loss: 0.1266\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1209 - val_loss: 0.1248\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1197 - val_loss: 0.1242\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1191 - val_loss: 0.1264\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.97      0.90       273\n","           1       0.80      0.37      0.51        86\n","\n","    accuracy                           0.83       359\n","   macro avg       0.82      0.67      0.70       359\n","weighted avg       0.82      0.83      0.80       359\n","\n","Accuracy: 0.8272980501392758\n","[[265   8]\n"," [ 54  32]]\n","Precision: 0.8000\n","Recall: 0.3721\n","F1 Score: 0.5079\n","INFO:tensorflow:Assets written to: ram://213e547b-4c84-43b1-8c96-2806e134b486/assets\n","model 8 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.1820 - val_loss: 0.1907\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1785 - val_loss: 0.1862\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1695 - val_loss: 0.1728\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1566 - val_loss: 0.1613\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1488 - val_loss: 0.1546\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1444 - val_loss: 0.1485\n","Epoch 7/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1405 - val_loss: 0.1484\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1394 - val_loss: 0.1487\n","Epoch 9/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1390 - val_loss: 0.1493\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1380 - val_loss: 0.1442\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1371 - val_loss: 0.1495\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1373 - val_loss: 0.1456\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1335 - val_loss: 0.1425\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1307 - val_loss: 0.1396\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1287 - val_loss: 0.1356\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1251 - val_loss: 0.1326\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1191 - val_loss: 0.1325\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1216 - val_loss: 0.1378\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1281 - val_loss: 0.1456\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1282 - val_loss: 0.1529\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1293 - val_loss: 0.1408\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1263 - val_loss: 0.1467\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1261 - val_loss: 0.1370\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1221 - val_loss: 0.1334\n","Epoch 25/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1162 - val_loss: 0.1269\n","Epoch 26/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1193 - val_loss: 0.1420\n","Epoch 27/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1186 - val_loss: 0.1319\n","Epoch 28/100\n","101/101 [==============================] - 0s 5ms/step - loss: 0.1185 - val_loss: 0.1320\n","Epoch 29/100\n","101/101 [==============================] - 0s 5ms/step - loss: 0.1182 - val_loss: 0.1320\n","Epoch 30/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1199 - val_loss: 0.1377\n","Epoch 31/100\n","101/101 [==============================] - 0s 5ms/step - loss: 0.1203 - val_loss: 0.1371\n","Epoch 32/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1185 - val_loss: 0.1394\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1180 - val_loss: 0.1355\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1151 - val_loss: 0.1364\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 0.1385\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.90      0.88       266\n","           1       0.65      0.55      0.60        92\n","\n","    accuracy                           0.81       358\n","   macro avg       0.75      0.73      0.74       358\n","weighted avg       0.80      0.81      0.80       358\n","\n","Accuracy: 0.8100558659217877\n","[[239  27]\n"," [ 41  51]]\n","Precision: 0.6538\n","Recall: 0.5543\n","F1 Score: 0.6000\n","INFO:tensorflow:Assets written to: ram://16df9683-0cd5-4e54-95a6-d055c01a758d/assets\n","model 9 saved\n","Average Validation Accuracy: 0.8489721604083348\n"]}]},{"cell_type":"code","source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/UNB/Binary/Models/HTML/NN_2/model_0.h5'\n","\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","def predict_prob(number):\n","  return [number[0],1-number[0]]\n","\n","y_prob = np.array(list(map(predict_prob, loaded_model.predict(x_test))))\n","y_prob \n","\n","# y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['nn2_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['nn2_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":609},"id":"JPT9oIQ0wuZf","executionInfo":{"status":"ok","timestamp":1656486989667,"user_tz":-330,"elapsed":1826,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"ffa92404-c22a-4b02-dd42-096904dfbf0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.00000000e+000 4.63278408e-021]\n"," [1.00000000e+000 1.83409020e-139]\n"," [2.77758362e-001 7.22241638e-001]\n"," ...\n"," [1.21342538e-001 8.78657462e-001]\n"," [9.99999994e-001 5.69171352e-009]\n"," [1.00000000e+000 2.72645734e-139]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  nn_prediction_non  \\\n","0          0            1.000000          4.632784e-21           1.000000   \n","1          0            1.000000         1.834090e-139           1.000000   \n","2          0            0.277758          7.222416e-01           0.277758   \n","3          1            0.303680          6.963204e-01           0.303680   \n","4          0            1.000000          2.524615e-08           1.000000   \n","...      ...                 ...                   ...                ...   \n","2933       1            0.000000          1.000000e+00           0.000000   \n","2934       0            0.168642          8.313583e-01           0.168642   \n","2935       1            0.121343          8.786575e-01           0.121343   \n","2936       1            1.000000          5.691714e-09           1.000000   \n","2937       0            1.000000         2.726457e-139           1.000000   \n","\n","      nn_prediction_phish  nn2_prediction_non  nn2_prediction_phish  \n","0            4.632784e-21            1.000000          4.632784e-21  \n","1           1.834090e-139            1.000000         1.834090e-139  \n","2            7.222416e-01            0.277758          7.222416e-01  \n","3            6.963204e-01            0.303680          6.963204e-01  \n","4            2.524615e-08            1.000000          2.524615e-08  \n","...                   ...                 ...                   ...  \n","2933         1.000000e+00            0.000000          1.000000e+00  \n","2934         8.313583e-01            0.168642          8.313583e-01  \n","2935         8.786575e-01            0.121343          8.786575e-01  \n","2936         5.691714e-09            1.000000          5.691714e-09  \n","2937        2.726457e-139            1.000000         2.726457e-139  \n","\n","[2938 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-23b52488-aa71-4a07-97f4-0a12a33bd7c0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","      <th>nn2_prediction_non</th>\n","      <th>nn2_prediction_phish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>4.632784e-21</td>\n","      <td>1.000000</td>\n","      <td>4.632784e-21</td>\n","      <td>1.000000</td>\n","      <td>4.632784e-21</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>1.834090e-139</td>\n","      <td>1.000000</td>\n","      <td>1.834090e-139</td>\n","      <td>1.000000</td>\n","      <td>1.834090e-139</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0.277758</td>\n","      <td>7.222416e-01</td>\n","      <td>0.277758</td>\n","      <td>7.222416e-01</td>\n","      <td>0.277758</td>\n","      <td>7.222416e-01</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0.303680</td>\n","      <td>6.963204e-01</td>\n","      <td>0.303680</td>\n","      <td>6.963204e-01</td>\n","      <td>0.303680</td>\n","      <td>6.963204e-01</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>2.524615e-08</td>\n","      <td>1.000000</td>\n","      <td>2.524615e-08</td>\n","      <td>1.000000</td>\n","      <td>2.524615e-08</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2933</th>\n","      <td>1</td>\n","      <td>0.000000</td>\n","      <td>1.000000e+00</td>\n","      <td>0.000000</td>\n","      <td>1.000000e+00</td>\n","      <td>0.000000</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>2934</th>\n","      <td>0</td>\n","      <td>0.168642</td>\n","      <td>8.313583e-01</td>\n","      <td>0.168642</td>\n","      <td>8.313583e-01</td>\n","      <td>0.168642</td>\n","      <td>8.313583e-01</td>\n","    </tr>\n","    <tr>\n","      <th>2935</th>\n","      <td>1</td>\n","      <td>0.121343</td>\n","      <td>8.786575e-01</td>\n","      <td>0.121343</td>\n","      <td>8.786575e-01</td>\n","      <td>0.121343</td>\n","      <td>8.786575e-01</td>\n","    </tr>\n","    <tr>\n","      <th>2936</th>\n","      <td>1</td>\n","      <td>1.000000</td>\n","      <td>5.691714e-09</td>\n","      <td>1.000000</td>\n","      <td>5.691714e-09</td>\n","      <td>1.000000</td>\n","      <td>5.691714e-09</td>\n","    </tr>\n","    <tr>\n","      <th>2937</th>\n","      <td>0</td>\n","      <td>1.000000</td>\n","      <td>2.726457e-139</td>\n","      <td>1.000000</td>\n","      <td>2.726457e-139</td>\n","      <td>1.000000</td>\n","      <td>2.726457e-139</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2938 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23b52488-aa71-4a07-97f4-0a12a33bd7c0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-23b52488-aa71-4a07-97f4-0a12a33bd7c0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-23b52488-aa71-4a07-97f4-0a12a33bd7c0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["output.shape\n"],"metadata":{"id":"0lDqtfllUmwv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656486992556,"user_tz":-330,"elapsed":7,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"fe9866a4-105f-4e9b-823e-1ea5842f7b99"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2938, 7)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["# Storing the data in CSV file\n","output.to_csv('/content/drive/MyDrive/Phishing/UNB/Binary/Base_classifier_result(HTML cross)(3).csv', index=False)"],"metadata":{"id":"ZsQkUbz6AiTx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"RN_-swX0JdhP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"W9DI0WYaJde9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"49lwyWNz0mSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"_9Vdw_Wx2NEo"},"execution_count":null,"outputs":[]}]}