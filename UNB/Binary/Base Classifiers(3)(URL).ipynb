{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Base Classifiers(3)(URL).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"PH13wfswmyDv"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Aiz0olfdKb4b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656484654804,"user_tz":-330,"elapsed":39639,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"fc6a1121-b0b5-4792-8209-4bb6b8777b13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["urldata = pd.read_csv(\"/content/drive/MyDrive/Phishing/UNB/URL-HTML/preprocessed_url_features(binary).csv\")\n","urldata\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":557},"id":"Dw-EEymHAGNs","outputId":"77a191dc-5cb3-40e9-f429-6e7154435a36","executionInfo":{"status":"ok","timestamp":1656484668288,"user_tz":-330,"elapsed":3358,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Unnamed: 0  Have IP  Have @  URL Length  URL Depth  Redirection  \\\n","0              0        0       0           1          1            0   \n","1              1        0       0           1          1            1   \n","2              2        0       0           1          1            0   \n","3              3        0       0           1          3            0   \n","4              4        0       0           1          3            0   \n","...          ...      ...     ...         ...        ...          ...   \n","6522        9992        0       0           1          5            0   \n","6523        9994        0       0           1          3            0   \n","6524        9995        0       0           1          6            0   \n","6525        9996        0       0           1          5            0   \n","6526        9997        0       0           1          4            0   \n","\n","      https Domain  TinyURL  Prefix/Suffix  Have client  ...  Num Embeds  \\\n","0                0        0              0            0  ...           0   \n","1                0        0              0            0  ...           0   \n","2                1        0              0            0  ...           0   \n","3                0        0              0            0  ...           0   \n","4                0        0              0            0  ...           0   \n","...            ...      ...            ...          ...  ...         ...   \n","6522             0        0              0            0  ...           0   \n","6523             0        0              0            0  ...           0   \n","6524             0        0              0            0  ...           0   \n","6525             0        0              0            0  ...           0   \n","6526             0        0              0            0  ...           0   \n","\n","      Num Images  Num Links  Num Titles  Num Script  Special Characters  \\\n","0             49        691          42       13135                6400   \n","1              4         66           3        2034                 818   \n","2              1        100          27       32987               10451   \n","3              0          0           1           0                  52   \n","4            117        219          23        7944                3468   \n","...          ...        ...         ...         ...                 ...   \n","6522           0          0           1           0                  34   \n","6523           0          0           1           0                  14   \n","6524           0          0           1           0                 249   \n","6525           0          0           1           0                   6   \n","6526           0          0           1           0                 630   \n","\n","      Script To Special Chars Ratio  Script To body Ratio  \\\n","0                          2.052344              0.528869   \n","1                          2.486553              0.676197   \n","2                          3.156349              0.836681   \n","3                          0.000000              0.000000   \n","4                          2.290657              0.524460   \n","...                             ...                   ...   \n","6522                       0.000000              0.000000   \n","6523                       0.000000              0.000000   \n","6524                       0.000000              0.000000   \n","6525                       0.000000              0.000000   \n","6526                       0.000000              0.000000   \n","\n","      Body To Special Char Ratio  Label  \n","0                       0.257690      0  \n","1                       0.271941      0  \n","2                       0.265079      0  \n","3                       0.227074      0  \n","4                       0.228956      0  \n","...                          ...    ...  \n","6522                    0.185792      1  \n","6523                    0.197183      1  \n","6524                    0.315990      1  \n","6525                    0.139535      1  \n","6526                    0.310192      1  \n","\n","[6527 rows x 46 columns]"],"text/html":["\n","  <div id=\"df-1e8c73cf-4e9d-4914-b89f-c6b81727bc7e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>...</th>\n","      <th>Num Embeds</th>\n","      <th>Num Images</th>\n","      <th>Num Links</th>\n","      <th>Num Titles</th>\n","      <th>Num Script</th>\n","      <th>Special Characters</th>\n","      <th>Script To Special Chars Ratio</th>\n","      <th>Script To body Ratio</th>\n","      <th>Body To Special Char Ratio</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>49</td>\n","      <td>691</td>\n","      <td>42</td>\n","      <td>13135</td>\n","      <td>6400</td>\n","      <td>2.052344</td>\n","      <td>0.528869</td>\n","      <td>0.257690</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>66</td>\n","      <td>3</td>\n","      <td>2034</td>\n","      <td>818</td>\n","      <td>2.486553</td>\n","      <td>0.676197</td>\n","      <td>0.271941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>27</td>\n","      <td>32987</td>\n","      <td>10451</td>\n","      <td>3.156349</td>\n","      <td>0.836681</td>\n","      <td>0.265079</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.227074</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>117</td>\n","      <td>219</td>\n","      <td>23</td>\n","      <td>7944</td>\n","      <td>3468</td>\n","      <td>2.290657</td>\n","      <td>0.524460</td>\n","      <td>0.228956</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6522</th>\n","      <td>9992</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>34</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.185792</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6523</th>\n","      <td>9994</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>14</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.197183</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6524</th>\n","      <td>9995</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>249</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.315990</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6525</th>\n","      <td>9996</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.139535</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6526</th>\n","      <td>9997</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>630</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.310192</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6527 rows × 46 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e8c73cf-4e9d-4914-b89f-c6b81727bc7e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1e8c73cf-4e9d-4914-b89f-c6b81727bc7e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1e8c73cf-4e9d-4914-b89f-c6b81727bc7e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["urldata.columns"],"metadata":{"id":"JQ4_qEulWybT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6e638f55-c467-454d-d363-bfdca39ed698","executionInfo":{"status":"ok","timestamp":1656484675265,"user_tz":-330,"elapsed":565,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Unnamed: 0', 'Have IP', 'Have @', 'URL Length', 'URL Depth',\n","       'Redirection', 'https Domain', 'TinyURL', 'Prefix/Suffix',\n","       'Have client', 'Have admin', 'Have login', 'Have server', '.php',\n","       '.html', '.info', '.txt', '.js', '.exe', 'Num of periods', 'Is encoded',\n","       'Num of encoded char', 'Num of parameters', 'Num of digits',\n","       'Num of spec char', 'iFrame', 'Mouse Over', 'Right Click',\n","       'Web Forwards', 'Number of page tokens', 'number of sentences',\n","       'number of html tags', 'number of whitespace', 'url Is Live',\n","       'HTML Length', 'Num Objects', 'Num Embeds', 'Num Images', 'Num Links',\n","       'Num Titles', 'Num Script', 'Special Characters',\n","       'Script To Special Chars Ratio', 'Script To body Ratio',\n","       'Body To Special Char Ratio', 'Label'],\n","      dtype='object')"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["urldata = urldata.drop(['Unnamed: 0', 'iFrame', 'Mouse Over', 'Right Click',\n","       'Web Forwards', 'Number of page tokens', 'number of sentences',\n","       'number of html tags', 'number of whitespace', 'url Is Live',\n","       'HTML Length', 'Num Objects', 'Num Embeds', 'Num Images', 'Num Links',\n","       'Num Titles', 'Num Script', 'Special Characters',\n","       'Script To Special Chars Ratio', 'Script To body Ratio',\n","       'Body To Special Char Ratio'], axis = 1).copy()\n","# urldata = urldata.drop(['Domain'], axis = 1).copy()\n","urldata.shape\n","urldata.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"qwye89TwRTOH","executionInfo":{"status":"ok","timestamp":1656484678626,"user_tz":-330,"elapsed":592,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"d1dea7c9-5d14-450f-b380-378cc83f4b94"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Have IP  Have @  URL Length  URL Depth  Redirection  https Domain  TinyURL  \\\n","0        0       0           1          1            0             0        0   \n","1        0       0           1          1            1             0        0   \n","2        0       0           1          1            0             1        0   \n","3        0       0           1          3            0             0        0   \n","4        0       0           1          3            0             0        0   \n","\n","   Prefix/Suffix  Have client  Have admin  ...  .txt  .js  .exe  \\\n","0              0            0           0  ...     0    0     0   \n","1              0            0           0  ...     0    0     0   \n","2              0            0           0  ...     0    0     0   \n","3              0            0           0  ...     0    0     0   \n","4              0            0           0  ...     0    0     0   \n","\n","   Num of periods  Is encoded  Num of encoded char  Num of parameters  \\\n","0               1           0                    0                 10   \n","1               4           1                    2                  3   \n","2               1           1                    2                  2   \n","3               4           1                    5                  0   \n","4               2           0                    0                  1   \n","\n","   Num of digits  Num of spec char  Label  \n","0              0                25      0  \n","1             22                13      0  \n","2              2                 9      0  \n","3             19                18      0  \n","4             17                 7      0  \n","\n","[5 rows x 25 columns]"],"text/html":["\n","  <div id=\"df-beb10b65-d64d-4040-9a3e-1ed9eb701621\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>Have admin</th>\n","      <th>...</th>\n","      <th>.txt</th>\n","      <th>.js</th>\n","      <th>.exe</th>\n","      <th>Num of periods</th>\n","      <th>Is encoded</th>\n","      <th>Num of encoded char</th>\n","      <th>Num of parameters</th>\n","      <th>Num of digits</th>\n","      <th>Num of spec char</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>25</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>22</td>\n","      <td>13</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>19</td>\n","      <td>18</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>17</td>\n","      <td>7</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 25 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-beb10b65-d64d-4040-9a3e-1ed9eb701621')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-beb10b65-d64d-4040-9a3e-1ed9eb701621 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-beb10b65-d64d-4040-9a3e-1ed9eb701621');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["urldata.info()"],"metadata":{"id":"kKvKkmUNP5Cx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b12a4b12-abd3-4b0c-a729-ecd124128077","executionInfo":{"status":"ok","timestamp":1656484681473,"user_tz":-330,"elapsed":8,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 6527 entries, 0 to 6526\n","Data columns (total 25 columns):\n"," #   Column               Non-Null Count  Dtype\n","---  ------               --------------  -----\n"," 0   Have IP              6527 non-null   int64\n"," 1   Have @               6527 non-null   int64\n"," 2   URL Length           6527 non-null   int64\n"," 3   URL Depth            6527 non-null   int64\n"," 4   Redirection          6527 non-null   int64\n"," 5   https Domain         6527 non-null   int64\n"," 6   TinyURL              6527 non-null   int64\n"," 7   Prefix/Suffix        6527 non-null   int64\n"," 8   Have client          6527 non-null   int64\n"," 9   Have admin           6527 non-null   int64\n"," 10  Have login           6527 non-null   int64\n"," 11  Have server          6527 non-null   int64\n"," 12  .php                 6527 non-null   int64\n"," 13  .html                6527 non-null   int64\n"," 14  .info                6527 non-null   int64\n"," 15  .txt                 6527 non-null   int64\n"," 16  .js                  6527 non-null   int64\n"," 17  .exe                 6527 non-null   int64\n"," 18  Num of periods       6527 non-null   int64\n"," 19  Is encoded           6527 non-null   int64\n"," 20  Num of encoded char  6527 non-null   int64\n"," 21  Num of parameters    6527 non-null   int64\n"," 22  Num of digits        6527 non-null   int64\n"," 23  Num of spec char     6527 non-null   int64\n"," 24  Label                6527 non-null   int64\n","dtypes: int64(25)\n","memory usage: 1.2 MB\n"]}]},{"cell_type":"code","source":["# Class Distribution of Labels\n","urldata.groupby('Label').size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvS3OQHTSHDt","executionInfo":{"status":"ok","timestamp":1656484682291,"user_tz":-330,"elapsed":5,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"b76e3488-44ca-4c3d-b5c5-8dc815e2adf8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Label\n","0    4954\n","1    1573\n","dtype: int64"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Analysis of Postives and Negatives in the Dataset\n","pos,neg = urldata['Label'].value_counts()\n","total = neg + pos\n","print ('Total of Samples: %s'% total)\n","print('Non-Phishing: {} ({:.2f}% of total)'.format(pos, 100 * pos / total))\n","print('Phishing: {} ({:.2f}% of total)'.format(neg, 100 * neg / total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kHCjZCSBSKi3","executionInfo":{"status":"ok","timestamp":1656484684976,"user_tz":-330,"elapsed":6,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"f9d066a9-d364-4de3-fc8a-e9f5ff585c1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total of Samples: 6527\n","Non-Phishing: 4954 (75.90% of total)\n","Phishing: 1573 (24.10% of total)\n"]}]},{"cell_type":"code","source":["\n","import numpy as np\n"],"metadata":{"id":"eLm1720QSaAv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["urldata.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"id":"WX-8Xbm3cfFf","outputId":"454eaa8e-f056-464d-f308-6ffb2c184d50","executionInfo":{"status":"ok","timestamp":1656484692459,"user_tz":-330,"elapsed":11,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Have IP       Have @  URL Length    URL Depth  Redirection  \\\n","count   6527.0  6527.000000      6527.0  6527.000000  6527.000000   \n","mean       0.0     0.004137         1.0     4.397579     0.050406   \n","std        0.0     0.064189         0.0     2.997529     0.218798   \n","min        0.0     0.000000         1.0     0.000000     0.000000   \n","25%        0.0     0.000000         1.0     2.000000     0.000000   \n","50%        0.0     0.000000         1.0     4.000000     0.000000   \n","75%        0.0     0.000000         1.0     6.000000     0.000000   \n","max        0.0     1.000000         1.0    18.000000     1.000000   \n","\n","       https Domain      TinyURL  Prefix/Suffix  Have client   Have admin  \\\n","count   6527.000000  6527.000000    6527.000000  6527.000000  6527.000000   \n","mean       0.060518     0.056841       0.042746     0.001379     0.019304   \n","std        0.238462     0.231556       0.202298     0.037111     0.137603   \n","min        0.000000     0.000000       0.000000     0.000000     0.000000   \n","25%        0.000000     0.000000       0.000000     0.000000     0.000000   \n","50%        0.000000     0.000000       0.000000     0.000000     0.000000   \n","75%        0.000000     0.000000       0.000000     0.000000     0.000000   \n","max        1.000000     1.000000       1.000000     1.000000     1.000000   \n","\n","       ...    .txt          .js         .exe  Num of periods   Is encoded  \\\n","count  ...  6527.0  6527.000000  6527.000000     6527.000000  6527.000000   \n","mean   ...     0.0     0.014249     0.002758        2.306573     0.151831   \n","std    ...     0.0     0.118523     0.052446        2.248695     0.358884   \n","min    ...     0.0     0.000000     0.000000        1.000000     0.000000   \n","25%    ...     0.0     0.000000     0.000000        1.000000     0.000000   \n","50%    ...     0.0     0.000000     0.000000        1.000000     0.000000   \n","75%    ...     0.0     0.000000     0.000000        2.000000     0.000000   \n","max    ...     0.0     1.000000     1.000000       21.000000     1.000000   \n","\n","       Num of encoded char  Num of parameters  Num of digits  \\\n","count          6527.000000        6527.000000    6527.000000   \n","mean              3.660028           0.640417      16.024207   \n","std              13.945412           1.608334      19.279340   \n","min               0.000000           0.000000       0.000000   \n","25%               0.000000           0.000000       5.000000   \n","50%               0.000000           0.000000      10.000000   \n","75%               0.000000           1.000000      21.000000   \n","max             201.000000          14.000000     259.000000   \n","\n","       Num of spec char        Label  \n","count       6527.000000  6527.000000  \n","mean           9.387008     0.240999  \n","std           14.849941     0.427722  \n","min            0.000000     0.000000  \n","25%            1.000000     0.000000  \n","50%            6.000000     0.000000  \n","75%           11.000000     0.000000  \n","max          201.000000     1.000000  \n","\n","[8 rows x 25 columns]"],"text/html":["\n","  <div id=\"df-21a3bc89-a99f-44e4-b2be-17d9406b807f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>Have admin</th>\n","      <th>...</th>\n","      <th>.txt</th>\n","      <th>.js</th>\n","      <th>.exe</th>\n","      <th>Num of periods</th>\n","      <th>Is encoded</th>\n","      <th>Num of encoded char</th>\n","      <th>Num of parameters</th>\n","      <th>Num of digits</th>\n","      <th>Num of spec char</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>6527.0</td>\n","      <td>6527.000000</td>\n","      <td>6527.0</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>...</td>\n","      <td>6527.0</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","      <td>6527.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.0</td>\n","      <td>0.004137</td>\n","      <td>1.0</td>\n","      <td>4.397579</td>\n","      <td>0.050406</td>\n","      <td>0.060518</td>\n","      <td>0.056841</td>\n","      <td>0.042746</td>\n","      <td>0.001379</td>\n","      <td>0.019304</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.014249</td>\n","      <td>0.002758</td>\n","      <td>2.306573</td>\n","      <td>0.151831</td>\n","      <td>3.660028</td>\n","      <td>0.640417</td>\n","      <td>16.024207</td>\n","      <td>9.387008</td>\n","      <td>0.240999</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.0</td>\n","      <td>0.064189</td>\n","      <td>0.0</td>\n","      <td>2.997529</td>\n","      <td>0.218798</td>\n","      <td>0.238462</td>\n","      <td>0.231556</td>\n","      <td>0.202298</td>\n","      <td>0.037111</td>\n","      <td>0.137603</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.118523</td>\n","      <td>0.052446</td>\n","      <td>2.248695</td>\n","      <td>0.358884</td>\n","      <td>13.945412</td>\n","      <td>1.608334</td>\n","      <td>19.279340</td>\n","      <td>14.849941</td>\n","      <td>0.427722</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>5.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>4.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>10.000000</td>\n","      <td>6.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>6.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>21.000000</td>\n","      <td>11.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>1.0</td>\n","      <td>18.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>21.000000</td>\n","      <td>1.000000</td>\n","      <td>201.000000</td>\n","      <td>14.000000</td>\n","      <td>259.000000</td>\n","      <td>201.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 25 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21a3bc89-a99f-44e4-b2be-17d9406b807f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-21a3bc89-a99f-44e4-b2be-17d9406b807f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-21a3bc89-a99f-44e4-b2be-17d9406b807f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":[""],"metadata":{"id":"bUPfWi4TcfIA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#checking the data for null or missing values\n","urldata.isnull().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3PEbrTLcfXg","outputId":"906a5adb-1503-4d5c-ec32-e23cdd8ff308","executionInfo":{"status":"ok","timestamp":1656484693387,"user_tz":-330,"elapsed":36,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Have IP                0\n","Have @                 0\n","URL Length             0\n","URL Depth              0\n","Redirection            0\n","https Domain           0\n","TinyURL                0\n","Prefix/Suffix          0\n","Have client            0\n","Have admin             0\n","Have login             0\n","Have server            0\n",".php                   0\n",".html                  0\n",".info                  0\n",".txt                   0\n",".js                    0\n",".exe                   0\n","Num of periods         0\n","Is encoded             0\n","Num of encoded char    0\n","Num of parameters      0\n","Num of digits          0\n","Num of spec char       0\n","Label                  0\n","dtype: int64"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# shuffling the rows in the dataset so that when splitting the train and test set are equally distributed\n","urldata = urldata.sample(frac=1).reset_index(drop=True)\n","urldata.head()"],"metadata":{"id":"n6YfGa82P5JZ","colab":{"base_uri":"https://localhost:8080/","height":352},"outputId":"1c174fcc-069b-451a-cfec-d9988664c3f1","executionInfo":{"status":"ok","timestamp":1656484693389,"user_tz":-330,"elapsed":36,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Have IP  Have @  URL Length  URL Depth  Redirection  https Domain  TinyURL  \\\n","0        0       0           1          3            0             0        0   \n","1        0       0           1         10            0             0        0   \n","2        0       0           1         10            0             0        0   \n","3        0       0           1          2            0             0        0   \n","4        0       0           1          5            0             0        0   \n","\n","   Prefix/Suffix  Have client  Have admin  ...  .txt  .js  .exe  \\\n","0              0            0           0  ...     0    0     0   \n","1              0            0           0  ...     0    0     0   \n","2              0            0           0  ...     0    0     0   \n","3              0            0           0  ...     0    0     0   \n","4              0            0           0  ...     0    0     0   \n","\n","   Num of periods  Is encoded  Num of encoded char  Num of parameters  \\\n","0               1           0                    0                  0   \n","1               1           0                    0                  0   \n","2               1           0                    0                  0   \n","3               2           0                    0                  0   \n","4               3           0                    0                  0   \n","\n","   Num of digits  Num of spec char  Label  \n","0              9                14      0  \n","1             20                 0      0  \n","2             22                 0      0  \n","3             20                12      0  \n","4              0                 1      1  \n","\n","[5 rows x 25 columns]"],"text/html":["\n","  <div id=\"df-2fe03da8-07bb-43fe-8557-aed7c2ae0098\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Have IP</th>\n","      <th>Have @</th>\n","      <th>URL Length</th>\n","      <th>URL Depth</th>\n","      <th>Redirection</th>\n","      <th>https Domain</th>\n","      <th>TinyURL</th>\n","      <th>Prefix/Suffix</th>\n","      <th>Have client</th>\n","      <th>Have admin</th>\n","      <th>...</th>\n","      <th>.txt</th>\n","      <th>.js</th>\n","      <th>.exe</th>\n","      <th>Num of periods</th>\n","      <th>Is encoded</th>\n","      <th>Num of encoded char</th>\n","      <th>Num of parameters</th>\n","      <th>Num of digits</th>\n","      <th>Num of spec char</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>12</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 25 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fe03da8-07bb-43fe-8557-aed7c2ae0098')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2fe03da8-07bb-43fe-8557-aed7c2ae0098 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2fe03da8-07bb-43fe-8557-aed7c2ae0098');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Sepratating & assigning features and target columns to X & y\n","y = urldata['Label'].values\n","x = np.array(urldata.drop('Label',axis=1))\n","\n"],"metadata":{"id":"Lasv_YzlP5L6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Splitting the dataset into train and test sets: 80-20 split\n","from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, \n","                                                    test_size = 0.45, random_state = 12)\n","print(x_train.shape, x_test.shape)\n","print(y_train.shape, y_test.shape)\n","\n"],"metadata":{"id":"in9C2ArWP5O0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"06f864c6-3278-4b1e-ebe9-a88bbbbaa071","executionInfo":{"status":"ok","timestamp":1656484694216,"user_tz":-330,"elapsed":857,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(3589, 24) (2938, 24)\n","(3589,) (2938,)\n"]}]},{"cell_type":"code","source":["output = {}\n","output['labels'] = y_test"],"metadata":{"id":"jv6Y5m8ddMHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"fg4rdoEnUE0O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOV9VybfNIgE"},"source":["**MLP**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mr-AOgJ1JtXY"},"outputs":[],"source":["import keras\n","\n","from sklearn.neural_network import MLPClassifier\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","import pickle\n","\n","def model_mlp(x_train, x_val, y_train, y_val, opt, n):\n","  mlpclassifier = MLPClassifier(alpha=0.0001, hidden_layer_sizes=([100,100,100]))\n","  #compile model using mse as a measure of model performance\n","  mlpclassifier.fit(x_train, y_train)\n","\n","  y_pred = mlpclassifier.predict(x_val)\n","\n","  conf_matrix = confusion_matrix(y_val, y_pred)\n","  print(conf_matrix)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred))\n","\n","  \n","  print(\"Validation Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/UNB/Binary/Models/URL/MLP/model_'+str(n)+'.h5'\n","  pickle.dump(mlpclassifier, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","  return metrics.accuracy_score(y_val, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUCxdcapJtXZ","executionInfo":{"status":"ok","timestamp":1656484766724,"user_tz":-330,"elapsed":60634,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"7b00ebc1-6195-433d-b636-750faefbd0fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[281   2]\n"," [  6  70]]\n","Precision: 0.9722\n","Recall: 0.9211\n","F1 Score: 0.9459\n","Validation Accuracy: 0.9777158774373259\n","model 0 saved\n","[[266   3]\n"," [  5  85]]\n","Precision: 0.9659\n","Recall: 0.9444\n","F1 Score: 0.9551\n","Validation Accuracy: 0.9777158774373259\n","model 1 saved\n","[[273   5]\n"," [  0  81]]\n","Precision: 0.9419\n","Recall: 1.0000\n","F1 Score: 0.9701\n","Validation Accuracy: 0.9860724233983287\n","model 2 saved\n","[[272   3]\n"," [  4  80]]\n","Precision: 0.9639\n","Recall: 0.9524\n","F1 Score: 0.9581\n","Validation Accuracy: 0.9805013927576601\n","model 3 saved\n","[[264   2]\n"," [ 13  80]]\n","Precision: 0.9756\n","Recall: 0.8602\n","F1 Score: 0.9143\n","Validation Accuracy: 0.958217270194986\n","model 4 saved\n","[[281   3]\n"," [  2  73]]\n","Precision: 0.9605\n","Recall: 0.9733\n","F1 Score: 0.9669\n","Validation Accuracy: 0.9860724233983287\n","model 5 saved\n","[[270   1]\n"," [  3  85]]\n","Precision: 0.9884\n","Recall: 0.9659\n","F1 Score: 0.9770\n","Validation Accuracy: 0.9888579387186629\n","model 6 saved\n","[[266   2]\n"," [  1  90]]\n","Precision: 0.9783\n","Recall: 0.9890\n","F1 Score: 0.9836\n","Validation Accuracy: 0.9916434540389972\n","model 7 saved\n","[[275   2]\n"," [  2  80]]\n","Precision: 0.9756\n","Recall: 0.9756\n","F1 Score: 0.9756\n","Validation Accuracy: 0.9888579387186629\n","model 8 saved\n","[[262   7]\n"," [  7  82]]\n","Precision: 0.9213\n","Recall: 0.9213\n","F1 Score: 0.9213\n","Validation Accuracy: 0.9608938547486033\n","model 9 saved\n","Average Validation Accuracy: 0.9796548450848881\n"]}],"source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_mlp(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545},"executionInfo":{"elapsed":708,"status":"ok","timestamp":1656484880228,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"},"user_tz":-330},"id":"6DA16IlPJtXZ","outputId":"a9eadb70-7868-4a14-bc05-9a9cbe27d47d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[4.11735529e-05 9.99958826e-01]\n"," [4.55413485e-12 1.00000000e+00]\n"," [9.99995064e-01 4.93597482e-06]\n"," ...\n"," [9.99999997e-01 2.56480135e-09]\n"," [9.99998836e-01 1.16405465e-06]\n"," [9.99994216e-01 5.78401868e-06]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish\n","0          1        4.117355e-05          9.999588e-01\n","1          1        4.554135e-12          1.000000e+00\n","2          0        9.999951e-01          4.935975e-06\n","3          0        1.000000e+00          2.150433e-19\n","4          1        1.044356e-01          8.955644e-01\n","...      ...                 ...                   ...\n","2933       1        3.264056e-14          1.000000e+00\n","2934       0        9.980053e-01          1.994709e-03\n","2935       0        1.000000e+00          2.564801e-09\n","2936       0        9.999988e-01          1.164055e-06\n","2937       0        9.999942e-01          5.784019e-06\n","\n","[2938 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-55e3f4fd-280f-4e95-8505-ce481f3bc722\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>4.117355e-05</td>\n","      <td>9.999588e-01</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>4.554135e-12</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>9.999951e-01</td>\n","      <td>4.935975e-06</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>2.150433e-19</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1.044356e-01</td>\n","      <td>8.955644e-01</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2933</th>\n","      <td>1</td>\n","      <td>3.264056e-14</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>2934</th>\n","      <td>0</td>\n","      <td>9.980053e-01</td>\n","      <td>1.994709e-03</td>\n","    </tr>\n","    <tr>\n","      <th>2935</th>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>2.564801e-09</td>\n","    </tr>\n","    <tr>\n","      <th>2936</th>\n","      <td>0</td>\n","      <td>9.999988e-01</td>\n","      <td>1.164055e-06</td>\n","    </tr>\n","    <tr>\n","      <th>2937</th>\n","      <td>0</td>\n","      <td>9.999942e-01</td>\n","      <td>5.784019e-06</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2938 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55e3f4fd-280f-4e95-8505-ce481f3bc722')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-55e3f4fd-280f-4e95-8505-ce481f3bc722 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-55e3f4fd-280f-4e95-8505-ce481f3bc722');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}],"source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/UNB/Binary/Models/URL/MLP/model_7.h5'\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['mlp_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['mlp_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output\n"]},{"cell_type":"markdown","source":["**Neural Network**"],"metadata":{"id":"iLF4sz5NsSZ6"}},{"cell_type":"code","source":["\n","import keras\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","def model_aa(x_train, x_val, y_train, y_val, opt, n, early_stopping_monitor):\n","\n","  n_cols = x_train.shape[1]\n","  # print(\"check point\")\n","  #create model\n","  model = Sequential()\n","  model.add(Dense(30, activation='relu', input_shape=(n_cols,)))\n","  model.add(Dense(10, activation='relu'))\n","\n","  model.add(Dense(1, activation = 'sigmoid'))\n","  # softmax\n","  #compile model using mse as a measure of model performance\n","  model.compile(optimizer = opt, loss= 'binary_crossentropy', metrics=[\"accuracy\"])\n","\n","  history = model.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping_monitor])\n","\n","\n","  # plt.plot(history.history['loss'])\n","  # plt.plot(history.history['val_loss'])\n","  # plt.title('model loss')\n","  # plt.ylabel('Loss')\n","  # plt.xlabel('Epoch')\n","  # plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n","  # plt.show()\n","\n","\n","  print('Validation Accuracy: ')\n","  # Predicting the Test set results\n","  y_pred = model.predict(x_val)\n","  y_pred = (y_pred > 0.5)\n","\n","\n","  print(classification_report(y_val, y_pred))\n","\n","  # Model Accuracy, how often is the classifier correct?\n","  print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","\n","  # Creating the Confusion Matrix\n","  cm = confusion_matrix(y_val, y_pred)\n","  print(cm)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred))\n","\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/UNB/Binary/Models/URL/NN/model_'+str(n)+'.h5'\n","  pickle.dump(model, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","\n","  return metrics.accuracy_score(y_val, y_pred)\n","\n"],"metadata":{"id":"UfilmHKnL3LC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_aa(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n, early_stopping_monitor)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_OHdM1HNDio","executionInfo":{"status":"ok","timestamp":1656485271589,"user_tz":-330,"elapsed":371593,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"fb052896-e887-4bad-db42-1678ca095802"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","101/101 [==============================] - 4s 4ms/step - loss: 1.0135 - accuracy: 0.7954 - val_loss: 0.4135 - val_accuracy: 0.8579\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.8836 - val_loss: 0.3131 - val_accuracy: 0.8942\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.2614 - accuracy: 0.9192 - val_loss: 0.2503 - val_accuracy: 0.9136\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.2209 - accuracy: 0.9272 - val_loss: 0.2179 - val_accuracy: 0.9248\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.9316 - val_loss: 0.1979 - val_accuracy: 0.9331\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1796 - accuracy: 0.9387 - val_loss: 0.1813 - val_accuracy: 0.9443\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1675 - accuracy: 0.9415 - val_loss: 0.1742 - val_accuracy: 0.9443\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1582 - accuracy: 0.9449 - val_loss: 0.1583 - val_accuracy: 0.9499\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9483 - val_loss: 0.1529 - val_accuracy: 0.9499\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9477 - val_loss: 0.1435 - val_accuracy: 0.9471\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1384 - accuracy: 0.9471 - val_loss: 0.1354 - val_accuracy: 0.9526\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1334 - accuracy: 0.9505 - val_loss: 0.1419 - val_accuracy: 0.9499\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 0.9495 - val_loss: 0.1254 - val_accuracy: 0.9554\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1246 - accuracy: 0.9529 - val_loss: 0.1230 - val_accuracy: 0.9554\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 0.9567 - val_loss: 0.1162 - val_accuracy: 0.9610\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9533 - val_loss: 0.1121 - val_accuracy: 0.9610\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9563 - val_loss: 0.1079 - val_accuracy: 0.9582\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9567 - val_loss: 0.1055 - val_accuracy: 0.9638\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1062 - accuracy: 0.9585 - val_loss: 0.1111 - val_accuracy: 0.9610\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1024 - accuracy: 0.9622 - val_loss: 0.0978 - val_accuracy: 0.9666\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9628 - val_loss: 0.0942 - val_accuracy: 0.9694\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0970 - accuracy: 0.9622 - val_loss: 0.0888 - val_accuracy: 0.9694\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0932 - accuracy: 0.9641 - val_loss: 0.0841 - val_accuracy: 0.9694\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0902 - accuracy: 0.9687 - val_loss: 0.0909 - val_accuracy: 0.9694\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.9706 - val_loss: 0.0987 - val_accuracy: 0.9666\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0845 - accuracy: 0.9687 - val_loss: 0.0771 - val_accuracy: 0.9805\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0828 - accuracy: 0.9690 - val_loss: 0.0767 - val_accuracy: 0.9805\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 0.9712 - val_loss: 0.0868 - val_accuracy: 0.9694\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0796 - accuracy: 0.9721 - val_loss: 0.0774 - val_accuracy: 0.9805\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9721 - val_loss: 0.0791 - val_accuracy: 0.9777\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0773 - accuracy: 0.9724 - val_loss: 0.0709 - val_accuracy: 0.9805\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.9737 - val_loss: 0.0710 - val_accuracy: 0.9833\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9740 - val_loss: 0.0715 - val_accuracy: 0.9805\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.9749 - val_loss: 0.0671 - val_accuracy: 0.9833\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9718 - val_loss: 0.0669 - val_accuracy: 0.9833\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9752 - val_loss: 0.0746 - val_accuracy: 0.9805\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9749 - val_loss: 0.0633 - val_accuracy: 0.9861\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9755 - val_loss: 0.0625 - val_accuracy: 0.9861\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.9759 - val_loss: 0.0707 - val_accuracy: 0.9805\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9762 - val_loss: 0.0631 - val_accuracy: 0.9861\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.9762 - val_loss: 0.0630 - val_accuracy: 0.9861\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9755 - val_loss: 0.0671 - val_accuracy: 0.9861\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9777 - val_loss: 0.0604 - val_accuracy: 0.9861\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9789 - val_loss: 0.0683 - val_accuracy: 0.9833\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9777 - val_loss: 0.0598 - val_accuracy: 0.9861\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9783 - val_loss: 0.0627 - val_accuracy: 0.9861\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9777 - val_loss: 0.0583 - val_accuracy: 0.9861\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9774 - val_loss: 0.0581 - val_accuracy: 0.9861\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9802 - val_loss: 0.0599 - val_accuracy: 0.9861\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9799 - val_loss: 0.0626 - val_accuracy: 0.9861\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9799 - val_loss: 0.0565 - val_accuracy: 0.9861\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9799 - val_loss: 0.0569 - val_accuracy: 0.9861\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9796 - val_loss: 0.0570 - val_accuracy: 0.9861\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9796 - val_loss: 0.0558 - val_accuracy: 0.9861\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9796 - val_loss: 0.0558 - val_accuracy: 0.9861\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9805 - val_loss: 0.0557 - val_accuracy: 0.9861\n","Epoch 57/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9814 - val_loss: 0.0566 - val_accuracy: 0.9861\n","Epoch 58/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9817 - val_loss: 0.0545 - val_accuracy: 0.9861\n","Epoch 59/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9808 - val_loss: 0.0545 - val_accuracy: 0.9861\n","Epoch 60/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9805 - val_loss: 0.0577 - val_accuracy: 0.9861\n","Epoch 61/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9814 - val_loss: 0.0547 - val_accuracy: 0.9861\n","Epoch 62/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9799 - val_loss: 0.0606 - val_accuracy: 0.9833\n","Epoch 63/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9817 - val_loss: 0.0547 - val_accuracy: 0.9861\n","Epoch 64/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9808 - val_loss: 0.0549 - val_accuracy: 0.9861\n","Epoch 65/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9805 - val_loss: 0.0584 - val_accuracy: 0.9833\n","Epoch 66/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9811 - val_loss: 0.0633 - val_accuracy: 0.9833\n","Epoch 67/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9814 - val_loss: 0.0537 - val_accuracy: 0.9861\n","Epoch 68/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9827 - val_loss: 0.0583 - val_accuracy: 0.9833\n","Epoch 69/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9808 - val_loss: 0.0547 - val_accuracy: 0.9861\n","Epoch 70/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9836 - val_loss: 0.0533 - val_accuracy: 0.9861\n","Epoch 71/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9851 - val_loss: 0.0561 - val_accuracy: 0.9861\n","Epoch 72/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9833 - val_loss: 0.0554 - val_accuracy: 0.9861\n","Epoch 73/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9830 - val_loss: 0.0539 - val_accuracy: 0.9861\n","Epoch 74/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9845 - val_loss: 0.0548 - val_accuracy: 0.9861\n","Epoch 75/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9833 - val_loss: 0.0546 - val_accuracy: 0.9861\n","Epoch 76/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9833 - val_loss: 0.0547 - val_accuracy: 0.9861\n","Epoch 77/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9842 - val_loss: 0.0549 - val_accuracy: 0.9833\n","Epoch 78/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9824 - val_loss: 0.0592 - val_accuracy: 0.9833\n","Epoch 79/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.9845 - val_loss: 0.0544 - val_accuracy: 0.9861\n","Epoch 80/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9851 - val_loss: 0.0534 - val_accuracy: 0.9833\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.99      0.99       283\n","           1       0.96      0.96      0.96        76\n","\n","    accuracy                           0.98       359\n","   macro avg       0.97      0.97      0.97       359\n","weighted avg       0.98      0.98      0.98       359\n","\n","Accuracy: 0.9832869080779945\n","[[280   3]\n"," [  3  73]]\n","Precision: 0.9605\n","Recall: 0.9605\n","F1 Score: 0.9605\n","INFO:tensorflow:Assets written to: ram://934d61a8-6ea3-432e-9403-d65100fc28a8/assets\n","model 0 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.3301 - accuracy: 0.8814 - val_loss: 0.2538 - val_accuracy: 0.8719\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.2166 - accuracy: 0.9065 - val_loss: 0.2129 - val_accuracy: 0.9025\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1911 - accuracy: 0.9214 - val_loss: 0.1945 - val_accuracy: 0.9109\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9341 - val_loss: 0.1804 - val_accuracy: 0.9276\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1634 - accuracy: 0.9424 - val_loss: 0.1689 - val_accuracy: 0.9220\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1564 - accuracy: 0.9402 - val_loss: 0.1677 - val_accuracy: 0.9276\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9455 - val_loss: 0.1607 - val_accuracy: 0.9276\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1382 - accuracy: 0.9464 - val_loss: 0.1605 - val_accuracy: 0.9415\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9498 - val_loss: 0.1499 - val_accuracy: 0.9415\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1241 - accuracy: 0.9498 - val_loss: 0.1511 - val_accuracy: 0.9471\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1165 - accuracy: 0.9554 - val_loss: 0.1452 - val_accuracy: 0.9554\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1134 - accuracy: 0.9576 - val_loss: 0.1370 - val_accuracy: 0.9443\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1098 - accuracy: 0.9598 - val_loss: 0.1399 - val_accuracy: 0.9554\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9616 - val_loss: 0.1362 - val_accuracy: 0.9526\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9610 - val_loss: 0.1295 - val_accuracy: 0.9554\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1016 - accuracy: 0.9613 - val_loss: 0.1338 - val_accuracy: 0.9499\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9644 - val_loss: 0.1316 - val_accuracy: 0.9582\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0947 - accuracy: 0.9644 - val_loss: 0.1259 - val_accuracy: 0.9499\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 0.9659 - val_loss: 0.1307 - val_accuracy: 0.9582\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0916 - accuracy: 0.9653 - val_loss: 0.1207 - val_accuracy: 0.9554\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0887 - accuracy: 0.9678 - val_loss: 0.1190 - val_accuracy: 0.9554\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0877 - accuracy: 0.9690 - val_loss: 0.1163 - val_accuracy: 0.9526\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.9669 - val_loss: 0.1189 - val_accuracy: 0.9582\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0828 - accuracy: 0.9693 - val_loss: 0.1207 - val_accuracy: 0.9582\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0841 - accuracy: 0.9690 - val_loss: 0.1202 - val_accuracy: 0.9554\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0809 - accuracy: 0.9706 - val_loss: 0.1222 - val_accuracy: 0.9610\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0819 - accuracy: 0.9712 - val_loss: 0.1154 - val_accuracy: 0.9554\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9703 - val_loss: 0.1129 - val_accuracy: 0.9610\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9737 - val_loss: 0.1124 - val_accuracy: 0.9582\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0754 - accuracy: 0.9737 - val_loss: 0.1086 - val_accuracy: 0.9582\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9731 - val_loss: 0.1007 - val_accuracy: 0.9610\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9749 - val_loss: 0.1040 - val_accuracy: 0.9610\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0726 - accuracy: 0.9743 - val_loss: 0.1150 - val_accuracy: 0.9582\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9740 - val_loss: 0.1053 - val_accuracy: 0.9610\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9734 - val_loss: 0.1068 - val_accuracy: 0.9610\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9749 - val_loss: 0.1024 - val_accuracy: 0.9610\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9762 - val_loss: 0.1121 - val_accuracy: 0.9638\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.9743 - val_loss: 0.1147 - val_accuracy: 0.9638\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9777 - val_loss: 0.1104 - val_accuracy: 0.9610\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9749 - val_loss: 0.1074 - val_accuracy: 0.9610\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9765 - val_loss: 0.0997 - val_accuracy: 0.9666\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.9749 - val_loss: 0.1001 - val_accuracy: 0.9610\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9765 - val_loss: 0.1028 - val_accuracy: 0.9610\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9759 - val_loss: 0.1026 - val_accuracy: 0.9666\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9765 - val_loss: 0.1017 - val_accuracy: 0.9638\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9762 - val_loss: 0.1029 - val_accuracy: 0.9610\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9768 - val_loss: 0.0975 - val_accuracy: 0.9666\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9789 - val_loss: 0.1066 - val_accuracy: 0.9638\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9793 - val_loss: 0.0990 - val_accuracy: 0.9610\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9774 - val_loss: 0.1004 - val_accuracy: 0.9610\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9796 - val_loss: 0.0974 - val_accuracy: 0.9610\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9786 - val_loss: 0.1022 - val_accuracy: 0.9638\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9793 - val_loss: 0.0987 - val_accuracy: 0.9610\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9805 - val_loss: 0.1050 - val_accuracy: 0.9610\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9796 - val_loss: 0.0991 - val_accuracy: 0.9666\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9802 - val_loss: 0.0972 - val_accuracy: 0.9610\n","Epoch 57/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9796 - val_loss: 0.0905 - val_accuracy: 0.9721\n","Epoch 58/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9802 - val_loss: 0.1065 - val_accuracy: 0.9694\n","Epoch 59/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9789 - val_loss: 0.1051 - val_accuracy: 0.9638\n","Epoch 60/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9802 - val_loss: 0.0978 - val_accuracy: 0.9721\n","Epoch 61/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9827 - val_loss: 0.0990 - val_accuracy: 0.9638\n","Epoch 62/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9799 - val_loss: 0.0978 - val_accuracy: 0.9694\n","Epoch 63/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9796 - val_loss: 0.0969 - val_accuracy: 0.9694\n","Epoch 64/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9817 - val_loss: 0.0943 - val_accuracy: 0.9694\n","Epoch 65/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9802 - val_loss: 0.0957 - val_accuracy: 0.9666\n","Epoch 66/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9808 - val_loss: 0.1049 - val_accuracy: 0.9638\n","Epoch 67/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9827 - val_loss: 0.0910 - val_accuracy: 0.9666\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.99      0.98       269\n","           1       0.96      0.90      0.93        90\n","\n","    accuracy                           0.97       359\n","   macro avg       0.97      0.94      0.95       359\n","weighted avg       0.97      0.97      0.97       359\n","\n","Accuracy: 0.9665738161559888\n","[[266   3]\n"," [  9  81]]\n","Precision: 0.9643\n","Recall: 0.9000\n","F1 Score: 0.9310\n","INFO:tensorflow:Assets written to: ram://df2a32ee-7d4b-4850-aa34-6706c75eade3/assets\n","model 1 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.5731 - accuracy: 0.7752 - val_loss: 0.2385 - val_accuracy: 0.8942\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.2248 - accuracy: 0.9068 - val_loss: 0.1770 - val_accuracy: 0.9220\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1891 - accuracy: 0.9263 - val_loss: 0.1534 - val_accuracy: 0.9471\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1694 - accuracy: 0.9365 - val_loss: 0.1434 - val_accuracy: 0.9471\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1562 - accuracy: 0.9412 - val_loss: 0.1353 - val_accuracy: 0.9526\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9458 - val_loss: 0.1237 - val_accuracy: 0.9499\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1389 - accuracy: 0.9492 - val_loss: 0.1192 - val_accuracy: 0.9499\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1332 - accuracy: 0.9508 - val_loss: 0.1137 - val_accuracy: 0.9526\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 0.9514 - val_loss: 0.1103 - val_accuracy: 0.9526\n","Epoch 10/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.9545 - val_loss: 0.1084 - val_accuracy: 0.9554\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9585 - val_loss: 0.1080 - val_accuracy: 0.9526\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1132 - accuracy: 0.9588 - val_loss: 0.1001 - val_accuracy: 0.9554\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1085 - accuracy: 0.9601 - val_loss: 0.0970 - val_accuracy: 0.9554\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 0.9601 - val_loss: 0.0969 - val_accuracy: 0.9638\n","Epoch 15/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1015 - accuracy: 0.9635 - val_loss: 0.0923 - val_accuracy: 0.9610\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9628 - val_loss: 0.0911 - val_accuracy: 0.9610\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0959 - accuracy: 0.9641 - val_loss: 0.0912 - val_accuracy: 0.9582\n","Epoch 18/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9625 - val_loss: 0.0883 - val_accuracy: 0.9666\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0918 - accuracy: 0.9666 - val_loss: 0.0881 - val_accuracy: 0.9666\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0889 - accuracy: 0.9678 - val_loss: 0.0834 - val_accuracy: 0.9694\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0885 - accuracy: 0.9669 - val_loss: 0.0862 - val_accuracy: 0.9638\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.9669 - val_loss: 0.0801 - val_accuracy: 0.9694\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9675 - val_loss: 0.0786 - val_accuracy: 0.9694\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0835 - accuracy: 0.9669 - val_loss: 0.0786 - val_accuracy: 0.9694\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9693 - val_loss: 0.0793 - val_accuracy: 0.9666\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9697 - val_loss: 0.0765 - val_accuracy: 0.9721\n","Epoch 27/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9700 - val_loss: 0.0749 - val_accuracy: 0.9721\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9706 - val_loss: 0.0771 - val_accuracy: 0.9694\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9721 - val_loss: 0.0723 - val_accuracy: 0.9666\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 0.9709 - val_loss: 0.0724 - val_accuracy: 0.9694\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9731 - val_loss: 0.0728 - val_accuracy: 0.9694\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9718 - val_loss: 0.0726 - val_accuracy: 0.9694\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9740 - val_loss: 0.0710 - val_accuracy: 0.9694\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9731 - val_loss: 0.0679 - val_accuracy: 0.9721\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9737 - val_loss: 0.0708 - val_accuracy: 0.9694\n","Epoch 36/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.9743 - val_loss: 0.0690 - val_accuracy: 0.9749\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9746 - val_loss: 0.0677 - val_accuracy: 0.9694\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9728 - val_loss: 0.0657 - val_accuracy: 0.9721\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9762 - val_loss: 0.0655 - val_accuracy: 0.9721\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9762 - val_loss: 0.0642 - val_accuracy: 0.9777\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9765 - val_loss: 0.0632 - val_accuracy: 0.9777\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.9762 - val_loss: 0.0624 - val_accuracy: 0.9777\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9762 - val_loss: 0.0639 - val_accuracy: 0.9721\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9774 - val_loss: 0.0653 - val_accuracy: 0.9721\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9768 - val_loss: 0.0615 - val_accuracy: 0.9721\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9759 - val_loss: 0.0636 - val_accuracy: 0.9694\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9771 - val_loss: 0.0624 - val_accuracy: 0.9805\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9762 - val_loss: 0.0659 - val_accuracy: 0.9666\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9771 - val_loss: 0.0609 - val_accuracy: 0.9805\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9774 - val_loss: 0.0592 - val_accuracy: 0.9777\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9774 - val_loss: 0.0595 - val_accuracy: 0.9777\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9789 - val_loss: 0.0596 - val_accuracy: 0.9805\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9777 - val_loss: 0.0607 - val_accuracy: 0.9666\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9789 - val_loss: 0.0684 - val_accuracy: 0.9666\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9774 - val_loss: 0.0607 - val_accuracy: 0.9694\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9789 - val_loss: 0.0568 - val_accuracy: 0.9777\n","Epoch 57/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9793 - val_loss: 0.0569 - val_accuracy: 0.9805\n","Epoch 58/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9802 - val_loss: 0.0560 - val_accuracy: 0.9805\n","Epoch 59/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9771 - val_loss: 0.0562 - val_accuracy: 0.9777\n","Epoch 60/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9820 - val_loss: 0.0582 - val_accuracy: 0.9666\n","Epoch 61/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9811 - val_loss: 0.0564 - val_accuracy: 0.9777\n","Epoch 62/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9786 - val_loss: 0.0586 - val_accuracy: 0.9721\n","Epoch 63/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9796 - val_loss: 0.0582 - val_accuracy: 0.9749\n","Epoch 64/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9793 - val_loss: 0.0559 - val_accuracy: 0.9777\n","Epoch 65/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9793 - val_loss: 0.0525 - val_accuracy: 0.9805\n","Epoch 66/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9820 - val_loss: 0.0536 - val_accuracy: 0.9777\n","Epoch 67/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9817 - val_loss: 0.0547 - val_accuracy: 0.9777\n","Epoch 68/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9824 - val_loss: 0.0538 - val_accuracy: 0.9749\n","Epoch 69/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9814 - val_loss: 0.0526 - val_accuracy: 0.9749\n","Epoch 70/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9820 - val_loss: 0.0523 - val_accuracy: 0.9749\n","Epoch 71/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9824 - val_loss: 0.0531 - val_accuracy: 0.9777\n","Epoch 72/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9824 - val_loss: 0.0507 - val_accuracy: 0.9749\n","Epoch 73/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9836 - val_loss: 0.0539 - val_accuracy: 0.9777\n","Epoch 74/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9833 - val_loss: 0.0513 - val_accuracy: 0.9777\n","Epoch 75/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9824 - val_loss: 0.0503 - val_accuracy: 0.9777\n","Epoch 76/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9827 - val_loss: 0.0525 - val_accuracy: 0.9721\n","Epoch 77/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9820 - val_loss: 0.0559 - val_accuracy: 0.9694\n","Epoch 78/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9848 - val_loss: 0.0514 - val_accuracy: 0.9777\n","Epoch 79/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9839 - val_loss: 0.0516 - val_accuracy: 0.9777\n","Epoch 80/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9830 - val_loss: 0.0503 - val_accuracy: 0.9777\n","Epoch 81/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9839 - val_loss: 0.0505 - val_accuracy: 0.9777\n","Epoch 82/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9817 - val_loss: 0.0519 - val_accuracy: 0.9777\n","Epoch 83/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9851 - val_loss: 0.0512 - val_accuracy: 0.9749\n","Epoch 84/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9842 - val_loss: 0.0478 - val_accuracy: 0.9777\n","Epoch 85/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9827 - val_loss: 0.0512 - val_accuracy: 0.9777\n","Epoch 86/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9842 - val_loss: 0.0530 - val_accuracy: 0.9721\n","Epoch 87/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9864 - val_loss: 0.0481 - val_accuracy: 0.9833\n","Epoch 88/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 0.9858 - val_loss: 0.0502 - val_accuracy: 0.9777\n","Epoch 89/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9836 - val_loss: 0.0516 - val_accuracy: 0.9749\n","Epoch 90/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9848 - val_loss: 0.0496 - val_accuracy: 0.9777\n","Epoch 91/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9854 - val_loss: 0.0479 - val_accuracy: 0.9805\n","Epoch 92/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9845 - val_loss: 0.0492 - val_accuracy: 0.9805\n","Epoch 93/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9851 - val_loss: 0.0475 - val_accuracy: 0.9749\n","Epoch 94/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9854 - val_loss: 0.0476 - val_accuracy: 0.9805\n","Epoch 95/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9861 - val_loss: 0.0479 - val_accuracy: 0.9777\n","Epoch 96/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9861 - val_loss: 0.0477 - val_accuracy: 0.9805\n","Epoch 97/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9873 - val_loss: 0.0453 - val_accuracy: 0.9805\n","Epoch 98/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.9851 - val_loss: 0.0474 - val_accuracy: 0.9833\n","Epoch 99/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9870 - val_loss: 0.0464 - val_accuracy: 0.9777\n","Epoch 100/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9851 - val_loss: 0.0481 - val_accuracy: 0.9805\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99       278\n","           1       0.93      0.99      0.96        81\n","\n","    accuracy                           0.98       359\n","   macro avg       0.96      0.98      0.97       359\n","weighted avg       0.98      0.98      0.98       359\n","\n","Accuracy: 0.9805013927576601\n","[[272   6]\n"," [  1  80]]\n","Precision: 0.9302\n","Recall: 0.9877\n","F1 Score: 0.9581\n","INFO:tensorflow:Assets written to: ram://57df1fe8-1335-4a04-8295-cd206a198c48/assets\n","model 2 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.7401 - accuracy: 0.7715 - val_loss: 0.2439 - val_accuracy: 0.8747\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.8994 - val_loss: 0.2120 - val_accuracy: 0.8886\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1903 - accuracy: 0.9152 - val_loss: 0.1976 - val_accuracy: 0.9053\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1786 - accuracy: 0.9192 - val_loss: 0.1878 - val_accuracy: 0.9053\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9220 - val_loss: 0.1818 - val_accuracy: 0.9109\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1600 - accuracy: 0.9303 - val_loss: 0.1710 - val_accuracy: 0.9164\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1525 - accuracy: 0.9390 - val_loss: 0.1647 - val_accuracy: 0.9164\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9477 - val_loss: 0.1559 - val_accuracy: 0.9359\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1393 - accuracy: 0.9505 - val_loss: 0.1480 - val_accuracy: 0.9359\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9533 - val_loss: 0.1439 - val_accuracy: 0.9415\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1264 - accuracy: 0.9545 - val_loss: 0.1395 - val_accuracy: 0.9387\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1235 - accuracy: 0.9551 - val_loss: 0.1338 - val_accuracy: 0.9471\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1174 - accuracy: 0.9573 - val_loss: 0.1287 - val_accuracy: 0.9499\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1128 - accuracy: 0.9585 - val_loss: 0.1255 - val_accuracy: 0.9554\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1092 - accuracy: 0.9610 - val_loss: 0.1197 - val_accuracy: 0.9526\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1056 - accuracy: 0.9616 - val_loss: 0.1203 - val_accuracy: 0.9499\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1033 - accuracy: 0.9613 - val_loss: 0.1149 - val_accuracy: 0.9526\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9638 - val_loss: 0.1124 - val_accuracy: 0.9526\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9625 - val_loss: 0.1111 - val_accuracy: 0.9582\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0952 - accuracy: 0.9656 - val_loss: 0.1068 - val_accuracy: 0.9582\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0922 - accuracy: 0.9666 - val_loss: 0.1083 - val_accuracy: 0.9554\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 0.9678 - val_loss: 0.1043 - val_accuracy: 0.9638\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0878 - accuracy: 0.9675 - val_loss: 0.1050 - val_accuracy: 0.9610\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0873 - accuracy: 0.9672 - val_loss: 0.1002 - val_accuracy: 0.9610\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9690 - val_loss: 0.0994 - val_accuracy: 0.9582\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0839 - accuracy: 0.9690 - val_loss: 0.0973 - val_accuracy: 0.9666\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0822 - accuracy: 0.9693 - val_loss: 0.0966 - val_accuracy: 0.9638\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9715 - val_loss: 0.0959 - val_accuracy: 0.9666\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9724 - val_loss: 0.0933 - val_accuracy: 0.9638\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9712 - val_loss: 0.0933 - val_accuracy: 0.9694\n","Epoch 31/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.9740 - val_loss: 0.0914 - val_accuracy: 0.9721\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9728 - val_loss: 0.0903 - val_accuracy: 0.9638\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9731 - val_loss: 0.0889 - val_accuracy: 0.9721\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0730 - accuracy: 0.9731 - val_loss: 0.0902 - val_accuracy: 0.9694\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9734 - val_loss: 0.0911 - val_accuracy: 0.9721\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9743 - val_loss: 0.0849 - val_accuracy: 0.9721\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9755 - val_loss: 0.0851 - val_accuracy: 0.9721\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9749 - val_loss: 0.0875 - val_accuracy: 0.9721\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9765 - val_loss: 0.0833 - val_accuracy: 0.9721\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9759 - val_loss: 0.0869 - val_accuracy: 0.9694\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9765 - val_loss: 0.0889 - val_accuracy: 0.9638\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.9759 - val_loss: 0.0849 - val_accuracy: 0.9749\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.9746 - val_loss: 0.0802 - val_accuracy: 0.9694\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.9771 - val_loss: 0.0801 - val_accuracy: 0.9749\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9774 - val_loss: 0.0786 - val_accuracy: 0.9721\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9759 - val_loss: 0.0791 - val_accuracy: 0.9749\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9780 - val_loss: 0.0776 - val_accuracy: 0.9777\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9765 - val_loss: 0.0758 - val_accuracy: 0.9749\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9793 - val_loss: 0.0740 - val_accuracy: 0.9777\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9780 - val_loss: 0.0740 - val_accuracy: 0.9777\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9783 - val_loss: 0.0734 - val_accuracy: 0.9777\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9789 - val_loss: 0.0713 - val_accuracy: 0.9777\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9780 - val_loss: 0.0682 - val_accuracy: 0.9777\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9768 - val_loss: 0.0705 - val_accuracy: 0.9749\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9783 - val_loss: 0.0697 - val_accuracy: 0.9749\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9780 - val_loss: 0.0702 - val_accuracy: 0.9749\n","Epoch 57/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9793 - val_loss: 0.0671 - val_accuracy: 0.9749\n","Epoch 58/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9802 - val_loss: 0.0680 - val_accuracy: 0.9777\n","Epoch 59/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9799 - val_loss: 0.0714 - val_accuracy: 0.9749\n","Epoch 60/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9805 - val_loss: 0.0686 - val_accuracy: 0.9777\n","Epoch 61/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9789 - val_loss: 0.0648 - val_accuracy: 0.9777\n","Epoch 62/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9799 - val_loss: 0.0701 - val_accuracy: 0.9749\n","Epoch 63/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9805 - val_loss: 0.0658 - val_accuracy: 0.9749\n","Epoch 64/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9805 - val_loss: 0.0704 - val_accuracy: 0.9721\n","Epoch 65/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9799 - val_loss: 0.0656 - val_accuracy: 0.9777\n","Epoch 66/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9805 - val_loss: 0.0724 - val_accuracy: 0.9721\n","Epoch 67/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9811 - val_loss: 0.0648 - val_accuracy: 0.9777\n","Epoch 68/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9805 - val_loss: 0.0607 - val_accuracy: 0.9805\n","Epoch 69/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9802 - val_loss: 0.0655 - val_accuracy: 0.9805\n","Epoch 70/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9814 - val_loss: 0.0631 - val_accuracy: 0.9777\n","Epoch 71/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9814 - val_loss: 0.0617 - val_accuracy: 0.9805\n","Epoch 72/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9786 - val_loss: 0.0598 - val_accuracy: 0.9777\n","Epoch 73/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9805 - val_loss: 0.0597 - val_accuracy: 0.9777\n","Epoch 74/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9811 - val_loss: 0.0628 - val_accuracy: 0.9749\n","Epoch 75/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9814 - val_loss: 0.0632 - val_accuracy: 0.9777\n","Epoch 76/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9833 - val_loss: 0.0617 - val_accuracy: 0.9777\n","Epoch 77/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9833 - val_loss: 0.0579 - val_accuracy: 0.9805\n","Epoch 78/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9833 - val_loss: 0.0641 - val_accuracy: 0.9721\n","Epoch 79/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9830 - val_loss: 0.0556 - val_accuracy: 0.9805\n","Epoch 80/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9833 - val_loss: 0.0599 - val_accuracy: 0.9805\n","Epoch 81/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9830 - val_loss: 0.0594 - val_accuracy: 0.9805\n","Epoch 82/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9839 - val_loss: 0.0567 - val_accuracy: 0.9805\n","Epoch 83/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9842 - val_loss: 0.0598 - val_accuracy: 0.9805\n","Epoch 84/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9854 - val_loss: 0.0613 - val_accuracy: 0.9805\n","Epoch 85/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9836 - val_loss: 0.0570 - val_accuracy: 0.9777\n","Epoch 86/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9839 - val_loss: 0.0548 - val_accuracy: 0.9777\n","Epoch 87/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9845 - val_loss: 0.0567 - val_accuracy: 0.9805\n","Epoch 88/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9830 - val_loss: 0.0584 - val_accuracy: 0.9777\n","Epoch 89/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9839 - val_loss: 0.0544 - val_accuracy: 0.9777\n","Epoch 90/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9854 - val_loss: 0.0578 - val_accuracy: 0.9777\n","Epoch 91/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9827 - val_loss: 0.0552 - val_accuracy: 0.9749\n","Epoch 92/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9839 - val_loss: 0.0563 - val_accuracy: 0.9777\n","Epoch 93/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9858 - val_loss: 0.0579 - val_accuracy: 0.9777\n","Epoch 94/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9854 - val_loss: 0.0564 - val_accuracy: 0.9777\n","Epoch 95/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9842 - val_loss: 0.0534 - val_accuracy: 0.9777\n","Epoch 96/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9864 - val_loss: 0.0560 - val_accuracy: 0.9749\n","Epoch 97/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9867 - val_loss: 0.0545 - val_accuracy: 0.9749\n","Epoch 98/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9854 - val_loss: 0.0592 - val_accuracy: 0.9749\n","Epoch 99/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9848 - val_loss: 0.0524 - val_accuracy: 0.9777\n","Epoch 100/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9858 - val_loss: 0.0616 - val_accuracy: 0.9777\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.99      0.99       275\n","           1       0.95      0.95      0.95        84\n","\n","    accuracy                           0.98       359\n","   macro avg       0.97      0.97      0.97       359\n","weighted avg       0.98      0.98      0.98       359\n","\n","Accuracy: 0.9777158774373259\n","[[271   4]\n"," [  4  80]]\n","Precision: 0.9524\n","Recall: 0.9524\n","F1 Score: 0.9524\n","INFO:tensorflow:Assets written to: ram://65875fa7-a157-4063-beea-a4d5e6f61ab2/assets\n","model 3 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.4192 - accuracy: 0.8458 - val_loss: 0.2332 - val_accuracy: 0.8942\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.2012 - accuracy: 0.9118 - val_loss: 0.1902 - val_accuracy: 0.9220\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1742 - accuracy: 0.9334 - val_loss: 0.1720 - val_accuracy: 0.9331\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9409 - val_loss: 0.1657 - val_accuracy: 0.9331\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9421 - val_loss: 0.1524 - val_accuracy: 0.9387\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1389 - accuracy: 0.9467 - val_loss: 0.1462 - val_accuracy: 0.9415\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1314 - accuracy: 0.9489 - val_loss: 0.1422 - val_accuracy: 0.9443\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1244 - accuracy: 0.9498 - val_loss: 0.1317 - val_accuracy: 0.9526\n","Epoch 9/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1201 - accuracy: 0.9545 - val_loss: 0.1347 - val_accuracy: 0.9387\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1135 - accuracy: 0.9545 - val_loss: 0.1267 - val_accuracy: 0.9471\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1088 - accuracy: 0.9570 - val_loss: 0.1293 - val_accuracy: 0.9415\n","Epoch 12/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1054 - accuracy: 0.9616 - val_loss: 0.1187 - val_accuracy: 0.9582\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1006 - accuracy: 0.9638 - val_loss: 0.1190 - val_accuracy: 0.9499\n","Epoch 14/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0973 - accuracy: 0.9666 - val_loss: 0.1172 - val_accuracy: 0.9554\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0944 - accuracy: 0.9663 - val_loss: 0.1184 - val_accuracy: 0.9526\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 0.9678 - val_loss: 0.1156 - val_accuracy: 0.9443\n","Epoch 17/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0894 - accuracy: 0.9687 - val_loss: 0.1198 - val_accuracy: 0.9471\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0867 - accuracy: 0.9693 - val_loss: 0.1092 - val_accuracy: 0.9666\n","Epoch 19/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0831 - accuracy: 0.9693 - val_loss: 0.1221 - val_accuracy: 0.9443\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0841 - accuracy: 0.9697 - val_loss: 0.1176 - val_accuracy: 0.9526\n","Epoch 21/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.9703 - val_loss: 0.1146 - val_accuracy: 0.9499\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0796 - accuracy: 0.9700 - val_loss: 0.1062 - val_accuracy: 0.9554\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0769 - accuracy: 0.9709 - val_loss: 0.1056 - val_accuracy: 0.9554\n","Epoch 24/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0759 - accuracy: 0.9724 - val_loss: 0.1015 - val_accuracy: 0.9582\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9715 - val_loss: 0.1062 - val_accuracy: 0.9499\n","Epoch 26/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0750 - accuracy: 0.9718 - val_loss: 0.1110 - val_accuracy: 0.9526\n","Epoch 27/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.9728 - val_loss: 0.1014 - val_accuracy: 0.9610\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9737 - val_loss: 0.1028 - val_accuracy: 0.9554\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9724 - val_loss: 0.1029 - val_accuracy: 0.9610\n","Epoch 30/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.9724 - val_loss: 0.0997 - val_accuracy: 0.9582\n","Epoch 31/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9740 - val_loss: 0.0940 - val_accuracy: 0.9666\n","Epoch 32/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9746 - val_loss: 0.0922 - val_accuracy: 0.9666\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9731 - val_loss: 0.0965 - val_accuracy: 0.9666\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9737 - val_loss: 0.0949 - val_accuracy: 0.9694\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9755 - val_loss: 0.0958 - val_accuracy: 0.9638\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9746 - val_loss: 0.0997 - val_accuracy: 0.9554\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9771 - val_loss: 0.0956 - val_accuracy: 0.9638\n","Epoch 38/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9771 - val_loss: 0.1080 - val_accuracy: 0.9471\n","Epoch 39/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9777 - val_loss: 0.0888 - val_accuracy: 0.9721\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9755 - val_loss: 0.0899 - val_accuracy: 0.9694\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9786 - val_loss: 0.0997 - val_accuracy: 0.9610\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9768 - val_loss: 0.0907 - val_accuracy: 0.9721\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9774 - val_loss: 0.0924 - val_accuracy: 0.9666\n","Epoch 44/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9799 - val_loss: 0.0875 - val_accuracy: 0.9694\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9780 - val_loss: 0.0892 - val_accuracy: 0.9694\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9783 - val_loss: 0.0866 - val_accuracy: 0.9721\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9799 - val_loss: 0.0896 - val_accuracy: 0.9721\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9777 - val_loss: 0.0882 - val_accuracy: 0.9721\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9802 - val_loss: 0.0934 - val_accuracy: 0.9638\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9793 - val_loss: 0.0900 - val_accuracy: 0.9694\n","Epoch 51/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.9780 - val_loss: 0.0859 - val_accuracy: 0.9666\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9799 - val_loss: 0.0900 - val_accuracy: 0.9694\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9789 - val_loss: 0.0869 - val_accuracy: 0.9666\n","Epoch 54/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.9814 - val_loss: 0.0900 - val_accuracy: 0.9610\n","Epoch 55/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9820 - val_loss: 0.0914 - val_accuracy: 0.9666\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9814 - val_loss: 0.0851 - val_accuracy: 0.9749\n","Epoch 57/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9817 - val_loss: 0.0883 - val_accuracy: 0.9666\n","Epoch 58/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9811 - val_loss: 0.0907 - val_accuracy: 0.9638\n","Epoch 59/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9814 - val_loss: 0.0888 - val_accuracy: 0.9638\n","Epoch 60/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9824 - val_loss: 0.0892 - val_accuracy: 0.9666\n","Epoch 61/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9817 - val_loss: 0.0917 - val_accuracy: 0.9666\n","Epoch 62/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9814 - val_loss: 0.0852 - val_accuracy: 0.9694\n","Epoch 63/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9817 - val_loss: 0.0856 - val_accuracy: 0.9666\n","Epoch 64/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9830 - val_loss: 0.0965 - val_accuracy: 0.9638\n","Epoch 65/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9833 - val_loss: 0.0844 - val_accuracy: 0.9666\n","Epoch 66/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9814 - val_loss: 0.0862 - val_accuracy: 0.9666\n","Epoch 67/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9820 - val_loss: 0.0887 - val_accuracy: 0.9638\n","Epoch 68/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9830 - val_loss: 0.0953 - val_accuracy: 0.9638\n","Epoch 69/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9830 - val_loss: 0.0886 - val_accuracy: 0.9666\n","Epoch 70/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9830 - val_loss: 0.0878 - val_accuracy: 0.9638\n","Epoch 71/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9824 - val_loss: 0.0875 - val_accuracy: 0.9666\n","Epoch 72/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.9830 - val_loss: 0.0871 - val_accuracy: 0.9638\n","Epoch 73/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9842 - val_loss: 0.0825 - val_accuracy: 0.9666\n","Epoch 74/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9842 - val_loss: 0.0860 - val_accuracy: 0.9666\n","Epoch 75/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9824 - val_loss: 0.0831 - val_accuracy: 0.9721\n","Epoch 76/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9830 - val_loss: 0.0854 - val_accuracy: 0.9638\n","Epoch 77/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9848 - val_loss: 0.0870 - val_accuracy: 0.9666\n","Epoch 78/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9833 - val_loss: 0.0813 - val_accuracy: 0.9721\n","Epoch 79/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9842 - val_loss: 0.0866 - val_accuracy: 0.9638\n","Epoch 80/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9836 - val_loss: 0.0813 - val_accuracy: 0.9749\n","Epoch 81/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9830 - val_loss: 0.0899 - val_accuracy: 0.9666\n","Epoch 82/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9830 - val_loss: 0.0849 - val_accuracy: 0.9638\n","Epoch 83/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9811 - val_loss: 0.0833 - val_accuracy: 0.9666\n","Epoch 84/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0416 - accuracy: 0.9836 - val_loss: 0.0847 - val_accuracy: 0.9666\n","Epoch 85/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9839 - val_loss: 0.0920 - val_accuracy: 0.9638\n","Epoch 86/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9842 - val_loss: 0.0860 - val_accuracy: 0.9666\n","Epoch 87/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9854 - val_loss: 0.0820 - val_accuracy: 0.9666\n","Epoch 88/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9854 - val_loss: 0.0891 - val_accuracy: 0.9721\n","Epoch 89/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9845 - val_loss: 0.0863 - val_accuracy: 0.9666\n","Epoch 90/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9854 - val_loss: 0.0856 - val_accuracy: 0.9610\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.98      0.97       266\n","           1       0.94      0.90      0.92        93\n","\n","    accuracy                           0.96       359\n","   macro avg       0.96      0.94      0.95       359\n","weighted avg       0.96      0.96      0.96       359\n","\n","Accuracy: 0.9610027855153204\n","[[261   5]\n"," [  9  84]]\n","Precision: 0.9438\n","Recall: 0.9032\n","F1 Score: 0.9231\n","INFO:tensorflow:Assets written to: ram://2d5a335b-3f0a-42f2-98dc-dd1f249874ba/assets\n","model 4 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.4010 - accuracy: 0.8443 - val_loss: 0.2709 - val_accuracy: 0.9053\n","Epoch 2/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.2463 - accuracy: 0.9108 - val_loss: 0.2333 - val_accuracy: 0.9109\n","Epoch 3/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.2162 - accuracy: 0.9115 - val_loss: 0.2166 - val_accuracy: 0.9053\n","Epoch 4/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.2029 - accuracy: 0.9111 - val_loss: 0.2090 - val_accuracy: 0.9109\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1939 - accuracy: 0.9192 - val_loss: 0.2002 - val_accuracy: 0.9164\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1874 - accuracy: 0.9220 - val_loss: 0.1957 - val_accuracy: 0.9192\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1832 - accuracy: 0.9211 - val_loss: 0.1950 - val_accuracy: 0.9136\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1781 - accuracy: 0.9229 - val_loss: 0.1867 - val_accuracy: 0.9248\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1727 - accuracy: 0.9257 - val_loss: 0.1862 - val_accuracy: 0.9248\n","Epoch 10/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1687 - accuracy: 0.9272 - val_loss: 0.1800 - val_accuracy: 0.9220\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1645 - accuracy: 0.9279 - val_loss: 0.1803 - val_accuracy: 0.9192\n","Epoch 12/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1601 - accuracy: 0.9282 - val_loss: 0.1693 - val_accuracy: 0.9220\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1562 - accuracy: 0.9285 - val_loss: 0.1640 - val_accuracy: 0.9248\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1514 - accuracy: 0.9307 - val_loss: 0.1635 - val_accuracy: 0.9220\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9307 - val_loss: 0.1561 - val_accuracy: 0.9220\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9313 - val_loss: 0.1499 - val_accuracy: 0.9276\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9331 - val_loss: 0.1524 - val_accuracy: 0.9304\n","Epoch 18/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1306 - accuracy: 0.9390 - val_loss: 0.1487 - val_accuracy: 0.9359\n","Epoch 19/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9461 - val_loss: 0.1401 - val_accuracy: 0.9499\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9505 - val_loss: 0.1407 - val_accuracy: 0.9471\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1172 - accuracy: 0.9548 - val_loss: 0.1348 - val_accuracy: 0.9694\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9576 - val_loss: 0.1330 - val_accuracy: 0.9582\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1120 - accuracy: 0.9591 - val_loss: 0.1296 - val_accuracy: 0.9666\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9616 - val_loss: 0.1313 - val_accuracy: 0.9610\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1073 - accuracy: 0.9641 - val_loss: 0.1232 - val_accuracy: 0.9666\n","Epoch 26/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1060 - accuracy: 0.9644 - val_loss: 0.1260 - val_accuracy: 0.9638\n","Epoch 27/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1035 - accuracy: 0.9672 - val_loss: 0.1267 - val_accuracy: 0.9610\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1015 - accuracy: 0.9641 - val_loss: 0.1206 - val_accuracy: 0.9694\n","Epoch 29/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0989 - accuracy: 0.9678 - val_loss: 0.1166 - val_accuracy: 0.9666\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0972 - accuracy: 0.9690 - val_loss: 0.1168 - val_accuracy: 0.9694\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0952 - accuracy: 0.9681 - val_loss: 0.1161 - val_accuracy: 0.9638\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9700 - val_loss: 0.1121 - val_accuracy: 0.9694\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0915 - accuracy: 0.9715 - val_loss: 0.1141 - val_accuracy: 0.9666\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0905 - accuracy: 0.9712 - val_loss: 0.1122 - val_accuracy: 0.9638\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0883 - accuracy: 0.9724 - val_loss: 0.1138 - val_accuracy: 0.9610\n","Epoch 36/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0879 - accuracy: 0.9718 - val_loss: 0.1107 - val_accuracy: 0.9666\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0864 - accuracy: 0.9731 - val_loss: 0.1105 - val_accuracy: 0.9666\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9724 - val_loss: 0.1059 - val_accuracy: 0.9666\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.9746 - val_loss: 0.1070 - val_accuracy: 0.9666\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9724 - val_loss: 0.1068 - val_accuracy: 0.9610\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9734 - val_loss: 0.1070 - val_accuracy: 0.9610\n","Epoch 42/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0797 - accuracy: 0.9762 - val_loss: 0.0996 - val_accuracy: 0.9666\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9749 - val_loss: 0.1010 - val_accuracy: 0.9694\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9746 - val_loss: 0.0988 - val_accuracy: 0.9694\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0762 - accuracy: 0.9752 - val_loss: 0.0954 - val_accuracy: 0.9721\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0758 - accuracy: 0.9762 - val_loss: 0.0989 - val_accuracy: 0.9666\n","Epoch 47/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0734 - accuracy: 0.9777 - val_loss: 0.1002 - val_accuracy: 0.9666\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0733 - accuracy: 0.9768 - val_loss: 0.0960 - val_accuracy: 0.9666\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9780 - val_loss: 0.0924 - val_accuracy: 0.9749\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9786 - val_loss: 0.0961 - val_accuracy: 0.9666\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9789 - val_loss: 0.0919 - val_accuracy: 0.9694\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9802 - val_loss: 0.0951 - val_accuracy: 0.9694\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9805 - val_loss: 0.0907 - val_accuracy: 0.9694\n","Epoch 54/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9799 - val_loss: 0.0912 - val_accuracy: 0.9694\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9799 - val_loss: 0.0933 - val_accuracy: 0.9666\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9789 - val_loss: 0.0908 - val_accuracy: 0.9694\n","Epoch 57/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9808 - val_loss: 0.0892 - val_accuracy: 0.9694\n","Epoch 58/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9808 - val_loss: 0.0879 - val_accuracy: 0.9694\n","Epoch 59/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9824 - val_loss: 0.0881 - val_accuracy: 0.9694\n","Epoch 60/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9814 - val_loss: 0.0831 - val_accuracy: 0.9721\n","Epoch 61/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9808 - val_loss: 0.0882 - val_accuracy: 0.9694\n","Epoch 62/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9811 - val_loss: 0.0858 - val_accuracy: 0.9721\n","Epoch 63/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9817 - val_loss: 0.0845 - val_accuracy: 0.9694\n","Epoch 64/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9817 - val_loss: 0.0869 - val_accuracy: 0.9721\n","Epoch 65/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.9814 - val_loss: 0.0913 - val_accuracy: 0.9666\n","Epoch 66/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9820 - val_loss: 0.0903 - val_accuracy: 0.9694\n","Epoch 67/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9814 - val_loss: 0.0849 - val_accuracy: 0.9721\n","Epoch 68/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9817 - val_loss: 0.0832 - val_accuracy: 0.9721\n","Epoch 69/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9836 - val_loss: 0.0892 - val_accuracy: 0.9694\n","Epoch 70/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9824 - val_loss: 0.0838 - val_accuracy: 0.9721\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.99      0.98       284\n","           1       0.95      0.92      0.93        75\n","\n","    accuracy                           0.97       359\n","   macro avg       0.96      0.95      0.96       359\n","weighted avg       0.97      0.97      0.97       359\n","\n","Accuracy: 0.9721448467966574\n","[[280   4]\n"," [  6  69]]\n","Precision: 0.9452\n","Recall: 0.9200\n","F1 Score: 0.9324\n","INFO:tensorflow:Assets written to: ram://d47755cf-c922-4dbc-a1be-1e76c5ab11f3/assets\n","model 5 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.2980 - accuracy: 0.8712 - val_loss: 0.1975 - val_accuracy: 0.9304\n","Epoch 2/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1942 - accuracy: 0.9204 - val_loss: 0.1676 - val_accuracy: 0.9526\n","Epoch 3/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1690 - accuracy: 0.9328 - val_loss: 0.1516 - val_accuracy: 0.9499\n","Epoch 4/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1533 - accuracy: 0.9452 - val_loss: 0.1387 - val_accuracy: 0.9610\n","Epoch 5/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9464 - val_loss: 0.1281 - val_accuracy: 0.9666\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1363 - accuracy: 0.9517 - val_loss: 0.1214 - val_accuracy: 0.9638\n","Epoch 7/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1289 - accuracy: 0.9539 - val_loss: 0.1150 - val_accuracy: 0.9638\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1233 - accuracy: 0.9545 - val_loss: 0.1087 - val_accuracy: 0.9610\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9576 - val_loss: 0.1033 - val_accuracy: 0.9694\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9588 - val_loss: 0.0996 - val_accuracy: 0.9610\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9616 - val_loss: 0.0964 - val_accuracy: 0.9833\n","Epoch 12/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1059 - accuracy: 0.9622 - val_loss: 0.0925 - val_accuracy: 0.9777\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1023 - accuracy: 0.9644 - val_loss: 0.0876 - val_accuracy: 0.9777\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.9650 - val_loss: 0.0864 - val_accuracy: 0.9833\n","Epoch 15/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0967 - accuracy: 0.9669 - val_loss: 0.0814 - val_accuracy: 0.9749\n","Epoch 16/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0954 - accuracy: 0.9666 - val_loss: 0.0785 - val_accuracy: 0.9805\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0924 - accuracy: 0.9697 - val_loss: 0.0803 - val_accuracy: 0.9777\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0894 - accuracy: 0.9703 - val_loss: 0.0776 - val_accuracy: 0.9805\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0880 - accuracy: 0.9703 - val_loss: 0.0717 - val_accuracy: 0.9833\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9712 - val_loss: 0.0717 - val_accuracy: 0.9833\n","Epoch 21/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0841 - accuracy: 0.9712 - val_loss: 0.0705 - val_accuracy: 0.9805\n","Epoch 22/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0824 - accuracy: 0.9706 - val_loss: 0.0657 - val_accuracy: 0.9833\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9715 - val_loss: 0.0730 - val_accuracy: 0.9805\n","Epoch 24/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 0.9724 - val_loss: 0.0669 - val_accuracy: 0.9833\n","Epoch 25/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0778 - accuracy: 0.9731 - val_loss: 0.0657 - val_accuracy: 0.9833\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9749 - val_loss: 0.0661 - val_accuracy: 0.9805\n","Epoch 27/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0749 - accuracy: 0.9740 - val_loss: 0.0586 - val_accuracy: 0.9833\n","Epoch 28/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.9752 - val_loss: 0.0611 - val_accuracy: 0.9833\n","Epoch 29/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9743 - val_loss: 0.0601 - val_accuracy: 0.9833\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.9749 - val_loss: 0.0597 - val_accuracy: 0.9833\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9752 - val_loss: 0.0590 - val_accuracy: 0.9833\n","Epoch 32/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.9768 - val_loss: 0.0564 - val_accuracy: 0.9833\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.9777 - val_loss: 0.0538 - val_accuracy: 0.9833\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9765 - val_loss: 0.0538 - val_accuracy: 0.9833\n","Epoch 35/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9771 - val_loss: 0.0516 - val_accuracy: 0.9861\n","Epoch 36/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9768 - val_loss: 0.0528 - val_accuracy: 0.9861\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9774 - val_loss: 0.0501 - val_accuracy: 0.9833\n","Epoch 38/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9762 - val_loss: 0.0504 - val_accuracy: 0.9833\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9774 - val_loss: 0.0494 - val_accuracy: 0.9833\n","Epoch 40/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9783 - val_loss: 0.0486 - val_accuracy: 0.9833\n","Epoch 41/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9786 - val_loss: 0.0475 - val_accuracy: 0.9833\n","Epoch 42/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9777 - val_loss: 0.0491 - val_accuracy: 0.9833\n","Epoch 43/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9786 - val_loss: 0.0475 - val_accuracy: 0.9833\n","Epoch 44/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9783 - val_loss: 0.0441 - val_accuracy: 0.9861\n","Epoch 45/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9796 - val_loss: 0.0431 - val_accuracy: 0.9861\n","Epoch 46/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.9789 - val_loss: 0.0441 - val_accuracy: 0.9861\n","Epoch 47/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.9789 - val_loss: 0.0430 - val_accuracy: 0.9861\n","Epoch 48/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9777 - val_loss: 0.0426 - val_accuracy: 0.9889\n","Epoch 49/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.9796 - val_loss: 0.0460 - val_accuracy: 0.9833\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9793 - val_loss: 0.0421 - val_accuracy: 0.9889\n","Epoch 51/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9789 - val_loss: 0.0442 - val_accuracy: 0.9861\n","Epoch 52/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9796 - val_loss: 0.0418 - val_accuracy: 0.9889\n","Epoch 53/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9808 - val_loss: 0.0394 - val_accuracy: 0.9889\n","Epoch 54/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9799 - val_loss: 0.0410 - val_accuracy: 0.9889\n","Epoch 55/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9811 - val_loss: 0.0374 - val_accuracy: 0.9889\n","Epoch 56/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9805 - val_loss: 0.0414 - val_accuracy: 0.9861\n","Epoch 57/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9817 - val_loss: 0.0372 - val_accuracy: 0.9889\n","Epoch 58/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9811 - val_loss: 0.0377 - val_accuracy: 0.9889\n","Epoch 59/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9799 - val_loss: 0.0388 - val_accuracy: 0.9916\n","Epoch 60/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9817 - val_loss: 0.0375 - val_accuracy: 0.9889\n","Epoch 61/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9824 - val_loss: 0.0355 - val_accuracy: 0.9889\n","Epoch 62/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9817 - val_loss: 0.0347 - val_accuracy: 0.9889\n","Epoch 63/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9827 - val_loss: 0.0388 - val_accuracy: 0.9889\n","Epoch 64/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9839 - val_loss: 0.0373 - val_accuracy: 0.9889\n","Epoch 65/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9827 - val_loss: 0.0355 - val_accuracy: 0.9889\n","Epoch 66/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9836 - val_loss: 0.0333 - val_accuracy: 0.9889\n","Epoch 67/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9836 - val_loss: 0.0336 - val_accuracy: 0.9889\n","Epoch 68/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9830 - val_loss: 0.0345 - val_accuracy: 0.9861\n","Epoch 69/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 0.9827 - val_loss: 0.0329 - val_accuracy: 0.9889\n","Epoch 70/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 0.9833 - val_loss: 0.0316 - val_accuracy: 0.9889\n","Epoch 71/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9836 - val_loss: 0.0335 - val_accuracy: 0.9889\n","Epoch 72/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9836 - val_loss: 0.0326 - val_accuracy: 0.9861\n","Epoch 73/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9845 - val_loss: 0.0305 - val_accuracy: 0.9916\n","Epoch 74/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0426 - accuracy: 0.9848 - val_loss: 0.0337 - val_accuracy: 0.9861\n","Epoch 75/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9833 - val_loss: 0.0308 - val_accuracy: 0.9916\n","Epoch 76/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9848 - val_loss: 0.0289 - val_accuracy: 0.9916\n","Epoch 77/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9842 - val_loss: 0.0318 - val_accuracy: 0.9889\n","Epoch 78/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9845 - val_loss: 0.0313 - val_accuracy: 0.9916\n","Epoch 79/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.9858 - val_loss: 0.0282 - val_accuracy: 0.9889\n","Epoch 80/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9854 - val_loss: 0.0284 - val_accuracy: 0.9889\n","Epoch 81/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9858 - val_loss: 0.0289 - val_accuracy: 0.9889\n","Epoch 82/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9839 - val_loss: 0.0300 - val_accuracy: 0.9889\n","Epoch 83/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.9864 - val_loss: 0.0301 - val_accuracy: 0.9889\n","Epoch 84/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9848 - val_loss: 0.0305 - val_accuracy: 0.9889\n","Epoch 85/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9851 - val_loss: 0.0267 - val_accuracy: 0.9889\n","Epoch 86/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9851 - val_loss: 0.0266 - val_accuracy: 0.9916\n","Epoch 87/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9864 - val_loss: 0.0301 - val_accuracy: 0.9889\n","Epoch 88/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9861 - val_loss: 0.0269 - val_accuracy: 0.9861\n","Epoch 89/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9873 - val_loss: 0.0283 - val_accuracy: 0.9944\n","Epoch 90/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9858 - val_loss: 0.0294 - val_accuracy: 0.9889\n","Epoch 91/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9870 - val_loss: 0.0269 - val_accuracy: 0.9916\n","Epoch 92/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9870 - val_loss: 0.0256 - val_accuracy: 0.9944\n","Epoch 93/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9858 - val_loss: 0.0278 - val_accuracy: 0.9889\n","Epoch 94/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9836 - val_loss: 0.0252 - val_accuracy: 0.9889\n","Epoch 95/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9854 - val_loss: 0.0249 - val_accuracy: 0.9916\n","Epoch 96/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9867 - val_loss: 0.0260 - val_accuracy: 0.9889\n","Epoch 97/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.9867 - val_loss: 0.0251 - val_accuracy: 0.9944\n","Epoch 98/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9870 - val_loss: 0.0245 - val_accuracy: 0.9916\n","Epoch 99/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0355 - accuracy: 0.9867 - val_loss: 0.0269 - val_accuracy: 0.9889\n","Epoch 100/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 0.9861 - val_loss: 0.0241 - val_accuracy: 0.9916\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99       271\n","           1       0.98      0.99      0.98        88\n","\n","    accuracy                           0.99       359\n","   macro avg       0.99      0.99      0.99       359\n","weighted avg       0.99      0.99      0.99       359\n","\n","Accuracy: 0.9916434540389972\n","[[269   2]\n"," [  1  87]]\n","Precision: 0.9775\n","Recall: 0.9886\n","F1 Score: 0.9831\n","INFO:tensorflow:Assets written to: ram://6649fa76-b833-40c3-80e5-73735e1c151b/assets\n","model 6 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.4461 - accuracy: 0.8269 - val_loss: 0.3040 - val_accuracy: 0.9053\n","Epoch 2/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.2608 - accuracy: 0.8932 - val_loss: 0.2031 - val_accuracy: 0.9276\n","Epoch 3/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.2040 - accuracy: 0.9161 - val_loss: 0.1726 - val_accuracy: 0.9415\n","Epoch 4/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1815 - accuracy: 0.9285 - val_loss: 0.1562 - val_accuracy: 0.9499\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1669 - accuracy: 0.9316 - val_loss: 0.1428 - val_accuracy: 0.9526\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1558 - accuracy: 0.9381 - val_loss: 0.1330 - val_accuracy: 0.9526\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9415 - val_loss: 0.1252 - val_accuracy: 0.9582\n","Epoch 8/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1400 - accuracy: 0.9474 - val_loss: 0.1214 - val_accuracy: 0.9554\n","Epoch 9/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1335 - accuracy: 0.9492 - val_loss: 0.1204 - val_accuracy: 0.9638\n","Epoch 10/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1268 - accuracy: 0.9489 - val_loss: 0.1084 - val_accuracy: 0.9666\n","Epoch 11/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9560 - val_loss: 0.1038 - val_accuracy: 0.9666\n","Epoch 12/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1177 - accuracy: 0.9567 - val_loss: 0.0998 - val_accuracy: 0.9666\n","Epoch 13/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1149 - accuracy: 0.9567 - val_loss: 0.0963 - val_accuracy: 0.9666\n","Epoch 14/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1111 - accuracy: 0.9625 - val_loss: 0.0997 - val_accuracy: 0.9721\n","Epoch 15/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9607 - val_loss: 0.0914 - val_accuracy: 0.9666\n","Epoch 16/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1053 - accuracy: 0.9622 - val_loss: 0.0891 - val_accuracy: 0.9721\n","Epoch 17/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1026 - accuracy: 0.9650 - val_loss: 0.0875 - val_accuracy: 0.9749\n","Epoch 18/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0979 - accuracy: 0.9653 - val_loss: 0.0909 - val_accuracy: 0.9749\n","Epoch 19/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0947 - accuracy: 0.9681 - val_loss: 0.0862 - val_accuracy: 0.9749\n","Epoch 20/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0938 - accuracy: 0.9659 - val_loss: 0.0794 - val_accuracy: 0.9749\n","Epoch 21/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0906 - accuracy: 0.9693 - val_loss: 0.0788 - val_accuracy: 0.9749\n","Epoch 22/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0886 - accuracy: 0.9684 - val_loss: 0.0820 - val_accuracy: 0.9749\n","Epoch 23/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9721 - val_loss: 0.0810 - val_accuracy: 0.9749\n","Epoch 24/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0853 - accuracy: 0.9721 - val_loss: 0.0734 - val_accuracy: 0.9749\n","Epoch 25/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0841 - accuracy: 0.9721 - val_loss: 0.0748 - val_accuracy: 0.9749\n","Epoch 26/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.9746 - val_loss: 0.0756 - val_accuracy: 0.9749\n","Epoch 27/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0796 - accuracy: 0.9737 - val_loss: 0.0702 - val_accuracy: 0.9777\n","Epoch 28/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0779 - accuracy: 0.9762 - val_loss: 0.0685 - val_accuracy: 0.9777\n","Epoch 29/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0766 - accuracy: 0.9749 - val_loss: 0.0676 - val_accuracy: 0.9805\n","Epoch 30/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0767 - accuracy: 0.9743 - val_loss: 0.0667 - val_accuracy: 0.9805\n","Epoch 31/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 0.9743 - val_loss: 0.0655 - val_accuracy: 0.9777\n","Epoch 32/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.9755 - val_loss: 0.0691 - val_accuracy: 0.9777\n","Epoch 33/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9777 - val_loss: 0.0661 - val_accuracy: 0.9777\n","Epoch 34/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.9759 - val_loss: 0.0631 - val_accuracy: 0.9777\n","Epoch 35/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9771 - val_loss: 0.0622 - val_accuracy: 0.9805\n","Epoch 36/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.9762 - val_loss: 0.0639 - val_accuracy: 0.9805\n","Epoch 37/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9780 - val_loss: 0.0603 - val_accuracy: 0.9805\n","Epoch 38/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9774 - val_loss: 0.0611 - val_accuracy: 0.9805\n","Epoch 39/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9777 - val_loss: 0.0693 - val_accuracy: 0.9749\n","Epoch 40/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.9765 - val_loss: 0.0629 - val_accuracy: 0.9777\n","Epoch 41/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9780 - val_loss: 0.0591 - val_accuracy: 0.9805\n","Epoch 42/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.9780 - val_loss: 0.0565 - val_accuracy: 0.9805\n","Epoch 43/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.9789 - val_loss: 0.0607 - val_accuracy: 0.9777\n","Epoch 44/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9765 - val_loss: 0.0542 - val_accuracy: 0.9805\n","Epoch 45/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9799 - val_loss: 0.0542 - val_accuracy: 0.9805\n","Epoch 46/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9793 - val_loss: 0.0565 - val_accuracy: 0.9777\n","Epoch 47/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9796 - val_loss: 0.0520 - val_accuracy: 0.9805\n","Epoch 48/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9799 - val_loss: 0.0508 - val_accuracy: 0.9805\n","Epoch 49/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9802 - val_loss: 0.0523 - val_accuracy: 0.9805\n","Epoch 50/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.9793 - val_loss: 0.0520 - val_accuracy: 0.9777\n","Epoch 51/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9811 - val_loss: 0.0494 - val_accuracy: 0.9805\n","Epoch 52/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9802 - val_loss: 0.0500 - val_accuracy: 0.9805\n","Epoch 53/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9811 - val_loss: 0.0484 - val_accuracy: 0.9833\n","Epoch 54/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.9811 - val_loss: 0.0490 - val_accuracy: 0.9805\n","Epoch 55/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.9811 - val_loss: 0.0485 - val_accuracy: 0.9833\n","Epoch 56/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.9811 - val_loss: 0.0458 - val_accuracy: 0.9805\n","Epoch 57/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0541 - accuracy: 0.9817 - val_loss: 0.0461 - val_accuracy: 0.9805\n","Epoch 58/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9814 - val_loss: 0.0443 - val_accuracy: 0.9833\n","Epoch 59/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9814 - val_loss: 0.0495 - val_accuracy: 0.9833\n","Epoch 60/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.9839 - val_loss: 0.0448 - val_accuracy: 0.9805\n","Epoch 61/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 0.9820 - val_loss: 0.0491 - val_accuracy: 0.9777\n","Epoch 62/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9811 - val_loss: 0.0426 - val_accuracy: 0.9833\n","Epoch 63/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.9824 - val_loss: 0.0419 - val_accuracy: 0.9861\n","Epoch 64/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.9824 - val_loss: 0.0411 - val_accuracy: 0.9861\n","Epoch 65/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9824 - val_loss: 0.0408 - val_accuracy: 0.9861\n","Epoch 66/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0500 - accuracy: 0.9814 - val_loss: 0.0404 - val_accuracy: 0.9861\n","Epoch 67/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9830 - val_loss: 0.0421 - val_accuracy: 0.9861\n","Epoch 68/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9817 - val_loss: 0.0409 - val_accuracy: 0.9861\n","Epoch 69/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9827 - val_loss: 0.0420 - val_accuracy: 0.9861\n","Epoch 70/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.0474 - accuracy: 0.9845 - val_loss: 0.0392 - val_accuracy: 0.9861\n","Epoch 71/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.0482 - accuracy: 0.9836 - val_loss: 0.0432 - val_accuracy: 0.9889\n","Epoch 72/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.0476 - accuracy: 0.9851 - val_loss: 0.0405 - val_accuracy: 0.9861\n","Epoch 73/100\n","101/101 [==============================] - 1s 6ms/step - loss: 0.0468 - accuracy: 0.9851 - val_loss: 0.0369 - val_accuracy: 0.9861\n","Epoch 74/100\n","101/101 [==============================] - 0s 5ms/step - loss: 0.0473 - accuracy: 0.9845 - val_loss: 0.0369 - val_accuracy: 0.9861\n","Epoch 75/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.0457 - accuracy: 0.9842 - val_loss: 0.0368 - val_accuracy: 0.9861\n","Epoch 76/100\n","101/101 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.9851 - val_loss: 0.0472 - val_accuracy: 0.9833\n","Epoch 77/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9848 - val_loss: 0.0363 - val_accuracy: 0.9861\n","Epoch 78/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.0369 - val_accuracy: 0.9861\n","Epoch 79/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9858 - val_loss: 0.0388 - val_accuracy: 0.9861\n","Epoch 80/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0436 - accuracy: 0.9839 - val_loss: 0.0346 - val_accuracy: 0.9861\n","Epoch 81/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9842 - val_loss: 0.0346 - val_accuracy: 0.9861\n","Epoch 82/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9861 - val_loss: 0.0343 - val_accuracy: 0.9861\n","Epoch 83/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9858 - val_loss: 0.0374 - val_accuracy: 0.9861\n","Epoch 84/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9854 - val_loss: 0.0337 - val_accuracy: 0.9861\n","Epoch 85/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9870 - val_loss: 0.0330 - val_accuracy: 0.9861\n","Epoch 86/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9861 - val_loss: 0.0314 - val_accuracy: 0.9889\n","Epoch 87/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9858 - val_loss: 0.0355 - val_accuracy: 0.9889\n","Epoch 88/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9858 - val_loss: 0.0341 - val_accuracy: 0.9889\n","Epoch 89/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9851 - val_loss: 0.0302 - val_accuracy: 0.9889\n","Epoch 90/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9851 - val_loss: 0.0359 - val_accuracy: 0.9889\n","Epoch 91/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9867 - val_loss: 0.0324 - val_accuracy: 0.9861\n","Epoch 92/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9867 - val_loss: 0.0340 - val_accuracy: 0.9861\n","Epoch 93/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9864 - val_loss: 0.0358 - val_accuracy: 0.9889\n","Epoch 94/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9854 - val_loss: 0.0351 - val_accuracy: 0.9861\n","Epoch 95/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9870 - val_loss: 0.0374 - val_accuracy: 0.9861\n","Epoch 96/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9867 - val_loss: 0.0332 - val_accuracy: 0.9861\n","Epoch 97/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 0.0328 - val_accuracy: 0.9889\n","Epoch 98/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9861 - val_loss: 0.0347 - val_accuracy: 0.9889\n","Epoch 99/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.9864 - val_loss: 0.0295 - val_accuracy: 0.9889\n","Epoch 100/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0367 - accuracy: 0.9879 - val_loss: 0.0291 - val_accuracy: 0.9861\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.99      0.99       268\n","           1       0.97      0.98      0.97        91\n","\n","    accuracy                           0.99       359\n","   macro avg       0.98      0.98      0.98       359\n","weighted avg       0.99      0.99      0.99       359\n","\n","Accuracy: 0.9860724233983287\n","[[265   3]\n"," [  2  89]]\n","Precision: 0.9674\n","Recall: 0.9780\n","F1 Score: 0.9727\n","INFO:tensorflow:Assets written to: ram://90cfeee7-3023-4d72-a589-b84f3e7a7491/assets\n","model 7 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.3353 - accuracy: 0.8529 - val_loss: 0.2296 - val_accuracy: 0.8942\n","Epoch 2/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.2127 - accuracy: 0.9087 - val_loss: 0.1955 - val_accuracy: 0.9220\n","Epoch 3/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1871 - accuracy: 0.9220 - val_loss: 0.1681 - val_accuracy: 0.9220\n","Epoch 4/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1683 - accuracy: 0.9350 - val_loss: 0.1530 - val_accuracy: 0.9248\n","Epoch 5/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1539 - accuracy: 0.9372 - val_loss: 0.1393 - val_accuracy: 0.9359\n","Epoch 6/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1433 - accuracy: 0.9446 - val_loss: 0.1363 - val_accuracy: 0.9359\n","Epoch 7/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1363 - accuracy: 0.9502 - val_loss: 0.1244 - val_accuracy: 0.9526\n","Epoch 8/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.9520 - val_loss: 0.1214 - val_accuracy: 0.9443\n","Epoch 9/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1229 - accuracy: 0.9585 - val_loss: 0.1217 - val_accuracy: 0.9387\n","Epoch 10/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1185 - accuracy: 0.9573 - val_loss: 0.1102 - val_accuracy: 0.9582\n","Epoch 11/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 0.9567 - val_loss: 0.1058 - val_accuracy: 0.9638\n","Epoch 12/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.9607 - val_loss: 0.1030 - val_accuracy: 0.9610\n","Epoch 13/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1064 - accuracy: 0.9635 - val_loss: 0.1070 - val_accuracy: 0.9610\n","Epoch 14/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1039 - accuracy: 0.9638 - val_loss: 0.1006 - val_accuracy: 0.9638\n","Epoch 15/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1014 - accuracy: 0.9653 - val_loss: 0.0972 - val_accuracy: 0.9638\n","Epoch 16/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0979 - accuracy: 0.9675 - val_loss: 0.0944 - val_accuracy: 0.9666\n","Epoch 17/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9672 - val_loss: 0.0955 - val_accuracy: 0.9694\n","Epoch 18/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0948 - accuracy: 0.9672 - val_loss: 0.0896 - val_accuracy: 0.9694\n","Epoch 19/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0917 - accuracy: 0.9684 - val_loss: 0.0921 - val_accuracy: 0.9694\n","Epoch 20/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0909 - accuracy: 0.9678 - val_loss: 0.0872 - val_accuracy: 0.9721\n","Epoch 21/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0892 - accuracy: 0.9669 - val_loss: 0.0878 - val_accuracy: 0.9694\n","Epoch 22/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9700 - val_loss: 0.0874 - val_accuracy: 0.9721\n","Epoch 23/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9684 - val_loss: 0.0831 - val_accuracy: 0.9721\n","Epoch 24/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0831 - accuracy: 0.9724 - val_loss: 0.0912 - val_accuracy: 0.9638\n","Epoch 25/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.9703 - val_loss: 0.0880 - val_accuracy: 0.9694\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9724 - val_loss: 0.0829 - val_accuracy: 0.9694\n","Epoch 27/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0807 - accuracy: 0.9706 - val_loss: 0.0818 - val_accuracy: 0.9694\n","Epoch 28/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.9693 - val_loss: 0.0766 - val_accuracy: 0.9721\n","Epoch 29/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.9731 - val_loss: 0.0758 - val_accuracy: 0.9749\n","Epoch 30/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0755 - accuracy: 0.9728 - val_loss: 0.0958 - val_accuracy: 0.9694\n","Epoch 31/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0752 - accuracy: 0.9746 - val_loss: 0.0785 - val_accuracy: 0.9694\n","Epoch 32/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0729 - accuracy: 0.9728 - val_loss: 0.0754 - val_accuracy: 0.9721\n","Epoch 33/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0728 - accuracy: 0.9762 - val_loss: 0.0855 - val_accuracy: 0.9749\n","Epoch 34/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9749 - val_loss: 0.0731 - val_accuracy: 0.9694\n","Epoch 35/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9749 - val_loss: 0.0720 - val_accuracy: 0.9777\n","Epoch 36/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9752 - val_loss: 0.0738 - val_accuracy: 0.9749\n","Epoch 37/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9768 - val_loss: 0.0741 - val_accuracy: 0.9749\n","Epoch 38/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9771 - val_loss: 0.0752 - val_accuracy: 0.9749\n","Epoch 39/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9768 - val_loss: 0.0685 - val_accuracy: 0.9749\n","Epoch 40/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9755 - val_loss: 0.0674 - val_accuracy: 0.9749\n","Epoch 41/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9799 - val_loss: 0.0691 - val_accuracy: 0.9777\n","Epoch 42/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.9765 - val_loss: 0.0652 - val_accuracy: 0.9721\n","Epoch 43/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9783 - val_loss: 0.0650 - val_accuracy: 0.9721\n","Epoch 44/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9780 - val_loss: 0.0677 - val_accuracy: 0.9777\n","Epoch 45/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9783 - val_loss: 0.0655 - val_accuracy: 0.9749\n","Epoch 46/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.9777 - val_loss: 0.0680 - val_accuracy: 0.9749\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9771 - val_loss: 0.0648 - val_accuracy: 0.9749\n","Epoch 48/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.9802 - val_loss: 0.0719 - val_accuracy: 0.9777\n","Epoch 49/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.9802 - val_loss: 0.0657 - val_accuracy: 0.9749\n","Epoch 50/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9783 - val_loss: 0.0632 - val_accuracy: 0.9721\n","Epoch 51/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9768 - val_loss: 0.0589 - val_accuracy: 0.9777\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9802 - val_loss: 0.0667 - val_accuracy: 0.9694\n","Epoch 53/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.9808 - val_loss: 0.0598 - val_accuracy: 0.9749\n","Epoch 54/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9799 - val_loss: 0.0599 - val_accuracy: 0.9694\n","Epoch 55/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.9805 - val_loss: 0.0620 - val_accuracy: 0.9694\n","Epoch 56/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9824 - val_loss: 0.0705 - val_accuracy: 0.9777\n","Epoch 57/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.9814 - val_loss: 0.0616 - val_accuracy: 0.9694\n","Epoch 58/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9799 - val_loss: 0.0614 - val_accuracy: 0.9721\n","Epoch 59/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0525 - accuracy: 0.9814 - val_loss: 0.0586 - val_accuracy: 0.9721\n","Epoch 60/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9799 - val_loss: 0.0571 - val_accuracy: 0.9694\n","Epoch 61/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9817 - val_loss: 0.0616 - val_accuracy: 0.9721\n","Epoch 62/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0492 - accuracy: 0.9814 - val_loss: 0.0572 - val_accuracy: 0.9721\n","Epoch 63/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9808 - val_loss: 0.0613 - val_accuracy: 0.9777\n","Epoch 64/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9814 - val_loss: 0.0654 - val_accuracy: 0.9694\n","Epoch 65/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9824 - val_loss: 0.0588 - val_accuracy: 0.9694\n","Epoch 66/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9811 - val_loss: 0.0711 - val_accuracy: 0.9749\n","Epoch 67/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9811 - val_loss: 0.0615 - val_accuracy: 0.9694\n","Epoch 68/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9827 - val_loss: 0.0562 - val_accuracy: 0.9721\n","Epoch 69/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.9842 - val_loss: 0.0565 - val_accuracy: 0.9805\n","Epoch 70/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0463 - accuracy: 0.9814 - val_loss: 0.0550 - val_accuracy: 0.9721\n","Epoch 71/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9827 - val_loss: 0.0568 - val_accuracy: 0.9805\n","Epoch 72/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9839 - val_loss: 0.0562 - val_accuracy: 0.9694\n","Epoch 73/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9820 - val_loss: 0.0571 - val_accuracy: 0.9777\n","Epoch 74/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9836 - val_loss: 0.0546 - val_accuracy: 0.9694\n","Epoch 75/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9845 - val_loss: 0.0500 - val_accuracy: 0.9777\n","Epoch 76/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9845 - val_loss: 0.0531 - val_accuracy: 0.9749\n","Epoch 77/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9845 - val_loss: 0.0570 - val_accuracy: 0.9721\n","Epoch 78/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.9839 - val_loss: 0.0601 - val_accuracy: 0.9833\n","Epoch 79/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9830 - val_loss: 0.0579 - val_accuracy: 0.9805\n","Epoch 80/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9858 - val_loss: 0.0625 - val_accuracy: 0.9805\n","Epoch 81/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9833 - val_loss: 0.0521 - val_accuracy: 0.9749\n","Epoch 82/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9845 - val_loss: 0.0494 - val_accuracy: 0.9777\n","Epoch 83/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9848 - val_loss: 0.0548 - val_accuracy: 0.9721\n","Epoch 84/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9833 - val_loss: 0.0705 - val_accuracy: 0.9749\n","Epoch 85/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9858 - val_loss: 0.0538 - val_accuracy: 0.9805\n","Epoch 86/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9861 - val_loss: 0.0498 - val_accuracy: 0.9833\n","Epoch 87/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9848 - val_loss: 0.0507 - val_accuracy: 0.9833\n","Epoch 88/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9858 - val_loss: 0.0554 - val_accuracy: 0.9749\n","Epoch 89/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.9854 - val_loss: 0.0569 - val_accuracy: 0.9833\n","Epoch 90/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.9854 - val_loss: 0.0500 - val_accuracy: 0.9833\n","Epoch 91/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9854 - val_loss: 0.0563 - val_accuracy: 0.9749\n","Epoch 92/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9858 - val_loss: 0.0537 - val_accuracy: 0.9805\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.99      0.99       277\n","           1       0.97      0.94      0.96        82\n","\n","    accuracy                           0.98       359\n","   macro avg       0.98      0.97      0.97       359\n","weighted avg       0.98      0.98      0.98       359\n","\n","Accuracy: 0.9805013927576601\n","[[275   2]\n"," [  5  77]]\n","Precision: 0.9747\n","Recall: 0.9390\n","F1 Score: 0.9565\n","INFO:tensorflow:Assets written to: ram://f22016f6-e31c-4f65-834b-482e9d65d66d/assets\n","model 8 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.3406 - accuracy: 0.8586 - val_loss: 0.2277 - val_accuracy: 0.9050\n","Epoch 2/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1939 - accuracy: 0.9341 - val_loss: 0.1887 - val_accuracy: 0.9330\n","Epoch 3/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1625 - accuracy: 0.9424 - val_loss: 0.1709 - val_accuracy: 0.9330\n","Epoch 4/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1465 - accuracy: 0.9486 - val_loss: 0.1614 - val_accuracy: 0.9385\n","Epoch 5/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1346 - accuracy: 0.9526 - val_loss: 0.1561 - val_accuracy: 0.9302\n","Epoch 6/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1269 - accuracy: 0.9520 - val_loss: 0.1519 - val_accuracy: 0.9385\n","Epoch 7/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9561 - val_loss: 0.1462 - val_accuracy: 0.9302\n","Epoch 8/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1109 - accuracy: 0.9629 - val_loss: 0.1485 - val_accuracy: 0.9358\n","Epoch 9/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1064 - accuracy: 0.9622 - val_loss: 0.1393 - val_accuracy: 0.9358\n","Epoch 10/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.1009 - accuracy: 0.9663 - val_loss: 0.1374 - val_accuracy: 0.9358\n","Epoch 11/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9672 - val_loss: 0.1350 - val_accuracy: 0.9358\n","Epoch 12/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0920 - accuracy: 0.9690 - val_loss: 0.1331 - val_accuracy: 0.9413\n","Epoch 13/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0895 - accuracy: 0.9700 - val_loss: 0.1326 - val_accuracy: 0.9497\n","Epoch 14/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0852 - accuracy: 0.9709 - val_loss: 0.1265 - val_accuracy: 0.9413\n","Epoch 15/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0832 - accuracy: 0.9715 - val_loss: 0.1286 - val_accuracy: 0.9385\n","Epoch 16/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.9731 - val_loss: 0.1317 - val_accuracy: 0.9497\n","Epoch 17/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9731 - val_loss: 0.1268 - val_accuracy: 0.9469\n","Epoch 18/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0765 - accuracy: 0.9737 - val_loss: 0.1239 - val_accuracy: 0.9497\n","Epoch 19/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0755 - accuracy: 0.9749 - val_loss: 0.1248 - val_accuracy: 0.9525\n","Epoch 20/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0728 - accuracy: 0.9740 - val_loss: 0.1257 - val_accuracy: 0.9525\n","Epoch 21/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 0.9734 - val_loss: 0.1166 - val_accuracy: 0.9525\n","Epoch 22/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.9759 - val_loss: 0.1171 - val_accuracy: 0.9553\n","Epoch 23/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.9755 - val_loss: 0.1169 - val_accuracy: 0.9525\n","Epoch 24/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9771 - val_loss: 0.1179 - val_accuracy: 0.9581\n","Epoch 25/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9771 - val_loss: 0.1187 - val_accuracy: 0.9525\n","Epoch 26/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9759 - val_loss: 0.1114 - val_accuracy: 0.9581\n","Epoch 27/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9783 - val_loss: 0.1129 - val_accuracy: 0.9581\n","Epoch 28/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9774 - val_loss: 0.1122 - val_accuracy: 0.9581\n","Epoch 29/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.9774 - val_loss: 0.1157 - val_accuracy: 0.9553\n","Epoch 30/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.9780 - val_loss: 0.1109 - val_accuracy: 0.9497\n","Epoch 31/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9783 - val_loss: 0.1111 - val_accuracy: 0.9525\n","Epoch 32/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.9796 - val_loss: 0.1132 - val_accuracy: 0.9553\n","Epoch 33/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.9793 - val_loss: 0.1121 - val_accuracy: 0.9581\n","Epoch 34/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9820 - val_loss: 0.1131 - val_accuracy: 0.9581\n","Epoch 35/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9790 - val_loss: 0.1159 - val_accuracy: 0.9553\n","Epoch 36/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9799 - val_loss: 0.1148 - val_accuracy: 0.9525\n","Epoch 37/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9817 - val_loss: 0.1081 - val_accuracy: 0.9581\n","Epoch 38/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.9817 - val_loss: 0.1078 - val_accuracy: 0.9553\n","Epoch 39/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9811 - val_loss: 0.1048 - val_accuracy: 0.9553\n","Epoch 40/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9824 - val_loss: 0.1047 - val_accuracy: 0.9553\n","Epoch 41/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9817 - val_loss: 0.1130 - val_accuracy: 0.9525\n","Epoch 42/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0491 - accuracy: 0.9817 - val_loss: 0.1028 - val_accuracy: 0.9581\n","Epoch 43/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9805 - val_loss: 0.1030 - val_accuracy: 0.9553\n","Epoch 44/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9817 - val_loss: 0.1026 - val_accuracy: 0.9637\n","Epoch 45/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9824 - val_loss: 0.1046 - val_accuracy: 0.9553\n","Epoch 46/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9833 - val_loss: 0.1052 - val_accuracy: 0.9609\n","Epoch 47/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9833 - val_loss: 0.0982 - val_accuracy: 0.9553\n","Epoch 48/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9830 - val_loss: 0.1017 - val_accuracy: 0.9553\n","Epoch 49/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 0.9820 - val_loss: 0.1023 - val_accuracy: 0.9553\n","Epoch 50/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.9839 - val_loss: 0.1015 - val_accuracy: 0.9581\n","Epoch 51/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9833 - val_loss: 0.1015 - val_accuracy: 0.9581\n","Epoch 52/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9824 - val_loss: 0.0998 - val_accuracy: 0.9525\n","Epoch 53/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9845 - val_loss: 0.0985 - val_accuracy: 0.9553\n","Epoch 54/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9827 - val_loss: 0.1022 - val_accuracy: 0.9581\n","Epoch 55/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.9827 - val_loss: 0.1049 - val_accuracy: 0.9553\n","Epoch 56/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 0.9842 - val_loss: 0.1009 - val_accuracy: 0.9553\n","Epoch 57/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9830 - val_loss: 0.1027 - val_accuracy: 0.9581\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.97      0.97       269\n","           1       0.92      0.91      0.92        89\n","\n","    accuracy                           0.96       358\n","   macro avg       0.95      0.94      0.94       358\n","weighted avg       0.96      0.96      0.96       358\n","\n","Accuracy: 0.9581005586592178\n","[[262   7]\n"," [  8  81]]\n","Precision: 0.9205\n","Recall: 0.9101\n","F1 Score: 0.9153\n","INFO:tensorflow:Assets written to: ram://221092b0-47e9-49e2-801a-0459f5525d2f/assets\n","model 9 saved\n","Average Validation Accuracy: 0.9757543455595151\n"]}]},{"cell_type":"code","source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/UNB/Binary/Models/URL/NN/model_6.h5'\n","\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","def predict_prob(number):\n","  return [number[0],1-number[0]]\n","\n","y_prob = np.array(list(map(predict_prob, loaded_model.predict(x_test))))\n","y_prob \n","\n","# y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['nn_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['nn_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545},"id":"dolEygpVsl_4","executionInfo":{"status":"ok","timestamp":1656485462125,"user_tz":-330,"elapsed":1619,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"af56148d-111a-4372-a1ac-8f3bdf03eb0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[4.11735529e-05 9.99958826e-01]\n"," [4.55413485e-12 1.00000000e+00]\n"," [9.99995064e-01 4.93597482e-06]\n"," ...\n"," [9.99999997e-01 2.56480135e-09]\n"," [9.99998836e-01 1.16405465e-06]\n"," [9.99994216e-01 5.78401868e-06]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  nn_prediction_non  \\\n","0          1        4.117355e-05          9.999588e-01       4.117355e-05   \n","1          1        4.554135e-12          1.000000e+00       4.554135e-12   \n","2          0        9.999951e-01          4.935975e-06       9.999951e-01   \n","3          0        1.000000e+00          2.150433e-19       1.000000e+00   \n","4          1        1.044356e-01          8.955644e-01       1.044356e-01   \n","...      ...                 ...                   ...                ...   \n","2933       1        3.264056e-14          1.000000e+00       3.264056e-14   \n","2934       0        9.980053e-01          1.994709e-03       9.980053e-01   \n","2935       0        1.000000e+00          2.564801e-09       1.000000e+00   \n","2936       0        9.999988e-01          1.164055e-06       9.999988e-01   \n","2937       0        9.999942e-01          5.784019e-06       9.999942e-01   \n","\n","      nn_prediction_phish  \n","0            9.999588e-01  \n","1            1.000000e+00  \n","2            4.935975e-06  \n","3            2.150433e-19  \n","4            8.955644e-01  \n","...                   ...  \n","2933         1.000000e+00  \n","2934         1.994709e-03  \n","2935         2.564801e-09  \n","2936         1.164055e-06  \n","2937         5.784019e-06  \n","\n","[2938 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-825b6d13-c74c-45e7-8da6-3d26e5756515\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>4.117355e-05</td>\n","      <td>9.999588e-01</td>\n","      <td>4.117355e-05</td>\n","      <td>9.999588e-01</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>4.554135e-12</td>\n","      <td>1.000000e+00</td>\n","      <td>4.554135e-12</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>9.999951e-01</td>\n","      <td>4.935975e-06</td>\n","      <td>9.999951e-01</td>\n","      <td>4.935975e-06</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>2.150433e-19</td>\n","      <td>1.000000e+00</td>\n","      <td>2.150433e-19</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1.044356e-01</td>\n","      <td>8.955644e-01</td>\n","      <td>1.044356e-01</td>\n","      <td>8.955644e-01</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2933</th>\n","      <td>1</td>\n","      <td>3.264056e-14</td>\n","      <td>1.000000e+00</td>\n","      <td>3.264056e-14</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>2934</th>\n","      <td>0</td>\n","      <td>9.980053e-01</td>\n","      <td>1.994709e-03</td>\n","      <td>9.980053e-01</td>\n","      <td>1.994709e-03</td>\n","    </tr>\n","    <tr>\n","      <th>2935</th>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>2.564801e-09</td>\n","      <td>1.000000e+00</td>\n","      <td>2.564801e-09</td>\n","    </tr>\n","    <tr>\n","      <th>2936</th>\n","      <td>0</td>\n","      <td>9.999988e-01</td>\n","      <td>1.164055e-06</td>\n","      <td>9.999988e-01</td>\n","      <td>1.164055e-06</td>\n","    </tr>\n","    <tr>\n","      <th>2937</th>\n","      <td>0</td>\n","      <td>9.999942e-01</td>\n","      <td>5.784019e-06</td>\n","      <td>9.999942e-01</td>\n","      <td>5.784019e-06</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2938 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-825b6d13-c74c-45e7-8da6-3d26e5756515')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-825b6d13-c74c-45e7-8da6-3d26e5756515 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-825b6d13-c74c-45e7-8da6-3d26e5756515');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["**Neural Network 2**"],"metadata":{"id":"fMdqVtYLwwy4"}},{"cell_type":"code","source":["\n","import keras\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","def model_a(x_train, x_val, y_train, y_val, opt, n, early_stopping_monitor):\n","\n","  n_cols = x_train.shape[1]\n","\n","  #create model\n","  model_2 = Sequential()\n","  model_2.add(Dense(30, activation='sigmoid', input_shape=(n_cols,)))\n","  model_2.add(Dense(25, activation='sigmoid'))\n","  model_2.add(Dense(20, activation='sigmoid'))\n","  model_2.add(Dense(15, activation='sigmoid'))\n","  model_2.add(Dense(10, activation='sigmoid'))\n","  model_2.add(Dense(1, activation = 'sigmoid'))\n","\n","  #compile model using mse as a measure of model performance\n","  model_2.compile(optimizer='adam', loss='mean_squared_error')\n","\n","\n","\n","  history = model_2.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stopping_monitor])\n","\n","\n","  # plt.plot(history.history['loss'])\n","  # plt.plot(history.history['val_loss'])\n","  # plt.title('model loss')\n","  # plt.ylabel('Loss')\n","  # plt.xlabel('Epoch')\n","  # plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n","  # plt.show()\n","\n","\n","  print('Validation Accuracy: ')\n","  # Predicting the Test set results\n","  y_pred = model_2.predict(x_val)\n","  y_pred = (y_pred > 0.5)\n","\n","\n","  print(classification_report(y_val, y_pred))\n","\n","  # Model Accuracy, how often is the classifier correct?\n","  print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))\n","\n","  # Creating the Confusion Matrix\n","  cm = confusion_matrix(y_val, y_pred)\n","  print(cm)\n","  print('Precision: %.4f' % precision_score(y_val, y_pred))\n","  print('Recall: %.4f' % recall_score(y_val, y_pred))\n","  print('F1 Score: %.4f' % f1_score(y_val, y_pred))\n","\n","  # save the model to disk\n","  filename = '/content/drive/MyDrive/Phishing/UNB/Binary/Models/URL/NN_2/model_'+str(n)+'.h5'\n","  pickle.dump(model_2, open(filename, 'wb'))\n","\n","  print('model ' + str(n) + ' saved')\n","\n","  return metrics.accuracy_score(y_val, y_pred)\n","\n"],"metadata":{"id":"L8ZhB8W9tVQS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","import tensorflow as tf\n","\n","optimizer1=tf.keras.optimizers.Adam(learning_rate=0.0005)\n","\n","\n","from keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve anymore\n","early_stopping_monitor = EarlyStopping(patience=10)\n","n_split = 10\n","acc = 0\n","n=0\n","kf = KFold(n_split, random_state=10, shuffle=True)\n","for train, val in kf.split(x_train, y_train):\n","  val_acc = model_a(x_train[train], x_train[val], y_train[train], y_train[val], optimizer1, n, early_stopping_monitor)\n","  n = n+1\n","  acc = acc + val_acc\n","\n","print(\"Average Validation Accuracy:\",acc/n_split)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osCV0Uo5wqac","executionInfo":{"status":"ok","timestamp":1656485721754,"user_tz":-330,"elapsed":256274,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"074989f6-495b-4d6e-b682-d556fcdbb98c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.1819 - val_loss: 0.1682\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1780 - val_loss: 0.1578\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1411 - val_loss: 0.1000\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0839 - val_loss: 0.0691\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0676 - val_loss: 0.0623\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0621 - val_loss: 0.0597\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0589\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0621\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0563 - val_loss: 0.0538\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0534 - val_loss: 0.0527\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0502\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0498\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0485\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0495 - val_loss: 0.0482\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0487 - val_loss: 0.0497\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.0479\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0474\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0478 - val_loss: 0.0473\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0473 - val_loss: 0.0481\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0471\n","Epoch 21/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0469 - val_loss: 0.0470\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0466 - val_loss: 0.0475\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0464 - val_loss: 0.0472\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.0460\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0460\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.0508\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0463 - val_loss: 0.0455\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0455 - val_loss: 0.0456\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0448 - val_loss: 0.0473\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0450 - val_loss: 0.0458\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0445 - val_loss: 0.0443\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.0477\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0440 - val_loss: 0.0454\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0437\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0469\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0497\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0438\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0432 - val_loss: 0.0444\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0425 - val_loss: 0.0459\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0440\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0442\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0456\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0426 - val_loss: 0.0441\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0437\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.95      0.97       283\n","           1       0.83      0.95      0.88        76\n","\n","    accuracy                           0.95       359\n","   macro avg       0.91      0.95      0.92       359\n","weighted avg       0.95      0.95      0.95       359\n","\n","Accuracy: 0.947075208913649\n","[[268  15]\n"," [  4  72]]\n","Precision: 0.8276\n","Recall: 0.9474\n","F1 Score: 0.8834\n","INFO:tensorflow:Assets written to: ram://76b7ed61-9653-46ed-b7e7-fa0926973427/assets\n","model 0 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.2086 - val_loss: 0.1884\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1798 - val_loss: 0.1864\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1761 - val_loss: 0.1792\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1578 - val_loss: 0.1427\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1103 - val_loss: 0.0927\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0726\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0662 - val_loss: 0.0686\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0613 - val_loss: 0.0658\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0660\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0564 - val_loss: 0.0652\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0554 - val_loss: 0.0650\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.0647\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0531 - val_loss: 0.0636\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0657\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0629\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0626\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0619\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0496 - val_loss: 0.0616\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0618\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.0617\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0483 - val_loss: 0.0603\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0477 - val_loss: 0.0602\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0472 - val_loss: 0.0596\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0465 - val_loss: 0.0596\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.0593\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0463 - val_loss: 0.0596\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0594\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.0598\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0455 - val_loss: 0.0597\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0452 - val_loss: 0.0604\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0569\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0427 - val_loss: 0.0551\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0535\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.0472\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0324 - val_loss: 0.0375\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0332\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0337\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0329\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0321\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0324\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0328\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0371\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0303\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0319\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0308\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0306\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0321\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0298\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0312\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0288\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0321\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0310\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0294\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0320\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0294\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0295\n","Epoch 57/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0309\n","Epoch 58/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0326\n","Epoch 59/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0289\n","Epoch 60/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0299\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.99      0.98       269\n","           1       0.96      0.91      0.94        90\n","\n","    accuracy                           0.97       359\n","   macro avg       0.97      0.95      0.96       359\n","weighted avg       0.97      0.97      0.97       359\n","\n","Accuracy: 0.9693593314763231\n","[[266   3]\n"," [  8  82]]\n","Precision: 0.9647\n","Recall: 0.9111\n","F1 Score: 0.9371\n","INFO:tensorflow:Assets written to: ram://b7a0bab7-3327-4c1e-b3aa-44ca5f9a9610/assets\n","model 1 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.2350 - val_loss: 0.1854\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1839 - val_loss: 0.1753\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1799 - val_loss: 0.1716\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1738 - val_loss: 0.1612\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1548 - val_loss: 0.1325\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1144 - val_loss: 0.0920\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0819 - val_loss: 0.0743\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0696 - val_loss: 0.0658\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0645 - val_loss: 0.0617\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0601 - val_loss: 0.0611\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0598\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0576\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0553 - val_loss: 0.0563\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0546 - val_loss: 0.0555\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0565\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0540\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0535\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0532\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0548\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0553\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0534\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0489 - val_loss: 0.0544\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0544\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0558\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0481 - val_loss: 0.0567\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0471 - val_loss: 0.0552\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0462 - val_loss: 0.0569\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0559\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.92      0.95       278\n","           1       0.78      0.96      0.86        81\n","\n","    accuracy                           0.93       359\n","   macro avg       0.88      0.94      0.91       359\n","weighted avg       0.94      0.93      0.93       359\n","\n","Accuracy: 0.9303621169916435\n","[[256  22]\n"," [  3  78]]\n","Precision: 0.7800\n","Recall: 0.9630\n","F1 Score: 0.8619\n","INFO:tensorflow:Assets written to: ram://87001837-86e3-479f-a2f0-9f9ab0b380a4/assets\n","model 2 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.2053 - val_loss: 0.1805\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1803 - val_loss: 0.1776\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1759 - val_loss: 0.1699\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1564 - val_loss: 0.1338\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1035 - val_loss: 0.0874\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0720 - val_loss: 0.0756\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0634 - val_loss: 0.0717\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0585 - val_loss: 0.0684\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0545 - val_loss: 0.0656\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0528 - val_loss: 0.0651\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.0637\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0633\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0626\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0483 - val_loss: 0.0620\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0472 - val_loss: 0.0619\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.0619\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0612\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0459 - val_loss: 0.0609\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.0623\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0447 - val_loss: 0.0610\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0612\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0606\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.0610\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0434 - val_loss: 0.0621\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0615\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0618\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0604\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0425 - val_loss: 0.0617\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0420 - val_loss: 0.0626\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0600\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0596\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0608\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0598\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0602\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0419 - val_loss: 0.0594\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0420 - val_loss: 0.0594\n","Epoch 37/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0415 - val_loss: 0.0612\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0596\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0411 - val_loss: 0.0585\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0587\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0412 - val_loss: 0.0587\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0589\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.0584\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0409 - val_loss: 0.0584\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0412 - val_loss: 0.0584\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0406 - val_loss: 0.0580\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0579\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0405 - val_loss: 0.0580\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0404 - val_loss: 0.0588\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0403 - val_loss: 0.0584\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0401 - val_loss: 0.0581\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0404 - val_loss: 0.0591\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0407 - val_loss: 0.0582\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0407 - val_loss: 0.0589\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0581\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0399 - val_loss: 0.0580\n","Epoch 57/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0396 - val_loss: 0.0582\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.93      0.96       275\n","           1       0.80      0.95      0.87        84\n","\n","    accuracy                           0.93       359\n","   macro avg       0.89      0.94      0.91       359\n","weighted avg       0.94      0.93      0.94       359\n","\n","Accuracy: 0.9331476323119777\n","[[255  20]\n"," [  4  80]]\n","Precision: 0.8000\n","Recall: 0.9524\n","F1 Score: 0.8696\n","INFO:tensorflow:Assets written to: ram://dc379586-ee59-4a6b-b13f-74d350556cae/assets\n","model 3 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.1793 - val_loss: 0.1917\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1759 - val_loss: 0.1806\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1426 - val_loss: 0.1185\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0904 - val_loss: 0.0778\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.0655\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0623 - val_loss: 0.0597\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0582\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0557 - val_loss: 0.0553\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0537 - val_loss: 0.0536\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0553\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0509 - val_loss: 0.0505\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0505 - val_loss: 0.0492\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0494 - val_loss: 0.0468\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0478\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0490 - val_loss: 0.0473\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0437\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0482 - val_loss: 0.0448\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0477 - val_loss: 0.0441\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0473 - val_loss: 0.0437\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0466 - val_loss: 0.0439\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0467 - val_loss: 0.0433\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0462 - val_loss: 0.0447\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0467\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.0438\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0452 - val_loss: 0.0405\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0469\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.0436\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0451 - val_loss: 0.0542\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0451 - val_loss: 0.0469\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0445 - val_loss: 0.0407\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0445 - val_loss: 0.0402\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0495\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0414\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0451\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0463\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0436\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0426\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0433\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0432 - val_loss: 0.0453\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0442\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0397\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0432\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0437\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0424\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0416\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0389\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0448\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0421\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0425 - val_loss: 0.0400\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0407\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0472\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0409\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0411 - val_loss: 0.0407\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0410\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.0424\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.0405\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.97      0.97       266\n","           1       0.91      0.91      0.91        93\n","\n","    accuracy                           0.96       359\n","   macro avg       0.94      0.94      0.94       359\n","weighted avg       0.96      0.96      0.96       359\n","\n","Accuracy: 0.9554317548746518\n","[[258   8]\n"," [  8  85]]\n","Precision: 0.9140\n","Recall: 0.9140\n","F1 Score: 0.9140\n","INFO:tensorflow:Assets written to: ram://86117600-3bff-46d2-98bc-5b3bee0671b2/assets\n","model 4 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.1837 - val_loss: 0.1663\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1797 - val_loss: 0.1597\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1501 - val_loss: 0.1101\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0875 - val_loss: 0.0780\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0666 - val_loss: 0.0689\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0678\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0642\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0552 - val_loss: 0.0610\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0536 - val_loss: 0.0624\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0583\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0566\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0509 - val_loss: 0.0558\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0550\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0494 - val_loss: 0.0525\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0481 - val_loss: 0.0531\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0478 - val_loss: 0.0532\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0533\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0517\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0469 - val_loss: 0.0507\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0464 - val_loss: 0.0508\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.0509\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0463 - val_loss: 0.0493\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0455 - val_loss: 0.0506\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0455 - val_loss: 0.0491\n","Epoch 25/100\n","101/101 [==============================] - 1s 7ms/step - loss: 0.0453 - val_loss: 0.0490\n","Epoch 26/100\n","101/101 [==============================] - 0s 5ms/step - loss: 0.0452 - val_loss: 0.0482\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.0468\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0450 - val_loss: 0.0470\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0494\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.0492\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0492\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.0479\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0484\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0466\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0464\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0481\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0432 - val_loss: 0.0458\n","Epoch 38/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0428 - val_loss: 0.0478\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.0478\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0461\n","Epoch 41/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0427 - val_loss: 0.0479\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0456\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0425 - val_loss: 0.0471\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0480\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0461\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0465\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0492\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0422 - val_loss: 0.0455\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.0471\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0422 - val_loss: 0.0461\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0447\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.0471\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.0448\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0460\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0455\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0419 - val_loss: 0.0452\n","Epoch 57/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0459\n","Epoch 58/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0483\n","Epoch 59/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0463\n","Epoch 60/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0419 - val_loss: 0.0467\n","Epoch 61/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0458\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.95      0.97       284\n","           1       0.83      0.96      0.89        75\n","\n","    accuracy                           0.95       359\n","   macro avg       0.91      0.95      0.93       359\n","weighted avg       0.96      0.95      0.95       359\n","\n","Accuracy: 0.9498607242339833\n","[[269  15]\n"," [  3  72]]\n","Precision: 0.8276\n","Recall: 0.9600\n","F1 Score: 0.8889\n","INFO:tensorflow:Assets written to: ram://25a209de-e27d-4abf-9675-443693bc7d5b/assets\n","model 5 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.1844 - val_loss: 0.1847\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1782 - val_loss: 0.1796\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1598 - val_loss: 0.1316\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0997 - val_loss: 0.0750\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0720 - val_loss: 0.0628\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.0592\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0632 - val_loss: 0.0582\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0617 - val_loss: 0.0566\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0609 - val_loss: 0.0565\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0554\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0554\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0552\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0530\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0573 - val_loss: 0.0523\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0495\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0560 - val_loss: 0.0490\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0463\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0542 - val_loss: 0.0454\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0533 - val_loss: 0.0433\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0419\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0415\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0438\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0514 - val_loss: 0.0410\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0393\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0385\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0410\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0381\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0408\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0386\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0490 - val_loss: 0.0376\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0368\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0372\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0481 - val_loss: 0.0363\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0404\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0477 - val_loss: 0.0351\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0356\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0455 - val_loss: 0.0362\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0464 - val_loss: 0.0352\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0352\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0365\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0356\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0451 - val_loss: 0.0361\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0450 - val_loss: 0.0360\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0349\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0450 - val_loss: 0.0346\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0445 - val_loss: 0.0339\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0349\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0354\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0343\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.0338\n","Epoch 51/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.0336\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0342\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0330\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0337\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0326\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0426 - val_loss: 0.0324\n","Epoch 57/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0324\n","Epoch 58/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0328\n","Epoch 59/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0419 - val_loss: 0.0314\n","Epoch 60/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0414 - val_loss: 0.0313\n","Epoch 61/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0319\n","Epoch 62/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0312\n","Epoch 63/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.0308\n","Epoch 64/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0305\n","Epoch 65/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0406 - val_loss: 0.0303\n","Epoch 66/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0414 - val_loss: 0.0307\n","Epoch 67/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0405 - val_loss: 0.0295\n","Epoch 68/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0404 - val_loss: 0.0290\n","Epoch 69/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0401 - val_loss: 0.0286\n","Epoch 70/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0401 - val_loss: 0.0290\n","Epoch 71/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0403 - val_loss: 0.0292\n","Epoch 72/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0396 - val_loss: 0.0286\n","Epoch 73/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.0285\n","Epoch 74/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0393 - val_loss: 0.0277\n","Epoch 75/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0392 - val_loss: 0.0275\n","Epoch 76/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0395 - val_loss: 0.0282\n","Epoch 77/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0391 - val_loss: 0.0271\n","Epoch 78/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.0274\n","Epoch 79/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0394 - val_loss: 0.0273\n","Epoch 80/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0403 - val_loss: 0.0279\n","Epoch 81/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.0271\n","Epoch 82/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0391 - val_loss: 0.0268\n","Epoch 83/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.0267\n","Epoch 84/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.0270\n","Epoch 85/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.0261\n","Epoch 86/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.0263\n","Epoch 87/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.0269\n","Epoch 88/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0379 - val_loss: 0.0260\n","Epoch 89/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0380 - val_loss: 0.0259\n","Epoch 90/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.0255\n","Epoch 91/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0257\n","Epoch 92/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.0259\n","Epoch 93/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0283\n","Epoch 94/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0391 - val_loss: 0.0273\n","Epoch 95/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.0260\n","Epoch 96/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0272\n","Epoch 97/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.0265\n","Epoch 98/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0380 - val_loss: 0.0264\n","Epoch 99/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0379 - val_loss: 0.0260\n","Epoch 100/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.0257\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.96      0.98       271\n","           1       0.90      1.00      0.95        88\n","\n","    accuracy                           0.97       359\n","   macro avg       0.95      0.98      0.96       359\n","weighted avg       0.97      0.97      0.97       359\n","\n","Accuracy: 0.9721448467966574\n","[[261  10]\n"," [  0  88]]\n","Precision: 0.8980\n","Recall: 1.0000\n","F1 Score: 0.9462\n","INFO:tensorflow:Assets written to: ram://66b43722-5d59-4e4f-a155-857fa5c1c703/assets\n","model 6 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.1857 - val_loss: 0.1886\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1779 - val_loss: 0.1844\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1629 - val_loss: 0.1456\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1095 - val_loss: 0.0861\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0753 - val_loss: 0.0683\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.0602\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0627 - val_loss: 0.0577\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0600 - val_loss: 0.0550\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0538\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0533\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.0512\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0532 - val_loss: 0.0501\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0513\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0505 - val_loss: 0.0498\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0498\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0492 - val_loss: 0.0517\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0477\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0480 - val_loss: 0.0479\n","Epoch 19/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0477 - val_loss: 0.0469\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0466\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0469 - val_loss: 0.0475\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0466 - val_loss: 0.0453\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0466 - val_loss: 0.0467\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0461\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0459 - val_loss: 0.0443\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0439\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.0447\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.0465\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0448 - val_loss: 0.0439\n","Epoch 30/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0456 - val_loss: 0.0438\n","Epoch 31/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0445 - val_loss: 0.0429\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0432\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.0423\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0426\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0419\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0432 - val_loss: 0.0416\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0416\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0417\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0427 - val_loss: 0.0418\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0425 - val_loss: 0.0415\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.0429\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0419 - val_loss: 0.0411\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0404\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0421\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0414 - val_loss: 0.0396\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0409 - val_loss: 0.0397\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0400\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.0394\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0404 - val_loss: 0.0391\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0400 - val_loss: 0.0405\n","Epoch 51/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0403 - val_loss: 0.0384\n","Epoch 52/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0399 - val_loss: 0.0418\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0406 - val_loss: 0.0386\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0399 - val_loss: 0.0386\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0399 - val_loss: 0.0382\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0396 - val_loss: 0.0375\n","Epoch 57/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0395 - val_loss: 0.0385\n","Epoch 58/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0392 - val_loss: 0.0394\n","Epoch 59/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0390 - val_loss: 0.0394\n","Epoch 60/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.0396\n","Epoch 61/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0390 - val_loss: 0.0387\n","Epoch 62/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0390 - val_loss: 0.0371\n","Epoch 63/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0386 - val_loss: 0.0382\n","Epoch 64/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.0413\n","Epoch 65/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0395\n","Epoch 66/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.0389\n","Epoch 67/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0376 - val_loss: 0.0369\n","Epoch 68/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.0416\n","Epoch 69/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0380 - val_loss: 0.0374\n","Epoch 70/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0370 - val_loss: 0.0372\n","Epoch 71/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0371 - val_loss: 0.0390\n","Epoch 72/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.0370\n","Epoch 73/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.0396\n","Epoch 74/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.0353\n","Epoch 75/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0361 - val_loss: 0.0383\n","Epoch 76/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0357 - val_loss: 0.0354\n","Epoch 77/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0353 - val_loss: 0.0351\n","Epoch 78/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0179\n","Epoch 79/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0148\n","Epoch 80/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0148\n","Epoch 81/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0150\n","Epoch 82/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0147\n","Epoch 83/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0153\n","Epoch 84/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0143\n","Epoch 85/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0134\n","Epoch 86/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0135\n","Epoch 87/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0135\n","Epoch 88/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0137\n","Epoch 89/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0137\n","Epoch 90/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0111\n","Epoch 91/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0129\n","Epoch 92/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0142\n","Epoch 93/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0135\n","Epoch 94/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0132\n","Epoch 95/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0132\n","Epoch 96/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0111\n","Epoch 97/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0108\n","Epoch 98/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0121\n","Epoch 99/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.0111\n","Epoch 100/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0113\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.99      0.99       268\n","           1       0.96      0.98      0.97        91\n","\n","    accuracy                           0.98       359\n","   macro avg       0.97      0.98      0.98       359\n","weighted avg       0.98      0.98      0.98       359\n","\n","Accuracy: 0.9832869080779945\n","[[264   4]\n"," [  2  89]]\n","Precision: 0.9570\n","Recall: 0.9780\n","F1 Score: 0.9674\n","INFO:tensorflow:Assets written to: ram://fb76b197-91fa-4477-a579-470ea95b0584/assets\n","model 7 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 5ms/step - loss: 0.2038 - val_loss: 0.1775\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1805 - val_loss: 0.1748\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1749 - val_loss: 0.1625\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1443 - val_loss: 0.1141\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0928 - val_loss: 0.0747\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.0637\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0626 - val_loss: 0.0583\n","Epoch 8/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0589 - val_loss: 0.0541\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0512\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0553 - val_loss: 0.0498\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0546 - val_loss: 0.0482\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0451\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0437\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0508 - val_loss: 0.0436\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0470\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0494 - val_loss: 0.0416\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0414\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0480 - val_loss: 0.0427\n","Epoch 19/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0479 - val_loss: 0.0418\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0483 - val_loss: 0.0411\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0471 - val_loss: 0.0416\n","Epoch 22/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0466 - val_loss: 0.0415\n","Epoch 23/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0463 - val_loss: 0.0419\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0469 - val_loss: 0.0404\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0416\n","Epoch 26/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0391\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0408\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0455\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0395\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0451 - val_loss: 0.0390\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0450 - val_loss: 0.0385\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0389\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0447 - val_loss: 0.0372\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0400\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0376\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0390\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0440 - val_loss: 0.0374\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0384\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0375\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0383\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0383\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0381\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0383\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.95      0.97       277\n","           1       0.86      0.94      0.90        82\n","\n","    accuracy                           0.95       359\n","   macro avg       0.92      0.95      0.93       359\n","weighted avg       0.95      0.95      0.95       359\n","\n","Accuracy: 0.9498607242339833\n","[[264  13]\n"," [  5  77]]\n","Precision: 0.8556\n","Recall: 0.9390\n","F1 Score: 0.8953\n","INFO:tensorflow:Assets written to: ram://3d0c7b9f-639f-40ec-9364-16474abdd369/assets\n","model 8 saved\n","Epoch 1/100\n","101/101 [==============================] - 1s 4ms/step - loss: 0.1816 - val_loss: 0.1856\n","Epoch 2/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1737 - val_loss: 0.1676\n","Epoch 3/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.1306 - val_loss: 0.0989\n","Epoch 4/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0818 - val_loss: 0.0705\n","Epoch 5/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0671 - val_loss: 0.0621\n","Epoch 6/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0627 - val_loss: 0.0606\n","Epoch 7/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0608 - val_loss: 0.0584\n","Epoch 8/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0576\n","Epoch 9/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0566 - val_loss: 0.0571\n","Epoch 10/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0562\n","Epoch 11/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0555\n","Epoch 12/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0494 - val_loss: 0.0540\n","Epoch 13/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0529\n","Epoch 14/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0476 - val_loss: 0.0529\n","Epoch 15/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.0539\n","Epoch 16/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0464 - val_loss: 0.0519\n","Epoch 17/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0459 - val_loss: 0.0524\n","Epoch 18/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0464 - val_loss: 0.0516\n","Epoch 19/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0460 - val_loss: 0.0511\n","Epoch 20/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0447 - val_loss: 0.0510\n","Epoch 21/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0447 - val_loss: 0.0501\n","Epoch 22/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0448 - val_loss: 0.0498\n","Epoch 23/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0437 - val_loss: 0.0508\n","Epoch 24/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0501\n","Epoch 25/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0497\n","Epoch 26/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0436 - val_loss: 0.0513\n","Epoch 27/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0432 - val_loss: 0.0550\n","Epoch 28/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0495\n","Epoch 29/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.0542\n","Epoch 30/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0432 - val_loss: 0.0498\n","Epoch 31/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0555\n","Epoch 32/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.0497\n","Epoch 33/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0419 - val_loss: 0.0500\n","Epoch 34/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0420 - val_loss: 0.0515\n","Epoch 35/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0533\n","Epoch 36/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.0493\n","Epoch 37/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0503\n","Epoch 38/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0497\n","Epoch 39/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0409 - val_loss: 0.0490\n","Epoch 40/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.0487\n","Epoch 41/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0497\n","Epoch 42/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0403 - val_loss: 0.0494\n","Epoch 43/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0403 - val_loss: 0.0502\n","Epoch 44/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.0490\n","Epoch 45/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0411 - val_loss: 0.0502\n","Epoch 46/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0403 - val_loss: 0.0488\n","Epoch 47/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0484\n","Epoch 48/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0406 - val_loss: 0.0489\n","Epoch 49/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0396 - val_loss: 0.0485\n","Epoch 50/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0488\n","Epoch 51/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0401 - val_loss: 0.0488\n","Epoch 52/100\n","101/101 [==============================] - 0s 4ms/step - loss: 0.0396 - val_loss: 0.0497\n","Epoch 53/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0390 - val_loss: 0.0499\n","Epoch 54/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.0483\n","Epoch 55/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.0492\n","Epoch 56/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0393 - val_loss: 0.0481\n","Epoch 57/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0391 - val_loss: 0.0505\n","Epoch 58/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0494\n","Epoch 59/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.0482\n","Epoch 60/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.0482\n","Epoch 61/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0380 - val_loss: 0.0499\n","Epoch 62/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0481\n","Epoch 63/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.0478\n","Epoch 64/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0487\n","Epoch 65/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0491\n","Epoch 66/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0490\n","Epoch 67/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0374 - val_loss: 0.0482\n","Epoch 68/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0372 - val_loss: 0.0481\n","Epoch 69/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0371 - val_loss: 0.0482\n","Epoch 70/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.0486\n","Epoch 71/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0369 - val_loss: 0.0487\n","Epoch 72/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0374 - val_loss: 0.0480\n","Epoch 73/100\n","101/101 [==============================] - 0s 3ms/step - loss: 0.0370 - val_loss: 0.0484\n","Validation Accuracy: \n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.96      0.96       269\n","           1       0.87      0.91      0.89        89\n","\n","    accuracy                           0.94       358\n","   macro avg       0.92      0.93      0.93       358\n","weighted avg       0.95      0.94      0.94       358\n","\n","Accuracy: 0.9441340782122905\n","[[257  12]\n"," [  8  81]]\n","Precision: 0.8710\n","Recall: 0.9101\n","F1 Score: 0.8901\n","INFO:tensorflow:Assets written to: ram://d8c70289-dbb8-4461-b892-e3be12f2f863/assets\n","model 9 saved\n","Average Validation Accuracy: 0.9534663326123155\n"]}]},{"cell_type":"code","source":["# load the model from disk\n","filename = '/content/drive/MyDrive/Phishing/UNB/Binary/Models/URL/NN_2/model_7.h5'\n","\n","loaded_model = pickle.load(open(filename, 'rb'))\n","\n","def predict_prob(number):\n","  return [number[0],1-number[0]]\n","\n","y_prob = np.array(list(map(predict_prob, loaded_model.predict(x_test))))\n","y_prob \n","\n","# y_pred_prob = loaded_model.predict_proba(x_test)\n","\n","print(y_pred_prob)\n","\n","output['nn2_prediction_non'] = [i[0] for i in y_pred_prob];\n","output['nn2_prediction_phish'] = [i[1] for i in y_pred_prob];\n","output = pd.DataFrame.from_dict(output)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":609},"id":"JPT9oIQ0wuZf","executionInfo":{"status":"ok","timestamp":1656486017841,"user_tz":-330,"elapsed":2772,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"a7d0034c-4415-4187-844d-63d696dd6238"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[4.11735529e-05 9.99958826e-01]\n"," [4.55413485e-12 1.00000000e+00]\n"," [9.99995064e-01 4.93597482e-06]\n"," ...\n"," [9.99999997e-01 2.56480135e-09]\n"," [9.99998836e-01 1.16405465e-06]\n"," [9.99994216e-01 5.78401868e-06]]\n"]},{"output_type":"execute_result","data":{"text/plain":["      labels  mlp_prediction_non  mlp_prediction_phish  nn_prediction_non  \\\n","0          1        4.117355e-05          9.999588e-01       4.117355e-05   \n","1          1        4.554135e-12          1.000000e+00       4.554135e-12   \n","2          0        9.999951e-01          4.935975e-06       9.999951e-01   \n","3          0        1.000000e+00          2.150433e-19       1.000000e+00   \n","4          1        1.044356e-01          8.955644e-01       1.044356e-01   \n","...      ...                 ...                   ...                ...   \n","2933       1        3.264056e-14          1.000000e+00       3.264056e-14   \n","2934       0        9.980053e-01          1.994709e-03       9.980053e-01   \n","2935       0        1.000000e+00          2.564801e-09       1.000000e+00   \n","2936       0        9.999988e-01          1.164055e-06       9.999988e-01   \n","2937       0        9.999942e-01          5.784019e-06       9.999942e-01   \n","\n","      nn_prediction_phish  nn2_prediction_non  nn2_prediction_phish  \n","0            9.999588e-01        4.117355e-05          9.999588e-01  \n","1            1.000000e+00        4.554135e-12          1.000000e+00  \n","2            4.935975e-06        9.999951e-01          4.935975e-06  \n","3            2.150433e-19        1.000000e+00          2.150433e-19  \n","4            8.955644e-01        1.044356e-01          8.955644e-01  \n","...                   ...                 ...                   ...  \n","2933         1.000000e+00        3.264056e-14          1.000000e+00  \n","2934         1.994709e-03        9.980053e-01          1.994709e-03  \n","2935         2.564801e-09        1.000000e+00          2.564801e-09  \n","2936         1.164055e-06        9.999988e-01          1.164055e-06  \n","2937         5.784019e-06        9.999942e-01          5.784019e-06  \n","\n","[2938 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-ce5aee15-124f-43b3-99e3-3d6eec72f575\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>mlp_prediction_non</th>\n","      <th>mlp_prediction_phish</th>\n","      <th>nn_prediction_non</th>\n","      <th>nn_prediction_phish</th>\n","      <th>nn2_prediction_non</th>\n","      <th>nn2_prediction_phish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>4.117355e-05</td>\n","      <td>9.999588e-01</td>\n","      <td>4.117355e-05</td>\n","      <td>9.999588e-01</td>\n","      <td>4.117355e-05</td>\n","      <td>9.999588e-01</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>4.554135e-12</td>\n","      <td>1.000000e+00</td>\n","      <td>4.554135e-12</td>\n","      <td>1.000000e+00</td>\n","      <td>4.554135e-12</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>9.999951e-01</td>\n","      <td>4.935975e-06</td>\n","      <td>9.999951e-01</td>\n","      <td>4.935975e-06</td>\n","      <td>9.999951e-01</td>\n","      <td>4.935975e-06</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>2.150433e-19</td>\n","      <td>1.000000e+00</td>\n","      <td>2.150433e-19</td>\n","      <td>1.000000e+00</td>\n","      <td>2.150433e-19</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1.044356e-01</td>\n","      <td>8.955644e-01</td>\n","      <td>1.044356e-01</td>\n","      <td>8.955644e-01</td>\n","      <td>1.044356e-01</td>\n","      <td>8.955644e-01</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2933</th>\n","      <td>1</td>\n","      <td>3.264056e-14</td>\n","      <td>1.000000e+00</td>\n","      <td>3.264056e-14</td>\n","      <td>1.000000e+00</td>\n","      <td>3.264056e-14</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>2934</th>\n","      <td>0</td>\n","      <td>9.980053e-01</td>\n","      <td>1.994709e-03</td>\n","      <td>9.980053e-01</td>\n","      <td>1.994709e-03</td>\n","      <td>9.980053e-01</td>\n","      <td>1.994709e-03</td>\n","    </tr>\n","    <tr>\n","      <th>2935</th>\n","      <td>0</td>\n","      <td>1.000000e+00</td>\n","      <td>2.564801e-09</td>\n","      <td>1.000000e+00</td>\n","      <td>2.564801e-09</td>\n","      <td>1.000000e+00</td>\n","      <td>2.564801e-09</td>\n","    </tr>\n","    <tr>\n","      <th>2936</th>\n","      <td>0</td>\n","      <td>9.999988e-01</td>\n","      <td>1.164055e-06</td>\n","      <td>9.999988e-01</td>\n","      <td>1.164055e-06</td>\n","      <td>9.999988e-01</td>\n","      <td>1.164055e-06</td>\n","    </tr>\n","    <tr>\n","      <th>2937</th>\n","      <td>0</td>\n","      <td>9.999942e-01</td>\n","      <td>5.784019e-06</td>\n","      <td>9.999942e-01</td>\n","      <td>5.784019e-06</td>\n","      <td>9.999942e-01</td>\n","      <td>5.784019e-06</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2938 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce5aee15-124f-43b3-99e3-3d6eec72f575')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ce5aee15-124f-43b3-99e3-3d6eec72f575 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ce5aee15-124f-43b3-99e3-3d6eec72f575');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["output.shape\n"],"metadata":{"id":"0lDqtfllUmwv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656486021364,"user_tz":-330,"elapsed":8,"user":{"displayName":"Akash Verma","userId":"01177376164851035372"}},"outputId":"5668f89c-6269-4536-bf14-66ae89dc9b71"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2938, 7)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["# Storing the data in CSV file\n","output.to_csv('/content/drive/MyDrive/Phishing/UNB/Binary/Base_classifier_result(URL cross)(3).csv', index=False)"],"metadata":{"id":"ZsQkUbz6AiTx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"RN_-swX0JdhP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"W9DI0WYaJde9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"49lwyWNz0mSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"_9Vdw_Wx2NEo"},"execution_count":null,"outputs":[]}]}